[
  {
    "function_name": "permission_fault",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.h",
    "lines": "152-200",
    "snippet": "static inline u8 permission_fault(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n\t\t\t\t  unsigned pte_access, unsigned pte_pkey,\n\t\t\t\t  unsigned pfec)\n{\n\tint cpl = kvm_x86_ops->get_cpl(vcpu);\n\tunsigned long rflags = kvm_x86_ops->get_rflags(vcpu);\n\n\t/*\n\t * If CPL < 3, SMAP prevention are disabled if EFLAGS.AC = 1.\n\t *\n\t * If CPL = 3, SMAP applies to all supervisor-mode data accesses\n\t * (these are implicit supervisor accesses) regardless of the value\n\t * of EFLAGS.AC.\n\t *\n\t * This computes (cpl < 3) && (rflags & X86_EFLAGS_AC), leaving\n\t * the result in X86_EFLAGS_AC. We then insert it in place of\n\t * the PFERR_RSVD_MASK bit; this bit will always be zero in pfec,\n\t * but it will be one in index if SMAP checks are being overridden.\n\t * It is important to keep this branchless.\n\t */\n\tunsigned long smap = (cpl - 3) & (rflags & X86_EFLAGS_AC);\n\tint index = (pfec >> 1) +\n\t\t    (smap >> (X86_EFLAGS_AC_BIT - PFERR_RSVD_BIT + 1));\n\tbool fault = (mmu->permissions[index] >> pte_access) & 1;\n\tu32 errcode = PFERR_PRESENT_MASK;\n\n\tWARN_ON(pfec & (PFERR_PK_MASK | PFERR_RSVD_MASK));\n\tif (unlikely(mmu->pkru_mask)) {\n\t\tu32 pkru_bits, offset;\n\n\t\t/*\n\t\t* PKRU defines 32 bits, there are 16 domains and 2\n\t\t* attribute bits per domain in pkru.  pte_pkey is the\n\t\t* index of the protection domain, so pte_pkey * 2 is\n\t\t* is the index of the first bit for the domain.\n\t\t*/\n\t\tpkru_bits = (kvm_read_pkru(vcpu) >> (pte_pkey * 2)) & 3;\n\n\t\t/* clear present bit, replace PFEC.RSVD with ACC_USER_MASK. */\n\t\toffset = (pfec & ~1) +\n\t\t\t((pte_access & PT_USER_MASK) << (PFERR_RSVD_BIT - PT_USER_SHIFT));\n\n\t\tpkru_bits &= mmu->pkru_mask >> offset;\n\t\terrcode |= -pkru_bits & PFERR_PK_MASK;\n\t\tfault |= (pkru_bits != 0);\n\t}\n\n\treturn -(u32)fault & errcode;\n}",
    "includes": [
      "#include \"kvm_cache_regs.h\"",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [
      "#define PT_USER_MASK (1ULL << PT_USER_SHIFT)",
      "#define PT_USER_SHIFT 2"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_read_pkru",
          "args": [
            "vcpu"
          ],
          "line": 188
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_read_pkru",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/kvm_cache_regs.h",
          "lines": "87-90",
          "snippet": "static inline u32 kvm_read_pkru(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_x86_ops->get_pkru(vcpu);\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static inline u32 kvm_read_pkru(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_x86_ops->get_pkru(vcpu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "mmu->pkru_mask"
          ],
          "line": 179
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "pfec & (PFERR_PK_MASK | PFERR_RSVD_MASK)"
          ],
          "line": 178
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_x86_ops->get_rflags",
          "args": [
            "vcpu"
          ],
          "line": 157
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_x86_ops->get_cpl",
          "args": [
            "vcpu"
          ],
          "line": 156
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\n#define PT_USER_MASK (1ULL << PT_USER_SHIFT)\n#define PT_USER_SHIFT 2\n\nstatic inline u8 permission_fault(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n\t\t\t\t  unsigned pte_access, unsigned pte_pkey,\n\t\t\t\t  unsigned pfec)\n{\n\tint cpl = kvm_x86_ops->get_cpl(vcpu);\n\tunsigned long rflags = kvm_x86_ops->get_rflags(vcpu);\n\n\t/*\n\t * If CPL < 3, SMAP prevention are disabled if EFLAGS.AC = 1.\n\t *\n\t * If CPL = 3, SMAP applies to all supervisor-mode data accesses\n\t * (these are implicit supervisor accesses) regardless of the value\n\t * of EFLAGS.AC.\n\t *\n\t * This computes (cpl < 3) && (rflags & X86_EFLAGS_AC), leaving\n\t * the result in X86_EFLAGS_AC. We then insert it in place of\n\t * the PFERR_RSVD_MASK bit; this bit will always be zero in pfec,\n\t * but it will be one in index if SMAP checks are being overridden.\n\t * It is important to keep this branchless.\n\t */\n\tunsigned long smap = (cpl - 3) & (rflags & X86_EFLAGS_AC);\n\tint index = (pfec >> 1) +\n\t\t    (smap >> (X86_EFLAGS_AC_BIT - PFERR_RSVD_BIT + 1));\n\tbool fault = (mmu->permissions[index] >> pte_access) & 1;\n\tu32 errcode = PFERR_PRESENT_MASK;\n\n\tWARN_ON(pfec & (PFERR_PK_MASK | PFERR_RSVD_MASK));\n\tif (unlikely(mmu->pkru_mask)) {\n\t\tu32 pkru_bits, offset;\n\n\t\t/*\n\t\t* PKRU defines 32 bits, there are 16 domains and 2\n\t\t* attribute bits per domain in pkru.  pte_pkey is the\n\t\t* index of the protection domain, so pte_pkey * 2 is\n\t\t* is the index of the first bit for the domain.\n\t\t*/\n\t\tpkru_bits = (kvm_read_pkru(vcpu) >> (pte_pkey * 2)) & 3;\n\n\t\t/* clear present bit, replace PFEC.RSVD with ACC_USER_MASK. */\n\t\toffset = (pfec & ~1) +\n\t\t\t((pte_access & PT_USER_MASK) << (PFERR_RSVD_BIT - PT_USER_SHIFT));\n\n\t\tpkru_bits &= mmu->pkru_mask >> offset;\n\t\terrcode |= -pkru_bits & PFERR_PK_MASK;\n\t\tfault |= (pkru_bits != 0);\n\t}\n\n\treturn -(u32)fault & errcode;\n}"
  },
  {
    "function_name": "is_write_protection",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.h",
    "lines": "139-142",
    "snippet": "static inline bool is_write_protection(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_read_cr0_bits(vcpu, X86_CR0_WP);\n}",
    "includes": [
      "#include \"kvm_cache_regs.h\"",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_read_cr0_bits",
          "args": [
            "vcpu",
            "X86_CR0_WP"
          ],
          "line": 141
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_read_cr0_bits",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/kvm_cache_regs.h",
          "lines": "48-54",
          "snippet": "static inline ulong kvm_read_cr0_bits(struct kvm_vcpu *vcpu, ulong mask)\n{\n\tulong tmask = mask & KVM_POSSIBLE_CR0_GUEST_BITS;\n\tif (tmask & vcpu->arch.cr0_guest_owned_bits)\n\t\tkvm_x86_ops->decache_cr0_guest_bits(vcpu);\n\treturn vcpu->arch.cr0 & mask;\n}",
          "includes": [],
          "macros_used": [
            "#define KVM_POSSIBLE_CR0_GUEST_BITS X86_CR0_TS"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#define KVM_POSSIBLE_CR0_GUEST_BITS X86_CR0_TS\n\nstatic inline ulong kvm_read_cr0_bits(struct kvm_vcpu *vcpu, ulong mask)\n{\n\tulong tmask = mask & KVM_POSSIBLE_CR0_GUEST_BITS;\n\tif (tmask & vcpu->arch.cr0_guest_owned_bits)\n\t\tkvm_x86_ops->decache_cr0_guest_bits(vcpu);\n\treturn vcpu->arch.cr0 & mask;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\nstatic inline bool is_write_protection(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_read_cr0_bits(vcpu, X86_CR0_WP);\n}"
  },
  {
    "function_name": "is_writable_pte",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.h",
    "lines": "134-137",
    "snippet": "static inline int is_writable_pte(unsigned long pte)\n{\n\treturn pte & PT_WRITABLE_MASK;\n}",
    "includes": [
      "#include \"kvm_cache_regs.h\"",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [
      "#define PT_WRITABLE_MASK (1ULL << PT_WRITABLE_SHIFT)"
    ],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\n#define PT_WRITABLE_MASK (1ULL << PT_WRITABLE_SHIFT)\n\nstatic inline int is_writable_pte(unsigned long pte)\n{\n\treturn pte & PT_WRITABLE_MASK;\n}"
  },
  {
    "function_name": "is_present_gpte",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.h",
    "lines": "96-99",
    "snippet": "static inline int is_present_gpte(unsigned long pte)\n{\n\treturn pte & PT_PRESENT_MASK;\n}",
    "includes": [
      "#include \"kvm_cache_regs.h\"",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [
      "#define PT_PRESENT_MASK (1ULL << 0)"
    ],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\n#define PT_PRESENT_MASK (1ULL << 0)\n\nstatic inline int is_present_gpte(unsigned long pte)\n{\n\treturn pte & PT_PRESENT_MASK;\n}"
  },
  {
    "function_name": "kvm_mmu_reload",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.h",
    "lines": "88-94",
    "snippet": "static inline int kvm_mmu_reload(struct kvm_vcpu *vcpu)\n{\n\tif (likely(vcpu->arch.mmu.root_hpa != INVALID_PAGE))\n\t\treturn 0;\n\n\treturn kvm_mmu_load(vcpu);\n}",
    "includes": [
      "#include \"kvm_cache_regs.h\"",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_mmu_load",
          "args": [
            "vcpu"
          ],
          "line": 93
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_mmu_load",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "4237-4252",
          "snippet": "int kvm_mmu_load(struct kvm_vcpu *vcpu)\n{\n\tint r;\n\n\tr = mmu_topup_memory_caches(vcpu);\n\tif (r)\n\t\tgoto out;\n\tr = mmu_alloc_roots(vcpu);\n\tkvm_mmu_sync_roots(vcpu);\n\tif (r)\n\t\tgoto out;\n\t/* set_cr3() should ensure TLB has been flushed */\n\tvcpu->arch.mmu.set_cr3(vcpu, vcpu->arch.mmu.root_hpa);\nout:\n\treturn r;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void mmu_free_roots(struct kvm_vcpu *vcpu);",
            "static void make_mmu_pages_available(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void mmu_free_roots(struct kvm_vcpu *vcpu);\nstatic void make_mmu_pages_available(struct kvm_vcpu *vcpu);\n\nint kvm_mmu_load(struct kvm_vcpu *vcpu)\n{\n\tint r;\n\n\tr = mmu_topup_memory_caches(vcpu);\n\tif (r)\n\t\tgoto out;\n\tr = mmu_alloc_roots(vcpu);\n\tkvm_mmu_sync_roots(vcpu);\n\tif (r)\n\t\tgoto out;\n\t/* set_cr3() should ensure TLB has been flushed */\n\tvcpu->arch.mmu.set_cr3(vcpu, vcpu->arch.mmu.root_hpa);\nout:\n\treturn r;\n}"
        }
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "vcpu->arch.mmu.root_hpa != INVALID_PAGE"
          ],
          "line": 90
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\nstatic inline int kvm_mmu_reload(struct kvm_vcpu *vcpu)\n{\n\tif (likely(vcpu->arch.mmu.root_hpa != INVALID_PAGE))\n\t\treturn 0;\n\n\treturn kvm_mmu_load(vcpu);\n}"
  },
  {
    "function_name": "kvm_mmu_available_pages",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.h",
    "lines": "79-86",
    "snippet": "static inline unsigned int kvm_mmu_available_pages(struct kvm *kvm)\n{\n\tif (kvm->arch.n_max_mmu_pages > kvm->arch.n_used_mmu_pages)\n\t\treturn kvm->arch.n_max_mmu_pages -\n\t\t\tkvm->arch.n_used_mmu_pages;\n\n\treturn 0;\n}",
    "includes": [
      "#include \"kvm_cache_regs.h\"",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\nstatic inline unsigned int kvm_mmu_available_pages(struct kvm *kvm)\n{\n\tif (kvm->arch.n_max_mmu_pages > kvm->arch.n_used_mmu_pages)\n\t\treturn kvm->arch.n_max_mmu_pages -\n\t\t\tkvm->arch.n_used_mmu_pages;\n\n\treturn 0;\n}"
  },
  {
    "function_name": "rsvd_bits",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.h",
    "lines": "49-52",
    "snippet": "static inline u64 rsvd_bits(int s, int e)\n{\n\treturn ((1ULL << (e - s + 1)) - 1) << s;\n}",
    "includes": [
      "#include \"kvm_cache_regs.h\"",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\nstatic inline u64 rsvd_bits(int s, int e)\n{\n\treturn ((1ULL << (e - s + 1)) - 1) << s;\n}"
  }
]