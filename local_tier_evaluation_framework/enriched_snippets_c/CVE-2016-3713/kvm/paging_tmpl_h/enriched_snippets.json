[
  {
    "function_name": "FNAME",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
    "lines": "936-1004",
    "snippet": "static int FNAME(sync_page)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp)\n{\n\tint i, nr_present = 0;\n\tbool host_writable;\n\tgpa_t first_pte_gpa;\n\n\t/* direct kvm_mmu_page can not be unsync. */\n\tBUG_ON(sp->role.direct);\n\n\tfirst_pte_gpa = FNAME(get_level1_sp_gpa)(sp);\n\n\tfor (i = 0; i < PT64_ENT_PER_PAGE; i++) {\n\t\tunsigned pte_access;\n\t\tpt_element_t gpte;\n\t\tgpa_t pte_gpa;\n\t\tgfn_t gfn;\n\n\t\tif (!sp->spt[i])\n\t\t\tcontinue;\n\n\t\tpte_gpa = first_pte_gpa + i * sizeof(pt_element_t);\n\n\t\tif (kvm_vcpu_read_guest_atomic(vcpu, pte_gpa, &gpte,\n\t\t\t\t\t       sizeof(pt_element_t)))\n\t\t\treturn 0;\n\n\t\tif (FNAME(prefetch_invalid_gpte)(vcpu, sp, &sp->spt[i], gpte)) {\n\t\t\t/*\n\t\t\t * Update spte before increasing tlbs_dirty to make\n\t\t\t * sure no tlb flush is lost after spte is zapped; see\n\t\t\t * the comments in kvm_flush_remote_tlbs().\n\t\t\t */\n\t\t\tsmp_wmb();\n\t\t\tvcpu->kvm->tlbs_dirty++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tgfn = gpte_to_gfn(gpte);\n\t\tpte_access = sp->role.access;\n\t\tpte_access &= FNAME(gpte_access)(vcpu, gpte);\n\t\tFNAME(protect_clean_gpte)(&pte_access, gpte);\n\n\t\tif (sync_mmio_spte(vcpu, &sp->spt[i], gfn, pte_access,\n\t\t      &nr_present))\n\t\t\tcontinue;\n\n\t\tif (gfn != sp->gfns[i]) {\n\t\t\tdrop_spte(vcpu->kvm, &sp->spt[i]);\n\t\t\t/*\n\t\t\t * The same as above where we are doing\n\t\t\t * prefetch_invalid_gpte().\n\t\t\t */\n\t\t\tsmp_wmb();\n\t\t\tvcpu->kvm->tlbs_dirty++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tnr_present++;\n\n\t\thost_writable = sp->spt[i] & SPTE_HOST_WRITEABLE;\n\n\t\tset_spte(vcpu, &sp->spt[i], pte_access,\n\t\t\t PT_PAGE_TABLE_LEVEL, gfn,\n\t\t\t spte_to_pfn(sp->spt[i]), true, false,\n\t\t\t host_writable);\n\t}\n\n\treturn nr_present;\n}",
    "includes": [],
    "macros_used": [
      "#define pt_element_t u64",
      "#define pt_element_t u32",
      "#define pt_element_t u64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "set_spte",
          "args": [
            "vcpu",
            "&sp->spt[i]",
            "pte_access",
            "PT_PAGE_TABLE_LEVEL",
            "gfn",
            "spte_to_pfn(sp->spt[i])",
            "true",
            "false",
            "host_writable"
          ],
          "line": 997
        },
        "resolved": true,
        "details": {
          "function_name": "mmu_set_spte",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "2593-2655",
          "snippet": "static bool mmu_set_spte(struct kvm_vcpu *vcpu, u64 *sptep, unsigned pte_access,\n\t\t\t int write_fault, int level, gfn_t gfn, kvm_pfn_t pfn,\n\t\t\t bool speculative, bool host_writable)\n{\n\tint was_rmapped = 0;\n\tint rmap_count;\n\tbool emulate = false;\n\n\tpgprintk(\"%s: spte %llx write_fault %d gfn %llx\\n\", __func__,\n\t\t *sptep, write_fault, gfn);\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\t/*\n\t\t * If we overwrite a PTE page pointer with a 2MB PMD, unlink\n\t\t * the parent of the now unreachable PTE.\n\t\t */\n\t\tif (level > PT_PAGE_TABLE_LEVEL &&\n\t\t    !is_large_pte(*sptep)) {\n\t\t\tstruct kvm_mmu_page *child;\n\t\t\tu64 pte = *sptep;\n\n\t\t\tchild = page_header(pte & PT64_BASE_ADDR_MASK);\n\t\t\tdrop_parent_pte(child, sptep);\n\t\t\tkvm_flush_remote_tlbs(vcpu->kvm);\n\t\t} else if (pfn != spte_to_pfn(*sptep)) {\n\t\t\tpgprintk(\"hfn old %llx new %llx\\n\",\n\t\t\t\t spte_to_pfn(*sptep), pfn);\n\t\t\tdrop_spte(vcpu->kvm, sptep);\n\t\t\tkvm_flush_remote_tlbs(vcpu->kvm);\n\t\t} else\n\t\t\twas_rmapped = 1;\n\t}\n\n\tif (set_spte(vcpu, sptep, pte_access, level, gfn, pfn, speculative,\n\t      true, host_writable)) {\n\t\tif (write_fault)\n\t\t\temulate = true;\n\t\tkvm_make_request(KVM_REQ_TLB_FLUSH, vcpu);\n\t}\n\n\tif (unlikely(is_mmio_spte(*sptep)))\n\t\temulate = true;\n\n\tpgprintk(\"%s: setting spte %llx\\n\", __func__, *sptep);\n\tpgprintk(\"instantiating %s PTE (%s) at %llx (%llx) addr %p\\n\",\n\t\t is_large_pte(*sptep)? \"2MB\" : \"4kB\",\n\t\t *sptep & PT_PRESENT_MASK ?\"RW\":\"R\", gfn,\n\t\t *sptep, sptep);\n\tif (!was_rmapped && is_large_pte(*sptep))\n\t\t++vcpu->kvm->stat.lpages;\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\tif (!was_rmapped) {\n\t\t\trmap_count = rmap_add(vcpu, sptep, gfn);\n\t\t\tif (rmap_count > RMAP_RECYCLE_THRESHOLD)\n\t\t\t\trmap_recycle(vcpu, sptep, gfn);\n\t\t}\n\t}\n\n\tkvm_release_pfn_clean(pfn);\n\n\treturn emulate;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [
            "#define RMAP_RECYCLE_THRESHOLD 1000",
            "#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))"
          ],
          "globals_used": [
            "static void mmu_spte_set(u64 *sptep, u64 spte);",
            "static void mmu_free_roots(struct kvm_vcpu *vcpu);",
            "static void mark_unsync(u64 *spte);",
            "static void make_mmu_pages_available(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\n#define RMAP_RECYCLE_THRESHOLD 1000\n#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))\n\nstatic void mmu_spte_set(u64 *sptep, u64 spte);\nstatic void mmu_free_roots(struct kvm_vcpu *vcpu);\nstatic void mark_unsync(u64 *spte);\nstatic void make_mmu_pages_available(struct kvm_vcpu *vcpu);\n\nstatic bool mmu_set_spte(struct kvm_vcpu *vcpu, u64 *sptep, unsigned pte_access,\n\t\t\t int write_fault, int level, gfn_t gfn, kvm_pfn_t pfn,\n\t\t\t bool speculative, bool host_writable)\n{\n\tint was_rmapped = 0;\n\tint rmap_count;\n\tbool emulate = false;\n\n\tpgprintk(\"%s: spte %llx write_fault %d gfn %llx\\n\", __func__,\n\t\t *sptep, write_fault, gfn);\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\t/*\n\t\t * If we overwrite a PTE page pointer with a 2MB PMD, unlink\n\t\t * the parent of the now unreachable PTE.\n\t\t */\n\t\tif (level > PT_PAGE_TABLE_LEVEL &&\n\t\t    !is_large_pte(*sptep)) {\n\t\t\tstruct kvm_mmu_page *child;\n\t\t\tu64 pte = *sptep;\n\n\t\t\tchild = page_header(pte & PT64_BASE_ADDR_MASK);\n\t\t\tdrop_parent_pte(child, sptep);\n\t\t\tkvm_flush_remote_tlbs(vcpu->kvm);\n\t\t} else if (pfn != spte_to_pfn(*sptep)) {\n\t\t\tpgprintk(\"hfn old %llx new %llx\\n\",\n\t\t\t\t spte_to_pfn(*sptep), pfn);\n\t\t\tdrop_spte(vcpu->kvm, sptep);\n\t\t\tkvm_flush_remote_tlbs(vcpu->kvm);\n\t\t} else\n\t\t\twas_rmapped = 1;\n\t}\n\n\tif (set_spte(vcpu, sptep, pte_access, level, gfn, pfn, speculative,\n\t      true, host_writable)) {\n\t\tif (write_fault)\n\t\t\temulate = true;\n\t\tkvm_make_request(KVM_REQ_TLB_FLUSH, vcpu);\n\t}\n\n\tif (unlikely(is_mmio_spte(*sptep)))\n\t\temulate = true;\n\n\tpgprintk(\"%s: setting spte %llx\\n\", __func__, *sptep);\n\tpgprintk(\"instantiating %s PTE (%s) at %llx (%llx) addr %p\\n\",\n\t\t is_large_pte(*sptep)? \"2MB\" : \"4kB\",\n\t\t *sptep & PT_PRESENT_MASK ?\"RW\":\"R\", gfn,\n\t\t *sptep, sptep);\n\tif (!was_rmapped && is_large_pte(*sptep))\n\t\t++vcpu->kvm->stat.lpages;\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\tif (!was_rmapped) {\n\t\t\trmap_count = rmap_add(vcpu, sptep, gfn);\n\t\t\tif (rmap_count > RMAP_RECYCLE_THRESHOLD)\n\t\t\t\trmap_recycle(vcpu, sptep, gfn);\n\t\t}\n\t}\n\n\tkvm_release_pfn_clean(pfn);\n\n\treturn emulate;\n}"
        }
      },
      {
        "call_info": {
          "callee": "spte_to_pfn",
          "args": [
            "sp->spt[i]"
          ],
          "line": 999
        },
        "resolved": true,
        "details": {
          "function_name": "spte_to_pfn",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "324-327",
          "snippet": "static kvm_pfn_t spte_to_pfn(u64 pte)\n{\n\treturn (pte & PT64_BASE_ADDR_MASK) >> PAGE_SHIFT;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [
            "#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\n#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))\n\nstatic kvm_pfn_t spte_to_pfn(u64 pte)\n{\n\treturn (pte & PT64_BASE_ADDR_MASK) >> PAGE_SHIFT;\n}"
        }
      },
      {
        "call_info": {
          "callee": "smp_wmb",
          "args": [],
          "line": 988
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "drop_spte",
          "args": [
            "vcpu->kvm",
            "&sp->spt[i]"
          ],
          "line": 983
        },
        "resolved": true,
        "details": {
          "function_name": "drop_spte",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "1168-1172",
          "snippet": "static void drop_spte(struct kvm *kvm, u64 *sptep)\n{\n\tif (mmu_spte_clear_track_bits(sptep))\n\t\trmap_remove(kvm, sptep);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void drop_spte(struct kvm *kvm, u64 *sptep)\n{\n\tif (mmu_spte_clear_track_bits(sptep))\n\t\trmap_remove(kvm, sptep);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sync_mmio_spte",
          "args": [
            "vcpu",
            "&sp->spt[i]",
            "gfn",
            "pte_access",
            "&nr_present"
          ],
          "line": 978
        },
        "resolved": true,
        "details": {
          "function_name": "sync_mmio_spte",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "3620-3635",
          "snippet": "static bool sync_mmio_spte(struct kvm_vcpu *vcpu, u64 *sptep, gfn_t gfn,\n\t\t\t   unsigned access, int *nr_present)\n{\n\tif (unlikely(is_mmio_spte(*sptep))) {\n\t\tif (gfn != get_mmio_spte_gfn(*sptep)) {\n\t\t\tmmu_spte_clear_no_track(sptep);\n\t\t\treturn true;\n\t\t}\n\n\t\t(*nr_present)++;\n\t\tmark_mmio_spte(vcpu, sptep, gfn, access);\n\t\treturn true;\n\t}\n\n\treturn false;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void mmu_free_roots(struct kvm_vcpu *vcpu);",
            "static void make_mmu_pages_available(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void mmu_free_roots(struct kvm_vcpu *vcpu);\nstatic void make_mmu_pages_available(struct kvm_vcpu *vcpu);\n\nstatic bool sync_mmio_spte(struct kvm_vcpu *vcpu, u64 *sptep, gfn_t gfn,\n\t\t\t   unsigned access, int *nr_present)\n{\n\tif (unlikely(is_mmio_spte(*sptep))) {\n\t\tif (gfn != get_mmio_spte_gfn(*sptep)) {\n\t\t\tmmu_spte_clear_no_track(sptep);\n\t\t\treturn true;\n\t\t}\n\n\t\t(*nr_present)++;\n\t\tmark_mmio_spte(vcpu, sptep, gfn, access);\n\t\treturn true;\n\t}\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "&pte_access",
            "gpte"
          ],
          "line": 976
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
          "lines": "936-1004",
          "snippet": "static int FNAME(sync_page)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp)\n{\n\tint i, nr_present = 0;\n\tbool host_writable;\n\tgpa_t first_pte_gpa;\n\n\t/* direct kvm_mmu_page can not be unsync. */\n\tBUG_ON(sp->role.direct);\n\n\tfirst_pte_gpa = FNAME(get_level1_sp_gpa)(sp);\n\n\tfor (i = 0; i < PT64_ENT_PER_PAGE; i++) {\n\t\tunsigned pte_access;\n\t\tpt_element_t gpte;\n\t\tgpa_t pte_gpa;\n\t\tgfn_t gfn;\n\n\t\tif (!sp->spt[i])\n\t\t\tcontinue;\n\n\t\tpte_gpa = first_pte_gpa + i * sizeof(pt_element_t);\n\n\t\tif (kvm_vcpu_read_guest_atomic(vcpu, pte_gpa, &gpte,\n\t\t\t\t\t       sizeof(pt_element_t)))\n\t\t\treturn 0;\n\n\t\tif (FNAME(prefetch_invalid_gpte)(vcpu, sp, &sp->spt[i], gpte)) {\n\t\t\t/*\n\t\t\t * Update spte before increasing tlbs_dirty to make\n\t\t\t * sure no tlb flush is lost after spte is zapped; see\n\t\t\t * the comments in kvm_flush_remote_tlbs().\n\t\t\t */\n\t\t\tsmp_wmb();\n\t\t\tvcpu->kvm->tlbs_dirty++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tgfn = gpte_to_gfn(gpte);\n\t\tpte_access = sp->role.access;\n\t\tpte_access &= FNAME(gpte_access)(vcpu, gpte);\n\t\tFNAME(protect_clean_gpte)(&pte_access, gpte);\n\n\t\tif (sync_mmio_spte(vcpu, &sp->spt[i], gfn, pte_access,\n\t\t      &nr_present))\n\t\t\tcontinue;\n\n\t\tif (gfn != sp->gfns[i]) {\n\t\t\tdrop_spte(vcpu->kvm, &sp->spt[i]);\n\t\t\t/*\n\t\t\t * The same as above where we are doing\n\t\t\t * prefetch_invalid_gpte().\n\t\t\t */\n\t\t\tsmp_wmb();\n\t\t\tvcpu->kvm->tlbs_dirty++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tnr_present++;\n\n\t\thost_writable = sp->spt[i] & SPTE_HOST_WRITEABLE;\n\n\t\tset_spte(vcpu, &sp->spt[i], pte_access,\n\t\t\t PT_PAGE_TABLE_LEVEL, gfn,\n\t\t\t spte_to_pfn(sp->spt[i]), true, false,\n\t\t\t host_writable);\n\t}\n\n\treturn nr_present;\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "gpte_to_gfn",
          "args": [
            "gpte"
          ],
          "line": 973
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_wmb",
          "args": [],
          "line": 968
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_vcpu_read_guest_atomic",
          "args": [
            "vcpu",
            "pte_gpa",
            "&gpte",
            "sizeof(pt_element_t)"
          ],
          "line": 958
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "sp->role.direct"
          ],
          "line": 943
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define pt_element_t u64\n#define pt_element_t u32\n#define pt_element_t u64\n\nstatic int FNAME(sync_page)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp)\n{\n\tint i, nr_present = 0;\n\tbool host_writable;\n\tgpa_t first_pte_gpa;\n\n\t/* direct kvm_mmu_page can not be unsync. */\n\tBUG_ON(sp->role.direct);\n\n\tfirst_pte_gpa = FNAME(get_level1_sp_gpa)(sp);\n\n\tfor (i = 0; i < PT64_ENT_PER_PAGE; i++) {\n\t\tunsigned pte_access;\n\t\tpt_element_t gpte;\n\t\tgpa_t pte_gpa;\n\t\tgfn_t gfn;\n\n\t\tif (!sp->spt[i])\n\t\t\tcontinue;\n\n\t\tpte_gpa = first_pte_gpa + i * sizeof(pt_element_t);\n\n\t\tif (kvm_vcpu_read_guest_atomic(vcpu, pte_gpa, &gpte,\n\t\t\t\t\t       sizeof(pt_element_t)))\n\t\t\treturn 0;\n\n\t\tif (FNAME(prefetch_invalid_gpte)(vcpu, sp, &sp->spt[i], gpte)) {\n\t\t\t/*\n\t\t\t * Update spte before increasing tlbs_dirty to make\n\t\t\t * sure no tlb flush is lost after spte is zapped; see\n\t\t\t * the comments in kvm_flush_remote_tlbs().\n\t\t\t */\n\t\t\tsmp_wmb();\n\t\t\tvcpu->kvm->tlbs_dirty++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tgfn = gpte_to_gfn(gpte);\n\t\tpte_access = sp->role.access;\n\t\tpte_access &= FNAME(gpte_access)(vcpu, gpte);\n\t\tFNAME(protect_clean_gpte)(&pte_access, gpte);\n\n\t\tif (sync_mmio_spte(vcpu, &sp->spt[i], gfn, pte_access,\n\t\t      &nr_present))\n\t\t\tcontinue;\n\n\t\tif (gfn != sp->gfns[i]) {\n\t\t\tdrop_spte(vcpu->kvm, &sp->spt[i]);\n\t\t\t/*\n\t\t\t * The same as above where we are doing\n\t\t\t * prefetch_invalid_gpte().\n\t\t\t */\n\t\t\tsmp_wmb();\n\t\t\tvcpu->kvm->tlbs_dirty++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tnr_present++;\n\n\t\thost_writable = sp->spt[i] & SPTE_HOST_WRITEABLE;\n\n\t\tset_spte(vcpu, &sp->spt[i], pte_access,\n\t\t\t PT_PAGE_TABLE_LEVEL, gfn,\n\t\t\t spte_to_pfn(sp->spt[i]), true, false,\n\t\t\t host_writable);\n\t}\n\n\treturn nr_present;\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
    "lines": "903-920",
    "snippet": "static gpa_t FNAME(gva_to_gpa_nested)(struct kvm_vcpu *vcpu, gva_t vaddr,\n\t\t\t\t      u32 access,\n\t\t\t\t      struct x86_exception *exception)\n{\n\tstruct guest_walker walker;\n\tgpa_t gpa = UNMAPPED_GVA;\n\tint r;\n\n\tr = FNAME(walk_addr_nested)(&walker, vcpu, vaddr, access);\n\n\tif (r) {\n\t\tgpa = gfn_to_gpa(walker.gfn);\n\t\tgpa |= vaddr & ~PAGE_MASK;\n\t} else if (exception)\n\t\t*exception = walker.fault;\n\n\treturn gpa;\n}",
    "includes": [],
    "macros_used": [
      "#define guest_walker guest_walkerEPT",
      "#define guest_walker guest_walker32",
      "#define guest_walker guest_walker64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "gfn_to_gpa",
          "args": [
            "walker.gfn"
          ],
          "line": 914
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "&walker",
            "vcpu",
            "vaddr",
            "access"
          ],
          "line": 911
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
          "lines": "903-920",
          "snippet": "static gpa_t FNAME(gva_to_gpa_nested)(struct kvm_vcpu *vcpu, gva_t vaddr,\n\t\t\t\t      u32 access,\n\t\t\t\t      struct x86_exception *exception)\n{\n\tstruct guest_walker walker;\n\tgpa_t gpa = UNMAPPED_GVA;\n\tint r;\n\n\tr = FNAME(walk_addr_nested)(&walker, vcpu, vaddr, access);\n\n\tif (r) {\n\t\tgpa = gfn_to_gpa(walker.gfn);\n\t\tgpa |= vaddr & ~PAGE_MASK;\n\t} else if (exception)\n\t\t*exception = walker.fault;\n\n\treturn gpa;\n}",
          "note": "cyclic_reference_detected"
        }
      }
    ],
    "contextual_snippet": "#define guest_walker guest_walkerEPT\n#define guest_walker guest_walker32\n#define guest_walker guest_walker64\n\nstatic gpa_t FNAME(gva_to_gpa_nested)(struct kvm_vcpu *vcpu, gva_t vaddr,\n\t\t\t\t      u32 access,\n\t\t\t\t      struct x86_exception *exception)\n{\n\tstruct guest_walker walker;\n\tgpa_t gpa = UNMAPPED_GVA;\n\tint r;\n\n\tr = FNAME(walk_addr_nested)(&walker, vcpu, vaddr, access);\n\n\tif (r) {\n\t\tgpa = gfn_to_gpa(walker.gfn);\n\t\tgpa |= vaddr & ~PAGE_MASK;\n\t} else if (exception)\n\t\t*exception = walker.fault;\n\n\treturn gpa;\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
    "lines": "884-900",
    "snippet": "static gpa_t FNAME(gva_to_gpa)(struct kvm_vcpu *vcpu, gva_t vaddr, u32 access,\n\t\t\t       struct x86_exception *exception)\n{\n\tstruct guest_walker walker;\n\tgpa_t gpa = UNMAPPED_GVA;\n\tint r;\n\n\tr = FNAME(walk_addr)(&walker, vcpu, vaddr, access);\n\n\tif (r) {\n\t\tgpa = gfn_to_gpa(walker.gfn);\n\t\tgpa |= vaddr & ~PAGE_MASK;\n\t} else if (exception)\n\t\t*exception = walker.fault;\n\n\treturn gpa;\n}",
    "includes": [],
    "macros_used": [
      "#define guest_walker guest_walkerEPT",
      "#define guest_walker guest_walker32",
      "#define guest_walker guest_walker64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "gfn_to_gpa",
          "args": [
            "walker.gfn"
          ],
          "line": 894
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "&walker",
            "vcpu",
            "vaddr",
            "access"
          ],
          "line": 891
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
          "lines": "903-920",
          "snippet": "static gpa_t FNAME(gva_to_gpa_nested)(struct kvm_vcpu *vcpu, gva_t vaddr,\n\t\t\t\t      u32 access,\n\t\t\t\t      struct x86_exception *exception)\n{\n\tstruct guest_walker walker;\n\tgpa_t gpa = UNMAPPED_GVA;\n\tint r;\n\n\tr = FNAME(walk_addr_nested)(&walker, vcpu, vaddr, access);\n\n\tif (r) {\n\t\tgpa = gfn_to_gpa(walker.gfn);\n\t\tgpa |= vaddr & ~PAGE_MASK;\n\t} else if (exception)\n\t\t*exception = walker.fault;\n\n\treturn gpa;\n}",
          "note": "cyclic_reference_detected"
        }
      }
    ],
    "contextual_snippet": "#define guest_walker guest_walkerEPT\n#define guest_walker guest_walker32\n#define guest_walker guest_walker64\n\nstatic gpa_t FNAME(gva_to_gpa)(struct kvm_vcpu *vcpu, gva_t vaddr, u32 access,\n\t\t\t       struct x86_exception *exception)\n{\n\tstruct guest_walker walker;\n\tgpa_t gpa = UNMAPPED_GVA;\n\tint r;\n\n\tr = FNAME(walk_addr)(&walker, vcpu, vaddr, access);\n\n\tif (r) {\n\t\tgpa = gfn_to_gpa(walker.gfn);\n\t\tgpa |= vaddr & ~PAGE_MASK;\n\t} else if (exception)\n\t\t*exception = walker.fault;\n\n\treturn gpa;\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
    "lines": "829-882",
    "snippet": "static void FNAME(invlpg)(struct kvm_vcpu *vcpu, gva_t gva)\n{\n\tstruct kvm_shadow_walk_iterator iterator;\n\tstruct kvm_mmu_page *sp;\n\tint level;\n\tu64 *sptep;\n\n\tvcpu_clear_mmio_info(vcpu, gva);\n\n\t/*\n\t * No need to check return value here, rmap_can_add() can\n\t * help us to skip pte prefetch later.\n\t */\n\tmmu_topup_memory_caches(vcpu);\n\n\tif (!VALID_PAGE(vcpu->arch.mmu.root_hpa)) {\n\t\tWARN_ON(1);\n\t\treturn;\n\t}\n\n\tspin_lock(&vcpu->kvm->mmu_lock);\n\tfor_each_shadow_entry(vcpu, gva, iterator) {\n\t\tlevel = iterator.level;\n\t\tsptep = iterator.sptep;\n\n\t\tsp = page_header(__pa(sptep));\n\t\tif (is_last_spte(*sptep, level)) {\n\t\t\tpt_element_t gpte;\n\t\t\tgpa_t pte_gpa;\n\n\t\t\tif (!sp->unsync)\n\t\t\t\tbreak;\n\n\t\t\tpte_gpa = FNAME(get_level1_sp_gpa)(sp);\n\t\t\tpte_gpa += (sptep - sp->spt) * sizeof(pt_element_t);\n\n\t\t\tif (mmu_page_zap_pte(vcpu->kvm, sp, sptep))\n\t\t\t\tkvm_flush_remote_tlbs(vcpu->kvm);\n\n\t\t\tif (!rmap_can_add(vcpu))\n\t\t\t\tbreak;\n\n\t\t\tif (kvm_vcpu_read_guest_atomic(vcpu, pte_gpa, &gpte,\n\t\t\t\t\t\t       sizeof(pt_element_t)))\n\t\t\t\tbreak;\n\n\t\t\tFNAME(update_pte)(vcpu, sp, sptep, &gpte);\n\t\t}\n\n\t\tif (!is_shadow_present_pte(*sptep) || !sp->unsync_children)\n\t\t\tbreak;\n\t}\n\tspin_unlock(&vcpu->kvm->mmu_lock);\n}",
    "includes": [],
    "macros_used": [
      "#define pt_element_t u64",
      "#define pt_element_t u32",
      "#define pt_element_t u64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "spin_unlock",
          "args": [
            "&vcpu->kvm->mmu_lock"
          ],
          "line": 881
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "is_shadow_present_pte",
          "args": [
            "*sptep"
          ],
          "line": 878
        },
        "resolved": true,
        "details": {
          "function_name": "is_shadow_present_pte",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "305-308",
          "snippet": "static int is_shadow_present_pte(u64 pte)\n{\n\treturn pte & PT_PRESENT_MASK && !is_mmio_spte(pte);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic int is_shadow_present_pte(u64 pte)\n{\n\treturn pte & PT_PRESENT_MASK && !is_mmio_spte(pte);\n}"
        }
      },
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "vcpu",
            "sp",
            "sptep",
            "&gpte"
          ],
          "line": 875
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
          "lines": "903-920",
          "snippet": "static gpa_t FNAME(gva_to_gpa_nested)(struct kvm_vcpu *vcpu, gva_t vaddr,\n\t\t\t\t      u32 access,\n\t\t\t\t      struct x86_exception *exception)\n{\n\tstruct guest_walker walker;\n\tgpa_t gpa = UNMAPPED_GVA;\n\tint r;\n\n\tr = FNAME(walk_addr_nested)(&walker, vcpu, vaddr, access);\n\n\tif (r) {\n\t\tgpa = gfn_to_gpa(walker.gfn);\n\t\tgpa |= vaddr & ~PAGE_MASK;\n\t} else if (exception)\n\t\t*exception = walker.fault;\n\n\treturn gpa;\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "kvm_vcpu_read_guest_atomic",
          "args": [
            "vcpu",
            "pte_gpa",
            "&gpte",
            "sizeof(pt_element_t)"
          ],
          "line": 871
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rmap_can_add",
          "args": [
            "vcpu"
          ],
          "line": 868
        },
        "resolved": true,
        "details": {
          "function_name": "rmap_can_add",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "1061-1067",
          "snippet": "static bool rmap_can_add(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_mmu_memory_cache *cache;\n\n\tcache = &vcpu->arch.mmu_pte_list_desc_cache;\n\treturn mmu_memory_cache_free_objects(cache);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void mmu_free_roots(struct kvm_vcpu *vcpu);",
            "static void make_mmu_pages_available(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void mmu_free_roots(struct kvm_vcpu *vcpu);\nstatic void make_mmu_pages_available(struct kvm_vcpu *vcpu);\n\nstatic bool rmap_can_add(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_mmu_memory_cache *cache;\n\n\tcache = &vcpu->arch.mmu_pte_list_desc_cache;\n\treturn mmu_memory_cache_free_objects(cache);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_flush_remote_tlbs",
          "args": [
            "vcpu->kvm"
          ],
          "line": 866
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mmu_page_zap_pte",
          "args": [
            "vcpu->kvm",
            "sp",
            "sptep"
          ],
          "line": 865
        },
        "resolved": true,
        "details": {
          "function_name": "mmu_page_zap_pte",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "2284-2307",
          "snippet": "static bool mmu_page_zap_pte(struct kvm *kvm, struct kvm_mmu_page *sp,\n\t\t\t     u64 *spte)\n{\n\tu64 pte;\n\tstruct kvm_mmu_page *child;\n\n\tpte = *spte;\n\tif (is_shadow_present_pte(pte)) {\n\t\tif (is_last_spte(pte, sp->role.level)) {\n\t\t\tdrop_spte(kvm, spte);\n\t\t\tif (is_large_pte(pte))\n\t\t\t\t--kvm->stat.lpages;\n\t\t} else {\n\t\t\tchild = page_header(pte & PT64_BASE_ADDR_MASK);\n\t\t\tdrop_parent_pte(child, spte);\n\t\t}\n\t\treturn true;\n\t}\n\n\tif (is_mmio_spte(pte))\n\t\tmmu_spte_clear_no_track(spte);\n\n\treturn false;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [
            "#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))"
          ],
          "globals_used": [
            "static void mmu_spte_set(u64 *sptep, u64 spte);",
            "static void mark_unsync(u64 *spte);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\n#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))\n\nstatic void mmu_spte_set(u64 *sptep, u64 spte);\nstatic void mark_unsync(u64 *spte);\n\nstatic bool mmu_page_zap_pte(struct kvm *kvm, struct kvm_mmu_page *sp,\n\t\t\t     u64 *spte)\n{\n\tu64 pte;\n\tstruct kvm_mmu_page *child;\n\n\tpte = *spte;\n\tif (is_shadow_present_pte(pte)) {\n\t\tif (is_last_spte(pte, sp->role.level)) {\n\t\t\tdrop_spte(kvm, spte);\n\t\t\tif (is_large_pte(pte))\n\t\t\t\t--kvm->stat.lpages;\n\t\t} else {\n\t\t\tchild = page_header(pte & PT64_BASE_ADDR_MASK);\n\t\t\tdrop_parent_pte(child, spte);\n\t\t}\n\t\treturn true;\n\t}\n\n\tif (is_mmio_spte(pte))\n\t\tmmu_spte_clear_no_track(spte);\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_last_spte",
          "args": [
            "*sptep",
            "level"
          ],
          "line": 855
        },
        "resolved": true,
        "details": {
          "function_name": "is_last_spte",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "315-322",
          "snippet": "static int is_last_spte(u64 pte, int level)\n{\n\tif (level == PT_PAGE_TABLE_LEVEL)\n\t\treturn 1;\n\tif (is_large_pte(pte))\n\t\treturn 1;\n\treturn 0;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic int is_last_spte(u64 pte, int level)\n{\n\tif (level == PT_PAGE_TABLE_LEVEL)\n\t\treturn 1;\n\tif (is_large_pte(pte))\n\t\treturn 1;\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "page_header",
          "args": [
            "__pa(sptep)"
          ],
          "line": 854
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__pa",
          "args": [
            "sptep"
          ],
          "line": 854
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "for_each_shadow_entry",
          "args": [
            "vcpu",
            "gva",
            "iterator"
          ],
          "line": 850
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_lock",
          "args": [
            "&vcpu->kvm->mmu_lock"
          ],
          "line": 849
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "1"
          ],
          "line": 845
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "VALID_PAGE",
          "args": [
            "vcpu->arch.mmu.root_hpa"
          ],
          "line": 844
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mmu_topup_memory_caches",
          "args": [
            "vcpu"
          ],
          "line": 842
        },
        "resolved": true,
        "details": {
          "function_name": "mmu_topup_memory_caches",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "712-727",
          "snippet": "static int mmu_topup_memory_caches(struct kvm_vcpu *vcpu)\n{\n\tint r;\n\n\tr = mmu_topup_memory_cache(&vcpu->arch.mmu_pte_list_desc_cache,\n\t\t\t\t   pte_list_desc_cache, 8 + PTE_PREFETCH_NUM);\n\tif (r)\n\t\tgoto out;\n\tr = mmu_topup_memory_cache_page(&vcpu->arch.mmu_page_cache, 8);\n\tif (r)\n\t\tgoto out;\n\tr = mmu_topup_memory_cache(&vcpu->arch.mmu_page_header_cache,\n\t\t\t\t   mmu_page_header_cache, 4);\nout:\n\treturn r;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [
            "#define PTE_PREFETCH_NUM\t\t8"
          ],
          "globals_used": [
            "static struct kmem_cache *pte_list_desc_cache;",
            "static struct kmem_cache *mmu_page_header_cache;",
            "static void mmu_free_roots(struct kvm_vcpu *vcpu);",
            "static void make_mmu_pages_available(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\n#define PTE_PREFETCH_NUM\t\t8\n\nstatic struct kmem_cache *pte_list_desc_cache;\nstatic struct kmem_cache *mmu_page_header_cache;\nstatic void mmu_free_roots(struct kvm_vcpu *vcpu);\nstatic void make_mmu_pages_available(struct kvm_vcpu *vcpu);\n\nstatic int mmu_topup_memory_caches(struct kvm_vcpu *vcpu)\n{\n\tint r;\n\n\tr = mmu_topup_memory_cache(&vcpu->arch.mmu_pte_list_desc_cache,\n\t\t\t\t   pte_list_desc_cache, 8 + PTE_PREFETCH_NUM);\n\tif (r)\n\t\tgoto out;\n\tr = mmu_topup_memory_cache_page(&vcpu->arch.mmu_page_cache, 8);\n\tif (r)\n\t\tgoto out;\n\tr = mmu_topup_memory_cache(&vcpu->arch.mmu_page_header_cache,\n\t\t\t\t   mmu_page_header_cache, 4);\nout:\n\treturn r;\n}"
        }
      },
      {
        "call_info": {
          "callee": "vcpu_clear_mmio_info",
          "args": [
            "vcpu",
            "gva"
          ],
          "line": 836
        },
        "resolved": true,
        "details": {
          "function_name": "vcpu_clear_mmio_info",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/x86.h",
          "lines": "107-113",
          "snippet": "static inline void vcpu_clear_mmio_info(struct kvm_vcpu *vcpu, gva_t gva)\n{\n\tif (gva != MMIO_GVA_ANY && vcpu->arch.mmio_gva != (gva & PAGE_MASK))\n\t\treturn;\n\n\tvcpu->arch.mmio_gva = 0;\n}",
          "includes": [
            "#include \"kvm_cache_regs.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [
            "#define MMIO_GVA_ANY (~(gva_t)0)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\n#define MMIO_GVA_ANY (~(gva_t)0)\n\nstatic inline void vcpu_clear_mmio_info(struct kvm_vcpu *vcpu, gva_t gva)\n{\n\tif (gva != MMIO_GVA_ANY && vcpu->arch.mmio_gva != (gva & PAGE_MASK))\n\t\treturn;\n\n\tvcpu->arch.mmio_gva = 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#define pt_element_t u64\n#define pt_element_t u32\n#define pt_element_t u64\n\nstatic void FNAME(invlpg)(struct kvm_vcpu *vcpu, gva_t gva)\n{\n\tstruct kvm_shadow_walk_iterator iterator;\n\tstruct kvm_mmu_page *sp;\n\tint level;\n\tu64 *sptep;\n\n\tvcpu_clear_mmio_info(vcpu, gva);\n\n\t/*\n\t * No need to check return value here, rmap_can_add() can\n\t * help us to skip pte prefetch later.\n\t */\n\tmmu_topup_memory_caches(vcpu);\n\n\tif (!VALID_PAGE(vcpu->arch.mmu.root_hpa)) {\n\t\tWARN_ON(1);\n\t\treturn;\n\t}\n\n\tspin_lock(&vcpu->kvm->mmu_lock);\n\tfor_each_shadow_entry(vcpu, gva, iterator) {\n\t\tlevel = iterator.level;\n\t\tsptep = iterator.sptep;\n\n\t\tsp = page_header(__pa(sptep));\n\t\tif (is_last_spte(*sptep, level)) {\n\t\t\tpt_element_t gpte;\n\t\t\tgpa_t pte_gpa;\n\n\t\t\tif (!sp->unsync)\n\t\t\t\tbreak;\n\n\t\t\tpte_gpa = FNAME(get_level1_sp_gpa)(sp);\n\t\t\tpte_gpa += (sptep - sp->spt) * sizeof(pt_element_t);\n\n\t\t\tif (mmu_page_zap_pte(vcpu->kvm, sp, sptep))\n\t\t\t\tkvm_flush_remote_tlbs(vcpu->kvm);\n\n\t\t\tif (!rmap_can_add(vcpu))\n\t\t\t\tbreak;\n\n\t\t\tif (kvm_vcpu_read_guest_atomic(vcpu, pte_gpa, &gpte,\n\t\t\t\t\t\t       sizeof(pt_element_t)))\n\t\t\t\tbreak;\n\n\t\t\tFNAME(update_pte)(vcpu, sp, sptep, &gpte);\n\t\t}\n\n\t\tif (!is_shadow_present_pte(*sptep) || !sp->unsync_children)\n\t\t\tbreak;\n\t}\n\tspin_unlock(&vcpu->kvm->mmu_lock);\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
    "lines": "817-827",
    "snippet": "static gpa_t FNAME(get_level1_sp_gpa)(struct kvm_mmu_page *sp)\n{\n\tint offset = 0;\n\n\tWARN_ON(sp->role.level != PT_PAGE_TABLE_LEVEL);\n\n\tif (PTTYPE == 32)\n\t\toffset = sp->role.quadrant << PT64_LEVEL_BITS;\n\n\treturn gfn_to_gpa(sp->gfn) + offset * sizeof(pt_element_t);\n}",
    "includes": [],
    "macros_used": [
      "#define pt_element_t u64",
      "#define pt_element_t u32",
      "#define pt_element_t u64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "gfn_to_gpa",
          "args": [
            "sp->gfn"
          ],
          "line": 826
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "sp->role.level != PT_PAGE_TABLE_LEVEL"
          ],
          "line": 821
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define pt_element_t u64\n#define pt_element_t u32\n#define pt_element_t u64\n\nstatic gpa_t FNAME(get_level1_sp_gpa)(struct kvm_mmu_page *sp)\n{\n\tint offset = 0;\n\n\tWARN_ON(sp->role.level != PT_PAGE_TABLE_LEVEL);\n\n\tif (PTTYPE == 32)\n\t\toffset = sp->role.quadrant << PT64_LEVEL_BITS;\n\n\treturn gfn_to_gpa(sp->gfn) + offset * sizeof(pt_element_t);\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
    "lines": "704-815",
    "snippet": "static int FNAME(page_fault)(struct kvm_vcpu *vcpu, gva_t addr, u32 error_code,\n\t\t\t     bool prefault)\n{\n\tint write_fault = error_code & PFERR_WRITE_MASK;\n\tint user_fault = error_code & PFERR_USER_MASK;\n\tstruct guest_walker walker;\n\tint r;\n\tkvm_pfn_t pfn;\n\tint level = PT_PAGE_TABLE_LEVEL;\n\tbool force_pt_level = false;\n\tunsigned long mmu_seq;\n\tbool map_writable, is_self_change_mapping;\n\n\tpgprintk(\"%s: addr %lx err %x\\n\", __func__, addr, error_code);\n\n\tr = mmu_topup_memory_caches(vcpu);\n\tif (r)\n\t\treturn r;\n\n\t/*\n\t * If PFEC.RSVD is set, this is a shadow page fault.\n\t * The bit needs to be cleared before walking guest page tables.\n\t */\n\terror_code &= ~PFERR_RSVD_MASK;\n\n\t/*\n\t * Look up the guest pte for the faulting address.\n\t */\n\tr = FNAME(walk_addr)(&walker, vcpu, addr, error_code);\n\n\t/*\n\t * The page is not mapped by the guest.  Let the guest handle it.\n\t */\n\tif (!r) {\n\t\tpgprintk(\"%s: guest page fault\\n\", __func__);\n\t\tif (!prefault)\n\t\t\tinject_page_fault(vcpu, &walker.fault);\n\n\t\treturn 0;\n\t}\n\n\tif (page_fault_handle_page_track(vcpu, error_code, walker.gfn)) {\n\t\tshadow_page_table_clear_flood(vcpu, addr);\n\t\treturn 1;\n\t}\n\n\tvcpu->arch.write_fault_to_shadow_pgtable = false;\n\n\tis_self_change_mapping = FNAME(is_self_change_mapping)(vcpu,\n\t      &walker, user_fault, &vcpu->arch.write_fault_to_shadow_pgtable);\n\n\tif (walker.level >= PT_DIRECTORY_LEVEL && !is_self_change_mapping) {\n\t\tlevel = mapping_level(vcpu, walker.gfn, &force_pt_level);\n\t\tif (likely(!force_pt_level)) {\n\t\t\tlevel = min(walker.level, level);\n\t\t\twalker.gfn = walker.gfn & ~(KVM_PAGES_PER_HPAGE(level) - 1);\n\t\t}\n\t} else\n\t\tforce_pt_level = true;\n\n\tmmu_seq = vcpu->kvm->mmu_notifier_seq;\n\tsmp_rmb();\n\n\tif (try_async_pf(vcpu, prefault, walker.gfn, addr, &pfn, write_fault,\n\t\t\t &map_writable))\n\t\treturn 0;\n\n\tif (handle_abnormal_pfn(vcpu, mmu_is_nested(vcpu) ? 0 : addr,\n\t\t\t\twalker.gfn, pfn, walker.pte_access, &r))\n\t\treturn r;\n\n\t/*\n\t * Do not change pte_access if the pfn is a mmio page, otherwise\n\t * we will cache the incorrect access into mmio spte.\n\t */\n\tif (write_fault && !(walker.pte_access & ACC_WRITE_MASK) &&\n\t     !is_write_protection(vcpu) && !user_fault &&\n\t      !is_noslot_pfn(pfn)) {\n\t\twalker.pte_access |= ACC_WRITE_MASK;\n\t\twalker.pte_access &= ~ACC_USER_MASK;\n\n\t\t/*\n\t\t * If we converted a user page to a kernel page,\n\t\t * so that the kernel can write to it when cr0.wp=0,\n\t\t * then we should prevent the kernel from executing it\n\t\t * if SMEP is enabled.\n\t\t */\n\t\tif (kvm_read_cr4_bits(vcpu, X86_CR4_SMEP))\n\t\t\twalker.pte_access &= ~ACC_EXEC_MASK;\n\t}\n\n\tspin_lock(&vcpu->kvm->mmu_lock);\n\tif (mmu_notifier_retry(vcpu->kvm, mmu_seq))\n\t\tgoto out_unlock;\n\n\tkvm_mmu_audit(vcpu, AUDIT_PRE_PAGE_FAULT);\n\tmake_mmu_pages_available(vcpu);\n\tif (!force_pt_level)\n\t\ttransparent_hugepage_adjust(vcpu, &walker.gfn, &pfn, &level);\n\tr = FNAME(fetch)(vcpu, addr, &walker, write_fault,\n\t\t\t level, pfn, map_writable, prefault);\n\t++vcpu->stat.pf_fixed;\n\tkvm_mmu_audit(vcpu, AUDIT_POST_PAGE_FAULT);\n\tspin_unlock(&vcpu->kvm->mmu_lock);\n\n\treturn r;\n\nout_unlock:\n\tspin_unlock(&vcpu->kvm->mmu_lock);\n\tkvm_release_pfn_clean(pfn);\n\treturn 0;\n}",
    "includes": [],
    "macros_used": [
      "#define guest_walker guest_walkerEPT",
      "#define guest_walker guest_walker32",
      "#define guest_walker guest_walker64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_release_pfn_clean",
          "args": [
            "pfn"
          ],
          "line": 813
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_unlock",
          "args": [
            "&vcpu->kvm->mmu_lock"
          ],
          "line": 812
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_unlock",
          "args": [
            "&vcpu->kvm->mmu_lock"
          ],
          "line": 807
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_mmu_audit",
          "args": [
            "vcpu",
            "AUDIT_POST_PAGE_FAULT"
          ],
          "line": 806
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_mmu_audit",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu_audit.c",
          "lines": "254-258",
          "snippet": "static inline void kvm_mmu_audit(struct kvm_vcpu *vcpu, int point)\n{\n\tif (static_key_false((&mmu_audit_key)))\n\t\t__kvm_mmu_audit(vcpu, point);\n}",
          "includes": [
            "#include <linux/ratelimit.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static struct static_key mmu_audit_key;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/ratelimit.h>\n\nstatic struct static_key mmu_audit_key;\n\nstatic inline void kvm_mmu_audit(struct kvm_vcpu *vcpu, int point)\n{\n\tif (static_key_false((&mmu_audit_key)))\n\t\t__kvm_mmu_audit(vcpu, point);\n}"
        }
      },
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "vcpu",
            "addr",
            "&walker",
            "write_fault",
            "level",
            "pfn",
            "map_writable",
            "prefault"
          ],
          "line": 803
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
          "lines": "565-648",
          "snippet": "static int FNAME(fetch)(struct kvm_vcpu *vcpu, gva_t addr,\n\t\t\t struct guest_walker *gw,\n\t\t\t int write_fault, int hlevel,\n\t\t\t kvm_pfn_t pfn, bool map_writable, bool prefault)\n{\n\tstruct kvm_mmu_page *sp = NULL;\n\tstruct kvm_shadow_walk_iterator it;\n\tunsigned direct_access, access = gw->pt_access;\n\tint top_level, emulate;\n\n\tdirect_access = gw->pte_access;\n\n\ttop_level = vcpu->arch.mmu.root_level;\n\tif (top_level == PT32E_ROOT_LEVEL)\n\t\ttop_level = PT32_ROOT_LEVEL;\n\t/*\n\t * Verify that the top-level gpte is still there.  Since the page\n\t * is a root page, it is either write protected (and cannot be\n\t * changed from now on) or it is invalid (in which case, we don't\n\t * really care if it changes underneath us after this point).\n\t */\n\tif (FNAME(gpte_changed)(vcpu, gw, top_level))\n\t\tgoto out_gpte_changed;\n\n\tif (!VALID_PAGE(vcpu->arch.mmu.root_hpa))\n\t\tgoto out_gpte_changed;\n\n\tfor (shadow_walk_init(&it, vcpu, addr);\n\t     shadow_walk_okay(&it) && it.level > gw->level;\n\t     shadow_walk_next(&it)) {\n\t\tgfn_t table_gfn;\n\n\t\tclear_sp_write_flooding_count(it.sptep);\n\t\tdrop_large_spte(vcpu, it.sptep);\n\n\t\tsp = NULL;\n\t\tif (!is_shadow_present_pte(*it.sptep)) {\n\t\t\ttable_gfn = gw->table_gfn[it.level - 2];\n\t\t\tsp = kvm_mmu_get_page(vcpu, table_gfn, addr, it.level-1,\n\t\t\t\t\t      false, access);\n\t\t}\n\n\t\t/*\n\t\t * Verify that the gpte in the page we've just write\n\t\t * protected is still there.\n\t\t */\n\t\tif (FNAME(gpte_changed)(vcpu, gw, it.level - 1))\n\t\t\tgoto out_gpte_changed;\n\n\t\tif (sp)\n\t\t\tlink_shadow_page(vcpu, it.sptep, sp);\n\t}\n\n\tfor (;\n\t     shadow_walk_okay(&it) && it.level > hlevel;\n\t     shadow_walk_next(&it)) {\n\t\tgfn_t direct_gfn;\n\n\t\tclear_sp_write_flooding_count(it.sptep);\n\t\tvalidate_direct_spte(vcpu, it.sptep, direct_access);\n\n\t\tdrop_large_spte(vcpu, it.sptep);\n\n\t\tif (is_shadow_present_pte(*it.sptep))\n\t\t\tcontinue;\n\n\t\tdirect_gfn = gw->gfn & ~(KVM_PAGES_PER_HPAGE(it.level) - 1);\n\n\t\tsp = kvm_mmu_get_page(vcpu, direct_gfn, addr, it.level-1,\n\t\t\t\t      true, direct_access);\n\t\tlink_shadow_page(vcpu, it.sptep, sp);\n\t}\n\n\tclear_sp_write_flooding_count(it.sptep);\n\temulate = mmu_set_spte(vcpu, it.sptep, gw->pte_access, write_fault,\n\t\t\t       it.level, gw->gfn, pfn, prefault, map_writable);\n\tFNAME(pte_prefetch)(vcpu, gw, it.sptep);\n\n\treturn emulate;\n\nout_gpte_changed:\n\tkvm_release_pfn_clean(pfn);\n\treturn 0;\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "transparent_hugepage_adjust",
          "args": [
            "vcpu",
            "&walker.gfn",
            "&pfn",
            "&level"
          ],
          "line": 802
        },
        "resolved": true,
        "details": {
          "function_name": "transparent_hugepage_adjust",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "2806-2846",
          "snippet": "static void transparent_hugepage_adjust(struct kvm_vcpu *vcpu,\n\t\t\t\t\tgfn_t *gfnp, kvm_pfn_t *pfnp,\n\t\t\t\t\tint *levelp)\n{\n\tkvm_pfn_t pfn = *pfnp;\n\tgfn_t gfn = *gfnp;\n\tint level = *levelp;\n\n\t/*\n\t * Check if it's a transparent hugepage. If this would be an\n\t * hugetlbfs page, level wouldn't be set to\n\t * PT_PAGE_TABLE_LEVEL and there would be no adjustment done\n\t * here.\n\t */\n\tif (!is_error_noslot_pfn(pfn) && !kvm_is_reserved_pfn(pfn) &&\n\t    level == PT_PAGE_TABLE_LEVEL &&\n\t    PageTransCompound(pfn_to_page(pfn)) &&\n\t    !mmu_gfn_lpage_is_disallowed(vcpu, gfn, PT_DIRECTORY_LEVEL)) {\n\t\tunsigned long mask;\n\t\t/*\n\t\t * mmu_notifier_retry was successful and we hold the\n\t\t * mmu_lock here, so the pmd can't become splitting\n\t\t * from under us, and in turn\n\t\t * __split_huge_page_refcount() can't run from under\n\t\t * us and we can safely transfer the refcount from\n\t\t * PG_tail to PG_head as we switch the pfn to tail to\n\t\t * head.\n\t\t */\n\t\t*levelp = level = PT_DIRECTORY_LEVEL;\n\t\tmask = KVM_PAGES_PER_HPAGE(level) - 1;\n\t\tVM_BUG_ON((gfn & mask) != (pfn & mask));\n\t\tif (pfn & mask) {\n\t\t\tgfn &= ~mask;\n\t\t\t*gfnp = gfn;\n\t\t\tkvm_release_pfn_clean(pfn);\n\t\t\tpfn &= ~mask;\n\t\t\tkvm_get_pfn(pfn);\n\t\t\t*pfnp = pfn;\n\t\t}\n\t}\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void mmu_free_roots(struct kvm_vcpu *vcpu);",
            "static void make_mmu_pages_available(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void mmu_free_roots(struct kvm_vcpu *vcpu);\nstatic void make_mmu_pages_available(struct kvm_vcpu *vcpu);\n\nstatic void transparent_hugepage_adjust(struct kvm_vcpu *vcpu,\n\t\t\t\t\tgfn_t *gfnp, kvm_pfn_t *pfnp,\n\t\t\t\t\tint *levelp)\n{\n\tkvm_pfn_t pfn = *pfnp;\n\tgfn_t gfn = *gfnp;\n\tint level = *levelp;\n\n\t/*\n\t * Check if it's a transparent hugepage. If this would be an\n\t * hugetlbfs page, level wouldn't be set to\n\t * PT_PAGE_TABLE_LEVEL and there would be no adjustment done\n\t * here.\n\t */\n\tif (!is_error_noslot_pfn(pfn) && !kvm_is_reserved_pfn(pfn) &&\n\t    level == PT_PAGE_TABLE_LEVEL &&\n\t    PageTransCompound(pfn_to_page(pfn)) &&\n\t    !mmu_gfn_lpage_is_disallowed(vcpu, gfn, PT_DIRECTORY_LEVEL)) {\n\t\tunsigned long mask;\n\t\t/*\n\t\t * mmu_notifier_retry was successful and we hold the\n\t\t * mmu_lock here, so the pmd can't become splitting\n\t\t * from under us, and in turn\n\t\t * __split_huge_page_refcount() can't run from under\n\t\t * us and we can safely transfer the refcount from\n\t\t * PG_tail to PG_head as we switch the pfn to tail to\n\t\t * head.\n\t\t */\n\t\t*levelp = level = PT_DIRECTORY_LEVEL;\n\t\tmask = KVM_PAGES_PER_HPAGE(level) - 1;\n\t\tVM_BUG_ON((gfn & mask) != (pfn & mask));\n\t\tif (pfn & mask) {\n\t\t\tgfn &= ~mask;\n\t\t\t*gfnp = gfn;\n\t\t\tkvm_release_pfn_clean(pfn);\n\t\t\tpfn &= ~mask;\n\t\t\tkvm_get_pfn(pfn);\n\t\t\t*pfnp = pfn;\n\t\t}\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "make_mmu_pages_available",
          "args": [
            "vcpu"
          ],
          "line": 800
        },
        "resolved": true,
        "details": {
          "function_name": "make_mmu_pages_available",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "4488-4502",
          "snippet": "static void make_mmu_pages_available(struct kvm_vcpu *vcpu)\n{\n\tLIST_HEAD(invalid_list);\n\n\tif (likely(kvm_mmu_available_pages(vcpu->kvm) >= KVM_MIN_FREE_MMU_PAGES))\n\t\treturn;\n\n\twhile (kvm_mmu_available_pages(vcpu->kvm) < KVM_REFILL_PAGES) {\n\t\tif (!prepare_zap_oldest_mmu_page(vcpu->kvm, &invalid_list))\n\t\t\tbreak;\n\n\t\t++vcpu->kvm->stat.mmu_recycled;\n\t}\n\tkvm_mmu_commit_zap_page(vcpu->kvm, &invalid_list);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void mmu_free_roots(struct kvm_vcpu *vcpu);",
            "static int kvm_mmu_prepare_zap_page(struct kvm *kvm, struct kvm_mmu_page *sp,\n\t\t\t\t    struct list_head *invalid_list);",
            "static void kvm_mmu_commit_zap_page(struct kvm *kvm,\n\t\t\t\t    struct list_head *invalid_list);",
            "static void make_mmu_pages_available(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void mmu_free_roots(struct kvm_vcpu *vcpu);\nstatic int kvm_mmu_prepare_zap_page(struct kvm *kvm, struct kvm_mmu_page *sp,\n\t\t\t\t    struct list_head *invalid_list);\nstatic void kvm_mmu_commit_zap_page(struct kvm *kvm,\n\t\t\t\t    struct list_head *invalid_list);\nstatic void make_mmu_pages_available(struct kvm_vcpu *vcpu);\n\nstatic void make_mmu_pages_available(struct kvm_vcpu *vcpu)\n{\n\tLIST_HEAD(invalid_list);\n\n\tif (likely(kvm_mmu_available_pages(vcpu->kvm) >= KVM_MIN_FREE_MMU_PAGES))\n\t\treturn;\n\n\twhile (kvm_mmu_available_pages(vcpu->kvm) < KVM_REFILL_PAGES) {\n\t\tif (!prepare_zap_oldest_mmu_page(vcpu->kvm, &invalid_list))\n\t\t\tbreak;\n\n\t\t++vcpu->kvm->stat.mmu_recycled;\n\t}\n\tkvm_mmu_commit_zap_page(vcpu->kvm, &invalid_list);\n}"
        }
      },
      {
        "call_info": {
          "callee": "mmu_notifier_retry",
          "args": [
            "vcpu->kvm",
            "mmu_seq"
          ],
          "line": 796
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_lock",
          "args": [
            "&vcpu->kvm->mmu_lock"
          ],
          "line": 795
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_read_cr4_bits",
          "args": [
            "vcpu",
            "X86_CR4_SMEP"
          ],
          "line": 791
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_read_cr4_bits",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/kvm_cache_regs.h",
          "lines": "61-67",
          "snippet": "static inline ulong kvm_read_cr4_bits(struct kvm_vcpu *vcpu, ulong mask)\n{\n\tulong tmask = mask & KVM_POSSIBLE_CR4_GUEST_BITS;\n\tif (tmask & vcpu->arch.cr4_guest_owned_bits)\n\t\tkvm_x86_ops->decache_cr4_guest_bits(vcpu);\n\treturn vcpu->arch.cr4 & mask;\n}",
          "includes": [],
          "macros_used": [
            "#define KVM_POSSIBLE_CR4_GUEST_BITS\t\t\t\t  \\\n\t(X86_CR4_PVI | X86_CR4_DE | X86_CR4_PCE | X86_CR4_OSFXSR  \\\n\t | X86_CR4_OSXMMEXCPT | X86_CR4_PGE)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#define KVM_POSSIBLE_CR4_GUEST_BITS\t\t\t\t  \\\n\t(X86_CR4_PVI | X86_CR4_DE | X86_CR4_PCE | X86_CR4_OSFXSR  \\\n\t | X86_CR4_OSXMMEXCPT | X86_CR4_PGE)\n\nstatic inline ulong kvm_read_cr4_bits(struct kvm_vcpu *vcpu, ulong mask)\n{\n\tulong tmask = mask & KVM_POSSIBLE_CR4_GUEST_BITS;\n\tif (tmask & vcpu->arch.cr4_guest_owned_bits)\n\t\tkvm_x86_ops->decache_cr4_guest_bits(vcpu);\n\treturn vcpu->arch.cr4 & mask;\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_noslot_pfn",
          "args": [
            "pfn"
          ],
          "line": 781
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "is_write_protection",
          "args": [
            "vcpu"
          ],
          "line": 780
        },
        "resolved": true,
        "details": {
          "function_name": "is_write_protection",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.h",
          "lines": "139-142",
          "snippet": "static inline bool is_write_protection(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_read_cr0_bits(vcpu, X86_CR0_WP);\n}",
          "includes": [
            "#include \"kvm_cache_regs.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\nstatic inline bool is_write_protection(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_read_cr0_bits(vcpu, X86_CR0_WP);\n}"
        }
      },
      {
        "call_info": {
          "callee": "handle_abnormal_pfn",
          "args": [
            "vcpu",
            "mmu_is_nested(vcpu) ? 0 : addr",
            "walker.gfn",
            "pfn",
            "walker.pte_access",
            "&r"
          ],
          "line": 771
        },
        "resolved": true,
        "details": {
          "function_name": "handle_abnormal_pfn",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "2848-2861",
          "snippet": "static bool handle_abnormal_pfn(struct kvm_vcpu *vcpu, gva_t gva, gfn_t gfn,\n\t\t\t\tkvm_pfn_t pfn, unsigned access, int *ret_val)\n{\n\t/* The pfn is invalid, report the error! */\n\tif (unlikely(is_error_pfn(pfn))) {\n\t\t*ret_val = kvm_handle_bad_page(vcpu, gfn, pfn);\n\t\treturn true;\n\t}\n\n\tif (unlikely(is_noslot_pfn(pfn)))\n\t\tvcpu_cache_mmio_info(vcpu, gva, gfn, access);\n\n\treturn false;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void mmu_free_roots(struct kvm_vcpu *vcpu);",
            "static void make_mmu_pages_available(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void mmu_free_roots(struct kvm_vcpu *vcpu);\nstatic void make_mmu_pages_available(struct kvm_vcpu *vcpu);\n\nstatic bool handle_abnormal_pfn(struct kvm_vcpu *vcpu, gva_t gva, gfn_t gfn,\n\t\t\t\tkvm_pfn_t pfn, unsigned access, int *ret_val)\n{\n\t/* The pfn is invalid, report the error! */\n\tif (unlikely(is_error_pfn(pfn))) {\n\t\t*ret_val = kvm_handle_bad_page(vcpu, gfn, pfn);\n\t\treturn true;\n\t}\n\n\tif (unlikely(is_noslot_pfn(pfn)))\n\t\tvcpu_cache_mmio_info(vcpu, gva, gfn, access);\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "mmu_is_nested",
          "args": [
            "vcpu"
          ],
          "line": 771
        },
        "resolved": true,
        "details": {
          "function_name": "mmu_is_nested",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/x86.h",
          "lines": "62-65",
          "snippet": "static inline bool mmu_is_nested(struct kvm_vcpu *vcpu)\n{\n\treturn vcpu->arch.walk_mmu == &vcpu->arch.nested_mmu;\n}",
          "includes": [
            "#include \"kvm_cache_regs.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\nstatic inline bool mmu_is_nested(struct kvm_vcpu *vcpu)\n{\n\treturn vcpu->arch.walk_mmu == &vcpu->arch.nested_mmu;\n}"
        }
      },
      {
        "call_info": {
          "callee": "try_async_pf",
          "args": [
            "vcpu",
            "prefault",
            "walker.gfn",
            "addr",
            "&pfn",
            "write_fault",
            "&map_writable"
          ],
          "line": 767
        },
        "resolved": true,
        "details": {
          "function_name": "try_async_pf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "3493-3517",
          "snippet": "static bool try_async_pf(struct kvm_vcpu *vcpu, bool prefault, gfn_t gfn,\n\t\t\t gva_t gva, kvm_pfn_t *pfn, bool write, bool *writable)\n{\n\tstruct kvm_memory_slot *slot;\n\tbool async;\n\n\tslot = kvm_vcpu_gfn_to_memslot(vcpu, gfn);\n\tasync = false;\n\t*pfn = __gfn_to_pfn_memslot(slot, gfn, false, &async, write, writable);\n\tif (!async)\n\t\treturn false; /* *pfn has correct page already */\n\n\tif (!prefault && can_do_async_pf(vcpu)) {\n\t\ttrace_kvm_try_async_get_page(gva, gfn);\n\t\tif (kvm_find_async_pf_gfn(vcpu, gfn)) {\n\t\t\ttrace_kvm_async_pf_doublefault(gva, gfn);\n\t\t\tkvm_make_request(KVM_REQ_APF_HALT, vcpu);\n\t\t\treturn true;\n\t\t} else if (kvm_arch_setup_async_pf(vcpu, gva, gfn))\n\t\t\treturn true;\n\t}\n\n\t*pfn = __gfn_to_pfn_memslot(slot, gfn, false, NULL, write, writable);\n\treturn false;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void mmu_free_roots(struct kvm_vcpu *vcpu);",
            "static bool try_async_pf(struct kvm_vcpu *vcpu, bool prefault, gfn_t gfn,\n\t\t\t gva_t gva, kvm_pfn_t *pfn, bool write, bool *writable);",
            "static void make_mmu_pages_available(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void mmu_free_roots(struct kvm_vcpu *vcpu);\nstatic bool try_async_pf(struct kvm_vcpu *vcpu, bool prefault, gfn_t gfn,\n\t\t\t gva_t gva, kvm_pfn_t *pfn, bool write, bool *writable);\nstatic void make_mmu_pages_available(struct kvm_vcpu *vcpu);\n\nstatic bool try_async_pf(struct kvm_vcpu *vcpu, bool prefault, gfn_t gfn,\n\t\t\t gva_t gva, kvm_pfn_t *pfn, bool write, bool *writable)\n{\n\tstruct kvm_memory_slot *slot;\n\tbool async;\n\n\tslot = kvm_vcpu_gfn_to_memslot(vcpu, gfn);\n\tasync = false;\n\t*pfn = __gfn_to_pfn_memslot(slot, gfn, false, &async, write, writable);\n\tif (!async)\n\t\treturn false; /* *pfn has correct page already */\n\n\tif (!prefault && can_do_async_pf(vcpu)) {\n\t\ttrace_kvm_try_async_get_page(gva, gfn);\n\t\tif (kvm_find_async_pf_gfn(vcpu, gfn)) {\n\t\t\ttrace_kvm_async_pf_doublefault(gva, gfn);\n\t\t\tkvm_make_request(KVM_REQ_APF_HALT, vcpu);\n\t\t\treturn true;\n\t\t} else if (kvm_arch_setup_async_pf(vcpu, gva, gfn))\n\t\t\treturn true;\n\t}\n\n\t*pfn = __gfn_to_pfn_memslot(slot, gfn, false, NULL, write, writable);\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "smp_rmb",
          "args": [],
          "line": 765
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "KVM_PAGES_PER_HPAGE",
          "args": [
            "level"
          ],
          "line": 759
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "min",
          "args": [
            "walker.level",
            "level"
          ],
          "line": 758
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "!force_pt_level"
          ],
          "line": 757
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mapping_level",
          "args": [
            "vcpu",
            "walker.gfn",
            "&force_pt_level"
          ],
          "line": 756
        },
        "resolved": true,
        "details": {
          "function_name": "mapping_level",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "909-935",
          "snippet": "static int mapping_level(struct kvm_vcpu *vcpu, gfn_t large_gfn,\n\t\t\t bool *force_pt_level)\n{\n\tint host_level, level, max_level;\n\tstruct kvm_memory_slot *slot;\n\n\tif (unlikely(*force_pt_level))\n\t\treturn PT_PAGE_TABLE_LEVEL;\n\n\tslot = kvm_vcpu_gfn_to_memslot(vcpu, large_gfn);\n\t*force_pt_level = !memslot_valid_for_gpte(slot, true);\n\tif (unlikely(*force_pt_level))\n\t\treturn PT_PAGE_TABLE_LEVEL;\n\n\thost_level = host_mapping_level(vcpu->kvm, large_gfn);\n\n\tif (host_level == PT_PAGE_TABLE_LEVEL)\n\t\treturn host_level;\n\n\tmax_level = min(kvm_x86_ops->get_lpage_level(), host_level);\n\n\tfor (level = PT_DIRECTORY_LEVEL; level <= max_level; ++level)\n\t\tif (__mmu_gfn_lpage_is_disallowed(large_gfn, level, slot))\n\t\t\tbreak;\n\n\treturn level - 1;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void mmu_free_roots(struct kvm_vcpu *vcpu);",
            "static void make_mmu_pages_available(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void mmu_free_roots(struct kvm_vcpu *vcpu);\nstatic void make_mmu_pages_available(struct kvm_vcpu *vcpu);\n\nstatic int mapping_level(struct kvm_vcpu *vcpu, gfn_t large_gfn,\n\t\t\t bool *force_pt_level)\n{\n\tint host_level, level, max_level;\n\tstruct kvm_memory_slot *slot;\n\n\tif (unlikely(*force_pt_level))\n\t\treturn PT_PAGE_TABLE_LEVEL;\n\n\tslot = kvm_vcpu_gfn_to_memslot(vcpu, large_gfn);\n\t*force_pt_level = !memslot_valid_for_gpte(slot, true);\n\tif (unlikely(*force_pt_level))\n\t\treturn PT_PAGE_TABLE_LEVEL;\n\n\thost_level = host_mapping_level(vcpu->kvm, large_gfn);\n\n\tif (host_level == PT_PAGE_TABLE_LEVEL)\n\t\treturn host_level;\n\n\tmax_level = min(kvm_x86_ops->get_lpage_level(), host_level);\n\n\tfor (level = PT_DIRECTORY_LEVEL; level <= max_level; ++level)\n\t\tif (__mmu_gfn_lpage_is_disallowed(large_gfn, level, slot))\n\t\t\tbreak;\n\n\treturn level - 1;\n}"
        }
      },
      {
        "call_info": {
          "callee": "shadow_page_table_clear_flood",
          "args": [
            "vcpu",
            "addr"
          ],
          "line": 746
        },
        "resolved": true,
        "details": {
          "function_name": "shadow_page_table_clear_flood",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "3433-3448",
          "snippet": "static void shadow_page_table_clear_flood(struct kvm_vcpu *vcpu, gva_t addr)\n{\n\tstruct kvm_shadow_walk_iterator iterator;\n\tu64 spte;\n\n\tif (!VALID_PAGE(vcpu->arch.mmu.root_hpa))\n\t\treturn;\n\n\twalk_shadow_page_lockless_begin(vcpu);\n\tfor_each_shadow_entry_lockless(vcpu, addr, iterator, spte) {\n\t\tclear_sp_write_flooding_count(iterator.sptep);\n\t\tif (!is_shadow_present_pte(spte))\n\t\t\tbreak;\n\t}\n\twalk_shadow_page_lockless_end(vcpu);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void mmu_spte_set(u64 *sptep, u64 spte);",
            "static void mmu_free_roots(struct kvm_vcpu *vcpu);",
            "static void mark_unsync(u64 *spte);",
            "static void make_mmu_pages_available(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void mmu_spte_set(u64 *sptep, u64 spte);\nstatic void mmu_free_roots(struct kvm_vcpu *vcpu);\nstatic void mark_unsync(u64 *spte);\nstatic void make_mmu_pages_available(struct kvm_vcpu *vcpu);\n\nstatic void shadow_page_table_clear_flood(struct kvm_vcpu *vcpu, gva_t addr)\n{\n\tstruct kvm_shadow_walk_iterator iterator;\n\tu64 spte;\n\n\tif (!VALID_PAGE(vcpu->arch.mmu.root_hpa))\n\t\treturn;\n\n\twalk_shadow_page_lockless_begin(vcpu);\n\tfor_each_shadow_entry_lockless(vcpu, addr, iterator, spte) {\n\t\tclear_sp_write_flooding_count(iterator.sptep);\n\t\tif (!is_shadow_present_pte(spte))\n\t\t\tbreak;\n\t}\n\twalk_shadow_page_lockless_end(vcpu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "page_fault_handle_page_track",
          "args": [
            "vcpu",
            "error_code",
            "walker.gfn"
          ],
          "line": 745
        },
        "resolved": true,
        "details": {
          "function_name": "page_fault_handle_page_track",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "3413-3431",
          "snippet": "static bool page_fault_handle_page_track(struct kvm_vcpu *vcpu,\n\t\t\t\t\t u32 error_code, gfn_t gfn)\n{\n\tif (unlikely(error_code & PFERR_RSVD_MASK))\n\t\treturn false;\n\n\tif (!(error_code & PFERR_PRESENT_MASK) ||\n\t      !(error_code & PFERR_WRITE_MASK))\n\t\treturn false;\n\n\t/*\n\t * guest is writing the page which is write tracked which can\n\t * not be fixed by page fault handler.\n\t */\n\tif (kvm_page_track_is_active(vcpu, gfn, KVM_PAGE_TRACK_WRITE))\n\t\treturn true;\n\n\treturn false;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void mmu_free_roots(struct kvm_vcpu *vcpu);",
            "static void make_mmu_pages_available(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void mmu_free_roots(struct kvm_vcpu *vcpu);\nstatic void make_mmu_pages_available(struct kvm_vcpu *vcpu);\n\nstatic bool page_fault_handle_page_track(struct kvm_vcpu *vcpu,\n\t\t\t\t\t u32 error_code, gfn_t gfn)\n{\n\tif (unlikely(error_code & PFERR_RSVD_MASK))\n\t\treturn false;\n\n\tif (!(error_code & PFERR_PRESENT_MASK) ||\n\t      !(error_code & PFERR_WRITE_MASK))\n\t\treturn false;\n\n\t/*\n\t * guest is writing the page which is write tracked which can\n\t * not be fixed by page fault handler.\n\t */\n\tif (kvm_page_track_is_active(vcpu, gfn, KVM_PAGE_TRACK_WRITE))\n\t\treturn true;\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "inject_page_fault",
          "args": [
            "vcpu",
            "&walker.fault"
          ],
          "line": 740
        },
        "resolved": true,
        "details": {
          "function_name": "vmx_inject_page_fault_nested",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/vmx.c",
          "lines": "9141-9154",
          "snippet": "static void vmx_inject_page_fault_nested(struct kvm_vcpu *vcpu,\n\t\tstruct x86_exception *fault)\n{\n\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\n\tWARN_ON(!is_guest_mode(vcpu));\n\n\tif (nested_vmx_is_page_fault_vmexit(vmcs12, fault->error_code))\n\t\tnested_vmx_vmexit(vcpu, to_vmx(vcpu)->exit_reason,\n\t\t\t\t  vmcs_read32(VM_EXIT_INTR_INFO),\n\t\t\t\t  vmcs_readl(EXIT_QUALIFICATION));\n\telse\n\t\tkvm_inject_page_fault(vcpu, fault);\n}",
          "includes": [
            "#include \"pmu.h\"",
            "#include \"trace.h\"",
            "#include <asm/irq_remapping.h>",
            "#include <asm/apic.h>",
            "#include <asm/kexec.h>",
            "#include <asm/debugreg.h>",
            "#include <asm/perf_event.h>",
            "#include <asm/fpu/internal.h>",
            "#include <asm/mce.h>",
            "#include <asm/virtext.h>",
            "#include <asm/vmx.h>",
            "#include <asm/desc.h>",
            "#include <asm/io.h>",
            "#include <asm/cpu.h>",
            "#include \"x86.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include <linux/hrtimer.h>",
            "#include <linux/tboot.h>",
            "#include <linux/slab.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/mod_devicetable.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/sched.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/kernel.h>",
            "#include <linux/module.h>",
            "#include <linux/kvm_host.h>",
            "#include \"lapic.h\"",
            "#include \"cpuid.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static unsigned long nested_ept_get_cr3(struct kvm_vcpu *vcpu);",
            "static bool guest_state_valid(struct kvm_vcpu *vcpu);",
            "static void ept_save_pdptrs(struct kvm_vcpu *vcpu);",
            "static void vmx_decache_cr0_guest_bits(struct kvm_vcpu *vcpu);",
            "static void vmx_leave_nested(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include <asm/irq_remapping.h>\n#include <asm/apic.h>\n#include <asm/kexec.h>\n#include <asm/debugreg.h>\n#include <asm/perf_event.h>\n#include <asm/fpu/internal.h>\n#include <asm/mce.h>\n#include <asm/virtext.h>\n#include <asm/vmx.h>\n#include <asm/desc.h>\n#include <asm/io.h>\n#include <asm/cpu.h>\n#include \"x86.h\"\n#include \"kvm_cache_regs.h\"\n#include <linux/hrtimer.h>\n#include <linux/tboot.h>\n#include <linux/slab.h>\n#include <linux/trace_events.h>\n#include <linux/mod_devicetable.h>\n#include <linux/moduleparam.h>\n#include <linux/sched.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/kvm_host.h>\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic unsigned long nested_ept_get_cr3(struct kvm_vcpu *vcpu);\nstatic bool guest_state_valid(struct kvm_vcpu *vcpu);\nstatic void ept_save_pdptrs(struct kvm_vcpu *vcpu);\nstatic void vmx_decache_cr0_guest_bits(struct kvm_vcpu *vcpu);\nstatic void vmx_leave_nested(struct kvm_vcpu *vcpu);\n\nstatic void vmx_inject_page_fault_nested(struct kvm_vcpu *vcpu,\n\t\tstruct x86_exception *fault)\n{\n\tstruct vmcs12 *vmcs12 = get_vmcs12(vcpu);\n\n\tWARN_ON(!is_guest_mode(vcpu));\n\n\tif (nested_vmx_is_page_fault_vmexit(vmcs12, fault->error_code))\n\t\tnested_vmx_vmexit(vcpu, to_vmx(vcpu)->exit_reason,\n\t\t\t\t  vmcs_read32(VM_EXIT_INTR_INFO),\n\t\t\t\t  vmcs_readl(EXIT_QUALIFICATION));\n\telse\n\t\tkvm_inject_page_fault(vcpu, fault);\n}"
        }
      },
      {
        "call_info": {
          "callee": "pgprintk",
          "args": [
            "\"%s: guest page fault\\n\"",
            "__func__"
          ],
          "line": 738
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mmu_topup_memory_caches",
          "args": [
            "vcpu"
          ],
          "line": 719
        },
        "resolved": true,
        "details": {
          "function_name": "mmu_topup_memory_caches",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "712-727",
          "snippet": "static int mmu_topup_memory_caches(struct kvm_vcpu *vcpu)\n{\n\tint r;\n\n\tr = mmu_topup_memory_cache(&vcpu->arch.mmu_pte_list_desc_cache,\n\t\t\t\t   pte_list_desc_cache, 8 + PTE_PREFETCH_NUM);\n\tif (r)\n\t\tgoto out;\n\tr = mmu_topup_memory_cache_page(&vcpu->arch.mmu_page_cache, 8);\n\tif (r)\n\t\tgoto out;\n\tr = mmu_topup_memory_cache(&vcpu->arch.mmu_page_header_cache,\n\t\t\t\t   mmu_page_header_cache, 4);\nout:\n\treturn r;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [
            "#define PTE_PREFETCH_NUM\t\t8"
          ],
          "globals_used": [
            "static struct kmem_cache *pte_list_desc_cache;",
            "static struct kmem_cache *mmu_page_header_cache;",
            "static void mmu_free_roots(struct kvm_vcpu *vcpu);",
            "static void make_mmu_pages_available(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\n#define PTE_PREFETCH_NUM\t\t8\n\nstatic struct kmem_cache *pte_list_desc_cache;\nstatic struct kmem_cache *mmu_page_header_cache;\nstatic void mmu_free_roots(struct kvm_vcpu *vcpu);\nstatic void make_mmu_pages_available(struct kvm_vcpu *vcpu);\n\nstatic int mmu_topup_memory_caches(struct kvm_vcpu *vcpu)\n{\n\tint r;\n\n\tr = mmu_topup_memory_cache(&vcpu->arch.mmu_pte_list_desc_cache,\n\t\t\t\t   pte_list_desc_cache, 8 + PTE_PREFETCH_NUM);\n\tif (r)\n\t\tgoto out;\n\tr = mmu_topup_memory_cache_page(&vcpu->arch.mmu_page_cache, 8);\n\tif (r)\n\t\tgoto out;\n\tr = mmu_topup_memory_cache(&vcpu->arch.mmu_page_header_cache,\n\t\t\t\t   mmu_page_header_cache, 4);\nout:\n\treturn r;\n}"
        }
      },
      {
        "call_info": {
          "callee": "pgprintk",
          "args": [
            "\"%s: addr %lx err %x\\n\"",
            "__func__",
            "addr",
            "error_code"
          ],
          "line": 717
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define guest_walker guest_walkerEPT\n#define guest_walker guest_walker32\n#define guest_walker guest_walker64\n\nstatic int FNAME(page_fault)(struct kvm_vcpu *vcpu, gva_t addr, u32 error_code,\n\t\t\t     bool prefault)\n{\n\tint write_fault = error_code & PFERR_WRITE_MASK;\n\tint user_fault = error_code & PFERR_USER_MASK;\n\tstruct guest_walker walker;\n\tint r;\n\tkvm_pfn_t pfn;\n\tint level = PT_PAGE_TABLE_LEVEL;\n\tbool force_pt_level = false;\n\tunsigned long mmu_seq;\n\tbool map_writable, is_self_change_mapping;\n\n\tpgprintk(\"%s: addr %lx err %x\\n\", __func__, addr, error_code);\n\n\tr = mmu_topup_memory_caches(vcpu);\n\tif (r)\n\t\treturn r;\n\n\t/*\n\t * If PFEC.RSVD is set, this is a shadow page fault.\n\t * The bit needs to be cleared before walking guest page tables.\n\t */\n\terror_code &= ~PFERR_RSVD_MASK;\n\n\t/*\n\t * Look up the guest pte for the faulting address.\n\t */\n\tr = FNAME(walk_addr)(&walker, vcpu, addr, error_code);\n\n\t/*\n\t * The page is not mapped by the guest.  Let the guest handle it.\n\t */\n\tif (!r) {\n\t\tpgprintk(\"%s: guest page fault\\n\", __func__);\n\t\tif (!prefault)\n\t\t\tinject_page_fault(vcpu, &walker.fault);\n\n\t\treturn 0;\n\t}\n\n\tif (page_fault_handle_page_track(vcpu, error_code, walker.gfn)) {\n\t\tshadow_page_table_clear_flood(vcpu, addr);\n\t\treturn 1;\n\t}\n\n\tvcpu->arch.write_fault_to_shadow_pgtable = false;\n\n\tis_self_change_mapping = FNAME(is_self_change_mapping)(vcpu,\n\t      &walker, user_fault, &vcpu->arch.write_fault_to_shadow_pgtable);\n\n\tif (walker.level >= PT_DIRECTORY_LEVEL && !is_self_change_mapping) {\n\t\tlevel = mapping_level(vcpu, walker.gfn, &force_pt_level);\n\t\tif (likely(!force_pt_level)) {\n\t\t\tlevel = min(walker.level, level);\n\t\t\twalker.gfn = walker.gfn & ~(KVM_PAGES_PER_HPAGE(level) - 1);\n\t\t}\n\t} else\n\t\tforce_pt_level = true;\n\n\tmmu_seq = vcpu->kvm->mmu_notifier_seq;\n\tsmp_rmb();\n\n\tif (try_async_pf(vcpu, prefault, walker.gfn, addr, &pfn, write_fault,\n\t\t\t &map_writable))\n\t\treturn 0;\n\n\tif (handle_abnormal_pfn(vcpu, mmu_is_nested(vcpu) ? 0 : addr,\n\t\t\t\twalker.gfn, pfn, walker.pte_access, &r))\n\t\treturn r;\n\n\t/*\n\t * Do not change pte_access if the pfn is a mmio page, otherwise\n\t * we will cache the incorrect access into mmio spte.\n\t */\n\tif (write_fault && !(walker.pte_access & ACC_WRITE_MASK) &&\n\t     !is_write_protection(vcpu) && !user_fault &&\n\t      !is_noslot_pfn(pfn)) {\n\t\twalker.pte_access |= ACC_WRITE_MASK;\n\t\twalker.pte_access &= ~ACC_USER_MASK;\n\n\t\t/*\n\t\t * If we converted a user page to a kernel page,\n\t\t * so that the kernel can write to it when cr0.wp=0,\n\t\t * then we should prevent the kernel from executing it\n\t\t * if SMEP is enabled.\n\t\t */\n\t\tif (kvm_read_cr4_bits(vcpu, X86_CR4_SMEP))\n\t\t\twalker.pte_access &= ~ACC_EXEC_MASK;\n\t}\n\n\tspin_lock(&vcpu->kvm->mmu_lock);\n\tif (mmu_notifier_retry(vcpu->kvm, mmu_seq))\n\t\tgoto out_unlock;\n\n\tkvm_mmu_audit(vcpu, AUDIT_PRE_PAGE_FAULT);\n\tmake_mmu_pages_available(vcpu);\n\tif (!force_pt_level)\n\t\ttransparent_hugepage_adjust(vcpu, &walker.gfn, &pfn, &level);\n\tr = FNAME(fetch)(vcpu, addr, &walker, write_fault,\n\t\t\t level, pfn, map_writable, prefault);\n\t++vcpu->stat.pf_fixed;\n\tkvm_mmu_audit(vcpu, AUDIT_POST_PAGE_FAULT);\n\tspin_unlock(&vcpu->kvm->mmu_lock);\n\n\treturn r;\n\nout_unlock:\n\tspin_unlock(&vcpu->kvm->mmu_lock);\n\tkvm_release_pfn_clean(pfn);\n\treturn 0;\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
    "lines": "667-688",
    "snippet": "static bool\nFNAME(is_self_change_mapping)(struct kvm_vcpu *vcpu,\n\t\t\t      struct guest_walker *walker, int user_fault,\n\t\t\t      bool *write_fault_to_shadow_pgtable)\n{\n\tint level;\n\tgfn_t mask = ~(KVM_PAGES_PER_HPAGE(walker->level) - 1);\n\tbool self_changed = false;\n\n\tif (!(walker->pte_access & ACC_WRITE_MASK ||\n\t      (!is_write_protection(vcpu) && !user_fault)))\n\t\treturn false;\n\n\tfor (level = walker->level; level <= walker->max_level; level++) {\n\t\tgfn_t gfn = walker->gfn ^ walker->table_gfn[level - 1];\n\n\t\tself_changed |= !(gfn & mask);\n\t\t*write_fault_to_shadow_pgtable |= !gfn;\n\t}\n\n\treturn self_changed;\n}",
    "includes": [],
    "macros_used": [
      "#define guest_walker guest_walkerEPT",
      "#define guest_walker guest_walker32",
      "#define guest_walker guest_walker64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "is_write_protection",
          "args": [
            "vcpu"
          ],
          "line": 677
        },
        "resolved": true,
        "details": {
          "function_name": "is_write_protection",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.h",
          "lines": "139-142",
          "snippet": "static inline bool is_write_protection(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_read_cr0_bits(vcpu, X86_CR0_WP);\n}",
          "includes": [
            "#include \"kvm_cache_regs.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\nstatic inline bool is_write_protection(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_read_cr0_bits(vcpu, X86_CR0_WP);\n}"
        }
      },
      {
        "call_info": {
          "callee": "KVM_PAGES_PER_HPAGE",
          "args": [
            "walker->level"
          ],
          "line": 673
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define guest_walker guest_walkerEPT\n#define guest_walker guest_walker32\n#define guest_walker guest_walker64\n\nstatic bool\nFNAME(is_self_change_mapping)(struct kvm_vcpu *vcpu,\n\t\t\t      struct guest_walker *walker, int user_fault,\n\t\t\t      bool *write_fault_to_shadow_pgtable)\n{\n\tint level;\n\tgfn_t mask = ~(KVM_PAGES_PER_HPAGE(walker->level) - 1);\n\tbool self_changed = false;\n\n\tif (!(walker->pte_access & ACC_WRITE_MASK ||\n\t      (!is_write_protection(vcpu) && !user_fault)))\n\t\treturn false;\n\n\tfor (level = walker->level; level <= walker->max_level; level++) {\n\t\tgfn_t gfn = walker->gfn ^ walker->table_gfn[level - 1];\n\n\t\tself_changed |= !(gfn & mask);\n\t\t*write_fault_to_shadow_pgtable |= !gfn;\n\t}\n\n\treturn self_changed;\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
    "lines": "565-648",
    "snippet": "static int FNAME(fetch)(struct kvm_vcpu *vcpu, gva_t addr,\n\t\t\t struct guest_walker *gw,\n\t\t\t int write_fault, int hlevel,\n\t\t\t kvm_pfn_t pfn, bool map_writable, bool prefault)\n{\n\tstruct kvm_mmu_page *sp = NULL;\n\tstruct kvm_shadow_walk_iterator it;\n\tunsigned direct_access, access = gw->pt_access;\n\tint top_level, emulate;\n\n\tdirect_access = gw->pte_access;\n\n\ttop_level = vcpu->arch.mmu.root_level;\n\tif (top_level == PT32E_ROOT_LEVEL)\n\t\ttop_level = PT32_ROOT_LEVEL;\n\t/*\n\t * Verify that the top-level gpte is still there.  Since the page\n\t * is a root page, it is either write protected (and cannot be\n\t * changed from now on) or it is invalid (in which case, we don't\n\t * really care if it changes underneath us after this point).\n\t */\n\tif (FNAME(gpte_changed)(vcpu, gw, top_level))\n\t\tgoto out_gpte_changed;\n\n\tif (!VALID_PAGE(vcpu->arch.mmu.root_hpa))\n\t\tgoto out_gpte_changed;\n\n\tfor (shadow_walk_init(&it, vcpu, addr);\n\t     shadow_walk_okay(&it) && it.level > gw->level;\n\t     shadow_walk_next(&it)) {\n\t\tgfn_t table_gfn;\n\n\t\tclear_sp_write_flooding_count(it.sptep);\n\t\tdrop_large_spte(vcpu, it.sptep);\n\n\t\tsp = NULL;\n\t\tif (!is_shadow_present_pte(*it.sptep)) {\n\t\t\ttable_gfn = gw->table_gfn[it.level - 2];\n\t\t\tsp = kvm_mmu_get_page(vcpu, table_gfn, addr, it.level-1,\n\t\t\t\t\t      false, access);\n\t\t}\n\n\t\t/*\n\t\t * Verify that the gpte in the page we've just write\n\t\t * protected is still there.\n\t\t */\n\t\tif (FNAME(gpte_changed)(vcpu, gw, it.level - 1))\n\t\t\tgoto out_gpte_changed;\n\n\t\tif (sp)\n\t\t\tlink_shadow_page(vcpu, it.sptep, sp);\n\t}\n\n\tfor (;\n\t     shadow_walk_okay(&it) && it.level > hlevel;\n\t     shadow_walk_next(&it)) {\n\t\tgfn_t direct_gfn;\n\n\t\tclear_sp_write_flooding_count(it.sptep);\n\t\tvalidate_direct_spte(vcpu, it.sptep, direct_access);\n\n\t\tdrop_large_spte(vcpu, it.sptep);\n\n\t\tif (is_shadow_present_pte(*it.sptep))\n\t\t\tcontinue;\n\n\t\tdirect_gfn = gw->gfn & ~(KVM_PAGES_PER_HPAGE(it.level) - 1);\n\n\t\tsp = kvm_mmu_get_page(vcpu, direct_gfn, addr, it.level-1,\n\t\t\t\t      true, direct_access);\n\t\tlink_shadow_page(vcpu, it.sptep, sp);\n\t}\n\n\tclear_sp_write_flooding_count(it.sptep);\n\temulate = mmu_set_spte(vcpu, it.sptep, gw->pte_access, write_fault,\n\t\t\t       it.level, gw->gfn, pfn, prefault, map_writable);\n\tFNAME(pte_prefetch)(vcpu, gw, it.sptep);\n\n\treturn emulate;\n\nout_gpte_changed:\n\tkvm_release_pfn_clean(pfn);\n\treturn 0;\n}",
    "includes": [],
    "macros_used": [
      "#define guest_walker guest_walkerEPT",
      "#define guest_walker guest_walker32",
      "#define guest_walker guest_walker64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_release_pfn_clean",
          "args": [
            "pfn"
          ],
          "line": 646
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "vcpu",
            "gw",
            "it.sptep"
          ],
          "line": 641
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
          "lines": "529-558",
          "snippet": "static void FNAME(pte_prefetch)(struct kvm_vcpu *vcpu, struct guest_walker *gw,\n\t\t\t\tu64 *sptep)\n{\n\tstruct kvm_mmu_page *sp;\n\tpt_element_t *gptep = gw->prefetch_ptes;\n\tu64 *spte;\n\tint i;\n\n\tsp = page_header(__pa(sptep));\n\n\tif (sp->role.level > PT_PAGE_TABLE_LEVEL)\n\t\treturn;\n\n\tif (sp->role.direct)\n\t\treturn __direct_pte_prefetch(vcpu, sp, sptep);\n\n\ti = (sptep - sp->spt) & ~(PTE_PREFETCH_NUM - 1);\n\tspte = sp->spt + i;\n\n\tfor (i = 0; i < PTE_PREFETCH_NUM; i++, spte++) {\n\t\tif (spte == sptep)\n\t\t\tcontinue;\n\n\t\tif (is_shadow_present_pte(*spte))\n\t\t\tcontinue;\n\n\t\tif (!FNAME(prefetch_gpte)(vcpu, sp, spte, gptep[i], true))\n\t\t\tbreak;\n\t}\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "mmu_set_spte",
          "args": [
            "vcpu",
            "it.sptep",
            "gw->pte_access",
            "write_fault",
            "it.level",
            "gw->gfn",
            "pfn",
            "prefault",
            "map_writable"
          ],
          "line": 639
        },
        "resolved": true,
        "details": {
          "function_name": "mmu_set_spte",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "2593-2655",
          "snippet": "static bool mmu_set_spte(struct kvm_vcpu *vcpu, u64 *sptep, unsigned pte_access,\n\t\t\t int write_fault, int level, gfn_t gfn, kvm_pfn_t pfn,\n\t\t\t bool speculative, bool host_writable)\n{\n\tint was_rmapped = 0;\n\tint rmap_count;\n\tbool emulate = false;\n\n\tpgprintk(\"%s: spte %llx write_fault %d gfn %llx\\n\", __func__,\n\t\t *sptep, write_fault, gfn);\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\t/*\n\t\t * If we overwrite a PTE page pointer with a 2MB PMD, unlink\n\t\t * the parent of the now unreachable PTE.\n\t\t */\n\t\tif (level > PT_PAGE_TABLE_LEVEL &&\n\t\t    !is_large_pte(*sptep)) {\n\t\t\tstruct kvm_mmu_page *child;\n\t\t\tu64 pte = *sptep;\n\n\t\t\tchild = page_header(pte & PT64_BASE_ADDR_MASK);\n\t\t\tdrop_parent_pte(child, sptep);\n\t\t\tkvm_flush_remote_tlbs(vcpu->kvm);\n\t\t} else if (pfn != spte_to_pfn(*sptep)) {\n\t\t\tpgprintk(\"hfn old %llx new %llx\\n\",\n\t\t\t\t spte_to_pfn(*sptep), pfn);\n\t\t\tdrop_spte(vcpu->kvm, sptep);\n\t\t\tkvm_flush_remote_tlbs(vcpu->kvm);\n\t\t} else\n\t\t\twas_rmapped = 1;\n\t}\n\n\tif (set_spte(vcpu, sptep, pte_access, level, gfn, pfn, speculative,\n\t      true, host_writable)) {\n\t\tif (write_fault)\n\t\t\temulate = true;\n\t\tkvm_make_request(KVM_REQ_TLB_FLUSH, vcpu);\n\t}\n\n\tif (unlikely(is_mmio_spte(*sptep)))\n\t\temulate = true;\n\n\tpgprintk(\"%s: setting spte %llx\\n\", __func__, *sptep);\n\tpgprintk(\"instantiating %s PTE (%s) at %llx (%llx) addr %p\\n\",\n\t\t is_large_pte(*sptep)? \"2MB\" : \"4kB\",\n\t\t *sptep & PT_PRESENT_MASK ?\"RW\":\"R\", gfn,\n\t\t *sptep, sptep);\n\tif (!was_rmapped && is_large_pte(*sptep))\n\t\t++vcpu->kvm->stat.lpages;\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\tif (!was_rmapped) {\n\t\t\trmap_count = rmap_add(vcpu, sptep, gfn);\n\t\t\tif (rmap_count > RMAP_RECYCLE_THRESHOLD)\n\t\t\t\trmap_recycle(vcpu, sptep, gfn);\n\t\t}\n\t}\n\n\tkvm_release_pfn_clean(pfn);\n\n\treturn emulate;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [
            "#define RMAP_RECYCLE_THRESHOLD 1000",
            "#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))"
          ],
          "globals_used": [
            "static void mmu_spte_set(u64 *sptep, u64 spte);",
            "static void mmu_free_roots(struct kvm_vcpu *vcpu);",
            "static void mark_unsync(u64 *spte);",
            "static void make_mmu_pages_available(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\n#define RMAP_RECYCLE_THRESHOLD 1000\n#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))\n\nstatic void mmu_spte_set(u64 *sptep, u64 spte);\nstatic void mmu_free_roots(struct kvm_vcpu *vcpu);\nstatic void mark_unsync(u64 *spte);\nstatic void make_mmu_pages_available(struct kvm_vcpu *vcpu);\n\nstatic bool mmu_set_spte(struct kvm_vcpu *vcpu, u64 *sptep, unsigned pte_access,\n\t\t\t int write_fault, int level, gfn_t gfn, kvm_pfn_t pfn,\n\t\t\t bool speculative, bool host_writable)\n{\n\tint was_rmapped = 0;\n\tint rmap_count;\n\tbool emulate = false;\n\n\tpgprintk(\"%s: spte %llx write_fault %d gfn %llx\\n\", __func__,\n\t\t *sptep, write_fault, gfn);\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\t/*\n\t\t * If we overwrite a PTE page pointer with a 2MB PMD, unlink\n\t\t * the parent of the now unreachable PTE.\n\t\t */\n\t\tif (level > PT_PAGE_TABLE_LEVEL &&\n\t\t    !is_large_pte(*sptep)) {\n\t\t\tstruct kvm_mmu_page *child;\n\t\t\tu64 pte = *sptep;\n\n\t\t\tchild = page_header(pte & PT64_BASE_ADDR_MASK);\n\t\t\tdrop_parent_pte(child, sptep);\n\t\t\tkvm_flush_remote_tlbs(vcpu->kvm);\n\t\t} else if (pfn != spte_to_pfn(*sptep)) {\n\t\t\tpgprintk(\"hfn old %llx new %llx\\n\",\n\t\t\t\t spte_to_pfn(*sptep), pfn);\n\t\t\tdrop_spte(vcpu->kvm, sptep);\n\t\t\tkvm_flush_remote_tlbs(vcpu->kvm);\n\t\t} else\n\t\t\twas_rmapped = 1;\n\t}\n\n\tif (set_spte(vcpu, sptep, pte_access, level, gfn, pfn, speculative,\n\t      true, host_writable)) {\n\t\tif (write_fault)\n\t\t\temulate = true;\n\t\tkvm_make_request(KVM_REQ_TLB_FLUSH, vcpu);\n\t}\n\n\tif (unlikely(is_mmio_spte(*sptep)))\n\t\temulate = true;\n\n\tpgprintk(\"%s: setting spte %llx\\n\", __func__, *sptep);\n\tpgprintk(\"instantiating %s PTE (%s) at %llx (%llx) addr %p\\n\",\n\t\t is_large_pte(*sptep)? \"2MB\" : \"4kB\",\n\t\t *sptep & PT_PRESENT_MASK ?\"RW\":\"R\", gfn,\n\t\t *sptep, sptep);\n\tif (!was_rmapped && is_large_pte(*sptep))\n\t\t++vcpu->kvm->stat.lpages;\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\tif (!was_rmapped) {\n\t\t\trmap_count = rmap_add(vcpu, sptep, gfn);\n\t\t\tif (rmap_count > RMAP_RECYCLE_THRESHOLD)\n\t\t\t\trmap_recycle(vcpu, sptep, gfn);\n\t\t}\n\t}\n\n\tkvm_release_pfn_clean(pfn);\n\n\treturn emulate;\n}"
        }
      },
      {
        "call_info": {
          "callee": "clear_sp_write_flooding_count",
          "args": [
            "it.sptep"
          ],
          "line": 638
        },
        "resolved": true,
        "details": {
          "function_name": "clear_sp_write_flooding_count",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "2105-2110",
          "snippet": "static void clear_sp_write_flooding_count(u64 *spte)\n{\n\tstruct kvm_mmu_page *sp =  page_header(__pa(spte));\n\n\t__clear_sp_write_flooding_count(sp);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void mmu_spte_set(u64 *sptep, u64 spte);",
            "static void mark_unsync(u64 *spte);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void mmu_spte_set(u64 *sptep, u64 spte);\nstatic void mark_unsync(u64 *spte);\n\nstatic void clear_sp_write_flooding_count(u64 *spte)\n{\n\tstruct kvm_mmu_page *sp =  page_header(__pa(spte));\n\n\t__clear_sp_write_flooding_count(sp);\n}"
        }
      },
      {
        "call_info": {
          "callee": "link_shadow_page",
          "args": [
            "vcpu",
            "it.sptep",
            "sp"
          ],
          "line": 635
        },
        "resolved": true,
        "details": {
          "function_name": "link_shadow_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "2243-2260",
          "snippet": "static void link_shadow_page(struct kvm_vcpu *vcpu, u64 *sptep,\n\t\t\t     struct kvm_mmu_page *sp)\n{\n\tu64 spte;\n\n\tBUILD_BUG_ON(VMX_EPT_READABLE_MASK != PT_PRESENT_MASK ||\n\t\t\tVMX_EPT_WRITABLE_MASK != PT_WRITABLE_MASK);\n\n\tspte = __pa(sp->spt) | PT_PRESENT_MASK | PT_WRITABLE_MASK |\n\t       shadow_user_mask | shadow_x_mask | shadow_accessed_mask;\n\n\tmmu_spte_set(sptep, spte);\n\n\tmmu_page_add_parent_pte(vcpu, sp, sptep);\n\n\tif (sp->unsync_children || sp->unsync)\n\t\tmark_unsync(sptep);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void mmu_spte_set(u64 *sptep, u64 spte);",
            "static void mmu_free_roots(struct kvm_vcpu *vcpu);",
            "static void mark_unsync(u64 *spte);",
            "static void make_mmu_pages_available(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void mmu_spte_set(u64 *sptep, u64 spte);\nstatic void mmu_free_roots(struct kvm_vcpu *vcpu);\nstatic void mark_unsync(u64 *spte);\nstatic void make_mmu_pages_available(struct kvm_vcpu *vcpu);\n\nstatic void link_shadow_page(struct kvm_vcpu *vcpu, u64 *sptep,\n\t\t\t     struct kvm_mmu_page *sp)\n{\n\tu64 spte;\n\n\tBUILD_BUG_ON(VMX_EPT_READABLE_MASK != PT_PRESENT_MASK ||\n\t\t\tVMX_EPT_WRITABLE_MASK != PT_WRITABLE_MASK);\n\n\tspte = __pa(sp->spt) | PT_PRESENT_MASK | PT_WRITABLE_MASK |\n\t       shadow_user_mask | shadow_x_mask | shadow_accessed_mask;\n\n\tmmu_spte_set(sptep, spte);\n\n\tmmu_page_add_parent_pte(vcpu, sp, sptep);\n\n\tif (sp->unsync_children || sp->unsync)\n\t\tmark_unsync(sptep);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_mmu_get_page",
          "args": [
            "vcpu",
            "direct_gfn",
            "addr",
            "it.level-1",
            "true",
            "direct_access"
          ],
          "line": 633
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_mmu_get_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "2112-2192",
          "snippet": "static struct kvm_mmu_page *kvm_mmu_get_page(struct kvm_vcpu *vcpu,\n\t\t\t\t\t     gfn_t gfn,\n\t\t\t\t\t     gva_t gaddr,\n\t\t\t\t\t     unsigned level,\n\t\t\t\t\t     int direct,\n\t\t\t\t\t     unsigned access)\n{\n\tunion kvm_mmu_page_role role;\n\tunsigned quadrant;\n\tstruct kvm_mmu_page *sp;\n\tbool need_sync = false;\n\tbool flush = false;\n\tLIST_HEAD(invalid_list);\n\n\trole = vcpu->arch.mmu.base_role;\n\trole.level = level;\n\trole.direct = direct;\n\tif (role.direct)\n\t\trole.cr4_pae = 0;\n\trole.access = access;\n\tif (!vcpu->arch.mmu.direct_map\n\t    && vcpu->arch.mmu.root_level <= PT32_ROOT_LEVEL) {\n\t\tquadrant = gaddr >> (PAGE_SHIFT + (PT64_PT_BITS * level));\n\t\tquadrant &= (1 << ((PT32_PT_BITS - PT64_PT_BITS) * level)) - 1;\n\t\trole.quadrant = quadrant;\n\t}\n\tfor_each_gfn_valid_sp(vcpu->kvm, sp, gfn) {\n\t\tif (!need_sync && sp->unsync)\n\t\t\tneed_sync = true;\n\n\t\tif (sp->role.word != role.word)\n\t\t\tcontinue;\n\n\t\tif (sp->unsync) {\n\t\t\t/* The page is good, but __kvm_sync_page might still end\n\t\t\t * up zapping it.  If so, break in order to rebuild it.\n\t\t\t */\n\t\t\tif (!__kvm_sync_page(vcpu, sp, &invalid_list))\n\t\t\t\tbreak;\n\n\t\t\tWARN_ON(!list_empty(&invalid_list));\n\t\t\tkvm_make_request(KVM_REQ_TLB_FLUSH, vcpu);\n\t\t}\n\n\t\tif (sp->unsync_children)\n\t\t\tkvm_make_request(KVM_REQ_MMU_SYNC, vcpu);\n\n\t\t__clear_sp_write_flooding_count(sp);\n\t\ttrace_kvm_mmu_get_page(sp, false);\n\t\treturn sp;\n\t}\n\n\t++vcpu->kvm->stat.mmu_cache_miss;\n\n\tsp = kvm_mmu_alloc_page(vcpu, direct);\n\n\tsp->gfn = gfn;\n\tsp->role = role;\n\thlist_add_head(&sp->hash_link,\n\t\t&vcpu->kvm->arch.mmu_page_hash[kvm_page_table_hashfn(gfn)]);\n\tif (!direct) {\n\t\t/*\n\t\t * we should do write protection before syncing pages\n\t\t * otherwise the content of the synced shadow page may\n\t\t * be inconsistent with guest page table.\n\t\t */\n\t\taccount_shadowed(vcpu->kvm, sp);\n\t\tif (level == PT_PAGE_TABLE_LEVEL &&\n\t\t      rmap_write_protect(vcpu, gfn))\n\t\t\tkvm_flush_remote_tlbs(vcpu->kvm);\n\n\t\tif (level > PT_PAGE_TABLE_LEVEL && need_sync)\n\t\t\tflush |= kvm_sync_pages(vcpu, gfn, &invalid_list);\n\t}\n\tsp->mmu_valid_gen = vcpu->kvm->arch.mmu_valid_gen;\n\tclear_page(sp->spt);\n\ttrace_kvm_mmu_get_page(sp, true);\n\n\tkvm_mmu_flush_or_zap(vcpu, &invalid_list, false, flush);\n\treturn sp;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void mmu_free_roots(struct kvm_vcpu *vcpu);",
            "static int kvm_mmu_prepare_zap_page(struct kvm *kvm, struct kvm_mmu_page *sp,\n\t\t\t\t    struct list_head *invalid_list);",
            "static void kvm_mmu_commit_zap_page(struct kvm *kvm,\n\t\t\t\t    struct list_head *invalid_list);",
            "static void make_mmu_pages_available(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void mmu_free_roots(struct kvm_vcpu *vcpu);\nstatic int kvm_mmu_prepare_zap_page(struct kvm *kvm, struct kvm_mmu_page *sp,\n\t\t\t\t    struct list_head *invalid_list);\nstatic void kvm_mmu_commit_zap_page(struct kvm *kvm,\n\t\t\t\t    struct list_head *invalid_list);\nstatic void make_mmu_pages_available(struct kvm_vcpu *vcpu);\n\nstatic struct kvm_mmu_page *kvm_mmu_get_page(struct kvm_vcpu *vcpu,\n\t\t\t\t\t     gfn_t gfn,\n\t\t\t\t\t     gva_t gaddr,\n\t\t\t\t\t     unsigned level,\n\t\t\t\t\t     int direct,\n\t\t\t\t\t     unsigned access)\n{\n\tunion kvm_mmu_page_role role;\n\tunsigned quadrant;\n\tstruct kvm_mmu_page *sp;\n\tbool need_sync = false;\n\tbool flush = false;\n\tLIST_HEAD(invalid_list);\n\n\trole = vcpu->arch.mmu.base_role;\n\trole.level = level;\n\trole.direct = direct;\n\tif (role.direct)\n\t\trole.cr4_pae = 0;\n\trole.access = access;\n\tif (!vcpu->arch.mmu.direct_map\n\t    && vcpu->arch.mmu.root_level <= PT32_ROOT_LEVEL) {\n\t\tquadrant = gaddr >> (PAGE_SHIFT + (PT64_PT_BITS * level));\n\t\tquadrant &= (1 << ((PT32_PT_BITS - PT64_PT_BITS) * level)) - 1;\n\t\trole.quadrant = quadrant;\n\t}\n\tfor_each_gfn_valid_sp(vcpu->kvm, sp, gfn) {\n\t\tif (!need_sync && sp->unsync)\n\t\t\tneed_sync = true;\n\n\t\tif (sp->role.word != role.word)\n\t\t\tcontinue;\n\n\t\tif (sp->unsync) {\n\t\t\t/* The page is good, but __kvm_sync_page might still end\n\t\t\t * up zapping it.  If so, break in order to rebuild it.\n\t\t\t */\n\t\t\tif (!__kvm_sync_page(vcpu, sp, &invalid_list))\n\t\t\t\tbreak;\n\n\t\t\tWARN_ON(!list_empty(&invalid_list));\n\t\t\tkvm_make_request(KVM_REQ_TLB_FLUSH, vcpu);\n\t\t}\n\n\t\tif (sp->unsync_children)\n\t\t\tkvm_make_request(KVM_REQ_MMU_SYNC, vcpu);\n\n\t\t__clear_sp_write_flooding_count(sp);\n\t\ttrace_kvm_mmu_get_page(sp, false);\n\t\treturn sp;\n\t}\n\n\t++vcpu->kvm->stat.mmu_cache_miss;\n\n\tsp = kvm_mmu_alloc_page(vcpu, direct);\n\n\tsp->gfn = gfn;\n\tsp->role = role;\n\thlist_add_head(&sp->hash_link,\n\t\t&vcpu->kvm->arch.mmu_page_hash[kvm_page_table_hashfn(gfn)]);\n\tif (!direct) {\n\t\t/*\n\t\t * we should do write protection before syncing pages\n\t\t * otherwise the content of the synced shadow page may\n\t\t * be inconsistent with guest page table.\n\t\t */\n\t\taccount_shadowed(vcpu->kvm, sp);\n\t\tif (level == PT_PAGE_TABLE_LEVEL &&\n\t\t      rmap_write_protect(vcpu, gfn))\n\t\t\tkvm_flush_remote_tlbs(vcpu->kvm);\n\n\t\tif (level > PT_PAGE_TABLE_LEVEL && need_sync)\n\t\t\tflush |= kvm_sync_pages(vcpu, gfn, &invalid_list);\n\t}\n\tsp->mmu_valid_gen = vcpu->kvm->arch.mmu_valid_gen;\n\tclear_page(sp->spt);\n\ttrace_kvm_mmu_get_page(sp, true);\n\n\tkvm_mmu_flush_or_zap(vcpu, &invalid_list, false, flush);\n\treturn sp;\n}"
        }
      },
      {
        "call_info": {
          "callee": "KVM_PAGES_PER_HPAGE",
          "args": [
            "it.level"
          ],
          "line": 631
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "is_shadow_present_pte",
          "args": [
            "*it.sptep"
          ],
          "line": 628
        },
        "resolved": true,
        "details": {
          "function_name": "is_shadow_present_pte",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "305-308",
          "snippet": "static int is_shadow_present_pte(u64 pte)\n{\n\treturn pte & PT_PRESENT_MASK && !is_mmio_spte(pte);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic int is_shadow_present_pte(u64 pte)\n{\n\treturn pte & PT_PRESENT_MASK && !is_mmio_spte(pte);\n}"
        }
      },
      {
        "call_info": {
          "callee": "drop_large_spte",
          "args": [
            "vcpu",
            "it.sptep"
          ],
          "line": 626
        },
        "resolved": true,
        "details": {
          "function_name": "drop_large_spte",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "1188-1192",
          "snippet": "static void drop_large_spte(struct kvm_vcpu *vcpu, u64 *sptep)\n{\n\tif (__drop_large_spte(vcpu->kvm, sptep))\n\t\tkvm_flush_remote_tlbs(vcpu->kvm);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void mmu_free_roots(struct kvm_vcpu *vcpu);",
            "static void make_mmu_pages_available(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void mmu_free_roots(struct kvm_vcpu *vcpu);\nstatic void make_mmu_pages_available(struct kvm_vcpu *vcpu);\n\nstatic void drop_large_spte(struct kvm_vcpu *vcpu, u64 *sptep)\n{\n\tif (__drop_large_spte(vcpu->kvm, sptep))\n\t\tkvm_flush_remote_tlbs(vcpu->kvm);\n}"
        }
      },
      {
        "call_info": {
          "callee": "validate_direct_spte",
          "args": [
            "vcpu",
            "it.sptep",
            "direct_access"
          ],
          "line": 624
        },
        "resolved": true,
        "details": {
          "function_name": "validate_direct_spte",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "2262-2282",
          "snippet": "static void validate_direct_spte(struct kvm_vcpu *vcpu, u64 *sptep,\n\t\t\t\t   unsigned direct_access)\n{\n\tif (is_shadow_present_pte(*sptep) && !is_large_pte(*sptep)) {\n\t\tstruct kvm_mmu_page *child;\n\n\t\t/*\n\t\t * For the direct sp, if the guest pte's dirty bit\n\t\t * changed form clean to dirty, it will corrupt the\n\t\t * sp's access: allow writable in the read-only sp,\n\t\t * so we should update the spte at this point to get\n\t\t * a new sp with the correct access.\n\t\t */\n\t\tchild = page_header(*sptep & PT64_BASE_ADDR_MASK);\n\t\tif (child->role.access == direct_access)\n\t\t\treturn;\n\n\t\tdrop_parent_pte(child, sptep);\n\t\tkvm_flush_remote_tlbs(vcpu->kvm);\n\t}\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [
            "#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))"
          ],
          "globals_used": [
            "static void mmu_spte_set(u64 *sptep, u64 spte);",
            "static void mmu_free_roots(struct kvm_vcpu *vcpu);",
            "static void mark_unsync(u64 *spte);",
            "static bool try_async_pf(struct kvm_vcpu *vcpu, bool prefault, gfn_t gfn,\n\t\t\t gva_t gva, kvm_pfn_t *pfn, bool write, bool *writable);",
            "static void make_mmu_pages_available(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\n#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))\n\nstatic void mmu_spte_set(u64 *sptep, u64 spte);\nstatic void mmu_free_roots(struct kvm_vcpu *vcpu);\nstatic void mark_unsync(u64 *spte);\nstatic bool try_async_pf(struct kvm_vcpu *vcpu, bool prefault, gfn_t gfn,\n\t\t\t gva_t gva, kvm_pfn_t *pfn, bool write, bool *writable);\nstatic void make_mmu_pages_available(struct kvm_vcpu *vcpu);\n\nstatic void validate_direct_spte(struct kvm_vcpu *vcpu, u64 *sptep,\n\t\t\t\t   unsigned direct_access)\n{\n\tif (is_shadow_present_pte(*sptep) && !is_large_pte(*sptep)) {\n\t\tstruct kvm_mmu_page *child;\n\n\t\t/*\n\t\t * For the direct sp, if the guest pte's dirty bit\n\t\t * changed form clean to dirty, it will corrupt the\n\t\t * sp's access: allow writable in the read-only sp,\n\t\t * so we should update the spte at this point to get\n\t\t * a new sp with the correct access.\n\t\t */\n\t\tchild = page_header(*sptep & PT64_BASE_ADDR_MASK);\n\t\tif (child->role.access == direct_access)\n\t\t\treturn;\n\n\t\tdrop_parent_pte(child, sptep);\n\t\tkvm_flush_remote_tlbs(vcpu->kvm);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "shadow_walk_next",
          "args": [
            "&it"
          ],
          "line": 620
        },
        "resolved": true,
        "details": {
          "function_name": "shadow_walk_next",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "2238-2241",
          "snippet": "static void shadow_walk_next(struct kvm_shadow_walk_iterator *iterator)\n{\n\treturn __shadow_walk_next(iterator, *iterator->sptep);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void shadow_walk_next(struct kvm_shadow_walk_iterator *iterator)\n{\n\treturn __shadow_walk_next(iterator, *iterator->sptep);\n}"
        }
      },
      {
        "call_info": {
          "callee": "shadow_walk_okay",
          "args": [
            "&it"
          ],
          "line": 619
        },
        "resolved": true,
        "details": {
          "function_name": "shadow_walk_okay",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "2216-2224",
          "snippet": "static bool shadow_walk_okay(struct kvm_shadow_walk_iterator *iterator)\n{\n\tif (iterator->level < PT_PAGE_TABLE_LEVEL)\n\t\treturn false;\n\n\titerator->index = SHADOW_PT_INDEX(iterator->addr, iterator->level);\n\titerator->sptep\t= ((u64 *)__va(iterator->shadow_addr)) + iterator->index;\n\treturn true;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic bool shadow_walk_okay(struct kvm_shadow_walk_iterator *iterator)\n{\n\tif (iterator->level < PT_PAGE_TABLE_LEVEL)\n\t\treturn false;\n\n\titerator->index = SHADOW_PT_INDEX(iterator->addr, iterator->level);\n\titerator->sptep\t= ((u64 *)__va(iterator->shadow_addr)) + iterator->index;\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "shadow_walk_init",
          "args": [
            "&it",
            "vcpu",
            "addr"
          ],
          "line": 592
        },
        "resolved": true,
        "details": {
          "function_name": "shadow_walk_init",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "2194-2214",
          "snippet": "static void shadow_walk_init(struct kvm_shadow_walk_iterator *iterator,\n\t\t\t     struct kvm_vcpu *vcpu, u64 addr)\n{\n\titerator->addr = addr;\n\titerator->shadow_addr = vcpu->arch.mmu.root_hpa;\n\titerator->level = vcpu->arch.mmu.shadow_root_level;\n\n\tif (iterator->level == PT64_ROOT_LEVEL &&\n\t    vcpu->arch.mmu.root_level < PT64_ROOT_LEVEL &&\n\t    !vcpu->arch.mmu.direct_map)\n\t\t--iterator->level;\n\n\tif (iterator->level == PT32E_ROOT_LEVEL) {\n\t\titerator->shadow_addr\n\t\t\t= vcpu->arch.mmu.pae_root[(addr >> 30) & 3];\n\t\titerator->shadow_addr &= PT64_BASE_ADDR_MASK;\n\t\t--iterator->level;\n\t\tif (!iterator->shadow_addr)\n\t\t\titerator->level = 0;\n\t}\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [
            "#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))"
          ],
          "globals_used": [
            "static void mmu_free_roots(struct kvm_vcpu *vcpu);",
            "static void make_mmu_pages_available(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\n#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))\n\nstatic void mmu_free_roots(struct kvm_vcpu *vcpu);\nstatic void make_mmu_pages_available(struct kvm_vcpu *vcpu);\n\nstatic void shadow_walk_init(struct kvm_shadow_walk_iterator *iterator,\n\t\t\t     struct kvm_vcpu *vcpu, u64 addr)\n{\n\titerator->addr = addr;\n\titerator->shadow_addr = vcpu->arch.mmu.root_hpa;\n\titerator->level = vcpu->arch.mmu.shadow_root_level;\n\n\tif (iterator->level == PT64_ROOT_LEVEL &&\n\t    vcpu->arch.mmu.root_level < PT64_ROOT_LEVEL &&\n\t    !vcpu->arch.mmu.direct_map)\n\t\t--iterator->level;\n\n\tif (iterator->level == PT32E_ROOT_LEVEL) {\n\t\titerator->shadow_addr\n\t\t\t= vcpu->arch.mmu.pae_root[(addr >> 30) & 3];\n\t\titerator->shadow_addr &= PT64_BASE_ADDR_MASK;\n\t\t--iterator->level;\n\t\tif (!iterator->shadow_addr)\n\t\t\titerator->level = 0;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "VALID_PAGE",
          "args": [
            "vcpu->arch.mmu.root_hpa"
          ],
          "line": 589
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define guest_walker guest_walkerEPT\n#define guest_walker guest_walker32\n#define guest_walker guest_walker64\n\nstatic int FNAME(fetch)(struct kvm_vcpu *vcpu, gva_t addr,\n\t\t\t struct guest_walker *gw,\n\t\t\t int write_fault, int hlevel,\n\t\t\t kvm_pfn_t pfn, bool map_writable, bool prefault)\n{\n\tstruct kvm_mmu_page *sp = NULL;\n\tstruct kvm_shadow_walk_iterator it;\n\tunsigned direct_access, access = gw->pt_access;\n\tint top_level, emulate;\n\n\tdirect_access = gw->pte_access;\n\n\ttop_level = vcpu->arch.mmu.root_level;\n\tif (top_level == PT32E_ROOT_LEVEL)\n\t\ttop_level = PT32_ROOT_LEVEL;\n\t/*\n\t * Verify that the top-level gpte is still there.  Since the page\n\t * is a root page, it is either write protected (and cannot be\n\t * changed from now on) or it is invalid (in which case, we don't\n\t * really care if it changes underneath us after this point).\n\t */\n\tif (FNAME(gpte_changed)(vcpu, gw, top_level))\n\t\tgoto out_gpte_changed;\n\n\tif (!VALID_PAGE(vcpu->arch.mmu.root_hpa))\n\t\tgoto out_gpte_changed;\n\n\tfor (shadow_walk_init(&it, vcpu, addr);\n\t     shadow_walk_okay(&it) && it.level > gw->level;\n\t     shadow_walk_next(&it)) {\n\t\tgfn_t table_gfn;\n\n\t\tclear_sp_write_flooding_count(it.sptep);\n\t\tdrop_large_spte(vcpu, it.sptep);\n\n\t\tsp = NULL;\n\t\tif (!is_shadow_present_pte(*it.sptep)) {\n\t\t\ttable_gfn = gw->table_gfn[it.level - 2];\n\t\t\tsp = kvm_mmu_get_page(vcpu, table_gfn, addr, it.level-1,\n\t\t\t\t\t      false, access);\n\t\t}\n\n\t\t/*\n\t\t * Verify that the gpte in the page we've just write\n\t\t * protected is still there.\n\t\t */\n\t\tif (FNAME(gpte_changed)(vcpu, gw, it.level - 1))\n\t\t\tgoto out_gpte_changed;\n\n\t\tif (sp)\n\t\t\tlink_shadow_page(vcpu, it.sptep, sp);\n\t}\n\n\tfor (;\n\t     shadow_walk_okay(&it) && it.level > hlevel;\n\t     shadow_walk_next(&it)) {\n\t\tgfn_t direct_gfn;\n\n\t\tclear_sp_write_flooding_count(it.sptep);\n\t\tvalidate_direct_spte(vcpu, it.sptep, direct_access);\n\n\t\tdrop_large_spte(vcpu, it.sptep);\n\n\t\tif (is_shadow_present_pte(*it.sptep))\n\t\t\tcontinue;\n\n\t\tdirect_gfn = gw->gfn & ~(KVM_PAGES_PER_HPAGE(it.level) - 1);\n\n\t\tsp = kvm_mmu_get_page(vcpu, direct_gfn, addr, it.level-1,\n\t\t\t\t      true, direct_access);\n\t\tlink_shadow_page(vcpu, it.sptep, sp);\n\t}\n\n\tclear_sp_write_flooding_count(it.sptep);\n\temulate = mmu_set_spte(vcpu, it.sptep, gw->pte_access, write_fault,\n\t\t\t       it.level, gw->gfn, pfn, prefault, map_writable);\n\tFNAME(pte_prefetch)(vcpu, gw, it.sptep);\n\n\treturn emulate;\n\nout_gpte_changed:\n\tkvm_release_pfn_clean(pfn);\n\treturn 0;\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
    "lines": "529-558",
    "snippet": "static void FNAME(pte_prefetch)(struct kvm_vcpu *vcpu, struct guest_walker *gw,\n\t\t\t\tu64 *sptep)\n{\n\tstruct kvm_mmu_page *sp;\n\tpt_element_t *gptep = gw->prefetch_ptes;\n\tu64 *spte;\n\tint i;\n\n\tsp = page_header(__pa(sptep));\n\n\tif (sp->role.level > PT_PAGE_TABLE_LEVEL)\n\t\treturn;\n\n\tif (sp->role.direct)\n\t\treturn __direct_pte_prefetch(vcpu, sp, sptep);\n\n\ti = (sptep - sp->spt) & ~(PTE_PREFETCH_NUM - 1);\n\tspte = sp->spt + i;\n\n\tfor (i = 0; i < PTE_PREFETCH_NUM; i++, spte++) {\n\t\tif (spte == sptep)\n\t\t\tcontinue;\n\n\t\tif (is_shadow_present_pte(*spte))\n\t\t\tcontinue;\n\n\t\tif (!FNAME(prefetch_gpte)(vcpu, sp, spte, gptep[i], true))\n\t\t\tbreak;\n\t}\n}",
    "includes": [],
    "macros_used": [
      "#define guest_walker guest_walkerEPT",
      "#define pt_element_t u64",
      "#define guest_walker guest_walker32",
      "#define pt_element_t u32",
      "#define guest_walker guest_walker64",
      "#define pt_element_t u64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "vcpu",
            "sp",
            "spte",
            "gptep[i]",
            "true"
          ],
          "line": 555
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
          "lines": "467-496",
          "snippet": "static bool\nFNAME(prefetch_gpte)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,\n\t\t     u64 *spte, pt_element_t gpte, bool no_dirty_log)\n{\n\tunsigned pte_access;\n\tgfn_t gfn;\n\tkvm_pfn_t pfn;\n\n\tif (FNAME(prefetch_invalid_gpte)(vcpu, sp, spte, gpte))\n\t\treturn false;\n\n\tpgprintk(\"%s: gpte %llx spte %p\\n\", __func__, (u64)gpte, spte);\n\n\tgfn = gpte_to_gfn(gpte);\n\tpte_access = sp->role.access & FNAME(gpte_access)(vcpu, gpte);\n\tFNAME(protect_clean_gpte)(&pte_access, gpte);\n\tpfn = pte_prefetch_gfn_to_pfn(vcpu, gfn,\n\t\t\tno_dirty_log && (pte_access & ACC_WRITE_MASK));\n\tif (is_error_pfn(pfn))\n\t\treturn false;\n\n\t/*\n\t * we call mmu_set_spte() with host_writable = true because\n\t * pte_prefetch_gfn_to_pfn always gets a writable pfn.\n\t */\n\tmmu_set_spte(vcpu, spte, pte_access, 0, PT_PAGE_TABLE_LEVEL, gfn, pfn,\n\t\t     true, true);\n\n\treturn true;\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "is_shadow_present_pte",
          "args": [
            "*spte"
          ],
          "line": 552
        },
        "resolved": true,
        "details": {
          "function_name": "is_shadow_present_pte",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "305-308",
          "snippet": "static int is_shadow_present_pte(u64 pte)\n{\n\treturn pte & PT_PRESENT_MASK && !is_mmio_spte(pte);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic int is_shadow_present_pte(u64 pte)\n{\n\treturn pte & PT_PRESENT_MASK && !is_mmio_spte(pte);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__direct_pte_prefetch",
          "args": [
            "vcpu",
            "sp",
            "sptep"
          ],
          "line": 543
        },
        "resolved": true,
        "details": {
          "function_name": "__direct_pte_prefetch",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "2695-2716",
          "snippet": "static void __direct_pte_prefetch(struct kvm_vcpu *vcpu,\n\t\t\t\t  struct kvm_mmu_page *sp, u64 *sptep)\n{\n\tu64 *spte, *start = NULL;\n\tint i;\n\n\tWARN_ON(!sp->role.direct);\n\n\ti = (sptep - sp->spt) & ~(PTE_PREFETCH_NUM - 1);\n\tspte = sp->spt + i;\n\n\tfor (i = 0; i < PTE_PREFETCH_NUM; i++, spte++) {\n\t\tif (is_shadow_present_pte(*spte) || spte == sptep) {\n\t\t\tif (!start)\n\t\t\t\tcontinue;\n\t\t\tif (direct_pte_prefetch_many(vcpu, sp, start, spte) < 0)\n\t\t\t\tbreak;\n\t\t\tstart = NULL;\n\t\t} else if (!start)\n\t\t\tstart = spte;\n\t}\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [
            "#define PTE_PREFETCH_NUM\t\t8"
          ],
          "globals_used": [
            "static void mmu_spte_set(u64 *sptep, u64 spte);",
            "static void mmu_free_roots(struct kvm_vcpu *vcpu);",
            "static void mark_unsync(u64 *spte);",
            "static void make_mmu_pages_available(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\n#define PTE_PREFETCH_NUM\t\t8\n\nstatic void mmu_spte_set(u64 *sptep, u64 spte);\nstatic void mmu_free_roots(struct kvm_vcpu *vcpu);\nstatic void mark_unsync(u64 *spte);\nstatic void make_mmu_pages_available(struct kvm_vcpu *vcpu);\n\nstatic void __direct_pte_prefetch(struct kvm_vcpu *vcpu,\n\t\t\t\t  struct kvm_mmu_page *sp, u64 *sptep)\n{\n\tu64 *spte, *start = NULL;\n\tint i;\n\n\tWARN_ON(!sp->role.direct);\n\n\ti = (sptep - sp->spt) & ~(PTE_PREFETCH_NUM - 1);\n\tspte = sp->spt + i;\n\n\tfor (i = 0; i < PTE_PREFETCH_NUM; i++, spte++) {\n\t\tif (is_shadow_present_pte(*spte) || spte == sptep) {\n\t\t\tif (!start)\n\t\t\t\tcontinue;\n\t\t\tif (direct_pte_prefetch_many(vcpu, sp, start, spte) < 0)\n\t\t\t\tbreak;\n\t\t\tstart = NULL;\n\t\t} else if (!start)\n\t\t\tstart = spte;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "page_header",
          "args": [
            "__pa(sptep)"
          ],
          "line": 537
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__pa",
          "args": [
            "sptep"
          ],
          "line": 537
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define guest_walker guest_walkerEPT\n#define pt_element_t u64\n#define guest_walker guest_walker32\n#define pt_element_t u32\n#define guest_walker guest_walker64\n#define pt_element_t u64\n\nstatic void FNAME(pte_prefetch)(struct kvm_vcpu *vcpu, struct guest_walker *gw,\n\t\t\t\tu64 *sptep)\n{\n\tstruct kvm_mmu_page *sp;\n\tpt_element_t *gptep = gw->prefetch_ptes;\n\tu64 *spte;\n\tint i;\n\n\tsp = page_header(__pa(sptep));\n\n\tif (sp->role.level > PT_PAGE_TABLE_LEVEL)\n\t\treturn;\n\n\tif (sp->role.direct)\n\t\treturn __direct_pte_prefetch(vcpu, sp, sptep);\n\n\ti = (sptep - sp->spt) & ~(PTE_PREFETCH_NUM - 1);\n\tspte = sp->spt + i;\n\n\tfor (i = 0; i < PTE_PREFETCH_NUM; i++, spte++) {\n\t\tif (spte == sptep)\n\t\t\tcontinue;\n\n\t\tif (is_shadow_present_pte(*spte))\n\t\t\tcontinue;\n\n\t\tif (!FNAME(prefetch_gpte)(vcpu, sp, spte, gptep[i], true))\n\t\t\tbreak;\n\t}\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
    "lines": "506-527",
    "snippet": "static bool FNAME(gpte_changed)(struct kvm_vcpu *vcpu,\n\t\t\t\tstruct guest_walker *gw, int level)\n{\n\tpt_element_t curr_pte;\n\tgpa_t base_gpa, pte_gpa = gw->pte_gpa[level - 1];\n\tu64 mask;\n\tint r, index;\n\n\tif (level == PT_PAGE_TABLE_LEVEL) {\n\t\tmask = PTE_PREFETCH_NUM * sizeof(pt_element_t) - 1;\n\t\tbase_gpa = pte_gpa & ~mask;\n\t\tindex = (pte_gpa - base_gpa) / sizeof(pt_element_t);\n\n\t\tr = kvm_vcpu_read_guest_atomic(vcpu, base_gpa,\n\t\t\t\tgw->prefetch_ptes, sizeof(gw->prefetch_ptes));\n\t\tcurr_pte = gw->prefetch_ptes[index];\n\t} else\n\t\tr = kvm_vcpu_read_guest_atomic(vcpu, pte_gpa,\n\t\t\t\t  &curr_pte, sizeof(curr_pte));\n\n\treturn r || curr_pte != gw->ptes[level - 1];\n}",
    "includes": [],
    "macros_used": [
      "#define guest_walker guest_walkerEPT",
      "#define pt_element_t u64",
      "#define guest_walker guest_walker32",
      "#define pt_element_t u32",
      "#define guest_walker guest_walker64",
      "#define pt_element_t u64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_vcpu_read_guest_atomic",
          "args": [
            "vcpu",
            "pte_gpa",
            "&curr_pte",
            "sizeof(curr_pte)"
          ],
          "line": 523
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_vcpu_read_guest_atomic",
          "args": [
            "vcpu",
            "base_gpa",
            "gw->prefetch_ptes",
            "sizeof(gw->prefetch_ptes)"
          ],
          "line": 519
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define guest_walker guest_walkerEPT\n#define pt_element_t u64\n#define guest_walker guest_walker32\n#define pt_element_t u32\n#define guest_walker guest_walker64\n#define pt_element_t u64\n\nstatic bool FNAME(gpte_changed)(struct kvm_vcpu *vcpu,\n\t\t\t\tstruct guest_walker *gw, int level)\n{\n\tpt_element_t curr_pte;\n\tgpa_t base_gpa, pte_gpa = gw->pte_gpa[level - 1];\n\tu64 mask;\n\tint r, index;\n\n\tif (level == PT_PAGE_TABLE_LEVEL) {\n\t\tmask = PTE_PREFETCH_NUM * sizeof(pt_element_t) - 1;\n\t\tbase_gpa = pte_gpa & ~mask;\n\t\tindex = (pte_gpa - base_gpa) / sizeof(pt_element_t);\n\n\t\tr = kvm_vcpu_read_guest_atomic(vcpu, base_gpa,\n\t\t\t\tgw->prefetch_ptes, sizeof(gw->prefetch_ptes));\n\t\tcurr_pte = gw->prefetch_ptes[index];\n\t} else\n\t\tr = kvm_vcpu_read_guest_atomic(vcpu, pte_gpa,\n\t\t\t\t  &curr_pte, sizeof(curr_pte));\n\n\treturn r || curr_pte != gw->ptes[level - 1];\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
    "lines": "498-504",
    "snippet": "static void FNAME(update_pte)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,\n\t\t\t      u64 *spte, const void *pte)\n{\n\tpt_element_t gpte = *(const pt_element_t *)pte;\n\n\tFNAME(prefetch_gpte)(vcpu, sp, spte, gpte, false);\n}",
    "includes": [],
    "macros_used": [
      "#define pt_element_t u64",
      "#define pt_element_t u32",
      "#define pt_element_t u64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "vcpu",
            "sp",
            "spte",
            "gpte",
            "false"
          ],
          "line": 503
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
          "lines": "467-496",
          "snippet": "static bool\nFNAME(prefetch_gpte)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,\n\t\t     u64 *spte, pt_element_t gpte, bool no_dirty_log)\n{\n\tunsigned pte_access;\n\tgfn_t gfn;\n\tkvm_pfn_t pfn;\n\n\tif (FNAME(prefetch_invalid_gpte)(vcpu, sp, spte, gpte))\n\t\treturn false;\n\n\tpgprintk(\"%s: gpte %llx spte %p\\n\", __func__, (u64)gpte, spte);\n\n\tgfn = gpte_to_gfn(gpte);\n\tpte_access = sp->role.access & FNAME(gpte_access)(vcpu, gpte);\n\tFNAME(protect_clean_gpte)(&pte_access, gpte);\n\tpfn = pte_prefetch_gfn_to_pfn(vcpu, gfn,\n\t\t\tno_dirty_log && (pte_access & ACC_WRITE_MASK));\n\tif (is_error_pfn(pfn))\n\t\treturn false;\n\n\t/*\n\t * we call mmu_set_spte() with host_writable = true because\n\t * pte_prefetch_gfn_to_pfn always gets a writable pfn.\n\t */\n\tmmu_set_spte(vcpu, spte, pte_access, 0, PT_PAGE_TABLE_LEVEL, gfn, pfn,\n\t\t     true, true);\n\n\treturn true;\n}",
          "note": "cyclic_reference_detected"
        }
      }
    ],
    "contextual_snippet": "#define pt_element_t u64\n#define pt_element_t u32\n#define pt_element_t u64\n\nstatic void FNAME(update_pte)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,\n\t\t\t      u64 *spte, const void *pte)\n{\n\tpt_element_t gpte = *(const pt_element_t *)pte;\n\n\tFNAME(prefetch_gpte)(vcpu, sp, spte, gpte, false);\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
    "lines": "467-496",
    "snippet": "static bool\nFNAME(prefetch_gpte)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,\n\t\t     u64 *spte, pt_element_t gpte, bool no_dirty_log)\n{\n\tunsigned pte_access;\n\tgfn_t gfn;\n\tkvm_pfn_t pfn;\n\n\tif (FNAME(prefetch_invalid_gpte)(vcpu, sp, spte, gpte))\n\t\treturn false;\n\n\tpgprintk(\"%s: gpte %llx spte %p\\n\", __func__, (u64)gpte, spte);\n\n\tgfn = gpte_to_gfn(gpte);\n\tpte_access = sp->role.access & FNAME(gpte_access)(vcpu, gpte);\n\tFNAME(protect_clean_gpte)(&pte_access, gpte);\n\tpfn = pte_prefetch_gfn_to_pfn(vcpu, gfn,\n\t\t\tno_dirty_log && (pte_access & ACC_WRITE_MASK));\n\tif (is_error_pfn(pfn))\n\t\treturn false;\n\n\t/*\n\t * we call mmu_set_spte() with host_writable = true because\n\t * pte_prefetch_gfn_to_pfn always gets a writable pfn.\n\t */\n\tmmu_set_spte(vcpu, spte, pte_access, 0, PT_PAGE_TABLE_LEVEL, gfn, pfn,\n\t\t     true, true);\n\n\treturn true;\n}",
    "includes": [],
    "macros_used": [
      "#define pt_element_t u64",
      "#define pt_element_t u32",
      "#define pt_element_t u64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "mmu_set_spte",
          "args": [
            "vcpu",
            "spte",
            "pte_access",
            "0",
            "PT_PAGE_TABLE_LEVEL",
            "gfn",
            "pfn",
            "true",
            "true"
          ],
          "line": 492
        },
        "resolved": true,
        "details": {
          "function_name": "mmu_set_spte",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "2593-2655",
          "snippet": "static bool mmu_set_spte(struct kvm_vcpu *vcpu, u64 *sptep, unsigned pte_access,\n\t\t\t int write_fault, int level, gfn_t gfn, kvm_pfn_t pfn,\n\t\t\t bool speculative, bool host_writable)\n{\n\tint was_rmapped = 0;\n\tint rmap_count;\n\tbool emulate = false;\n\n\tpgprintk(\"%s: spte %llx write_fault %d gfn %llx\\n\", __func__,\n\t\t *sptep, write_fault, gfn);\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\t/*\n\t\t * If we overwrite a PTE page pointer with a 2MB PMD, unlink\n\t\t * the parent of the now unreachable PTE.\n\t\t */\n\t\tif (level > PT_PAGE_TABLE_LEVEL &&\n\t\t    !is_large_pte(*sptep)) {\n\t\t\tstruct kvm_mmu_page *child;\n\t\t\tu64 pte = *sptep;\n\n\t\t\tchild = page_header(pte & PT64_BASE_ADDR_MASK);\n\t\t\tdrop_parent_pte(child, sptep);\n\t\t\tkvm_flush_remote_tlbs(vcpu->kvm);\n\t\t} else if (pfn != spte_to_pfn(*sptep)) {\n\t\t\tpgprintk(\"hfn old %llx new %llx\\n\",\n\t\t\t\t spte_to_pfn(*sptep), pfn);\n\t\t\tdrop_spte(vcpu->kvm, sptep);\n\t\t\tkvm_flush_remote_tlbs(vcpu->kvm);\n\t\t} else\n\t\t\twas_rmapped = 1;\n\t}\n\n\tif (set_spte(vcpu, sptep, pte_access, level, gfn, pfn, speculative,\n\t      true, host_writable)) {\n\t\tif (write_fault)\n\t\t\temulate = true;\n\t\tkvm_make_request(KVM_REQ_TLB_FLUSH, vcpu);\n\t}\n\n\tif (unlikely(is_mmio_spte(*sptep)))\n\t\temulate = true;\n\n\tpgprintk(\"%s: setting spte %llx\\n\", __func__, *sptep);\n\tpgprintk(\"instantiating %s PTE (%s) at %llx (%llx) addr %p\\n\",\n\t\t is_large_pte(*sptep)? \"2MB\" : \"4kB\",\n\t\t *sptep & PT_PRESENT_MASK ?\"RW\":\"R\", gfn,\n\t\t *sptep, sptep);\n\tif (!was_rmapped && is_large_pte(*sptep))\n\t\t++vcpu->kvm->stat.lpages;\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\tif (!was_rmapped) {\n\t\t\trmap_count = rmap_add(vcpu, sptep, gfn);\n\t\t\tif (rmap_count > RMAP_RECYCLE_THRESHOLD)\n\t\t\t\trmap_recycle(vcpu, sptep, gfn);\n\t\t}\n\t}\n\n\tkvm_release_pfn_clean(pfn);\n\n\treturn emulate;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [
            "#define RMAP_RECYCLE_THRESHOLD 1000",
            "#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))"
          ],
          "globals_used": [
            "static void mmu_spte_set(u64 *sptep, u64 spte);",
            "static void mmu_free_roots(struct kvm_vcpu *vcpu);",
            "static void mark_unsync(u64 *spte);",
            "static void make_mmu_pages_available(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\n#define RMAP_RECYCLE_THRESHOLD 1000\n#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))\n\nstatic void mmu_spte_set(u64 *sptep, u64 spte);\nstatic void mmu_free_roots(struct kvm_vcpu *vcpu);\nstatic void mark_unsync(u64 *spte);\nstatic void make_mmu_pages_available(struct kvm_vcpu *vcpu);\n\nstatic bool mmu_set_spte(struct kvm_vcpu *vcpu, u64 *sptep, unsigned pte_access,\n\t\t\t int write_fault, int level, gfn_t gfn, kvm_pfn_t pfn,\n\t\t\t bool speculative, bool host_writable)\n{\n\tint was_rmapped = 0;\n\tint rmap_count;\n\tbool emulate = false;\n\n\tpgprintk(\"%s: spte %llx write_fault %d gfn %llx\\n\", __func__,\n\t\t *sptep, write_fault, gfn);\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\t/*\n\t\t * If we overwrite a PTE page pointer with a 2MB PMD, unlink\n\t\t * the parent of the now unreachable PTE.\n\t\t */\n\t\tif (level > PT_PAGE_TABLE_LEVEL &&\n\t\t    !is_large_pte(*sptep)) {\n\t\t\tstruct kvm_mmu_page *child;\n\t\t\tu64 pte = *sptep;\n\n\t\t\tchild = page_header(pte & PT64_BASE_ADDR_MASK);\n\t\t\tdrop_parent_pte(child, sptep);\n\t\t\tkvm_flush_remote_tlbs(vcpu->kvm);\n\t\t} else if (pfn != spte_to_pfn(*sptep)) {\n\t\t\tpgprintk(\"hfn old %llx new %llx\\n\",\n\t\t\t\t spte_to_pfn(*sptep), pfn);\n\t\t\tdrop_spte(vcpu->kvm, sptep);\n\t\t\tkvm_flush_remote_tlbs(vcpu->kvm);\n\t\t} else\n\t\t\twas_rmapped = 1;\n\t}\n\n\tif (set_spte(vcpu, sptep, pte_access, level, gfn, pfn, speculative,\n\t      true, host_writable)) {\n\t\tif (write_fault)\n\t\t\temulate = true;\n\t\tkvm_make_request(KVM_REQ_TLB_FLUSH, vcpu);\n\t}\n\n\tif (unlikely(is_mmio_spte(*sptep)))\n\t\temulate = true;\n\n\tpgprintk(\"%s: setting spte %llx\\n\", __func__, *sptep);\n\tpgprintk(\"instantiating %s PTE (%s) at %llx (%llx) addr %p\\n\",\n\t\t is_large_pte(*sptep)? \"2MB\" : \"4kB\",\n\t\t *sptep & PT_PRESENT_MASK ?\"RW\":\"R\", gfn,\n\t\t *sptep, sptep);\n\tif (!was_rmapped && is_large_pte(*sptep))\n\t\t++vcpu->kvm->stat.lpages;\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\tif (!was_rmapped) {\n\t\t\trmap_count = rmap_add(vcpu, sptep, gfn);\n\t\t\tif (rmap_count > RMAP_RECYCLE_THRESHOLD)\n\t\t\t\trmap_recycle(vcpu, sptep, gfn);\n\t\t}\n\t}\n\n\tkvm_release_pfn_clean(pfn);\n\n\treturn emulate;\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_error_pfn",
          "args": [
            "pfn"
          ],
          "line": 485
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pte_prefetch_gfn_to_pfn",
          "args": [
            "vcpu",
            "gfn",
            "no_dirty_log && (pte_access & ACC_WRITE_MASK)"
          ],
          "line": 483
        },
        "resolved": true,
        "details": {
          "function_name": "pte_prefetch_gfn_to_pfn",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "2657-2667",
          "snippet": "static kvm_pfn_t pte_prefetch_gfn_to_pfn(struct kvm_vcpu *vcpu, gfn_t gfn,\n\t\t\t\t     bool no_dirty_log)\n{\n\tstruct kvm_memory_slot *slot;\n\n\tslot = gfn_to_memslot_dirty_bitmap(vcpu, gfn, no_dirty_log);\n\tif (!slot)\n\t\treturn KVM_PFN_ERR_FAULT;\n\n\treturn gfn_to_pfn_memslot_atomic(slot, gfn);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void mmu_free_roots(struct kvm_vcpu *vcpu);",
            "static void make_mmu_pages_available(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void mmu_free_roots(struct kvm_vcpu *vcpu);\nstatic void make_mmu_pages_available(struct kvm_vcpu *vcpu);\n\nstatic kvm_pfn_t pte_prefetch_gfn_to_pfn(struct kvm_vcpu *vcpu, gfn_t gfn,\n\t\t\t\t     bool no_dirty_log)\n{\n\tstruct kvm_memory_slot *slot;\n\n\tslot = gfn_to_memslot_dirty_bitmap(vcpu, gfn, no_dirty_log);\n\tif (!slot)\n\t\treturn KVM_PFN_ERR_FAULT;\n\n\treturn gfn_to_pfn_memslot_atomic(slot, gfn);\n}"
        }
      },
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "&pte_access",
            "gpte"
          ],
          "line": 482
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
          "lines": "936-1004",
          "snippet": "static int FNAME(sync_page)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp)\n{\n\tint i, nr_present = 0;\n\tbool host_writable;\n\tgpa_t first_pte_gpa;\n\n\t/* direct kvm_mmu_page can not be unsync. */\n\tBUG_ON(sp->role.direct);\n\n\tfirst_pte_gpa = FNAME(get_level1_sp_gpa)(sp);\n\n\tfor (i = 0; i < PT64_ENT_PER_PAGE; i++) {\n\t\tunsigned pte_access;\n\t\tpt_element_t gpte;\n\t\tgpa_t pte_gpa;\n\t\tgfn_t gfn;\n\n\t\tif (!sp->spt[i])\n\t\t\tcontinue;\n\n\t\tpte_gpa = first_pte_gpa + i * sizeof(pt_element_t);\n\n\t\tif (kvm_vcpu_read_guest_atomic(vcpu, pte_gpa, &gpte,\n\t\t\t\t\t       sizeof(pt_element_t)))\n\t\t\treturn 0;\n\n\t\tif (FNAME(prefetch_invalid_gpte)(vcpu, sp, &sp->spt[i], gpte)) {\n\t\t\t/*\n\t\t\t * Update spte before increasing tlbs_dirty to make\n\t\t\t * sure no tlb flush is lost after spte is zapped; see\n\t\t\t * the comments in kvm_flush_remote_tlbs().\n\t\t\t */\n\t\t\tsmp_wmb();\n\t\t\tvcpu->kvm->tlbs_dirty++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tgfn = gpte_to_gfn(gpte);\n\t\tpte_access = sp->role.access;\n\t\tpte_access &= FNAME(gpte_access)(vcpu, gpte);\n\t\tFNAME(protect_clean_gpte)(&pte_access, gpte);\n\n\t\tif (sync_mmio_spte(vcpu, &sp->spt[i], gfn, pte_access,\n\t\t      &nr_present))\n\t\t\tcontinue;\n\n\t\tif (gfn != sp->gfns[i]) {\n\t\t\tdrop_spte(vcpu->kvm, &sp->spt[i]);\n\t\t\t/*\n\t\t\t * The same as above where we are doing\n\t\t\t * prefetch_invalid_gpte().\n\t\t\t */\n\t\t\tsmp_wmb();\n\t\t\tvcpu->kvm->tlbs_dirty++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tnr_present++;\n\n\t\thost_writable = sp->spt[i] & SPTE_HOST_WRITEABLE;\n\n\t\tset_spte(vcpu, &sp->spt[i], pte_access,\n\t\t\t PT_PAGE_TABLE_LEVEL, gfn,\n\t\t\t spte_to_pfn(sp->spt[i]), true, false,\n\t\t\t host_writable);\n\t}\n\n\treturn nr_present;\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "gpte_to_gfn",
          "args": [
            "gpte"
          ],
          "line": 480
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pgprintk",
          "args": [
            "\"%s: gpte %llx spte %p\\n\"",
            "__func__",
            "(u64)gpte",
            "spte"
          ],
          "line": 478
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define pt_element_t u64\n#define pt_element_t u32\n#define pt_element_t u64\n\nstatic bool\nFNAME(prefetch_gpte)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,\n\t\t     u64 *spte, pt_element_t gpte, bool no_dirty_log)\n{\n\tunsigned pte_access;\n\tgfn_t gfn;\n\tkvm_pfn_t pfn;\n\n\tif (FNAME(prefetch_invalid_gpte)(vcpu, sp, spte, gpte))\n\t\treturn false;\n\n\tpgprintk(\"%s: gpte %llx spte %p\\n\", __func__, (u64)gpte, spte);\n\n\tgfn = gpte_to_gfn(gpte);\n\tpte_access = sp->role.access & FNAME(gpte_access)(vcpu, gpte);\n\tFNAME(protect_clean_gpte)(&pte_access, gpte);\n\tpfn = pte_prefetch_gfn_to_pfn(vcpu, gfn,\n\t\t\tno_dirty_log && (pte_access & ACC_WRITE_MASK));\n\tif (is_error_pfn(pfn))\n\t\treturn false;\n\n\t/*\n\t * we call mmu_set_spte() with host_writable = true because\n\t * pte_prefetch_gfn_to_pfn always gets a writable pfn.\n\t */\n\tmmu_set_spte(vcpu, spte, pte_access, 0, PT_PAGE_TABLE_LEVEL, gfn, pfn,\n\t\t     true, true);\n\n\treturn true;\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
    "lines": "458-464",
    "snippet": "static int FNAME(walk_addr_nested)(struct guest_walker *walker,\n\t\t\t\t   struct kvm_vcpu *vcpu, gva_t addr,\n\t\t\t\t   u32 access)\n{\n\treturn FNAME(walk_addr_generic)(walker, vcpu, &vcpu->arch.nested_mmu,\n\t\t\t\t\taddr, access);\n}",
    "includes": [],
    "macros_used": [
      "#define guest_walker guest_walkerEPT",
      "#define guest_walker guest_walker32",
      "#define guest_walker guest_walker64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "walker",
            "vcpu",
            "&vcpu->arch.nested_mmu",
            "addr",
            "access"
          ],
          "line": 462
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
          "lines": "467-496",
          "snippet": "static bool\nFNAME(prefetch_gpte)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,\n\t\t     u64 *spte, pt_element_t gpte, bool no_dirty_log)\n{\n\tunsigned pte_access;\n\tgfn_t gfn;\n\tkvm_pfn_t pfn;\n\n\tif (FNAME(prefetch_invalid_gpte)(vcpu, sp, spte, gpte))\n\t\treturn false;\n\n\tpgprintk(\"%s: gpte %llx spte %p\\n\", __func__, (u64)gpte, spte);\n\n\tgfn = gpte_to_gfn(gpte);\n\tpte_access = sp->role.access & FNAME(gpte_access)(vcpu, gpte);\n\tFNAME(protect_clean_gpte)(&pte_access, gpte);\n\tpfn = pte_prefetch_gfn_to_pfn(vcpu, gfn,\n\t\t\tno_dirty_log && (pte_access & ACC_WRITE_MASK));\n\tif (is_error_pfn(pfn))\n\t\treturn false;\n\n\t/*\n\t * we call mmu_set_spte() with host_writable = true because\n\t * pte_prefetch_gfn_to_pfn always gets a writable pfn.\n\t */\n\tmmu_set_spte(vcpu, spte, pte_access, 0, PT_PAGE_TABLE_LEVEL, gfn, pfn,\n\t\t     true, true);\n\n\treturn true;\n}",
          "note": "cyclic_reference_detected"
        }
      }
    ],
    "contextual_snippet": "#define guest_walker guest_walkerEPT\n#define guest_walker guest_walker32\n#define guest_walker guest_walker64\n\nstatic int FNAME(walk_addr_nested)(struct guest_walker *walker,\n\t\t\t\t   struct kvm_vcpu *vcpu, gva_t addr,\n\t\t\t\t   u32 access)\n{\n\treturn FNAME(walk_addr_generic)(walker, vcpu, &vcpu->arch.nested_mmu,\n\t\t\t\t\taddr, access);\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
    "lines": "450-455",
    "snippet": "static int FNAME(walk_addr)(struct guest_walker *walker,\n\t\t\t    struct kvm_vcpu *vcpu, gva_t addr, u32 access)\n{\n\treturn FNAME(walk_addr_generic)(walker, vcpu, &vcpu->arch.mmu, addr,\n\t\t\t\t\taccess);\n}",
    "includes": [],
    "macros_used": [
      "#define guest_walker guest_walkerEPT",
      "#define guest_walker guest_walker32",
      "#define guest_walker guest_walker64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "walker",
            "vcpu",
            "&vcpu->arch.mmu",
            "addr",
            "access"
          ],
          "line": 453
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
          "lines": "467-496",
          "snippet": "static bool\nFNAME(prefetch_gpte)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,\n\t\t     u64 *spte, pt_element_t gpte, bool no_dirty_log)\n{\n\tunsigned pte_access;\n\tgfn_t gfn;\n\tkvm_pfn_t pfn;\n\n\tif (FNAME(prefetch_invalid_gpte)(vcpu, sp, spte, gpte))\n\t\treturn false;\n\n\tpgprintk(\"%s: gpte %llx spte %p\\n\", __func__, (u64)gpte, spte);\n\n\tgfn = gpte_to_gfn(gpte);\n\tpte_access = sp->role.access & FNAME(gpte_access)(vcpu, gpte);\n\tFNAME(protect_clean_gpte)(&pte_access, gpte);\n\tpfn = pte_prefetch_gfn_to_pfn(vcpu, gfn,\n\t\t\tno_dirty_log && (pte_access & ACC_WRITE_MASK));\n\tif (is_error_pfn(pfn))\n\t\treturn false;\n\n\t/*\n\t * we call mmu_set_spte() with host_writable = true because\n\t * pte_prefetch_gfn_to_pfn always gets a writable pfn.\n\t */\n\tmmu_set_spte(vcpu, spte, pte_access, 0, PT_PAGE_TABLE_LEVEL, gfn, pfn,\n\t\t     true, true);\n\n\treturn true;\n}",
          "note": "cyclic_reference_detected"
        }
      }
    ],
    "contextual_snippet": "#define guest_walker guest_walkerEPT\n#define guest_walker guest_walker32\n#define guest_walker guest_walker64\n\nstatic int FNAME(walk_addr)(struct guest_walker *walker,\n\t\t\t    struct kvm_vcpu *vcpu, gva_t addr, u32 access)\n{\n\treturn FNAME(walk_addr_generic)(walker, vcpu, &vcpu->arch.mmu, addr,\n\t\t\t\t\taccess);\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
    "lines": "274-448",
    "snippet": "static int FNAME(walk_addr_generic)(struct guest_walker *walker,\n\t\t\t\t    struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n\t\t\t\t    gva_t addr, u32 access)\n{\n\tint ret;\n\tpt_element_t pte;\n\tpt_element_t __user *uninitialized_var(ptep_user);\n\tgfn_t table_gfn;\n\tunsigned index, pt_access, pte_access, accessed_dirty, pte_pkey;\n\tgpa_t pte_gpa;\n\tint offset;\n\tconst int write_fault = access & PFERR_WRITE_MASK;\n\tconst int user_fault  = access & PFERR_USER_MASK;\n\tconst int fetch_fault = access & PFERR_FETCH_MASK;\n\tu16 errcode = 0;\n\tgpa_t real_gpa;\n\tgfn_t gfn;\n\n\ttrace_kvm_mmu_pagetable_walk(addr, access);\nretry_walk:\n\twalker->level = mmu->root_level;\n\tpte           = mmu->get_cr3(vcpu);\n\n#if PTTYPE == 64\n\tif (walker->level == PT32E_ROOT_LEVEL) {\n\t\tpte = mmu->get_pdptr(vcpu, (addr >> 30) & 3);\n\t\ttrace_kvm_mmu_paging_element(pte, walker->level);\n\t\tif (!FNAME(is_present_gpte)(pte))\n\t\t\tgoto error;\n\t\t--walker->level;\n\t}\n#endif\n\twalker->max_level = walker->level;\n\tASSERT(!(is_long_mode(vcpu) && !is_pae(vcpu)));\n\n\taccessed_dirty = PT_GUEST_ACCESSED_MASK;\n\tpt_access = pte_access = ACC_ALL;\n\t++walker->level;\n\n\tdo {\n\t\tgfn_t real_gfn;\n\t\tunsigned long host_addr;\n\n\t\tpt_access &= pte_access;\n\t\t--walker->level;\n\n\t\tindex = PT_INDEX(addr, walker->level);\n\n\t\ttable_gfn = gpte_to_gfn(pte);\n\t\toffset    = index * sizeof(pt_element_t);\n\t\tpte_gpa   = gfn_to_gpa(table_gfn) + offset;\n\t\twalker->table_gfn[walker->level - 1] = table_gfn;\n\t\twalker->pte_gpa[walker->level - 1] = pte_gpa;\n\n\t\treal_gfn = mmu->translate_gpa(vcpu, gfn_to_gpa(table_gfn),\n\t\t\t\t\t      PFERR_USER_MASK|PFERR_WRITE_MASK,\n\t\t\t\t\t      &walker->fault);\n\n\t\t/*\n\t\t * FIXME: This can happen if emulation (for of an INS/OUTS\n\t\t * instruction) triggers a nested page fault.  The exit\n\t\t * qualification / exit info field will incorrectly have\n\t\t * \"guest page access\" as the nested page fault's cause,\n\t\t * instead of \"guest page structure access\".  To fix this,\n\t\t * the x86_exception struct should be augmented with enough\n\t\t * information to fix the exit_qualification or exit_info_1\n\t\t * fields.\n\t\t */\n\t\tif (unlikely(real_gfn == UNMAPPED_GVA))\n\t\t\treturn 0;\n\n\t\treal_gfn = gpa_to_gfn(real_gfn);\n\n\t\thost_addr = kvm_vcpu_gfn_to_hva_prot(vcpu, real_gfn,\n\t\t\t\t\t    &walker->pte_writable[walker->level - 1]);\n\t\tif (unlikely(kvm_is_error_hva(host_addr)))\n\t\t\tgoto error;\n\n\t\tptep_user = (pt_element_t __user *)((void *)host_addr + offset);\n\t\tif (unlikely(__copy_from_user(&pte, ptep_user, sizeof(pte))))\n\t\t\tgoto error;\n\t\twalker->ptep_user[walker->level - 1] = ptep_user;\n\n\t\ttrace_kvm_mmu_paging_element(pte, walker->level);\n\n\t\tif (unlikely(!FNAME(is_present_gpte)(pte)))\n\t\t\tgoto error;\n\n\t\tif (unlikely(is_rsvd_bits_set(mmu, pte, walker->level))) {\n\t\t\terrcode = PFERR_RSVD_MASK | PFERR_PRESENT_MASK;\n\t\t\tgoto error;\n\t\t}\n\n\t\taccessed_dirty &= pte;\n\t\tpte_access = pt_access & FNAME(gpte_access)(vcpu, pte);\n\n\t\twalker->ptes[walker->level - 1] = pte;\n\t} while (!is_last_gpte(mmu, walker->level, pte));\n\n\tpte_pkey = FNAME(gpte_pkeys)(vcpu, pte);\n\terrcode = permission_fault(vcpu, mmu, pte_access, pte_pkey, access);\n\tif (unlikely(errcode))\n\t\tgoto error;\n\n\tgfn = gpte_to_gfn_lvl(pte, walker->level);\n\tgfn += (addr & PT_LVL_OFFSET_MASK(walker->level)) >> PAGE_SHIFT;\n\n\tif (PTTYPE == 32 && walker->level == PT_DIRECTORY_LEVEL && is_cpuid_PSE36())\n\t\tgfn += pse36_gfn_delta(pte);\n\n\treal_gpa = mmu->translate_gpa(vcpu, gfn_to_gpa(gfn), access, &walker->fault);\n\tif (real_gpa == UNMAPPED_GVA)\n\t\treturn 0;\n\n\twalker->gfn = real_gpa >> PAGE_SHIFT;\n\n\tif (!write_fault)\n\t\tFNAME(protect_clean_gpte)(&pte_access, pte);\n\telse\n\t\t/*\n\t\t * On a write fault, fold the dirty bit into accessed_dirty.\n\t\t * For modes without A/D bits support accessed_dirty will be\n\t\t * always clear.\n\t\t */\n\t\taccessed_dirty &= pte >>\n\t\t\t(PT_GUEST_DIRTY_SHIFT - PT_GUEST_ACCESSED_SHIFT);\n\n\tif (unlikely(!accessed_dirty)) {\n\t\tret = FNAME(update_accessed_dirty_bits)(vcpu, mmu, walker, write_fault);\n\t\tif (unlikely(ret < 0))\n\t\t\tgoto error;\n\t\telse if (ret)\n\t\t\tgoto retry_walk;\n\t}\n\n\twalker->pt_access = pt_access;\n\twalker->pte_access = pte_access;\n\tpgprintk(\"%s: pte %llx pte_access %x pt_access %x\\n\",\n\t\t __func__, (u64)pte, pte_access, pt_access);\n\treturn 1;\n\nerror:\n\terrcode |= write_fault | user_fault;\n\tif (fetch_fault && (mmu->nx ||\n\t\t\t    kvm_read_cr4_bits(vcpu, X86_CR4_SMEP)))\n\t\terrcode |= PFERR_FETCH_MASK;\n\n\twalker->fault.vector = PF_VECTOR;\n\twalker->fault.error_code_valid = true;\n\twalker->fault.error_code = errcode;\n\n#if PTTYPE == PTTYPE_EPT\n\t/*\n\t * Use PFERR_RSVD_MASK in error_code to to tell if EPT\n\t * misconfiguration requires to be injected. The detection is\n\t * done by is_rsvd_bits_set() above.\n\t *\n\t * We set up the value of exit_qualification to inject:\n\t * [2:0] - Derive from [2:0] of real exit_qualification at EPT violation\n\t * [5:3] - Calculated by the page walk of the guest EPT page tables\n\t * [7:8] - Derived from [7:8] of real exit_qualification\n\t *\n\t * The other bits are set to 0.\n\t */\n\tif (!(errcode & PFERR_RSVD_MASK)) {\n\t\tvcpu->arch.exit_qualification &= 0x187;\n\t\tvcpu->arch.exit_qualification |= ((pt_access & pte) & 0x7) << 3;\n\t}\n#endif\n\twalker->fault.address = addr;\n\twalker->fault.nested_page_fault = mmu != vcpu->arch.walk_mmu;\n\n\ttrace_kvm_mmu_walker_error(walker->fault.error_code);\n\treturn 0;\n}",
    "includes": [],
    "macros_used": [
      "#define gpte_to_gfn_lvl FNAME(gpte_to_gfn_lvl)",
      "#define PT_GUEST_ACCESSED_SHIFT __using_nonexistent_pte_bit()",
      "#define PT_GUEST_DIRTY_SHIFT __using_nonexistent_pte_bit()",
      "#define PT_GUEST_ACCESSED_MASK 0",
      "#define guest_walker guest_walkerEPT",
      "#define pt_element_t u64",
      "#define PT_GUEST_ACCESSED_SHIFT PT_ACCESSED_SHIFT",
      "#define PT_GUEST_DIRTY_SHIFT PT_DIRTY_SHIFT",
      "#define PT_GUEST_ACCESSED_MASK PT_ACCESSED_MASK",
      "#define guest_walker guest_walker32",
      "#define pt_element_t u32",
      "#define PT_GUEST_ACCESSED_SHIFT PT_ACCESSED_SHIFT",
      "#define PT_GUEST_DIRTY_SHIFT PT_DIRTY_SHIFT",
      "#define PT_GUEST_ACCESSED_MASK PT_ACCESSED_MASK",
      "#define guest_walker guest_walker64",
      "#define pt_element_t u64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "trace_kvm_mmu_walker_error",
          "args": [
            "walker->fault.error_code"
          ],
          "line": 446
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_read_cr4_bits",
          "args": [
            "vcpu",
            "X86_CR4_SMEP"
          ],
          "line": 418
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_read_cr4_bits",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/kvm_cache_regs.h",
          "lines": "61-67",
          "snippet": "static inline ulong kvm_read_cr4_bits(struct kvm_vcpu *vcpu, ulong mask)\n{\n\tulong tmask = mask & KVM_POSSIBLE_CR4_GUEST_BITS;\n\tif (tmask & vcpu->arch.cr4_guest_owned_bits)\n\t\tkvm_x86_ops->decache_cr4_guest_bits(vcpu);\n\treturn vcpu->arch.cr4 & mask;\n}",
          "includes": [],
          "macros_used": [
            "#define KVM_POSSIBLE_CR4_GUEST_BITS\t\t\t\t  \\\n\t(X86_CR4_PVI | X86_CR4_DE | X86_CR4_PCE | X86_CR4_OSFXSR  \\\n\t | X86_CR4_OSXMMEXCPT | X86_CR4_PGE)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#define KVM_POSSIBLE_CR4_GUEST_BITS\t\t\t\t  \\\n\t(X86_CR4_PVI | X86_CR4_DE | X86_CR4_PCE | X86_CR4_OSFXSR  \\\n\t | X86_CR4_OSXMMEXCPT | X86_CR4_PGE)\n\nstatic inline ulong kvm_read_cr4_bits(struct kvm_vcpu *vcpu, ulong mask)\n{\n\tulong tmask = mask & KVM_POSSIBLE_CR4_GUEST_BITS;\n\tif (tmask & vcpu->arch.cr4_guest_owned_bits)\n\t\tkvm_x86_ops->decache_cr4_guest_bits(vcpu);\n\treturn vcpu->arch.cr4 & mask;\n}"
        }
      },
      {
        "call_info": {
          "callee": "pgprintk",
          "args": [
            "\"%s: pte %llx pte_access %x pt_access %x\\n\"",
            "__func__",
            "(u64)pte",
            "pte_access",
            "pt_access"
          ],
          "line": 411
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "ret < 0"
          ],
          "line": 403
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "vcpu",
            "mmu",
            "walker",
            "write_fault"
          ],
          "line": 402
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
          "lines": "903-920",
          "snippet": "static gpa_t FNAME(gva_to_gpa_nested)(struct kvm_vcpu *vcpu, gva_t vaddr,\n\t\t\t\t      u32 access,\n\t\t\t\t      struct x86_exception *exception)\n{\n\tstruct guest_walker walker;\n\tgpa_t gpa = UNMAPPED_GVA;\n\tint r;\n\n\tr = FNAME(walk_addr_nested)(&walker, vcpu, vaddr, access);\n\n\tif (r) {\n\t\tgpa = gfn_to_gpa(walker.gfn);\n\t\tgpa |= vaddr & ~PAGE_MASK;\n\t} else if (exception)\n\t\t*exception = walker.fault;\n\n\treturn gpa;\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!accessed_dirty"
          ],
          "line": 401
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mmu->translate_gpa",
          "args": [
            "vcpu",
            "gfn_to_gpa(gfn)",
            "access",
            "&walker->fault"
          ],
          "line": 384
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "gfn_to_gpa",
          "args": [
            "gfn"
          ],
          "line": 384
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pse36_gfn_delta",
          "args": [
            "pte"
          ],
          "line": 382
        },
        "resolved": true,
        "details": {
          "function_name": "pse36_gfn_delta",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "329-334",
          "snippet": "static gfn_t pse36_gfn_delta(u32 gpte)\n{\n\tint shift = 32 - PT32_DIR_PSE36_SHIFT - PAGE_SHIFT;\n\n\treturn (gpte & PT32_DIR_PSE36_MASK) << shift;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic gfn_t pse36_gfn_delta(u32 gpte)\n{\n\tint shift = 32 - PT32_DIR_PSE36_SHIFT - PAGE_SHIFT;\n\n\treturn (gpte & PT32_DIR_PSE36_MASK) << shift;\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_cpuid_PSE36",
          "args": [],
          "line": 381
        },
        "resolved": true,
        "details": {
          "function_name": "is_cpuid_PSE36",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "295-298",
          "snippet": "static int is_cpuid_PSE36(void)\n{\n\treturn 1;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic int is_cpuid_PSE36(void)\n{\n\treturn 1;\n}"
        }
      },
      {
        "call_info": {
          "callee": "PT_LVL_OFFSET_MASK",
          "args": [
            "walker->level"
          ],
          "line": 379
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "gpte_to_gfn_lvl",
          "args": [
            "pte",
            "walker->level"
          ],
          "line": 378
        },
        "resolved": true,
        "details": {
          "function_name": "gpte_to_gfn_lvl",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
          "lines": "109-112",
          "snippet": "static gfn_t gpte_to_gfn_lvl(pt_element_t gpte, int lvl)\n{\n\treturn (gpte & PT_LVL_ADDR_MASK(lvl)) >> PAGE_SHIFT;\n}",
          "includes": [],
          "macros_used": [
            "#define gpte_to_gfn_lvl FNAME(gpte_to_gfn_lvl)",
            "#define pt_element_t u64",
            "#define pt_element_t u32",
            "#define pt_element_t u64"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#define gpte_to_gfn_lvl FNAME(gpte_to_gfn_lvl)\n#define pt_element_t u64\n#define pt_element_t u32\n#define pt_element_t u64\n\nstatic gfn_t gpte_to_gfn_lvl(pt_element_t gpte, int lvl)\n{\n\treturn (gpte & PT_LVL_ADDR_MASK(lvl)) >> PAGE_SHIFT;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "errcode"
          ],
          "line": 375
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "permission_fault",
          "args": [
            "vcpu",
            "mmu",
            "pte_access",
            "pte_pkey",
            "access"
          ],
          "line": 374
        },
        "resolved": true,
        "details": {
          "function_name": "permission_fault",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.h",
          "lines": "152-200",
          "snippet": "static inline u8 permission_fault(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n\t\t\t\t  unsigned pte_access, unsigned pte_pkey,\n\t\t\t\t  unsigned pfec)\n{\n\tint cpl = kvm_x86_ops->get_cpl(vcpu);\n\tunsigned long rflags = kvm_x86_ops->get_rflags(vcpu);\n\n\t/*\n\t * If CPL < 3, SMAP prevention are disabled if EFLAGS.AC = 1.\n\t *\n\t * If CPL = 3, SMAP applies to all supervisor-mode data accesses\n\t * (these are implicit supervisor accesses) regardless of the value\n\t * of EFLAGS.AC.\n\t *\n\t * This computes (cpl < 3) && (rflags & X86_EFLAGS_AC), leaving\n\t * the result in X86_EFLAGS_AC. We then insert it in place of\n\t * the PFERR_RSVD_MASK bit; this bit will always be zero in pfec,\n\t * but it will be one in index if SMAP checks are being overridden.\n\t * It is important to keep this branchless.\n\t */\n\tunsigned long smap = (cpl - 3) & (rflags & X86_EFLAGS_AC);\n\tint index = (pfec >> 1) +\n\t\t    (smap >> (X86_EFLAGS_AC_BIT - PFERR_RSVD_BIT + 1));\n\tbool fault = (mmu->permissions[index] >> pte_access) & 1;\n\tu32 errcode = PFERR_PRESENT_MASK;\n\n\tWARN_ON(pfec & (PFERR_PK_MASK | PFERR_RSVD_MASK));\n\tif (unlikely(mmu->pkru_mask)) {\n\t\tu32 pkru_bits, offset;\n\n\t\t/*\n\t\t* PKRU defines 32 bits, there are 16 domains and 2\n\t\t* attribute bits per domain in pkru.  pte_pkey is the\n\t\t* index of the protection domain, so pte_pkey * 2 is\n\t\t* is the index of the first bit for the domain.\n\t\t*/\n\t\tpkru_bits = (kvm_read_pkru(vcpu) >> (pte_pkey * 2)) & 3;\n\n\t\t/* clear present bit, replace PFEC.RSVD with ACC_USER_MASK. */\n\t\toffset = (pfec & ~1) +\n\t\t\t((pte_access & PT_USER_MASK) << (PFERR_RSVD_BIT - PT_USER_SHIFT));\n\n\t\tpkru_bits &= mmu->pkru_mask >> offset;\n\t\terrcode |= -pkru_bits & PFERR_PK_MASK;\n\t\tfault |= (pkru_bits != 0);\n\t}\n\n\treturn -(u32)fault & errcode;\n}",
          "includes": [
            "#include \"kvm_cache_regs.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [
            "#define PT_USER_MASK (1ULL << PT_USER_SHIFT)",
            "#define PT_USER_SHIFT 2"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\n#define PT_USER_MASK (1ULL << PT_USER_SHIFT)\n#define PT_USER_SHIFT 2\n\nstatic inline u8 permission_fault(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n\t\t\t\t  unsigned pte_access, unsigned pte_pkey,\n\t\t\t\t  unsigned pfec)\n{\n\tint cpl = kvm_x86_ops->get_cpl(vcpu);\n\tunsigned long rflags = kvm_x86_ops->get_rflags(vcpu);\n\n\t/*\n\t * If CPL < 3, SMAP prevention are disabled if EFLAGS.AC = 1.\n\t *\n\t * If CPL = 3, SMAP applies to all supervisor-mode data accesses\n\t * (these are implicit supervisor accesses) regardless of the value\n\t * of EFLAGS.AC.\n\t *\n\t * This computes (cpl < 3) && (rflags & X86_EFLAGS_AC), leaving\n\t * the result in X86_EFLAGS_AC. We then insert it in place of\n\t * the PFERR_RSVD_MASK bit; this bit will always be zero in pfec,\n\t * but it will be one in index if SMAP checks are being overridden.\n\t * It is important to keep this branchless.\n\t */\n\tunsigned long smap = (cpl - 3) & (rflags & X86_EFLAGS_AC);\n\tint index = (pfec >> 1) +\n\t\t    (smap >> (X86_EFLAGS_AC_BIT - PFERR_RSVD_BIT + 1));\n\tbool fault = (mmu->permissions[index] >> pte_access) & 1;\n\tu32 errcode = PFERR_PRESENT_MASK;\n\n\tWARN_ON(pfec & (PFERR_PK_MASK | PFERR_RSVD_MASK));\n\tif (unlikely(mmu->pkru_mask)) {\n\t\tu32 pkru_bits, offset;\n\n\t\t/*\n\t\t* PKRU defines 32 bits, there are 16 domains and 2\n\t\t* attribute bits per domain in pkru.  pte_pkey is the\n\t\t* index of the protection domain, so pte_pkey * 2 is\n\t\t* is the index of the first bit for the domain.\n\t\t*/\n\t\tpkru_bits = (kvm_read_pkru(vcpu) >> (pte_pkey * 2)) & 3;\n\n\t\t/* clear present bit, replace PFEC.RSVD with ACC_USER_MASK. */\n\t\toffset = (pfec & ~1) +\n\t\t\t((pte_access & PT_USER_MASK) << (PFERR_RSVD_BIT - PT_USER_SHIFT));\n\n\t\tpkru_bits &= mmu->pkru_mask >> offset;\n\t\terrcode |= -pkru_bits & PFERR_PK_MASK;\n\t\tfault |= (pkru_bits != 0);\n\t}\n\n\treturn -(u32)fault & errcode;\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_last_gpte",
          "args": [
            "mmu",
            "walker->level",
            "pte"
          ],
          "line": 371
        },
        "resolved": true,
        "details": {
          "function_name": "is_last_gpte",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "3637-3655",
          "snippet": "static inline bool is_last_gpte(struct kvm_mmu *mmu,\n\t\t\t\tunsigned level, unsigned gpte)\n{\n\t/*\n\t * PT_PAGE_TABLE_LEVEL always terminates.  The RHS has bit 7 set\n\t * iff level <= PT_PAGE_TABLE_LEVEL, which for our purpose means\n\t * level == PT_PAGE_TABLE_LEVEL; set PT_PAGE_SIZE_MASK in gpte then.\n\t */\n\tgpte |= level - PT_PAGE_TABLE_LEVEL - 1;\n\n\t/*\n\t * The RHS has bit 7 set iff level < mmu->last_nonleaf_level.\n\t * If it is clear, there are no large pages at this level, so clear\n\t * PT_PAGE_SIZE_MASK in gpte if that is the case.\n\t */\n\tgpte &= level - mmu->last_nonleaf_level;\n\n\treturn gpte & PT_PAGE_SIZE_MASK;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic inline bool is_last_gpte(struct kvm_mmu *mmu,\n\t\t\t\tunsigned level, unsigned gpte)\n{\n\t/*\n\t * PT_PAGE_TABLE_LEVEL always terminates.  The RHS has bit 7 set\n\t * iff level <= PT_PAGE_TABLE_LEVEL, which for our purpose means\n\t * level == PT_PAGE_TABLE_LEVEL; set PT_PAGE_SIZE_MASK in gpte then.\n\t */\n\tgpte |= level - PT_PAGE_TABLE_LEVEL - 1;\n\n\t/*\n\t * The RHS has bit 7 set iff level < mmu->last_nonleaf_level.\n\t * If it is clear, there are no large pages at this level, so clear\n\t * PT_PAGE_SIZE_MASK in gpte if that is the case.\n\t */\n\tgpte &= level - mmu->last_nonleaf_level;\n\n\treturn gpte & PT_PAGE_SIZE_MASK;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "is_rsvd_bits_set(mmu, pte, walker->level)"
          ],
          "line": 362
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "is_rsvd_bits_set",
          "args": [
            "mmu",
            "pte",
            "walker->level"
          ],
          "line": 362
        },
        "resolved": true,
        "details": {
          "function_name": "is_rsvd_bits_set",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "3314-3317",
          "snippet": "static bool is_rsvd_bits_set(struct kvm_mmu *mmu, u64 gpte, int level)\n{\n\treturn __is_rsvd_bits_set(&mmu->guest_rsvd_check, gpte, level);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic bool is_rsvd_bits_set(struct kvm_mmu *mmu, u64 gpte, int level)\n{\n\treturn __is_rsvd_bits_set(&mmu->guest_rsvd_check, gpte, level);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!FNAME(is_present_gpte)(pte)"
          ],
          "line": 359
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_kvm_mmu_paging_element",
          "args": [
            "pte",
            "walker->level"
          ],
          "line": 357
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "__copy_from_user(&pte, ptep_user, sizeof(pte))"
          ],
          "line": 353
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__copy_from_user",
          "args": [
            "&pte",
            "ptep_user",
            "sizeof(pte)"
          ],
          "line": 353
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "kvm_is_error_hva(host_addr)"
          ],
          "line": 349
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_is_error_hva",
          "args": [
            "host_addr"
          ],
          "line": 349
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_vcpu_gfn_to_hva_prot",
          "args": [
            "vcpu",
            "real_gfn",
            "&walker->pte_writable[walker->level - 1]"
          ],
          "line": 347
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "gpa_to_gfn",
          "args": [
            "real_gfn"
          ],
          "line": 345
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "real_gfn == UNMAPPED_GVA"
          ],
          "line": 342
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mmu->translate_gpa",
          "args": [
            "vcpu",
            "gfn_to_gpa(table_gfn)",
            "PFERR_USER_MASK|PFERR_WRITE_MASK",
            "&walker->fault"
          ],
          "line": 328
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "gfn_to_gpa",
          "args": [
            "table_gfn"
          ],
          "line": 328
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "gfn_to_gpa",
          "args": [
            "table_gfn"
          ],
          "line": 324
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "gpte_to_gfn",
          "args": [
            "pte"
          ],
          "line": 322
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "PT_INDEX",
          "args": [
            "addr",
            "walker->level"
          ],
          "line": 320
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ASSERT",
          "args": [
            "!(is_long_mode(vcpu) && !is_pae(vcpu))"
          ],
          "line": 307
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "is_pae",
          "args": [
            "vcpu"
          ],
          "line": 307
        },
        "resolved": true,
        "details": {
          "function_name": "is_pae",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/x86.h",
          "lines": "67-70",
          "snippet": "static inline int is_pae(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_read_cr4_bits(vcpu, X86_CR4_PAE);\n}",
          "includes": [
            "#include \"kvm_cache_regs.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\nstatic inline int is_pae(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_read_cr4_bits(vcpu, X86_CR4_PAE);\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_long_mode",
          "args": [
            "vcpu"
          ],
          "line": 307
        },
        "resolved": true,
        "details": {
          "function_name": "is_long_mode",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/x86.h",
          "lines": "43-50",
          "snippet": "static inline int is_long_mode(struct kvm_vcpu *vcpu)\n{\n#ifdef CONFIG_X86_64\n\treturn vcpu->arch.efer & EFER_LMA;\n#else\n\treturn 0;\n#endif\n}",
          "includes": [
            "#include \"kvm_cache_regs.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\nstatic inline int is_long_mode(struct kvm_vcpu *vcpu)\n{\n#ifdef CONFIG_X86_64\n\treturn vcpu->arch.efer & EFER_LMA;\n#else\n\treturn 0;\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "trace_kvm_mmu_paging_element",
          "args": [
            "pte",
            "walker->level"
          ],
          "line": 300
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mmu->get_pdptr",
          "args": [
            "vcpu",
            "(addr >> 30) & 3"
          ],
          "line": 299
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mmu->get_cr3",
          "args": [
            "vcpu"
          ],
          "line": 295
        },
        "resolved": true,
        "details": {
          "function_name": "get_cr3",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "3609-3612",
          "snippet": "static unsigned long get_cr3(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_read_cr3(vcpu);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void mmu_free_roots(struct kvm_vcpu *vcpu);",
            "static void make_mmu_pages_available(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void mmu_free_roots(struct kvm_vcpu *vcpu);\nstatic void make_mmu_pages_available(struct kvm_vcpu *vcpu);\n\nstatic unsigned long get_cr3(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_read_cr3(vcpu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "trace_kvm_mmu_pagetable_walk",
          "args": [
            "addr",
            "access"
          ],
          "line": 292
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define gpte_to_gfn_lvl FNAME(gpte_to_gfn_lvl)\n#define PT_GUEST_ACCESSED_SHIFT __using_nonexistent_pte_bit()\n#define PT_GUEST_DIRTY_SHIFT __using_nonexistent_pte_bit()\n#define PT_GUEST_ACCESSED_MASK 0\n#define guest_walker guest_walkerEPT\n#define pt_element_t u64\n#define PT_GUEST_ACCESSED_SHIFT PT_ACCESSED_SHIFT\n#define PT_GUEST_DIRTY_SHIFT PT_DIRTY_SHIFT\n#define PT_GUEST_ACCESSED_MASK PT_ACCESSED_MASK\n#define guest_walker guest_walker32\n#define pt_element_t u32\n#define PT_GUEST_ACCESSED_SHIFT PT_ACCESSED_SHIFT\n#define PT_GUEST_DIRTY_SHIFT PT_DIRTY_SHIFT\n#define PT_GUEST_ACCESSED_MASK PT_ACCESSED_MASK\n#define guest_walker guest_walker64\n#define pt_element_t u64\n\nstatic int FNAME(walk_addr_generic)(struct guest_walker *walker,\n\t\t\t\t    struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n\t\t\t\t    gva_t addr, u32 access)\n{\n\tint ret;\n\tpt_element_t pte;\n\tpt_element_t __user *uninitialized_var(ptep_user);\n\tgfn_t table_gfn;\n\tunsigned index, pt_access, pte_access, accessed_dirty, pte_pkey;\n\tgpa_t pte_gpa;\n\tint offset;\n\tconst int write_fault = access & PFERR_WRITE_MASK;\n\tconst int user_fault  = access & PFERR_USER_MASK;\n\tconst int fetch_fault = access & PFERR_FETCH_MASK;\n\tu16 errcode = 0;\n\tgpa_t real_gpa;\n\tgfn_t gfn;\n\n\ttrace_kvm_mmu_pagetable_walk(addr, access);\nretry_walk:\n\twalker->level = mmu->root_level;\n\tpte           = mmu->get_cr3(vcpu);\n\n#if PTTYPE == 64\n\tif (walker->level == PT32E_ROOT_LEVEL) {\n\t\tpte = mmu->get_pdptr(vcpu, (addr >> 30) & 3);\n\t\ttrace_kvm_mmu_paging_element(pte, walker->level);\n\t\tif (!FNAME(is_present_gpte)(pte))\n\t\t\tgoto error;\n\t\t--walker->level;\n\t}\n#endif\n\twalker->max_level = walker->level;\n\tASSERT(!(is_long_mode(vcpu) && !is_pae(vcpu)));\n\n\taccessed_dirty = PT_GUEST_ACCESSED_MASK;\n\tpt_access = pte_access = ACC_ALL;\n\t++walker->level;\n\n\tdo {\n\t\tgfn_t real_gfn;\n\t\tunsigned long host_addr;\n\n\t\tpt_access &= pte_access;\n\t\t--walker->level;\n\n\t\tindex = PT_INDEX(addr, walker->level);\n\n\t\ttable_gfn = gpte_to_gfn(pte);\n\t\toffset    = index * sizeof(pt_element_t);\n\t\tpte_gpa   = gfn_to_gpa(table_gfn) + offset;\n\t\twalker->table_gfn[walker->level - 1] = table_gfn;\n\t\twalker->pte_gpa[walker->level - 1] = pte_gpa;\n\n\t\treal_gfn = mmu->translate_gpa(vcpu, gfn_to_gpa(table_gfn),\n\t\t\t\t\t      PFERR_USER_MASK|PFERR_WRITE_MASK,\n\t\t\t\t\t      &walker->fault);\n\n\t\t/*\n\t\t * FIXME: This can happen if emulation (for of an INS/OUTS\n\t\t * instruction) triggers a nested page fault.  The exit\n\t\t * qualification / exit info field will incorrectly have\n\t\t * \"guest page access\" as the nested page fault's cause,\n\t\t * instead of \"guest page structure access\".  To fix this,\n\t\t * the x86_exception struct should be augmented with enough\n\t\t * information to fix the exit_qualification or exit_info_1\n\t\t * fields.\n\t\t */\n\t\tif (unlikely(real_gfn == UNMAPPED_GVA))\n\t\t\treturn 0;\n\n\t\treal_gfn = gpa_to_gfn(real_gfn);\n\n\t\thost_addr = kvm_vcpu_gfn_to_hva_prot(vcpu, real_gfn,\n\t\t\t\t\t    &walker->pte_writable[walker->level - 1]);\n\t\tif (unlikely(kvm_is_error_hva(host_addr)))\n\t\t\tgoto error;\n\n\t\tptep_user = (pt_element_t __user *)((void *)host_addr + offset);\n\t\tif (unlikely(__copy_from_user(&pte, ptep_user, sizeof(pte))))\n\t\t\tgoto error;\n\t\twalker->ptep_user[walker->level - 1] = ptep_user;\n\n\t\ttrace_kvm_mmu_paging_element(pte, walker->level);\n\n\t\tif (unlikely(!FNAME(is_present_gpte)(pte)))\n\t\t\tgoto error;\n\n\t\tif (unlikely(is_rsvd_bits_set(mmu, pte, walker->level))) {\n\t\t\terrcode = PFERR_RSVD_MASK | PFERR_PRESENT_MASK;\n\t\t\tgoto error;\n\t\t}\n\n\t\taccessed_dirty &= pte;\n\t\tpte_access = pt_access & FNAME(gpte_access)(vcpu, pte);\n\n\t\twalker->ptes[walker->level - 1] = pte;\n\t} while (!is_last_gpte(mmu, walker->level, pte));\n\n\tpte_pkey = FNAME(gpte_pkeys)(vcpu, pte);\n\terrcode = permission_fault(vcpu, mmu, pte_access, pte_pkey, access);\n\tif (unlikely(errcode))\n\t\tgoto error;\n\n\tgfn = gpte_to_gfn_lvl(pte, walker->level);\n\tgfn += (addr & PT_LVL_OFFSET_MASK(walker->level)) >> PAGE_SHIFT;\n\n\tif (PTTYPE == 32 && walker->level == PT_DIRECTORY_LEVEL && is_cpuid_PSE36())\n\t\tgfn += pse36_gfn_delta(pte);\n\n\treal_gpa = mmu->translate_gpa(vcpu, gfn_to_gpa(gfn), access, &walker->fault);\n\tif (real_gpa == UNMAPPED_GVA)\n\t\treturn 0;\n\n\twalker->gfn = real_gpa >> PAGE_SHIFT;\n\n\tif (!write_fault)\n\t\tFNAME(protect_clean_gpte)(&pte_access, pte);\n\telse\n\t\t/*\n\t\t * On a write fault, fold the dirty bit into accessed_dirty.\n\t\t * For modes without A/D bits support accessed_dirty will be\n\t\t * always clear.\n\t\t */\n\t\taccessed_dirty &= pte >>\n\t\t\t(PT_GUEST_DIRTY_SHIFT - PT_GUEST_ACCESSED_SHIFT);\n\n\tif (unlikely(!accessed_dirty)) {\n\t\tret = FNAME(update_accessed_dirty_bits)(vcpu, mmu, walker, write_fault);\n\t\tif (unlikely(ret < 0))\n\t\t\tgoto error;\n\t\telse if (ret)\n\t\t\tgoto retry_walk;\n\t}\n\n\twalker->pt_access = pt_access;\n\twalker->pte_access = pte_access;\n\tpgprintk(\"%s: pte %llx pte_access %x pt_access %x\\n\",\n\t\t __func__, (u64)pte, pte_access, pt_access);\n\treturn 1;\n\nerror:\n\terrcode |= write_fault | user_fault;\n\tif (fetch_fault && (mmu->nx ||\n\t\t\t    kvm_read_cr4_bits(vcpu, X86_CR4_SMEP)))\n\t\terrcode |= PFERR_FETCH_MASK;\n\n\twalker->fault.vector = PF_VECTOR;\n\twalker->fault.error_code_valid = true;\n\twalker->fault.error_code = errcode;\n\n#if PTTYPE == PTTYPE_EPT\n\t/*\n\t * Use PFERR_RSVD_MASK in error_code to to tell if EPT\n\t * misconfiguration requires to be injected. The detection is\n\t * done by is_rsvd_bits_set() above.\n\t *\n\t * We set up the value of exit_qualification to inject:\n\t * [2:0] - Derive from [2:0] of real exit_qualification at EPT violation\n\t * [5:3] - Calculated by the page walk of the guest EPT page tables\n\t * [7:8] - Derived from [7:8] of real exit_qualification\n\t *\n\t * The other bits are set to 0.\n\t */\n\tif (!(errcode & PFERR_RSVD_MASK)) {\n\t\tvcpu->arch.exit_qualification &= 0x187;\n\t\tvcpu->arch.exit_qualification |= ((pt_access & pte) & 0x7) << 3;\n\t}\n#endif\n\twalker->fault.address = addr;\n\twalker->fault.nested_page_fault = mmu != vcpu->arch.walk_mmu;\n\n\ttrace_kvm_mmu_walker_error(walker->fault.error_code);\n\treturn 0;\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
    "lines": "260-269",
    "snippet": "static inline unsigned FNAME(gpte_pkeys)(struct kvm_vcpu *vcpu, u64 gpte)\n{\n\tunsigned pkeys = 0;\n#if PTTYPE == 64\n\tpte_t pte = {.pte = gpte};\n\n\tpkeys = pte_flags_pkey(pte_flags(pte));\n#endif\n\treturn pkeys;\n}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "pte_flags_pkey",
          "args": [
            "pte_flags(pte)"
          ],
          "line": 266
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pte_flags",
          "args": [
            "pte"
          ],
          "line": 266
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "static inline unsigned FNAME(gpte_pkeys)(struct kvm_vcpu *vcpu, u64 gpte)\n{\n\tunsigned pkeys = 0;\n#if PTTYPE == 64\n\tpte_t pte = {.pte = gpte};\n\n\tpkeys = pte_flags_pkey(pte_flags(pte));\n#endif\n\treturn pkeys;\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
    "lines": "202-258",
    "snippet": "static int FNAME(update_accessed_dirty_bits)(struct kvm_vcpu *vcpu,\n\t\t\t\t\t     struct kvm_mmu *mmu,\n\t\t\t\t\t     struct guest_walker *walker,\n\t\t\t\t\t     int write_fault)\n{\n\tunsigned level, index;\n\tpt_element_t pte, orig_pte;\n\tpt_element_t __user *ptep_user;\n\tgfn_t table_gfn;\n\tint ret;\n\n\t/* dirty/accessed bits are not supported, so no need to update them */\n\tif (!PT_GUEST_DIRTY_MASK)\n\t\treturn 0;\n\n\tfor (level = walker->max_level; level >= walker->level; --level) {\n\t\tpte = orig_pte = walker->ptes[level - 1];\n\t\ttable_gfn = walker->table_gfn[level - 1];\n\t\tptep_user = walker->ptep_user[level - 1];\n\t\tindex = offset_in_page(ptep_user) / sizeof(pt_element_t);\n\t\tif (!(pte & PT_GUEST_ACCESSED_MASK)) {\n\t\t\ttrace_kvm_mmu_set_accessed_bit(table_gfn, index, sizeof(pte));\n\t\t\tpte |= PT_GUEST_ACCESSED_MASK;\n\t\t}\n\t\tif (level == walker->level && write_fault &&\n\t\t\t\t!(pte & PT_GUEST_DIRTY_MASK)) {\n\t\t\ttrace_kvm_mmu_set_dirty_bit(table_gfn, index, sizeof(pte));\n\t\t\tpte |= PT_GUEST_DIRTY_MASK;\n\t\t}\n\t\tif (pte == orig_pte)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * If the slot is read-only, simply do not process the accessed\n\t\t * and dirty bits.  This is the correct thing to do if the slot\n\t\t * is ROM, and page tables in read-as-ROM/write-as-MMIO slots\n\t\t * are only supported if the accessed and dirty bits are already\n\t\t * set in the ROM (so that MMIO writes are never needed).\n\t\t *\n\t\t * Note that NPT does not allow this at all and faults, since\n\t\t * it always wants nested page table entries for the guest\n\t\t * page tables to be writable.  And EPT works but will simply\n\t\t * overwrite the read-only memory to set the accessed and dirty\n\t\t * bits.\n\t\t */\n\t\tif (unlikely(!walker->pte_writable[level - 1]))\n\t\t\tcontinue;\n\n\t\tret = FNAME(cmpxchg_gpte)(vcpu, mmu, ptep_user, index, orig_pte, pte);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tkvm_vcpu_mark_page_dirty(vcpu, table_gfn);\n\t\twalker->ptes[level - 1] = pte;\n\t}\n\treturn 0;\n}",
    "includes": [],
    "macros_used": [
      "#define PT_GUEST_DIRTY_MASK 0",
      "#define PT_GUEST_ACCESSED_MASK 0",
      "#define guest_walker guest_walkerEPT",
      "#define pt_element_t u64",
      "#define PT_GUEST_DIRTY_MASK PT_DIRTY_MASK",
      "#define PT_GUEST_ACCESSED_MASK PT_ACCESSED_MASK",
      "#define guest_walker guest_walker32",
      "#define pt_element_t u32",
      "#define PT_GUEST_DIRTY_MASK PT_DIRTY_MASK",
      "#define PT_GUEST_ACCESSED_MASK PT_ACCESSED_MASK",
      "#define guest_walker guest_walker64",
      "#define pt_element_t u64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_vcpu_mark_page_dirty",
          "args": [
            "vcpu",
            "table_gfn"
          ],
          "line": 254
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "vcpu",
            "mmu",
            "ptep_user",
            "index",
            "orig_pte",
            "pte"
          ],
          "line": 250
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
          "lines": "140-161",
          "snippet": "static int FNAME(cmpxchg_gpte)(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n\t\t\t       pt_element_t __user *ptep_user, unsigned index,\n\t\t\t       pt_element_t orig_pte, pt_element_t new_pte)\n{\n\tint npages;\n\tpt_element_t ret;\n\tpt_element_t *table;\n\tstruct page *page;\n\n\tnpages = get_user_pages_fast((unsigned long)ptep_user, 1, 1, &page);\n\t/* Check if the user is doing something meaningless. */\n\tif (unlikely(npages != 1))\n\t\treturn -EFAULT;\n\n\ttable = kmap_atomic(page);\n\tret = CMPXCHG(&table[index], orig_pte, new_pte);\n\tkunmap_atomic(table);\n\n\tkvm_release_page_dirty(page);\n\n\treturn (ret != orig_pte);\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!walker->pte_writable[level - 1]"
          ],
          "line": 247
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_kvm_mmu_set_dirty_bit",
          "args": [
            "table_gfn",
            "index",
            "sizeof(pte)"
          ],
          "line": 228
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_kvm_mmu_set_accessed_bit",
          "args": [
            "table_gfn",
            "index",
            "sizeof(pte)"
          ],
          "line": 223
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "offset_in_page",
          "args": [
            "ptep_user"
          ],
          "line": 221
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define PT_GUEST_DIRTY_MASK 0\n#define PT_GUEST_ACCESSED_MASK 0\n#define guest_walker guest_walkerEPT\n#define pt_element_t u64\n#define PT_GUEST_DIRTY_MASK PT_DIRTY_MASK\n#define PT_GUEST_ACCESSED_MASK PT_ACCESSED_MASK\n#define guest_walker guest_walker32\n#define pt_element_t u32\n#define PT_GUEST_DIRTY_MASK PT_DIRTY_MASK\n#define PT_GUEST_ACCESSED_MASK PT_ACCESSED_MASK\n#define guest_walker guest_walker64\n#define pt_element_t u64\n\nstatic int FNAME(update_accessed_dirty_bits)(struct kvm_vcpu *vcpu,\n\t\t\t\t\t     struct kvm_mmu *mmu,\n\t\t\t\t\t     struct guest_walker *walker,\n\t\t\t\t\t     int write_fault)\n{\n\tunsigned level, index;\n\tpt_element_t pte, orig_pte;\n\tpt_element_t __user *ptep_user;\n\tgfn_t table_gfn;\n\tint ret;\n\n\t/* dirty/accessed bits are not supported, so no need to update them */\n\tif (!PT_GUEST_DIRTY_MASK)\n\t\treturn 0;\n\n\tfor (level = walker->max_level; level >= walker->level; --level) {\n\t\tpte = orig_pte = walker->ptes[level - 1];\n\t\ttable_gfn = walker->table_gfn[level - 1];\n\t\tptep_user = walker->ptep_user[level - 1];\n\t\tindex = offset_in_page(ptep_user) / sizeof(pt_element_t);\n\t\tif (!(pte & PT_GUEST_ACCESSED_MASK)) {\n\t\t\ttrace_kvm_mmu_set_accessed_bit(table_gfn, index, sizeof(pte));\n\t\t\tpte |= PT_GUEST_ACCESSED_MASK;\n\t\t}\n\t\tif (level == walker->level && write_fault &&\n\t\t\t\t!(pte & PT_GUEST_DIRTY_MASK)) {\n\t\t\ttrace_kvm_mmu_set_dirty_bit(table_gfn, index, sizeof(pte));\n\t\t\tpte |= PT_GUEST_DIRTY_MASK;\n\t\t}\n\t\tif (pte == orig_pte)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * If the slot is read-only, simply do not process the accessed\n\t\t * and dirty bits.  This is the correct thing to do if the slot\n\t\t * is ROM, and page tables in read-as-ROM/write-as-MMIO slots\n\t\t * are only supported if the accessed and dirty bits are already\n\t\t * set in the ROM (so that MMIO writes are never needed).\n\t\t *\n\t\t * Note that NPT does not allow this at all and faults, since\n\t\t * it always wants nested page table entries for the guest\n\t\t * page tables to be writable.  And EPT works but will simply\n\t\t * overwrite the read-only memory to set the accessed and dirty\n\t\t * bits.\n\t\t */\n\t\tif (unlikely(!walker->pte_writable[level - 1]))\n\t\t\tcontinue;\n\n\t\tret = FNAME(cmpxchg_gpte)(vcpu, mmu, ptep_user, index, orig_pte, pte);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tkvm_vcpu_mark_page_dirty(vcpu, table_gfn);\n\t\twalker->ptes[level - 1] = pte;\n\t}\n\treturn 0;\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
    "lines": "184-200",
    "snippet": "static inline unsigned FNAME(gpte_access)(struct kvm_vcpu *vcpu, u64 gpte)\n{\n\tunsigned access;\n#if PTTYPE == PTTYPE_EPT\n\taccess = ((gpte & VMX_EPT_WRITABLE_MASK) ? ACC_WRITE_MASK : 0) |\n\t\t((gpte & VMX_EPT_EXECUTABLE_MASK) ? ACC_EXEC_MASK : 0) |\n\t\tACC_USER_MASK;\n#else\n\tBUILD_BUG_ON(ACC_EXEC_MASK != PT_PRESENT_MASK);\n\tBUILD_BUG_ON(ACC_EXEC_MASK != 1);\n\taccess = gpte & (PT_WRITABLE_MASK | PT_USER_MASK | PT_PRESENT_MASK);\n\t/* Combine NX with P (which is set here) to get ACC_EXEC_MASK.  */\n\taccess ^= (gpte >> PT64_NX_SHIFT);\n#endif\n\n\treturn access;\n}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "BUILD_BUG_ON",
          "args": [
            "ACC_EXEC_MASK != 1"
          ],
          "line": 193
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUILD_BUG_ON",
          "args": [
            "ACC_EXEC_MASK != PT_PRESENT_MASK"
          ],
          "line": 192
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "static inline unsigned FNAME(gpte_access)(struct kvm_vcpu *vcpu, u64 gpte)\n{\n\tunsigned access;\n#if PTTYPE == PTTYPE_EPT\n\taccess = ((gpte & VMX_EPT_WRITABLE_MASK) ? ACC_WRITE_MASK : 0) |\n\t\t((gpte & VMX_EPT_EXECUTABLE_MASK) ? ACC_EXEC_MASK : 0) |\n\t\tACC_USER_MASK;\n#else\n\tBUILD_BUG_ON(ACC_EXEC_MASK != PT_PRESENT_MASK);\n\tBUILD_BUG_ON(ACC_EXEC_MASK != 1);\n\taccess = gpte & (PT_WRITABLE_MASK | PT_USER_MASK | PT_PRESENT_MASK);\n\t/* Combine NX with P (which is set here) to get ACC_EXEC_MASK.  */\n\taccess ^= (gpte >> PT64_NX_SHIFT);\n#endif\n\n\treturn access;\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
    "lines": "163-182",
    "snippet": "static bool FNAME(prefetch_invalid_gpte)(struct kvm_vcpu *vcpu,\n\t\t\t\t  struct kvm_mmu_page *sp, u64 *spte,\n\t\t\t\t  u64 gpte)\n{\n\tif (is_rsvd_bits_set(&vcpu->arch.mmu, gpte, PT_PAGE_TABLE_LEVEL))\n\t\tgoto no_present;\n\n\tif (!FNAME(is_present_gpte)(gpte))\n\t\tgoto no_present;\n\n\t/* if accessed bit is not supported prefetch non accessed gpte */\n\tif (PT_GUEST_ACCESSED_MASK && !(gpte & PT_GUEST_ACCESSED_MASK))\n\t\tgoto no_present;\n\n\treturn false;\n\nno_present:\n\tdrop_spte(vcpu->kvm, spte);\n\treturn true;\n}",
    "includes": [],
    "macros_used": [
      "#define PT_GUEST_ACCESSED_MASK 0",
      "#define PT_GUEST_ACCESSED_MASK PT_ACCESSED_MASK",
      "#define PT_GUEST_ACCESSED_MASK PT_ACCESSED_MASK"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "drop_spte",
          "args": [
            "vcpu->kvm",
            "spte"
          ],
          "line": 180
        },
        "resolved": true,
        "details": {
          "function_name": "drop_spte",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "1168-1172",
          "snippet": "static void drop_spte(struct kvm *kvm, u64 *sptep)\n{\n\tif (mmu_spte_clear_track_bits(sptep))\n\t\trmap_remove(kvm, sptep);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void drop_spte(struct kvm *kvm, u64 *sptep)\n{\n\tif (mmu_spte_clear_track_bits(sptep))\n\t\trmap_remove(kvm, sptep);\n}"
        }
      },
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "gpte"
          ],
          "line": 170
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
          "lines": "817-827",
          "snippet": "static gpa_t FNAME(get_level1_sp_gpa)(struct kvm_mmu_page *sp)\n{\n\tint offset = 0;\n\n\tWARN_ON(sp->role.level != PT_PAGE_TABLE_LEVEL);\n\n\tif (PTTYPE == 32)\n\t\toffset = sp->role.quadrant << PT64_LEVEL_BITS;\n\n\treturn gfn_to_gpa(sp->gfn) + offset * sizeof(pt_element_t);\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "is_rsvd_bits_set",
          "args": [
            "&vcpu->arch.mmu",
            "gpte",
            "PT_PAGE_TABLE_LEVEL"
          ],
          "line": 167
        },
        "resolved": true,
        "details": {
          "function_name": "is_rsvd_bits_set",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.c",
          "lines": "3314-3317",
          "snippet": "static bool is_rsvd_bits_set(struct kvm_mmu *mmu, u64 gpte, int level)\n{\n\treturn __is_rsvd_bits_set(&mmu->guest_rsvd_check, gpte, level);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/page.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/module.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/cmpxchg.h>\n#include <asm/page.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic bool is_rsvd_bits_set(struct kvm_mmu *mmu, u64 gpte, int level)\n{\n\treturn __is_rsvd_bits_set(&mmu->guest_rsvd_check, gpte, level);\n}"
        }
      }
    ],
    "contextual_snippet": "#define PT_GUEST_ACCESSED_MASK 0\n#define PT_GUEST_ACCESSED_MASK PT_ACCESSED_MASK\n#define PT_GUEST_ACCESSED_MASK PT_ACCESSED_MASK\n\nstatic bool FNAME(prefetch_invalid_gpte)(struct kvm_vcpu *vcpu,\n\t\t\t\t  struct kvm_mmu_page *sp, u64 *spte,\n\t\t\t\t  u64 gpte)\n{\n\tif (is_rsvd_bits_set(&vcpu->arch.mmu, gpte, PT_PAGE_TABLE_LEVEL))\n\t\tgoto no_present;\n\n\tif (!FNAME(is_present_gpte)(gpte))\n\t\tgoto no_present;\n\n\t/* if accessed bit is not supported prefetch non accessed gpte */\n\tif (PT_GUEST_ACCESSED_MASK && !(gpte & PT_GUEST_ACCESSED_MASK))\n\t\tgoto no_present;\n\n\treturn false;\n\nno_present:\n\tdrop_spte(vcpu->kvm, spte);\n\treturn true;\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
    "lines": "140-161",
    "snippet": "static int FNAME(cmpxchg_gpte)(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n\t\t\t       pt_element_t __user *ptep_user, unsigned index,\n\t\t\t       pt_element_t orig_pte, pt_element_t new_pte)\n{\n\tint npages;\n\tpt_element_t ret;\n\tpt_element_t *table;\n\tstruct page *page;\n\n\tnpages = get_user_pages_fast((unsigned long)ptep_user, 1, 1, &page);\n\t/* Check if the user is doing something meaningless. */\n\tif (unlikely(npages != 1))\n\t\treturn -EFAULT;\n\n\ttable = kmap_atomic(page);\n\tret = CMPXCHG(&table[index], orig_pte, new_pte);\n\tkunmap_atomic(table);\n\n\tkvm_release_page_dirty(page);\n\n\treturn (ret != orig_pte);\n}",
    "includes": [],
    "macros_used": [
      "#define CMPXCHG cmpxchg64",
      "#define pt_element_t u64",
      "#define CMPXCHG cmpxchg",
      "#define pt_element_t u32",
      "#define CMPXCHG cmpxchg64",
      "#define CMPXCHG cmpxchg",
      "#define pt_element_t u64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_release_page_dirty",
          "args": [
            "page"
          ],
          "line": 158
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kunmap_atomic",
          "args": [
            "table"
          ],
          "line": 156
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "CMPXCHG",
          "args": [
            "&table[index]",
            "orig_pte",
            "new_pte"
          ],
          "line": 155
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kmap_atomic",
          "args": [
            "page"
          ],
          "line": 154
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "npages != 1"
          ],
          "line": 151
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "get_user_pages_fast",
          "args": [
            "(unsigned long)ptep_user",
            "1",
            "1",
            "&page"
          ],
          "line": 149
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define CMPXCHG cmpxchg64\n#define pt_element_t u64\n#define CMPXCHG cmpxchg\n#define pt_element_t u32\n#define CMPXCHG cmpxchg64\n#define CMPXCHG cmpxchg\n#define pt_element_t u64\n\nstatic int FNAME(cmpxchg_gpte)(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n\t\t\t       pt_element_t __user *ptep_user, unsigned index,\n\t\t\t       pt_element_t orig_pte, pt_element_t new_pte)\n{\n\tint npages;\n\tpt_element_t ret;\n\tpt_element_t *table;\n\tstruct page *page;\n\n\tnpages = get_user_pages_fast((unsigned long)ptep_user, 1, 1, &page);\n\t/* Check if the user is doing something meaningless. */\n\tif (unlikely(npages != 1))\n\t\treturn -EFAULT;\n\n\ttable = kmap_atomic(page);\n\tret = CMPXCHG(&table[index], orig_pte, new_pte);\n\tkunmap_atomic(table);\n\n\tkvm_release_page_dirty(page);\n\n\treturn (ret != orig_pte);\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
    "lines": "131-138",
    "snippet": "static inline int FNAME(is_present_gpte)(unsigned long pte)\n{\n#if PTTYPE != PTTYPE_EPT\n\treturn is_present_gpte(pte);\n#else\n\treturn pte & 7;\n#endif\n}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "is_present_gpte",
          "args": [
            "pte"
          ],
          "line": 134
        },
        "resolved": true,
        "details": {
          "function_name": "is_present_gpte",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/mmu.h",
          "lines": "96-99",
          "snippet": "static inline int is_present_gpte(unsigned long pte)\n{\n\treturn pte & PT_PRESENT_MASK;\n}",
          "includes": [
            "#include \"kvm_cache_regs.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [
            "#define PT_PRESENT_MASK (1ULL << 0)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\n#define PT_PRESENT_MASK (1ULL << 0)\n\nstatic inline int is_present_gpte(unsigned long pte)\n{\n\treturn pte & PT_PRESENT_MASK;\n}"
        }
      }
    ],
    "contextual_snippet": "static inline int FNAME(is_present_gpte)(unsigned long pte)\n{\n#if PTTYPE != PTTYPE_EPT\n\treturn is_present_gpte(pte);\n#else\n\treturn pte & 7;\n#endif\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
    "lines": "114-129",
    "snippet": "static inline void FNAME(protect_clean_gpte)(unsigned *access, unsigned gpte)\n{\n\tunsigned mask;\n\n\t/* dirty bit is not supported, so no need to track it */\n\tif (!PT_GUEST_DIRTY_MASK)\n\t\treturn;\n\n\tBUILD_BUG_ON(PT_WRITABLE_MASK != ACC_WRITE_MASK);\n\n\tmask = (unsigned)~ACC_WRITE_MASK;\n\t/* Allow write access to dirty gptes */\n\tmask |= (gpte >> (PT_GUEST_DIRTY_SHIFT - PT_WRITABLE_SHIFT)) &\n\t\tPT_WRITABLE_MASK;\n\t*access &= mask;\n}",
    "includes": [],
    "macros_used": [
      "#define PT_GUEST_DIRTY_SHIFT __using_nonexistent_pte_bit()",
      "#define PT_GUEST_DIRTY_MASK 0",
      "#define PT_GUEST_DIRTY_SHIFT PT_DIRTY_SHIFT",
      "#define PT_GUEST_DIRTY_MASK PT_DIRTY_MASK",
      "#define PT_GUEST_DIRTY_SHIFT PT_DIRTY_SHIFT",
      "#define PT_GUEST_DIRTY_MASK PT_DIRTY_MASK"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "BUILD_BUG_ON",
          "args": [
            "PT_WRITABLE_MASK != ACC_WRITE_MASK"
          ],
          "line": 122
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define PT_GUEST_DIRTY_SHIFT __using_nonexistent_pte_bit()\n#define PT_GUEST_DIRTY_MASK 0\n#define PT_GUEST_DIRTY_SHIFT PT_DIRTY_SHIFT\n#define PT_GUEST_DIRTY_MASK PT_DIRTY_MASK\n#define PT_GUEST_DIRTY_SHIFT PT_DIRTY_SHIFT\n#define PT_GUEST_DIRTY_MASK PT_DIRTY_MASK\n\nstatic inline void FNAME(protect_clean_gpte)(unsigned *access, unsigned gpte)\n{\n\tunsigned mask;\n\n\t/* dirty bit is not supported, so no need to track it */\n\tif (!PT_GUEST_DIRTY_MASK)\n\t\treturn;\n\n\tBUILD_BUG_ON(PT_WRITABLE_MASK != ACC_WRITE_MASK);\n\n\tmask = (unsigned)~ACC_WRITE_MASK;\n\t/* Allow write access to dirty gptes */\n\tmask |= (gpte >> (PT_GUEST_DIRTY_SHIFT - PT_WRITABLE_SHIFT)) &\n\t\tPT_WRITABLE_MASK;\n\t*access &= mask;\n}"
  },
  {
    "function_name": "gpte_to_gfn_lvl",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2016-3713/repo/arch/x86/kvm/paging_tmpl.h",
    "lines": "109-112",
    "snippet": "static gfn_t gpte_to_gfn_lvl(pt_element_t gpte, int lvl)\n{\n\treturn (gpte & PT_LVL_ADDR_MASK(lvl)) >> PAGE_SHIFT;\n}",
    "includes": [],
    "macros_used": [
      "#define gpte_to_gfn_lvl FNAME(gpte_to_gfn_lvl)",
      "#define pt_element_t u64",
      "#define pt_element_t u32",
      "#define pt_element_t u64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "PT_LVL_ADDR_MASK",
          "args": [
            "lvl"
          ],
          "line": 111
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define gpte_to_gfn_lvl FNAME(gpte_to_gfn_lvl)\n#define pt_element_t u64\n#define pt_element_t u32\n#define pt_element_t u64\n\nstatic gfn_t gpte_to_gfn_lvl(pt_element_t gpte, int lvl)\n{\n\treturn (gpte & PT_LVL_ADDR_MASK(lvl)) >> PAGE_SHIFT;\n}"
  }
]