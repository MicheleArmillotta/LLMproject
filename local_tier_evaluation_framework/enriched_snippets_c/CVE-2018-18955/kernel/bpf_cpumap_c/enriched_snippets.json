[
  {
    "function_name": "__cpu_map_flush",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
    "lines": "646-675",
    "snippet": "void __cpu_map_flush(struct bpf_map *map)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tunsigned long *bitmap = this_cpu_ptr(cmap->flush_needed);\n\tu32 bit;\n\n\t/* The napi->poll softirq makes sure __cpu_map_insert_ctx()\n\t * and __cpu_map_flush() happen on same CPU. Thus, the percpu\n\t * bitmap indicate which percpu bulkq have packets.\n\t */\n\tfor_each_set_bit(bit, bitmap, map->max_entries) {\n\t\tstruct bpf_cpu_map_entry *rcpu = READ_ONCE(cmap->cpu_map[bit]);\n\t\tstruct xdp_bulk_queue *bq;\n\n\t\t/* This is possible if entry is removed by user space\n\t\t * between xdp redirect and flush op.\n\t\t */\n\t\tif (unlikely(!rcpu))\n\t\t\tcontinue;\n\n\t\t__clear_bit(bit, bitmap);\n\n\t\t/* Flush all frames in bulkq to real queue */\n\t\tbq = this_cpu_ptr(rcpu->bulkq);\n\t\tbq_flush_to_queue(rcpu, bq, true);\n\n\t\t/* If already running, costs spin_lock_irqsave + smb_mb */\n\t\twake_up_process(rcpu->kthread);\n\t}\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "wake_up_process",
          "args": [
            "rcpu->kthread"
          ],
          "line": 673
        },
        "resolved": true,
        "details": {
          "function_name": "wake_up_process",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/core.c",
          "lines": "2127-2130",
          "snippet": "int wake_up_process(struct task_struct *p)\n{\n\treturn try_to_wake_up(p, TASK_NORMAL, 0);\n}",
          "includes": [
            "#include \"features.h\"",
            "#include <trace/events/sched.h>",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/kcov.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include <trace/events/sched.h>\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/kcov.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n\nstatic __always_inline struct;\n\nint wake_up_process(struct task_struct *p)\n{\n\treturn try_to_wake_up(p, TASK_NORMAL, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bq_flush_to_queue",
          "args": [
            "rcpu",
            "bq",
            "true"
          ],
          "line": 670
        },
        "resolved": true,
        "details": {
          "function_name": "bq_flush_to_queue",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
          "lines": "563-597",
          "snippet": "static int bq_flush_to_queue(struct bpf_cpu_map_entry *rcpu,\n\t\t\t     struct xdp_bulk_queue *bq, bool in_napi_ctx)\n{\n\tunsigned int processed = 0, drops = 0;\n\tconst int to_cpu = rcpu->cpu;\n\tstruct ptr_ring *q;\n\tint i;\n\n\tif (unlikely(!bq->count))\n\t\treturn 0;\n\n\tq = rcpu->queue;\n\tspin_lock(&q->producer_lock);\n\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\t\tint err;\n\n\t\terr = __ptr_ring_produce(q, xdpf);\n\t\tif (err) {\n\t\t\tdrops++;\n\t\t\tif (likely(in_napi_ctx))\n\t\t\t\txdp_return_frame_rx_napi(xdpf);\n\t\t\telse\n\t\t\t\txdp_return_frame(xdpf);\n\t\t}\n\t\tprocessed++;\n\t}\n\tbq->count = 0;\n\tspin_unlock(&q->producer_lock);\n\n\t/* Feedback loop via tracepoints */\n\ttrace_xdp_cpumap_enqueue(rcpu->map_id, processed, drops, to_cpu);\n\treturn 0;\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static int bq_flush_to_queue(struct bpf_cpu_map_entry *rcpu,\n\t\t\t     struct xdp_bulk_queue *bq, bool in_napi_ctx);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic int bq_flush_to_queue(struct bpf_cpu_map_entry *rcpu,\n\t\t\t     struct xdp_bulk_queue *bq, bool in_napi_ctx);\n\nstatic int bq_flush_to_queue(struct bpf_cpu_map_entry *rcpu,\n\t\t\t     struct xdp_bulk_queue *bq, bool in_napi_ctx)\n{\n\tunsigned int processed = 0, drops = 0;\n\tconst int to_cpu = rcpu->cpu;\n\tstruct ptr_ring *q;\n\tint i;\n\n\tif (unlikely(!bq->count))\n\t\treturn 0;\n\n\tq = rcpu->queue;\n\tspin_lock(&q->producer_lock);\n\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\t\tint err;\n\n\t\terr = __ptr_ring_produce(q, xdpf);\n\t\tif (err) {\n\t\t\tdrops++;\n\t\t\tif (likely(in_napi_ctx))\n\t\t\t\txdp_return_frame_rx_napi(xdpf);\n\t\t\telse\n\t\t\t\txdp_return_frame(xdpf);\n\t\t}\n\t\tprocessed++;\n\t}\n\tbq->count = 0;\n\tspin_unlock(&q->producer_lock);\n\n\t/* Feedback loop via tracepoints */\n\ttrace_xdp_cpumap_enqueue(rcpu->map_id, processed, drops, to_cpu);\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "rcpu->bulkq"
          ],
          "line": 669
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__clear_bit",
          "args": [
            "bit",
            "bitmap"
          ],
          "line": 666
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!rcpu"
          ],
          "line": 663
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "cmap->cpu_map[bit]"
          ],
          "line": 657
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "for_each_set_bit",
          "args": [
            "bit",
            "bitmap",
            "map->max_entries"
          ],
          "line": 656
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "cmap->flush_needed"
          ],
          "line": 649
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_cpu_map",
            "map"
          ],
          "line": 648
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nvoid __cpu_map_flush(struct bpf_map *map)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tunsigned long *bitmap = this_cpu_ptr(cmap->flush_needed);\n\tu32 bit;\n\n\t/* The napi->poll softirq makes sure __cpu_map_insert_ctx()\n\t * and __cpu_map_flush() happen on same CPU. Thus, the percpu\n\t * bitmap indicate which percpu bulkq have packets.\n\t */\n\tfor_each_set_bit(bit, bitmap, map->max_entries) {\n\t\tstruct bpf_cpu_map_entry *rcpu = READ_ONCE(cmap->cpu_map[bit]);\n\t\tstruct xdp_bulk_queue *bq;\n\n\t\t/* This is possible if entry is removed by user space\n\t\t * between xdp redirect and flush op.\n\t\t */\n\t\tif (unlikely(!rcpu))\n\t\t\tcontinue;\n\n\t\t__clear_bit(bit, bitmap);\n\n\t\t/* Flush all frames in bulkq to real queue */\n\t\tbq = this_cpu_ptr(rcpu->bulkq);\n\t\tbq_flush_to_queue(rcpu, bq, true);\n\n\t\t/* If already running, costs spin_lock_irqsave + smb_mb */\n\t\twake_up_process(rcpu->kthread);\n\t}\n}"
  },
  {
    "function_name": "__cpu_map_insert_ctx",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
    "lines": "638-644",
    "snippet": "void __cpu_map_insert_ctx(struct bpf_map *map, u32 bit)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tunsigned long *bitmap = this_cpu_ptr(cmap->flush_needed);\n\n\t__set_bit(bit, bitmap);\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__set_bit",
          "args": [
            "bit",
            "bitmap"
          ],
          "line": 643
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "cmap->flush_needed"
          ],
          "line": 641
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_cpu_map",
            "map"
          ],
          "line": 640
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nvoid __cpu_map_insert_ctx(struct bpf_map *map, u32 bit)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tunsigned long *bitmap = this_cpu_ptr(cmap->flush_needed);\n\n\t__set_bit(bit, bitmap);\n}"
  },
  {
    "function_name": "cpu_map_enqueue",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
    "lines": "622-636",
    "snippet": "int cpu_map_enqueue(struct bpf_cpu_map_entry *rcpu, struct xdp_buff *xdp,\n\t\t    struct net_device *dev_rx)\n{\n\tstruct xdp_frame *xdpf;\n\n\txdpf = convert_to_xdp_frame(xdp);\n\tif (unlikely(!xdpf))\n\t\treturn -EOVERFLOW;\n\n\t/* Info needed when constructing SKB on remote CPU */\n\txdpf->dev_rx = dev_rx;\n\n\tbq_enqueue(rcpu, xdpf);\n\treturn 0;\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bq_enqueue",
          "args": [
            "rcpu",
            "xdpf"
          ],
          "line": 634
        },
        "resolved": true,
        "details": {
          "function_name": "bq_enqueue",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
          "lines": "602-620",
          "snippet": "static int bq_enqueue(struct bpf_cpu_map_entry *rcpu, struct xdp_frame *xdpf)\n{\n\tstruct xdp_bulk_queue *bq = this_cpu_ptr(rcpu->bulkq);\n\n\tif (unlikely(bq->count == CPU_MAP_BULK_SIZE))\n\t\tbq_flush_to_queue(rcpu, bq, true);\n\n\t/* Notice, xdp_buff/page MUST be queued here, long enough for\n\t * driver to code invoking us to finished, due to driver\n\t * (e.g. ixgbe) recycle tricks based on page-refcnt.\n\t *\n\t * Thus, incoming xdp_frame is always queued here (else we race\n\t * with another CPU on page-refcnt and remaining driver code).\n\t * Queue time is very short, as driver will invoke flush\n\t * operation, when completing napi->poll call.\n\t */\n\tbq->q[bq->count++] = xdpf;\n\treturn 0;\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [
            "#define CPU_MAP_BULK_SIZE 8  /* 8 == one cacheline on 64-bit archs */"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\n#define CPU_MAP_BULK_SIZE 8  /* 8 == one cacheline on 64-bit archs */\n\nstatic int bq_enqueue(struct bpf_cpu_map_entry *rcpu, struct xdp_frame *xdpf)\n{\n\tstruct xdp_bulk_queue *bq = this_cpu_ptr(rcpu->bulkq);\n\n\tif (unlikely(bq->count == CPU_MAP_BULK_SIZE))\n\t\tbq_flush_to_queue(rcpu, bq, true);\n\n\t/* Notice, xdp_buff/page MUST be queued here, long enough for\n\t * driver to code invoking us to finished, due to driver\n\t * (e.g. ixgbe) recycle tricks based on page-refcnt.\n\t *\n\t * Thus, incoming xdp_frame is always queued here (else we race\n\t * with another CPU on page-refcnt and remaining driver code).\n\t * Queue time is very short, as driver will invoke flush\n\t * operation, when completing napi->poll call.\n\t */\n\tbq->q[bq->count++] = xdpf;\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!xdpf"
          ],
          "line": 628
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "convert_to_xdp_frame",
          "args": [
            "xdp"
          ],
          "line": 627
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nint cpu_map_enqueue(struct bpf_cpu_map_entry *rcpu, struct xdp_buff *xdp,\n\t\t    struct net_device *dev_rx)\n{\n\tstruct xdp_frame *xdpf;\n\n\txdpf = convert_to_xdp_frame(xdp);\n\tif (unlikely(!xdpf))\n\t\treturn -EOVERFLOW;\n\n\t/* Info needed when constructing SKB on remote CPU */\n\txdpf->dev_rx = dev_rx;\n\n\tbq_enqueue(rcpu, xdpf);\n\treturn 0;\n}"
  },
  {
    "function_name": "bq_enqueue",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
    "lines": "602-620",
    "snippet": "static int bq_enqueue(struct bpf_cpu_map_entry *rcpu, struct xdp_frame *xdpf)\n{\n\tstruct xdp_bulk_queue *bq = this_cpu_ptr(rcpu->bulkq);\n\n\tif (unlikely(bq->count == CPU_MAP_BULK_SIZE))\n\t\tbq_flush_to_queue(rcpu, bq, true);\n\n\t/* Notice, xdp_buff/page MUST be queued here, long enough for\n\t * driver to code invoking us to finished, due to driver\n\t * (e.g. ixgbe) recycle tricks based on page-refcnt.\n\t *\n\t * Thus, incoming xdp_frame is always queued here (else we race\n\t * with another CPU on page-refcnt and remaining driver code).\n\t * Queue time is very short, as driver will invoke flush\n\t * operation, when completing napi->poll call.\n\t */\n\tbq->q[bq->count++] = xdpf;\n\treturn 0;\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [
      "#define CPU_MAP_BULK_SIZE 8  /* 8 == one cacheline on 64-bit archs */"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bq_flush_to_queue",
          "args": [
            "rcpu",
            "bq",
            "true"
          ],
          "line": 607
        },
        "resolved": true,
        "details": {
          "function_name": "bq_flush_to_queue",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
          "lines": "563-597",
          "snippet": "static int bq_flush_to_queue(struct bpf_cpu_map_entry *rcpu,\n\t\t\t     struct xdp_bulk_queue *bq, bool in_napi_ctx)\n{\n\tunsigned int processed = 0, drops = 0;\n\tconst int to_cpu = rcpu->cpu;\n\tstruct ptr_ring *q;\n\tint i;\n\n\tif (unlikely(!bq->count))\n\t\treturn 0;\n\n\tq = rcpu->queue;\n\tspin_lock(&q->producer_lock);\n\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\t\tint err;\n\n\t\terr = __ptr_ring_produce(q, xdpf);\n\t\tif (err) {\n\t\t\tdrops++;\n\t\t\tif (likely(in_napi_ctx))\n\t\t\t\txdp_return_frame_rx_napi(xdpf);\n\t\t\telse\n\t\t\t\txdp_return_frame(xdpf);\n\t\t}\n\t\tprocessed++;\n\t}\n\tbq->count = 0;\n\tspin_unlock(&q->producer_lock);\n\n\t/* Feedback loop via tracepoints */\n\ttrace_xdp_cpumap_enqueue(rcpu->map_id, processed, drops, to_cpu);\n\treturn 0;\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static int bq_flush_to_queue(struct bpf_cpu_map_entry *rcpu,\n\t\t\t     struct xdp_bulk_queue *bq, bool in_napi_ctx);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic int bq_flush_to_queue(struct bpf_cpu_map_entry *rcpu,\n\t\t\t     struct xdp_bulk_queue *bq, bool in_napi_ctx);\n\nstatic int bq_flush_to_queue(struct bpf_cpu_map_entry *rcpu,\n\t\t\t     struct xdp_bulk_queue *bq, bool in_napi_ctx)\n{\n\tunsigned int processed = 0, drops = 0;\n\tconst int to_cpu = rcpu->cpu;\n\tstruct ptr_ring *q;\n\tint i;\n\n\tif (unlikely(!bq->count))\n\t\treturn 0;\n\n\tq = rcpu->queue;\n\tspin_lock(&q->producer_lock);\n\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\t\tint err;\n\n\t\terr = __ptr_ring_produce(q, xdpf);\n\t\tif (err) {\n\t\t\tdrops++;\n\t\t\tif (likely(in_napi_ctx))\n\t\t\t\txdp_return_frame_rx_napi(xdpf);\n\t\t\telse\n\t\t\t\txdp_return_frame(xdpf);\n\t\t}\n\t\tprocessed++;\n\t}\n\tbq->count = 0;\n\tspin_unlock(&q->producer_lock);\n\n\t/* Feedback loop via tracepoints */\n\ttrace_xdp_cpumap_enqueue(rcpu->map_id, processed, drops, to_cpu);\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "bq->count == CPU_MAP_BULK_SIZE"
          ],
          "line": 606
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "rcpu->bulkq"
          ],
          "line": 604
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\n#define CPU_MAP_BULK_SIZE 8  /* 8 == one cacheline on 64-bit archs */\n\nstatic int bq_enqueue(struct bpf_cpu_map_entry *rcpu, struct xdp_frame *xdpf)\n{\n\tstruct xdp_bulk_queue *bq = this_cpu_ptr(rcpu->bulkq);\n\n\tif (unlikely(bq->count == CPU_MAP_BULK_SIZE))\n\t\tbq_flush_to_queue(rcpu, bq, true);\n\n\t/* Notice, xdp_buff/page MUST be queued here, long enough for\n\t * driver to code invoking us to finished, due to driver\n\t * (e.g. ixgbe) recycle tricks based on page-refcnt.\n\t *\n\t * Thus, incoming xdp_frame is always queued here (else we race\n\t * with another CPU on page-refcnt and remaining driver code).\n\t * Queue time is very short, as driver will invoke flush\n\t * operation, when completing napi->poll call.\n\t */\n\tbq->q[bq->count++] = xdpf;\n\treturn 0;\n}"
  },
  {
    "function_name": "bq_flush_to_queue",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
    "lines": "563-597",
    "snippet": "static int bq_flush_to_queue(struct bpf_cpu_map_entry *rcpu,\n\t\t\t     struct xdp_bulk_queue *bq, bool in_napi_ctx)\n{\n\tunsigned int processed = 0, drops = 0;\n\tconst int to_cpu = rcpu->cpu;\n\tstruct ptr_ring *q;\n\tint i;\n\n\tif (unlikely(!bq->count))\n\t\treturn 0;\n\n\tq = rcpu->queue;\n\tspin_lock(&q->producer_lock);\n\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\t\tint err;\n\n\t\terr = __ptr_ring_produce(q, xdpf);\n\t\tif (err) {\n\t\t\tdrops++;\n\t\t\tif (likely(in_napi_ctx))\n\t\t\t\txdp_return_frame_rx_napi(xdpf);\n\t\t\telse\n\t\t\t\txdp_return_frame(xdpf);\n\t\t}\n\t\tprocessed++;\n\t}\n\tbq->count = 0;\n\tspin_unlock(&q->producer_lock);\n\n\t/* Feedback loop via tracepoints */\n\ttrace_xdp_cpumap_enqueue(rcpu->map_id, processed, drops, to_cpu);\n\treturn 0;\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static int bq_flush_to_queue(struct bpf_cpu_map_entry *rcpu,\n\t\t\t     struct xdp_bulk_queue *bq, bool in_napi_ctx);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "trace_xdp_cpumap_enqueue",
          "args": [
            "rcpu->map_id",
            "processed",
            "drops",
            "to_cpu"
          ],
          "line": 595
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_unlock",
          "args": [
            "&q->producer_lock"
          ],
          "line": 592
        },
        "resolved": true,
        "details": {
          "function_name": "__pv_queued_spin_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/qspinlock_paravirt.h",
          "lines": "546-560",
          "snippet": "__visible void __pv_queued_spin_unlock(struct qspinlock *lock)\n{\n\tu8 locked;\n\n\t/*\n\t * We must not unlock if SLOW, because in that case we must first\n\t * unhash. Otherwise it would be possible to have multiple @lock\n\t * entries, which would be BAD.\n\t */\n\tlocked = cmpxchg_release(&lock->locked, _Q_LOCKED_VAL, 0);\n\tif (likely(locked == _Q_LOCKED_VAL))\n\t\treturn;\n\n\t__pv_queued_spin_unlock_slowpath(lock, locked);\n}",
          "includes": [
            "#include <asm/qspinlock_paravirt.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/memblock.h>",
            "#include <linux/hash.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/qspinlock_paravirt.h>\n#include <linux/debug_locks.h>\n#include <linux/memblock.h>\n#include <linux/hash.h>\n\n__visible void __pv_queued_spin_unlock(struct qspinlock *lock)\n{\n\tu8 locked;\n\n\t/*\n\t * We must not unlock if SLOW, because in that case we must first\n\t * unhash. Otherwise it would be possible to have multiple @lock\n\t * entries, which would be BAD.\n\t */\n\tlocked = cmpxchg_release(&lock->locked, _Q_LOCKED_VAL, 0);\n\tif (likely(locked == _Q_LOCKED_VAL))\n\t\treturn;\n\n\t__pv_queued_spin_unlock_slowpath(lock, locked);\n}"
        }
      },
      {
        "call_info": {
          "callee": "xdp_return_frame",
          "args": [
            "xdpf"
          ],
          "line": 587
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "xdp_return_frame_rx_napi",
          "args": [
            "xdpf"
          ],
          "line": 585
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "in_napi_ctx"
          ],
          "line": 584
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__ptr_ring_produce",
          "args": [
            "q",
            "xdpf"
          ],
          "line": 581
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_lock",
          "args": [
            "&q->producer_lock"
          ],
          "line": 575
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "166-169",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!bq->count"
          ],
          "line": 571
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic int bq_flush_to_queue(struct bpf_cpu_map_entry *rcpu,\n\t\t\t     struct xdp_bulk_queue *bq, bool in_napi_ctx);\n\nstatic int bq_flush_to_queue(struct bpf_cpu_map_entry *rcpu,\n\t\t\t     struct xdp_bulk_queue *bq, bool in_napi_ctx)\n{\n\tunsigned int processed = 0, drops = 0;\n\tconst int to_cpu = rcpu->cpu;\n\tstruct ptr_ring *q;\n\tint i;\n\n\tif (unlikely(!bq->count))\n\t\treturn 0;\n\n\tq = rcpu->queue;\n\tspin_lock(&q->producer_lock);\n\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\t\tint err;\n\n\t\terr = __ptr_ring_produce(q, xdpf);\n\t\tif (err) {\n\t\t\tdrops++;\n\t\t\tif (likely(in_napi_ctx))\n\t\t\t\txdp_return_frame_rx_napi(xdpf);\n\t\t\telse\n\t\t\t\txdp_return_frame(xdpf);\n\t\t}\n\t\tprocessed++;\n\t}\n\tbq->count = 0;\n\tspin_unlock(&q->producer_lock);\n\n\t/* Feedback loop via tracepoints */\n\ttrace_xdp_cpumap_enqueue(rcpu->map_id, processed, drops, to_cpu);\n\treturn 0;\n}"
  },
  {
    "function_name": "cpu_map_get_next_key",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
    "lines": "536-551",
    "snippet": "static int cpu_map_get_next_key(struct bpf_map *map, void *key, void *next_key)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tu32 index = key ? *(u32 *)key : U32_MAX;\n\tu32 *next = next_key;\n\n\tif (index >= cmap->map.max_entries) {\n\t\t*next = 0;\n\t\treturn 0;\n\t}\n\n\tif (index == cmap->map.max_entries - 1)\n\t\treturn -ENOENT;\n\t*next = index + 1;\n\treturn 0;\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_cpu_map",
            "map"
          ],
          "line": 538
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic int cpu_map_get_next_key(struct bpf_map *map, void *key, void *next_key)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tu32 index = key ? *(u32 *)key : U32_MAX;\n\tu32 *next = next_key;\n\n\tif (index >= cmap->map.max_entries) {\n\t\t*next = 0;\n\t\treturn 0;\n\t}\n\n\tif (index == cmap->map.max_entries - 1)\n\t\treturn -ENOENT;\n\t*next = index + 1;\n\treturn 0;\n}"
  },
  {
    "function_name": "cpu_map_lookup_elem",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
    "lines": "528-534",
    "snippet": "static void *cpu_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_cpu_map_entry *rcpu =\n\t\t__cpu_map_lookup_elem(map, *(u32 *)key);\n\n\treturn rcpu ? &rcpu->qsize : NULL;\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__cpu_map_lookup_elem",
          "args": [
            "map",
            "*(u32 *)key"
          ],
          "line": 531
        },
        "resolved": true,
        "details": {
          "function_name": "__cpu_map_lookup_elem",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
          "lines": "516-526",
          "snippet": "struct bpf_cpu_map_entry *__cpu_map_lookup_elem(struct bpf_map *map, u32 key)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tstruct bpf_cpu_map_entry *rcpu;\n\n\tif (key >= map->max_entries)\n\t\treturn NULL;\n\n\trcpu = READ_ONCE(cmap->cpu_map[key]);\n\treturn rcpu;\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstruct bpf_cpu_map_entry *__cpu_map_lookup_elem(struct bpf_map *map, u32 key)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tstruct bpf_cpu_map_entry *rcpu;\n\n\tif (key >= map->max_entries)\n\t\treturn NULL;\n\n\trcpu = READ_ONCE(cmap->cpu_map[key]);\n\treturn rcpu;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic void *cpu_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_cpu_map_entry *rcpu =\n\t\t__cpu_map_lookup_elem(map, *(u32 *)key);\n\n\treturn rcpu ? &rcpu->qsize : NULL;\n}"
  },
  {
    "function_name": "__cpu_map_lookup_elem",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
    "lines": "516-526",
    "snippet": "struct bpf_cpu_map_entry *__cpu_map_lookup_elem(struct bpf_map *map, u32 key)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tstruct bpf_cpu_map_entry *rcpu;\n\n\tif (key >= map->max_entries)\n\t\treturn NULL;\n\n\trcpu = READ_ONCE(cmap->cpu_map[key]);\n\treturn rcpu;\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "cmap->cpu_map[key]"
          ],
          "line": 524
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_cpu_map",
            "map"
          ],
          "line": 518
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstruct bpf_cpu_map_entry *__cpu_map_lookup_elem(struct bpf_map *map, u32 key)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tstruct bpf_cpu_map_entry *rcpu;\n\n\tif (key >= map->max_entries)\n\t\treturn NULL;\n\n\trcpu = READ_ONCE(cmap->cpu_map[key]);\n\treturn rcpu;\n}"
  },
  {
    "function_name": "cpu_map_free",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
    "lines": "468-514",
    "snippet": "static void cpu_map_free(struct bpf_map *map)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tint cpu;\n\tu32 i;\n\n\t/* At this point bpf_prog->aux->refcnt == 0 and this map->refcnt == 0,\n\t * so the bpf programs (can be more than one that used this map) were\n\t * disconnected from events. Wait for outstanding critical sections in\n\t * these programs to complete. The rcu critical section only guarantees\n\t * no further \"XDP/bpf-side\" reads against bpf_cpu_map->cpu_map.\n\t * It does __not__ ensure pending flush operations (if any) are\n\t * complete.\n\t */\n\n\tbpf_clear_redirect_map(map);\n\tsynchronize_rcu();\n\n\t/* To ensure all pending flush operations have completed wait for flush\n\t * bitmap to indicate all flush_needed bits to be zero on _all_ cpus.\n\t * Because the above synchronize_rcu() ensures the map is disconnected\n\t * from the program we can assume no new bits will be set.\n\t */\n\tfor_each_online_cpu(cpu) {\n\t\tunsigned long *bitmap = per_cpu_ptr(cmap->flush_needed, cpu);\n\n\t\twhile (!bitmap_empty(bitmap, cmap->map.max_entries))\n\t\t\tcond_resched();\n\t}\n\n\t/* For cpu_map the remote CPUs can still be using the entries\n\t * (struct bpf_cpu_map_entry).\n\t */\n\tfor (i = 0; i < cmap->map.max_entries; i++) {\n\t\tstruct bpf_cpu_map_entry *rcpu;\n\n\t\trcpu = READ_ONCE(cmap->cpu_map[i]);\n\t\tif (!rcpu)\n\t\t\tcontinue;\n\n\t\t/* bq flush and cleanup happens after RCU graze-period */\n\t\t__cpu_map_entry_replace(cmap, i, NULL); /* call_rcu */\n\t}\n\tfree_percpu(cmap->flush_needed);\n\tbpf_map_area_free(cmap->cpu_map);\n\tkfree(cmap);\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "cmap"
          ],
          "line": 513
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/params.c",
          "lines": "73-86",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_area_free",
          "args": [
            "cmap->cpu_map"
          ],
          "line": 512
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_area_free",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/syscall.c",
          "lines": "156-159",
          "snippet": "void bpf_map_area_free(void *area)\n{\n\tkvfree(area);\n}",
          "includes": [
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/version.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/version.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf.h>\n\nvoid bpf_map_area_free(void *area)\n{\n\tkvfree(area);\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_percpu",
          "args": [
            "cmap->flush_needed"
          ],
          "line": 511
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_array_free_percpu",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/arraymap.c",
          "lines": "27-35",
          "snippet": "static void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include <uapi/linux/btf.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/filter.h>",
            "#include <linux/mm.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include <uapi/linux/btf.h>\n#include <linux/perf_event.h>\n#include <linux/filter.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "__cpu_map_entry_replace",
          "args": [
            "cmap",
            "i",
            "NULL"
          ],
          "line": 509
        },
        "resolved": true,
        "details": {
          "function_name": "__cpu_map_entry_replace",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
          "lines": "404-415",
          "snippet": "static void __cpu_map_entry_replace(struct bpf_cpu_map *cmap,\n\t\t\t\t    u32 key_cpu, struct bpf_cpu_map_entry *rcpu)\n{\n\tstruct bpf_cpu_map_entry *old_rcpu;\n\n\told_rcpu = xchg(&cmap->cpu_map[key_cpu], rcpu);\n\tif (old_rcpu) {\n\t\tcall_rcu(&old_rcpu->rcu, __cpu_map_entry_free);\n\t\tINIT_WORK(&old_rcpu->kthread_stop_wq, cpu_map_kthread_stop);\n\t\tschedule_work(&old_rcpu->kthread_stop_wq);\n\t}\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic void __cpu_map_entry_replace(struct bpf_cpu_map *cmap,\n\t\t\t\t    u32 key_cpu, struct bpf_cpu_map_entry *rcpu)\n{\n\tstruct bpf_cpu_map_entry *old_rcpu;\n\n\told_rcpu = xchg(&cmap->cpu_map[key_cpu], rcpu);\n\tif (old_rcpu) {\n\t\tcall_rcu(&old_rcpu->rcu, __cpu_map_entry_free);\n\t\tINIT_WORK(&old_rcpu->kthread_stop_wq, cpu_map_kthread_stop);\n\t\tschedule_work(&old_rcpu->kthread_stop_wq);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "cmap->cpu_map[i]"
          ],
          "line": 504
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cond_resched",
          "args": [],
          "line": 495
        },
        "resolved": true,
        "details": {
          "function_name": "_cond_resched",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/core.c",
          "lines": "4957-4965",
          "snippet": "int __sched _cond_resched(void)\n{\n\tif (should_resched(0)) {\n\t\tpreempt_schedule_common();\n\t\treturn 1;\n\t}\n\trcu_all_qs();\n\treturn 0;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include <trace/events/sched.h>",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/kcov.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include <trace/events/sched.h>\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/kcov.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n\nstatic void __sched;\nstatic void __sched;\n\nint __sched _cond_resched(void)\n{\n\tif (should_resched(0)) {\n\t\tpreempt_schedule_common();\n\t\treturn 1;\n\t}\n\trcu_all_qs();\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "bitmap_empty",
          "args": [
            "bitmap",
            "cmap->map.max_entries"
          ],
          "line": 494
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "cmap->flush_needed",
            "cpu"
          ],
          "line": 492
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "synchronize_rcu",
          "args": [],
          "line": 484
        },
        "resolved": true,
        "details": {
          "function_name": "synchronize_rcu_tasks",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/update.c",
          "lines": "603-611",
          "snippet": "void synchronize_rcu_tasks(void)\n{\n\t/* Complain if the scheduler has not started.  */\n\tRCU_LOCKDEP_WARN(rcu_scheduler_active == RCU_SCHEDULER_INACTIVE,\n\t\t\t \"synchronize_rcu_tasks called too soon\");\n\n\t/* Wait for the grace period. */\n\twait_rcu_gp(call_rcu_tasks);\n}",
          "includes": [
            "#include \"rcu.h\"",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu.h\"\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nvoid synchronize_rcu_tasks(void)\n{\n\t/* Complain if the scheduler has not started.  */\n\tRCU_LOCKDEP_WARN(rcu_scheduler_active == RCU_SCHEDULER_INACTIVE,\n\t\t\t \"synchronize_rcu_tasks called too soon\");\n\n\t/* Wait for the grace period. */\n\twait_rcu_gp(call_rcu_tasks);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_clear_redirect_map",
          "args": [
            "map"
          ],
          "line": 483
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_cpu_map",
            "map"
          ],
          "line": 470
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic void cpu_map_free(struct bpf_map *map)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tint cpu;\n\tu32 i;\n\n\t/* At this point bpf_prog->aux->refcnt == 0 and this map->refcnt == 0,\n\t * so the bpf programs (can be more than one that used this map) were\n\t * disconnected from events. Wait for outstanding critical sections in\n\t * these programs to complete. The rcu critical section only guarantees\n\t * no further \"XDP/bpf-side\" reads against bpf_cpu_map->cpu_map.\n\t * It does __not__ ensure pending flush operations (if any) are\n\t * complete.\n\t */\n\n\tbpf_clear_redirect_map(map);\n\tsynchronize_rcu();\n\n\t/* To ensure all pending flush operations have completed wait for flush\n\t * bitmap to indicate all flush_needed bits to be zero on _all_ cpus.\n\t * Because the above synchronize_rcu() ensures the map is disconnected\n\t * from the program we can assume no new bits will be set.\n\t */\n\tfor_each_online_cpu(cpu) {\n\t\tunsigned long *bitmap = per_cpu_ptr(cmap->flush_needed, cpu);\n\n\t\twhile (!bitmap_empty(bitmap, cmap->map.max_entries))\n\t\t\tcond_resched();\n\t}\n\n\t/* For cpu_map the remote CPUs can still be using the entries\n\t * (struct bpf_cpu_map_entry).\n\t */\n\tfor (i = 0; i < cmap->map.max_entries; i++) {\n\t\tstruct bpf_cpu_map_entry *rcpu;\n\n\t\trcpu = READ_ONCE(cmap->cpu_map[i]);\n\t\tif (!rcpu)\n\t\t\tcontinue;\n\n\t\t/* bq flush and cleanup happens after RCU graze-period */\n\t\t__cpu_map_entry_replace(cmap, i, NULL); /* call_rcu */\n\t}\n\tfree_percpu(cmap->flush_needed);\n\tbpf_map_area_free(cmap->cpu_map);\n\tkfree(cmap);\n}"
  },
  {
    "function_name": "cpu_map_update_elem",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
    "lines": "430-466",
    "snippet": "static int cpu_map_update_elem(struct bpf_map *map, void *key, void *value,\n\t\t\t       u64 map_flags)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tstruct bpf_cpu_map_entry *rcpu;\n\n\t/* Array index key correspond to CPU number */\n\tu32 key_cpu = *(u32 *)key;\n\t/* Value is the queue size */\n\tu32 qsize = *(u32 *)value;\n\n\tif (unlikely(map_flags > BPF_EXIST))\n\t\treturn -EINVAL;\n\tif (unlikely(key_cpu >= cmap->map.max_entries))\n\t\treturn -E2BIG;\n\tif (unlikely(map_flags == BPF_NOEXIST))\n\t\treturn -EEXIST;\n\tif (unlikely(qsize > 16384)) /* sanity limit on qsize */\n\t\treturn -EOVERFLOW;\n\n\t/* Make sure CPU is a valid possible cpu */\n\tif (!cpu_possible(key_cpu))\n\t\treturn -ENODEV;\n\n\tif (qsize == 0) {\n\t\trcpu = NULL; /* Same as deleting */\n\t} else {\n\t\t/* Updating qsize cause re-allocation of bpf_cpu_map_entry */\n\t\trcpu = __cpu_map_entry_alloc(qsize, key_cpu, map->id);\n\t\tif (!rcpu)\n\t\t\treturn -ENOMEM;\n\t}\n\trcu_read_lock();\n\t__cpu_map_entry_replace(cmap, key_cpu, rcpu);\n\trcu_read_unlock();\n\treturn 0;\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 464
        },
        "resolved": true,
        "details": {
          "function_name": "__rcu_read_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/tree_plugin.h",
          "lines": "419-441",
          "snippet": "void __rcu_read_unlock(void)\n{\n\tstruct task_struct *t = current;\n\n\tif (t->rcu_read_lock_nesting != 1) {\n\t\t--t->rcu_read_lock_nesting;\n\t} else {\n\t\tbarrier();  /* critical section before exit code. */\n\t\tt->rcu_read_lock_nesting = INT_MIN;\n\t\tbarrier();  /* assign before ->rcu_read_unlock_special load */\n\t\tif (unlikely(READ_ONCE(t->rcu_read_unlock_special.s)))\n\t\t\trcu_read_unlock_special(t);\n\t\tbarrier();  /* ->rcu_read_unlock_special load before assign */\n\t\tt->rcu_read_lock_nesting = 0;\n\t}\n#ifdef CONFIG_PROVE_LOCKING\n\t{\n\t\tint rrln = READ_ONCE(t->rcu_read_lock_nesting);\n\n\t\tWARN_ON_ONCE(rrln < 0 && rrln > INT_MIN / 2);\n\t}\n#endif /* #ifdef CONFIG_PROVE_LOCKING */\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"../time/tick-internal.h\"",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/oom.h>",
            "#include <linux/gfp.h>",
            "#include <linux/delay.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"../time/tick-internal.h\"\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/isolation.h>\n#include <linux/smpboot.h>\n#include <linux/sched/debug.h>\n#include <linux/oom.h>\n#include <linux/gfp.h>\n#include <linux/delay.h>\n\nvoid __rcu_read_unlock(void)\n{\n\tstruct task_struct *t = current;\n\n\tif (t->rcu_read_lock_nesting != 1) {\n\t\t--t->rcu_read_lock_nesting;\n\t} else {\n\t\tbarrier();  /* critical section before exit code. */\n\t\tt->rcu_read_lock_nesting = INT_MIN;\n\t\tbarrier();  /* assign before ->rcu_read_unlock_special load */\n\t\tif (unlikely(READ_ONCE(t->rcu_read_unlock_special.s)))\n\t\t\trcu_read_unlock_special(t);\n\t\tbarrier();  /* ->rcu_read_unlock_special load before assign */\n\t\tt->rcu_read_lock_nesting = 0;\n\t}\n#ifdef CONFIG_PROVE_LOCKING\n\t{\n\t\tint rrln = READ_ONCE(t->rcu_read_lock_nesting);\n\n\t\tWARN_ON_ONCE(rrln < 0 && rrln > INT_MIN / 2);\n\t}\n#endif /* #ifdef CONFIG_PROVE_LOCKING */\n}"
        }
      },
      {
        "call_info": {
          "callee": "__cpu_map_entry_replace",
          "args": [
            "cmap",
            "key_cpu",
            "rcpu"
          ],
          "line": 463
        },
        "resolved": true,
        "details": {
          "function_name": "__cpu_map_entry_replace",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
          "lines": "404-415",
          "snippet": "static void __cpu_map_entry_replace(struct bpf_cpu_map *cmap,\n\t\t\t\t    u32 key_cpu, struct bpf_cpu_map_entry *rcpu)\n{\n\tstruct bpf_cpu_map_entry *old_rcpu;\n\n\told_rcpu = xchg(&cmap->cpu_map[key_cpu], rcpu);\n\tif (old_rcpu) {\n\t\tcall_rcu(&old_rcpu->rcu, __cpu_map_entry_free);\n\t\tINIT_WORK(&old_rcpu->kthread_stop_wq, cpu_map_kthread_stop);\n\t\tschedule_work(&old_rcpu->kthread_stop_wq);\n\t}\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic void __cpu_map_entry_replace(struct bpf_cpu_map *cmap,\n\t\t\t\t    u32 key_cpu, struct bpf_cpu_map_entry *rcpu)\n{\n\tstruct bpf_cpu_map_entry *old_rcpu;\n\n\told_rcpu = xchg(&cmap->cpu_map[key_cpu], rcpu);\n\tif (old_rcpu) {\n\t\tcall_rcu(&old_rcpu->rcu, __cpu_map_entry_free);\n\t\tINIT_WORK(&old_rcpu->kthread_stop_wq, cpu_map_kthread_stop);\n\t\tschedule_work(&old_rcpu->kthread_stop_wq);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 462
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_bh_held",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/update.c",
          "lines": "300-309",
          "snippet": "int rcu_read_lock_bh_held(void)\n{\n\tif (!debug_lockdep_rcu_enabled())\n\t\treturn 1;\n\tif (!rcu_is_watching())\n\t\treturn 0;\n\tif (!rcu_lockdep_current_cpu_online())\n\t\treturn 0;\n\treturn in_softirq() || irqs_disabled();\n}",
          "includes": [
            "#include \"rcu.h\"",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu.h\"\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_bh_held(void)\n{\n\tif (!debug_lockdep_rcu_enabled())\n\t\treturn 1;\n\tif (!rcu_is_watching())\n\t\treturn 0;\n\tif (!rcu_lockdep_current_cpu_online())\n\t\treturn 0;\n\treturn in_softirq() || irqs_disabled();\n}"
        }
      },
      {
        "call_info": {
          "callee": "__cpu_map_entry_alloc",
          "args": [
            "qsize",
            "key_cpu",
            "map->id"
          ],
          "line": 458
        },
        "resolved": true,
        "details": {
          "function_name": "__cpu_map_entry_alloc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
          "lines": "302-359",
          "snippet": "static struct bpf_cpu_map_entry *__cpu_map_entry_alloc(u32 qsize, u32 cpu,\n\t\t\t\t\t\t       int map_id)\n{\n\tgfp_t gfp = GFP_KERNEL | __GFP_NOWARN;\n\tstruct bpf_cpu_map_entry *rcpu;\n\tint numa, err;\n\n\t/* Have map->numa_node, but choose node of redirect target CPU */\n\tnuma = cpu_to_node(cpu);\n\n\trcpu = kzalloc_node(sizeof(*rcpu), gfp, numa);\n\tif (!rcpu)\n\t\treturn NULL;\n\n\t/* Alloc percpu bulkq */\n\trcpu->bulkq = __alloc_percpu_gfp(sizeof(*rcpu->bulkq),\n\t\t\t\t\t sizeof(void *), gfp);\n\tif (!rcpu->bulkq)\n\t\tgoto free_rcu;\n\n\t/* Alloc queue */\n\trcpu->queue = kzalloc_node(sizeof(*rcpu->queue), gfp, numa);\n\tif (!rcpu->queue)\n\t\tgoto free_bulkq;\n\n\terr = ptr_ring_init(rcpu->queue, qsize, gfp);\n\tif (err)\n\t\tgoto free_queue;\n\n\trcpu->cpu    = cpu;\n\trcpu->map_id = map_id;\n\trcpu->qsize  = qsize;\n\n\t/* Setup kthread */\n\trcpu->kthread = kthread_create_on_node(cpu_map_kthread_run, rcpu, numa,\n\t\t\t\t\t       \"cpumap/%d/map:%d\", cpu, map_id);\n\tif (IS_ERR(rcpu->kthread))\n\t\tgoto free_ptr_ring;\n\n\tget_cpu_map_entry(rcpu); /* 1-refcnt for being in cmap->cpu_map[] */\n\tget_cpu_map_entry(rcpu); /* 1-refcnt for kthread */\n\n\t/* Make sure kthread runs on a single CPU */\n\tkthread_bind(rcpu->kthread, cpu);\n\twake_up_process(rcpu->kthread);\n\n\treturn rcpu;\n\nfree_ptr_ring:\n\tptr_ring_cleanup(rcpu->queue, NULL);\nfree_queue:\n\tkfree(rcpu->queue);\nfree_bulkq:\n\tfree_percpu(rcpu->bulkq);\nfree_rcu:\n\tkfree(rcpu);\n\treturn NULL;\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic struct bpf_cpu_map_entry *__cpu_map_entry_alloc(u32 qsize, u32 cpu,\n\t\t\t\t\t\t       int map_id)\n{\n\tgfp_t gfp = GFP_KERNEL | __GFP_NOWARN;\n\tstruct bpf_cpu_map_entry *rcpu;\n\tint numa, err;\n\n\t/* Have map->numa_node, but choose node of redirect target CPU */\n\tnuma = cpu_to_node(cpu);\n\n\trcpu = kzalloc_node(sizeof(*rcpu), gfp, numa);\n\tif (!rcpu)\n\t\treturn NULL;\n\n\t/* Alloc percpu bulkq */\n\trcpu->bulkq = __alloc_percpu_gfp(sizeof(*rcpu->bulkq),\n\t\t\t\t\t sizeof(void *), gfp);\n\tif (!rcpu->bulkq)\n\t\tgoto free_rcu;\n\n\t/* Alloc queue */\n\trcpu->queue = kzalloc_node(sizeof(*rcpu->queue), gfp, numa);\n\tif (!rcpu->queue)\n\t\tgoto free_bulkq;\n\n\terr = ptr_ring_init(rcpu->queue, qsize, gfp);\n\tif (err)\n\t\tgoto free_queue;\n\n\trcpu->cpu    = cpu;\n\trcpu->map_id = map_id;\n\trcpu->qsize  = qsize;\n\n\t/* Setup kthread */\n\trcpu->kthread = kthread_create_on_node(cpu_map_kthread_run, rcpu, numa,\n\t\t\t\t\t       \"cpumap/%d/map:%d\", cpu, map_id);\n\tif (IS_ERR(rcpu->kthread))\n\t\tgoto free_ptr_ring;\n\n\tget_cpu_map_entry(rcpu); /* 1-refcnt for being in cmap->cpu_map[] */\n\tget_cpu_map_entry(rcpu); /* 1-refcnt for kthread */\n\n\t/* Make sure kthread runs on a single CPU */\n\tkthread_bind(rcpu->kthread, cpu);\n\twake_up_process(rcpu->kthread);\n\n\treturn rcpu;\n\nfree_ptr_ring:\n\tptr_ring_cleanup(rcpu->queue, NULL);\nfree_queue:\n\tkfree(rcpu->queue);\nfree_bulkq:\n\tfree_percpu(rcpu->bulkq);\nfree_rcu:\n\tkfree(rcpu);\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpu_possible",
          "args": [
            "key_cpu"
          ],
          "line": 451
        },
        "resolved": true,
        "details": {
          "function_name": "init_cpu_possible",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/cpu.c",
          "lines": "2269-2272",
          "snippet": "void init_cpu_possible(const struct cpumask *src)\n{\n\tcpumask_copy(&__cpu_possible_mask, src);\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <trace/events/cpuhp.h>",
            "#include <trace/events/power.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/slab.h>",
            "#include <linux/relay.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/nmi.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/suspend.h>",
            "#include <linux/gfp.h>",
            "#include <linux/mutex.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/kthread.h>",
            "#include <linux/bug.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/unistd.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/notifier.h>",
            "#include <linux/init.h>",
            "#include <linux/smp.h>",
            "#include <linux/proc_fs.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <trace/events/cpuhp.h>\n#include <trace/events/power.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/slab.h>\n#include <linux/relay.h>\n#include <linux/smpboot.h>\n#include <linux/nmi.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/lockdep.h>\n#include <linux/suspend.h>\n#include <linux/gfp.h>\n#include <linux/mutex.h>\n#include <linux/stop_machine.h>\n#include <linux/kthread.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/unistd.h>\n#include <linux/sched/task.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/signal.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/smp.h>\n#include <linux/proc_fs.h>\n\nvoid init_cpu_possible(const struct cpumask *src)\n{\n\tcpumask_copy(&__cpu_possible_mask, src);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "qsize > 16384"
          ],
          "line": 447
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "map_flags == BPF_NOEXIST"
          ],
          "line": 445
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "key_cpu >= cmap->map.max_entries"
          ],
          "line": 443
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "map_flags > BPF_EXIST"
          ],
          "line": 441
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_cpu_map",
            "map"
          ],
          "line": 433
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic int cpu_map_update_elem(struct bpf_map *map, void *key, void *value,\n\t\t\t       u64 map_flags)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tstruct bpf_cpu_map_entry *rcpu;\n\n\t/* Array index key correspond to CPU number */\n\tu32 key_cpu = *(u32 *)key;\n\t/* Value is the queue size */\n\tu32 qsize = *(u32 *)value;\n\n\tif (unlikely(map_flags > BPF_EXIST))\n\t\treturn -EINVAL;\n\tif (unlikely(key_cpu >= cmap->map.max_entries))\n\t\treturn -E2BIG;\n\tif (unlikely(map_flags == BPF_NOEXIST))\n\t\treturn -EEXIST;\n\tif (unlikely(qsize > 16384)) /* sanity limit on qsize */\n\t\treturn -EOVERFLOW;\n\n\t/* Make sure CPU is a valid possible cpu */\n\tif (!cpu_possible(key_cpu))\n\t\treturn -ENODEV;\n\n\tif (qsize == 0) {\n\t\trcpu = NULL; /* Same as deleting */\n\t} else {\n\t\t/* Updating qsize cause re-allocation of bpf_cpu_map_entry */\n\t\trcpu = __cpu_map_entry_alloc(qsize, key_cpu, map->id);\n\t\tif (!rcpu)\n\t\t\treturn -ENOMEM;\n\t}\n\trcu_read_lock();\n\t__cpu_map_entry_replace(cmap, key_cpu, rcpu);\n\trcu_read_unlock();\n\treturn 0;\n}"
  },
  {
    "function_name": "cpu_map_delete_elem",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
    "lines": "417-428",
    "snippet": "static int cpu_map_delete_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tu32 key_cpu = *(u32 *)key;\n\n\tif (key_cpu >= map->max_entries)\n\t\treturn -EINVAL;\n\n\t/* notice caller map_delete_elem() use preempt_disable() */\n\t__cpu_map_entry_replace(cmap, key_cpu, NULL);\n\treturn 0;\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__cpu_map_entry_replace",
          "args": [
            "cmap",
            "key_cpu",
            "NULL"
          ],
          "line": 426
        },
        "resolved": true,
        "details": {
          "function_name": "__cpu_map_entry_replace",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
          "lines": "404-415",
          "snippet": "static void __cpu_map_entry_replace(struct bpf_cpu_map *cmap,\n\t\t\t\t    u32 key_cpu, struct bpf_cpu_map_entry *rcpu)\n{\n\tstruct bpf_cpu_map_entry *old_rcpu;\n\n\told_rcpu = xchg(&cmap->cpu_map[key_cpu], rcpu);\n\tif (old_rcpu) {\n\t\tcall_rcu(&old_rcpu->rcu, __cpu_map_entry_free);\n\t\tINIT_WORK(&old_rcpu->kthread_stop_wq, cpu_map_kthread_stop);\n\t\tschedule_work(&old_rcpu->kthread_stop_wq);\n\t}\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic void __cpu_map_entry_replace(struct bpf_cpu_map *cmap,\n\t\t\t\t    u32 key_cpu, struct bpf_cpu_map_entry *rcpu)\n{\n\tstruct bpf_cpu_map_entry *old_rcpu;\n\n\told_rcpu = xchg(&cmap->cpu_map[key_cpu], rcpu);\n\tif (old_rcpu) {\n\t\tcall_rcu(&old_rcpu->rcu, __cpu_map_entry_free);\n\t\tINIT_WORK(&old_rcpu->kthread_stop_wq, cpu_map_kthread_stop);\n\t\tschedule_work(&old_rcpu->kthread_stop_wq);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_cpu_map",
            "map"
          ],
          "line": 419
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic int cpu_map_delete_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tu32 key_cpu = *(u32 *)key;\n\n\tif (key_cpu >= map->max_entries)\n\t\treturn -EINVAL;\n\n\t/* notice caller map_delete_elem() use preempt_disable() */\n\t__cpu_map_entry_replace(cmap, key_cpu, NULL);\n\treturn 0;\n}"
  },
  {
    "function_name": "__cpu_map_entry_replace",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
    "lines": "404-415",
    "snippet": "static void __cpu_map_entry_replace(struct bpf_cpu_map *cmap,\n\t\t\t\t    u32 key_cpu, struct bpf_cpu_map_entry *rcpu)\n{\n\tstruct bpf_cpu_map_entry *old_rcpu;\n\n\told_rcpu = xchg(&cmap->cpu_map[key_cpu], rcpu);\n\tif (old_rcpu) {\n\t\tcall_rcu(&old_rcpu->rcu, __cpu_map_entry_free);\n\t\tINIT_WORK(&old_rcpu->kthread_stop_wq, cpu_map_kthread_stop);\n\t\tschedule_work(&old_rcpu->kthread_stop_wq);\n\t}\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "schedule_work",
          "args": [
            "&old_rcpu->kthread_stop_wq"
          ],
          "line": 413
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "INIT_WORK",
          "args": [
            "&old_rcpu->kthread_stop_wq",
            "cpu_map_kthread_stop"
          ],
          "line": 412
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "call_rcu",
          "args": [
            "&old_rcpu->rcu",
            "__cpu_map_entry_free"
          ],
          "line": 411
        },
        "resolved": true,
        "details": {
          "function_name": "call_rcu_tasks",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/update.c",
          "lines": "552-567",
          "snippet": "void call_rcu_tasks(struct rcu_head *rhp, rcu_callback_t func)\n{\n\tunsigned long flags;\n\tbool needwake;\n\n\trhp->next = NULL;\n\trhp->func = func;\n\traw_spin_lock_irqsave(&rcu_tasks_cbs_lock, flags);\n\tneedwake = !rcu_tasks_cbs_head;\n\t*rcu_tasks_cbs_tail = rhp;\n\trcu_tasks_cbs_tail = &rhp->next;\n\traw_spin_unlock_irqrestore(&rcu_tasks_cbs_lock, flags);\n\t/* We can't create the thread unless interrupts are enabled. */\n\tif (needwake && READ_ONCE(rcu_tasks_kthread_ptr))\n\t\twake_up(&rcu_tasks_cbs_wq);\n}",
          "includes": [
            "#include \"rcu.h\"",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu.h\"\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nvoid call_rcu_tasks(struct rcu_head *rhp, rcu_callback_t func)\n{\n\tunsigned long flags;\n\tbool needwake;\n\n\trhp->next = NULL;\n\trhp->func = func;\n\traw_spin_lock_irqsave(&rcu_tasks_cbs_lock, flags);\n\tneedwake = !rcu_tasks_cbs_head;\n\t*rcu_tasks_cbs_tail = rhp;\n\trcu_tasks_cbs_tail = &rhp->next;\n\traw_spin_unlock_irqrestore(&rcu_tasks_cbs_lock, flags);\n\t/* We can't create the thread unless interrupts are enabled. */\n\tif (needwake && READ_ONCE(rcu_tasks_kthread_ptr))\n\t\twake_up(&rcu_tasks_cbs_wq);\n}"
        }
      },
      {
        "call_info": {
          "callee": "xchg",
          "args": [
            "&cmap->cpu_map[key_cpu]",
            "rcpu"
          ],
          "line": 409
        },
        "resolved": true,
        "details": {
          "function_name": "xchg_tail",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/qspinlock.c",
          "lines": "231-249",
          "snippet": "static __always_inline u32 xchg_tail(struct qspinlock *lock, u32 tail)\n{\n\tu32 old, new, val = atomic_read(&lock->val);\n\n\tfor (;;) {\n\t\tnew = (val & _Q_LOCKED_PENDING_MASK) | tail;\n\t\t/*\n\t\t * We can use relaxed semantics since the caller ensures that\n\t\t * the MCS node is properly initialized before updating the\n\t\t * tail.\n\t\t */\n\t\told = atomic_cmpxchg_relaxed(&lock->val, val, new);\n\t\tif (old == val)\n\t\t\tbreak;\n\n\t\tval = old;\n\t}\n\treturn old;\n}",
          "includes": [
            "#include \"qspinlock.c\"",
            "#include \"qspinlock_paravirt.h\"",
            "#include \"mcs_spinlock.h\"",
            "#include \"qspinlock_stat.h\"",
            "#include <asm/qspinlock.h>",
            "#include <asm/byteorder.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/mutex.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/cpumask.h>",
            "#include <linux/bug.h>",
            "#include <linux/smp.h>"
          ],
          "macros_used": [
            "#define _Q_LOCKED_PENDING_MASK (_Q_LOCKED_MASK | _Q_PENDING_MASK)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"qspinlock.c\"\n#include \"qspinlock_paravirt.h\"\n#include \"mcs_spinlock.h\"\n#include \"qspinlock_stat.h\"\n#include <asm/qspinlock.h>\n#include <asm/byteorder.h>\n#include <linux/prefetch.h>\n#include <linux/mutex.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/cpumask.h>\n#include <linux/bug.h>\n#include <linux/smp.h>\n\n#define _Q_LOCKED_PENDING_MASK (_Q_LOCKED_MASK | _Q_PENDING_MASK)\n\nstatic __always_inline u32 xchg_tail(struct qspinlock *lock, u32 tail)\n{\n\tu32 old, new, val = atomic_read(&lock->val);\n\n\tfor (;;) {\n\t\tnew = (val & _Q_LOCKED_PENDING_MASK) | tail;\n\t\t/*\n\t\t * We can use relaxed semantics since the caller ensures that\n\t\t * the MCS node is properly initialized before updating the\n\t\t * tail.\n\t\t */\n\t\told = atomic_cmpxchg_relaxed(&lock->val, val, new);\n\t\tif (old == val)\n\t\t\tbreak;\n\n\t\tval = old;\n\t}\n\treturn old;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic void __cpu_map_entry_replace(struct bpf_cpu_map *cmap,\n\t\t\t\t    u32 key_cpu, struct bpf_cpu_map_entry *rcpu)\n{\n\tstruct bpf_cpu_map_entry *old_rcpu;\n\n\told_rcpu = xchg(&cmap->cpu_map[key_cpu], rcpu);\n\tif (old_rcpu) {\n\t\tcall_rcu(&old_rcpu->rcu, __cpu_map_entry_free);\n\t\tINIT_WORK(&old_rcpu->kthread_stop_wq, cpu_map_kthread_stop);\n\t\tschedule_work(&old_rcpu->kthread_stop_wq);\n\t}\n}"
  },
  {
    "function_name": "__cpu_map_entry_free",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
    "lines": "361-383",
    "snippet": "static void __cpu_map_entry_free(struct rcu_head *rcu)\n{\n\tstruct bpf_cpu_map_entry *rcpu;\n\tint cpu;\n\n\t/* This cpu_map_entry have been disconnected from map and one\n\t * RCU graze-period have elapsed.  Thus, XDP cannot queue any\n\t * new packets and cannot change/set flush_needed that can\n\t * find this entry.\n\t */\n\trcpu = container_of(rcu, struct bpf_cpu_map_entry, rcu);\n\n\t/* Flush remaining packets in percpu bulkq */\n\tfor_each_online_cpu(cpu) {\n\t\tstruct xdp_bulk_queue *bq = per_cpu_ptr(rcpu->bulkq, cpu);\n\n\t\t/* No concurrent bq_enqueue can run at this point */\n\t\tbq_flush_to_queue(rcpu, bq, false);\n\t}\n\tfree_percpu(rcpu->bulkq);\n\t/* Cannot kthread_stop() here, last put free rcpu resources */\n\tput_cpu_map_entry(rcpu);\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "put_cpu_map_entry",
          "args": [
            "rcpu"
          ],
          "line": 382
        },
        "resolved": true,
        "details": {
          "function_name": "put_cpu_map_entry",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
          "lines": "225-234",
          "snippet": "static void put_cpu_map_entry(struct bpf_cpu_map_entry *rcpu)\n{\n\tif (atomic_dec_and_test(&rcpu->refcnt)) {\n\t\t/* The queue should be empty at this point */\n\t\t__cpu_map_ring_cleanup(rcpu->queue);\n\t\tptr_ring_cleanup(rcpu->queue, NULL);\n\t\tkfree(rcpu->queue);\n\t\tkfree(rcpu);\n\t}\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic void put_cpu_map_entry(struct bpf_cpu_map_entry *rcpu)\n{\n\tif (atomic_dec_and_test(&rcpu->refcnt)) {\n\t\t/* The queue should be empty at this point */\n\t\t__cpu_map_ring_cleanup(rcpu->queue);\n\t\tptr_ring_cleanup(rcpu->queue, NULL);\n\t\tkfree(rcpu->queue);\n\t\tkfree(rcpu);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_percpu",
          "args": [
            "rcpu->bulkq"
          ],
          "line": 380
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_array_free_percpu",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/arraymap.c",
          "lines": "27-35",
          "snippet": "static void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include <uapi/linux/btf.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/filter.h>",
            "#include <linux/mm.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include <uapi/linux/btf.h>\n#include <linux/perf_event.h>\n#include <linux/filter.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "bq_flush_to_queue",
          "args": [
            "rcpu",
            "bq",
            "false"
          ],
          "line": 378
        },
        "resolved": true,
        "details": {
          "function_name": "bq_flush_to_queue",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
          "lines": "563-597",
          "snippet": "static int bq_flush_to_queue(struct bpf_cpu_map_entry *rcpu,\n\t\t\t     struct xdp_bulk_queue *bq, bool in_napi_ctx)\n{\n\tunsigned int processed = 0, drops = 0;\n\tconst int to_cpu = rcpu->cpu;\n\tstruct ptr_ring *q;\n\tint i;\n\n\tif (unlikely(!bq->count))\n\t\treturn 0;\n\n\tq = rcpu->queue;\n\tspin_lock(&q->producer_lock);\n\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\t\tint err;\n\n\t\terr = __ptr_ring_produce(q, xdpf);\n\t\tif (err) {\n\t\t\tdrops++;\n\t\t\tif (likely(in_napi_ctx))\n\t\t\t\txdp_return_frame_rx_napi(xdpf);\n\t\t\telse\n\t\t\t\txdp_return_frame(xdpf);\n\t\t}\n\t\tprocessed++;\n\t}\n\tbq->count = 0;\n\tspin_unlock(&q->producer_lock);\n\n\t/* Feedback loop via tracepoints */\n\ttrace_xdp_cpumap_enqueue(rcpu->map_id, processed, drops, to_cpu);\n\treturn 0;\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static int bq_flush_to_queue(struct bpf_cpu_map_entry *rcpu,\n\t\t\t     struct xdp_bulk_queue *bq, bool in_napi_ctx);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic int bq_flush_to_queue(struct bpf_cpu_map_entry *rcpu,\n\t\t\t     struct xdp_bulk_queue *bq, bool in_napi_ctx);\n\nstatic int bq_flush_to_queue(struct bpf_cpu_map_entry *rcpu,\n\t\t\t     struct xdp_bulk_queue *bq, bool in_napi_ctx)\n{\n\tunsigned int processed = 0, drops = 0;\n\tconst int to_cpu = rcpu->cpu;\n\tstruct ptr_ring *q;\n\tint i;\n\n\tif (unlikely(!bq->count))\n\t\treturn 0;\n\n\tq = rcpu->queue;\n\tspin_lock(&q->producer_lock);\n\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\t\tint err;\n\n\t\terr = __ptr_ring_produce(q, xdpf);\n\t\tif (err) {\n\t\t\tdrops++;\n\t\t\tif (likely(in_napi_ctx))\n\t\t\t\txdp_return_frame_rx_napi(xdpf);\n\t\t\telse\n\t\t\t\txdp_return_frame(xdpf);\n\t\t}\n\t\tprocessed++;\n\t}\n\tbq->count = 0;\n\tspin_unlock(&q->producer_lock);\n\n\t/* Feedback loop via tracepoints */\n\ttrace_xdp_cpumap_enqueue(rcpu->map_id, processed, drops, to_cpu);\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "rcpu->bulkq",
            "cpu"
          ],
          "line": 375
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "rcu",
            "structbpf_cpu_map_entry",
            "rcu"
          ],
          "line": 371
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic void __cpu_map_entry_free(struct rcu_head *rcu)\n{\n\tstruct bpf_cpu_map_entry *rcpu;\n\tint cpu;\n\n\t/* This cpu_map_entry have been disconnected from map and one\n\t * RCU graze-period have elapsed.  Thus, XDP cannot queue any\n\t * new packets and cannot change/set flush_needed that can\n\t * find this entry.\n\t */\n\trcpu = container_of(rcu, struct bpf_cpu_map_entry, rcu);\n\n\t/* Flush remaining packets in percpu bulkq */\n\tfor_each_online_cpu(cpu) {\n\t\tstruct xdp_bulk_queue *bq = per_cpu_ptr(rcpu->bulkq, cpu);\n\n\t\t/* No concurrent bq_enqueue can run at this point */\n\t\tbq_flush_to_queue(rcpu, bq, false);\n\t}\n\tfree_percpu(rcpu->bulkq);\n\t/* Cannot kthread_stop() here, last put free rcpu resources */\n\tput_cpu_map_entry(rcpu);\n}"
  },
  {
    "function_name": "__cpu_map_entry_alloc",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
    "lines": "302-359",
    "snippet": "static struct bpf_cpu_map_entry *__cpu_map_entry_alloc(u32 qsize, u32 cpu,\n\t\t\t\t\t\t       int map_id)\n{\n\tgfp_t gfp = GFP_KERNEL | __GFP_NOWARN;\n\tstruct bpf_cpu_map_entry *rcpu;\n\tint numa, err;\n\n\t/* Have map->numa_node, but choose node of redirect target CPU */\n\tnuma = cpu_to_node(cpu);\n\n\trcpu = kzalloc_node(sizeof(*rcpu), gfp, numa);\n\tif (!rcpu)\n\t\treturn NULL;\n\n\t/* Alloc percpu bulkq */\n\trcpu->bulkq = __alloc_percpu_gfp(sizeof(*rcpu->bulkq),\n\t\t\t\t\t sizeof(void *), gfp);\n\tif (!rcpu->bulkq)\n\t\tgoto free_rcu;\n\n\t/* Alloc queue */\n\trcpu->queue = kzalloc_node(sizeof(*rcpu->queue), gfp, numa);\n\tif (!rcpu->queue)\n\t\tgoto free_bulkq;\n\n\terr = ptr_ring_init(rcpu->queue, qsize, gfp);\n\tif (err)\n\t\tgoto free_queue;\n\n\trcpu->cpu    = cpu;\n\trcpu->map_id = map_id;\n\trcpu->qsize  = qsize;\n\n\t/* Setup kthread */\n\trcpu->kthread = kthread_create_on_node(cpu_map_kthread_run, rcpu, numa,\n\t\t\t\t\t       \"cpumap/%d/map:%d\", cpu, map_id);\n\tif (IS_ERR(rcpu->kthread))\n\t\tgoto free_ptr_ring;\n\n\tget_cpu_map_entry(rcpu); /* 1-refcnt for being in cmap->cpu_map[] */\n\tget_cpu_map_entry(rcpu); /* 1-refcnt for kthread */\n\n\t/* Make sure kthread runs on a single CPU */\n\tkthread_bind(rcpu->kthread, cpu);\n\twake_up_process(rcpu->kthread);\n\n\treturn rcpu;\n\nfree_ptr_ring:\n\tptr_ring_cleanup(rcpu->queue, NULL);\nfree_queue:\n\tkfree(rcpu->queue);\nfree_bulkq:\n\tfree_percpu(rcpu->bulkq);\nfree_rcu:\n\tkfree(rcpu);\n\treturn NULL;\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "rcpu"
          ],
          "line": 357
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/params.c",
          "lines": "73-86",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_percpu",
          "args": [
            "rcpu->bulkq"
          ],
          "line": 355
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_array_free_percpu",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/arraymap.c",
          "lines": "27-35",
          "snippet": "static void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include <uapi/linux/btf.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/filter.h>",
            "#include <linux/mm.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include <uapi/linux/btf.h>\n#include <linux/perf_event.h>\n#include <linux/filter.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "ptr_ring_cleanup",
          "args": [
            "rcpu->queue",
            "NULL"
          ],
          "line": 351
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "wake_up_process",
          "args": [
            "rcpu->kthread"
          ],
          "line": 346
        },
        "resolved": true,
        "details": {
          "function_name": "wake_up_process",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/core.c",
          "lines": "2127-2130",
          "snippet": "int wake_up_process(struct task_struct *p)\n{\n\treturn try_to_wake_up(p, TASK_NORMAL, 0);\n}",
          "includes": [
            "#include \"features.h\"",
            "#include <trace/events/sched.h>",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/kcov.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include <trace/events/sched.h>\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/kcov.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n\nstatic __always_inline struct;\n\nint wake_up_process(struct task_struct *p)\n{\n\treturn try_to_wake_up(p, TASK_NORMAL, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kthread_bind",
          "args": [
            "rcpu->kthread",
            "cpu"
          ],
          "line": 345
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_bind",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/kthread.c",
          "lines": "421-424",
          "snippet": "void kthread_bind(struct task_struct *p, unsigned int cpu)\n{\n\t__kthread_bind(p, cpu, TASK_UNINTERRUPTIBLE);\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <uapi/linux/sched/types.h>\n\nvoid kthread_bind(struct task_struct *p, unsigned int cpu)\n{\n\t__kthread_bind(p, cpu, TASK_UNINTERRUPTIBLE);\n}"
        }
      },
      {
        "call_info": {
          "callee": "get_cpu_map_entry",
          "args": [
            "rcpu"
          ],
          "line": 342
        },
        "resolved": true,
        "details": {
          "function_name": "get_cpu_map_entry",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
          "lines": "141-144",
          "snippet": "static void get_cpu_map_entry(struct bpf_cpu_map_entry *rcpu)\n{\n\tatomic_inc(&rcpu->refcnt);\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic void get_cpu_map_entry(struct bpf_cpu_map_entry *rcpu)\n{\n\tatomic_inc(&rcpu->refcnt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "IS_ERR",
          "args": [
            "rcpu->kthread"
          ],
          "line": 338
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kthread_create_on_node",
          "args": [
            "cpu_map_kthread_run",
            "rcpu",
            "numa",
            "\"cpumap/%d/map:%d\"",
            "cpu",
            "map_id"
          ],
          "line": 336
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_create_on_node",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/kthread.c",
          "lines": "370-383",
          "snippet": "struct task_struct *kthread_create_on_node(int (*threadfn)(void *data),\n\t\t\t\t\t   void *data, int node,\n\t\t\t\t\t   const char namefmt[],\n\t\t\t\t\t   ...)\n{\n\tstruct task_struct *task;\n\tva_list args;\n\n\tva_start(args, namefmt);\n\ttask = __kthread_create_on_node(threadfn, data, node, namefmt, args);\n\tva_end(args);\n\n\treturn task;\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __printf(4, 0)\nstruct task_struct *__kthread_create_on_node(int (*threadfn)(void *data),\n\t\t\t\t\t\t    void *data, int node,\n\t\t\t\t\t\t    const char namefmt[],\n\t\t\t\t\t\t    va_list args)\n{\n\tDECLARE_COMPLETION_ONSTACK(done);\n\tstruct task_struct *task;",
            "static __printf(3, 0) struct kthread_worker *\n__kthread_create_worker(int cpu, unsigned int flags,\n\t\t\tconst char namefmt[], va_list args)\n{\n\tstruct kthread_worker *worker;",
            "struct task_struct *task;",
            "int node = -1;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <uapi/linux/sched/types.h>\n\nstatic __printf(4, 0)\nstruct task_struct *__kthread_create_on_node(int (*threadfn)(void *data),\n\t\t\t\t\t\t    void *data, int node,\n\t\t\t\t\t\t    const char namefmt[],\n\t\t\t\t\t\t    va_list args)\n{\n\tDECLARE_COMPLETION_ONSTACK(done);\n\tstruct task_struct *task;\nstatic __printf(3, 0) struct kthread_worker *\n__kthread_create_worker(int cpu, unsigned int flags,\n\t\t\tconst char namefmt[], va_list args)\n{\n\tstruct kthread_worker *worker;\nstruct task_struct *task;\nint node = -1;\n\nstruct task_struct *kthread_create_on_node(int (*threadfn)(void *data),\n\t\t\t\t\t   void *data, int node,\n\t\t\t\t\t   const char namefmt[],\n\t\t\t\t\t   ...)\n{\n\tstruct task_struct *task;\n\tva_list args;\n\n\tva_start(args, namefmt);\n\ttask = __kthread_create_on_node(threadfn, data, node, namefmt, args);\n\tva_end(args);\n\n\treturn task;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ptr_ring_init",
          "args": [
            "rcpu->queue",
            "qsize",
            "gfp"
          ],
          "line": 327
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kzalloc_node",
          "args": [
            "sizeof(*rcpu->queue)",
            "gfp",
            "numa"
          ],
          "line": 323
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__alloc_percpu_gfp",
          "args": [
            "sizeof(*rcpu->bulkq)",
            "sizeof(void *)",
            "gfp"
          ],
          "line": 317
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kzalloc_node",
          "args": [
            "sizeof(*rcpu)",
            "gfp",
            "numa"
          ],
          "line": 312
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_to_node",
          "args": [
            "cpu"
          ],
          "line": 310
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic struct bpf_cpu_map_entry *__cpu_map_entry_alloc(u32 qsize, u32 cpu,\n\t\t\t\t\t\t       int map_id)\n{\n\tgfp_t gfp = GFP_KERNEL | __GFP_NOWARN;\n\tstruct bpf_cpu_map_entry *rcpu;\n\tint numa, err;\n\n\t/* Have map->numa_node, but choose node of redirect target CPU */\n\tnuma = cpu_to_node(cpu);\n\n\trcpu = kzalloc_node(sizeof(*rcpu), gfp, numa);\n\tif (!rcpu)\n\t\treturn NULL;\n\n\t/* Alloc percpu bulkq */\n\trcpu->bulkq = __alloc_percpu_gfp(sizeof(*rcpu->bulkq),\n\t\t\t\t\t sizeof(void *), gfp);\n\tif (!rcpu->bulkq)\n\t\tgoto free_rcu;\n\n\t/* Alloc queue */\n\trcpu->queue = kzalloc_node(sizeof(*rcpu->queue), gfp, numa);\n\tif (!rcpu->queue)\n\t\tgoto free_bulkq;\n\n\terr = ptr_ring_init(rcpu->queue, qsize, gfp);\n\tif (err)\n\t\tgoto free_queue;\n\n\trcpu->cpu    = cpu;\n\trcpu->map_id = map_id;\n\trcpu->qsize  = qsize;\n\n\t/* Setup kthread */\n\trcpu->kthread = kthread_create_on_node(cpu_map_kthread_run, rcpu, numa,\n\t\t\t\t\t       \"cpumap/%d/map:%d\", cpu, map_id);\n\tif (IS_ERR(rcpu->kthread))\n\t\tgoto free_ptr_ring;\n\n\tget_cpu_map_entry(rcpu); /* 1-refcnt for being in cmap->cpu_map[] */\n\tget_cpu_map_entry(rcpu); /* 1-refcnt for kthread */\n\n\t/* Make sure kthread runs on a single CPU */\n\tkthread_bind(rcpu->kthread, cpu);\n\twake_up_process(rcpu->kthread);\n\n\treturn rcpu;\n\nfree_ptr_ring:\n\tptr_ring_cleanup(rcpu->queue, NULL);\nfree_queue:\n\tkfree(rcpu->queue);\nfree_bulkq:\n\tfree_percpu(rcpu->bulkq);\nfree_rcu:\n\tkfree(rcpu);\n\treturn NULL;\n}"
  },
  {
    "function_name": "cpu_map_kthread_run",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
    "lines": "236-300",
    "snippet": "static int cpu_map_kthread_run(void *data)\n{\n\tstruct bpf_cpu_map_entry *rcpu = data;\n\n\tset_current_state(TASK_INTERRUPTIBLE);\n\n\t/* When kthread gives stop order, then rcpu have been disconnected\n\t * from map, thus no new packets can enter. Remaining in-flight\n\t * per CPU stored packets are flushed to this queue.  Wait honoring\n\t * kthread_stop signal until queue is empty.\n\t */\n\twhile (!kthread_should_stop() || !__ptr_ring_empty(rcpu->queue)) {\n\t\tunsigned int processed = 0, drops = 0, sched = 0;\n\t\tstruct xdp_frame *xdpf;\n\n\t\t/* Release CPU reschedule checks */\n\t\tif (__ptr_ring_empty(rcpu->queue)) {\n\t\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\t\t/* Recheck to avoid lost wake-up */\n\t\t\tif (__ptr_ring_empty(rcpu->queue)) {\n\t\t\t\tschedule();\n\t\t\t\tsched = 1;\n\t\t\t} else {\n\t\t\t\t__set_current_state(TASK_RUNNING);\n\t\t\t}\n\t\t} else {\n\t\t\tsched = cond_resched();\n\t\t}\n\n\t\t/* Process packets in rcpu->queue */\n\t\tlocal_bh_disable();\n\t\t/*\n\t\t * The bpf_cpu_map_entry is single consumer, with this\n\t\t * kthread CPU pinned. Lockless access to ptr_ring\n\t\t * consume side valid as no-resize allowed of queue.\n\t\t */\n\t\twhile ((xdpf = __ptr_ring_consume(rcpu->queue))) {\n\t\t\tstruct sk_buff *skb;\n\t\t\tint ret;\n\n\t\t\tskb = cpu_map_build_skb(rcpu, xdpf);\n\t\t\tif (!skb) {\n\t\t\t\txdp_return_frame(xdpf);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t/* Inject into network stack */\n\t\t\tret = netif_receive_skb_core(skb);\n\t\t\tif (ret == NET_RX_DROP)\n\t\t\t\tdrops++;\n\n\t\t\t/* Limit BH-disable period */\n\t\t\tif (++processed == 8)\n\t\t\t\tbreak;\n\t\t}\n\t\t/* Feedback loop via tracepoint */\n\t\ttrace_xdp_cpumap_kthread(rcpu->map_id, processed, drops, sched);\n\n\t\tlocal_bh_enable(); /* resched point, may call do_softirq() */\n\t}\n\t__set_current_state(TASK_RUNNING);\n\n\tput_cpu_map_entry(rcpu);\n\treturn 0;\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "put_cpu_map_entry",
          "args": [
            "rcpu"
          ],
          "line": 298
        },
        "resolved": true,
        "details": {
          "function_name": "put_cpu_map_entry",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
          "lines": "225-234",
          "snippet": "static void put_cpu_map_entry(struct bpf_cpu_map_entry *rcpu)\n{\n\tif (atomic_dec_and_test(&rcpu->refcnt)) {\n\t\t/* The queue should be empty at this point */\n\t\t__cpu_map_ring_cleanup(rcpu->queue);\n\t\tptr_ring_cleanup(rcpu->queue, NULL);\n\t\tkfree(rcpu->queue);\n\t\tkfree(rcpu);\n\t}\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic void put_cpu_map_entry(struct bpf_cpu_map_entry *rcpu)\n{\n\tif (atomic_dec_and_test(&rcpu->refcnt)) {\n\t\t/* The queue should be empty at this point */\n\t\t__cpu_map_ring_cleanup(rcpu->queue);\n\t\tptr_ring_cleanup(rcpu->queue, NULL);\n\t\tkfree(rcpu->queue);\n\t\tkfree(rcpu);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "__set_current_state",
          "args": [
            "TASK_RUNNING"
          ],
          "line": 296
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_bh_enable",
          "args": [],
          "line": 294
        },
        "resolved": true,
        "details": {
          "function_name": "_local_bh_enable",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/softirq.c",
          "lines": "159-163",
          "snippet": "void _local_bh_enable(void)\n{\n\tWARN_ON_ONCE(in_irq());\n\t__local_bh_enable(SOFTIRQ_DISABLE_OFFSET);\n}",
          "includes": [
            "#include <trace/events/irq.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/smp.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/kthread.h>",
            "#include <linux/freezer.h>",
            "#include <linux/cpu.h>",
            "#include <linux/percpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/mm.h>",
            "#include <linux/init.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/irq.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/smpboot.h>\n#include <linux/smp.h>\n#include <linux/ftrace.h>\n#include <linux/rcupdate.h>\n#include <linux/kthread.h>\n#include <linux/freezer.h>\n#include <linux/cpu.h>\n#include <linux/percpu.h>\n#include <linux/notifier.h>\n#include <linux/mm.h>\n#include <linux/init.h>\n#include <linux/interrupt.h>\n#include <linux/kernel_stat.h>\n#include <linux/export.h>\n\nvoid _local_bh_enable(void)\n{\n\tWARN_ON_ONCE(in_irq());\n\t__local_bh_enable(SOFTIRQ_DISABLE_OFFSET);\n}"
        }
      },
      {
        "call_info": {
          "callee": "trace_xdp_cpumap_kthread",
          "args": [
            "rcpu->map_id",
            "processed",
            "drops",
            "sched"
          ],
          "line": 292
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "netif_receive_skb_core",
          "args": [
            "skb"
          ],
          "line": 283
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "xdp_return_frame",
          "args": [
            "xdpf"
          ],
          "line": 278
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_map_build_skb",
          "args": [
            "rcpu",
            "xdpf"
          ],
          "line": 276
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_map_build_skb",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
          "lines": "162-209",
          "snippet": "static struct sk_buff *cpu_map_build_skb(struct bpf_cpu_map_entry *rcpu,\n\t\t\t\t\t struct xdp_frame *xdpf)\n{\n\tunsigned int frame_size;\n\tvoid *pkt_data_start;\n\tstruct sk_buff *skb;\n\n\t/* build_skb need to place skb_shared_info after SKB end, and\n\t * also want to know the memory \"truesize\".  Thus, need to\n\t * know the memory frame size backing xdp_buff.\n\t *\n\t * XDP was designed to have PAGE_SIZE frames, but this\n\t * assumption is not longer true with ixgbe and i40e.  It\n\t * would be preferred to set frame_size to 2048 or 4096\n\t * depending on the driver.\n\t *   frame_size = 2048;\n\t *   frame_len  = frame_size - sizeof(*xdp_frame);\n\t *\n\t * Instead, with info avail, skb_shared_info in placed after\n\t * packet len.  This, unfortunately fakes the truesize.\n\t * Another disadvantage of this approach, the skb_shared_info\n\t * is not at a fixed memory location, with mixed length\n\t * packets, which is bad for cache-line hotness.\n\t */\n\tframe_size = SKB_DATA_ALIGN(xdpf->len) + xdpf->headroom +\n\t\tSKB_DATA_ALIGN(sizeof(struct skb_shared_info));\n\n\tpkt_data_start = xdpf->data - xdpf->headroom;\n\tskb = build_skb(pkt_data_start, frame_size);\n\tif (!skb)\n\t\treturn NULL;\n\n\tskb_reserve(skb, xdpf->headroom);\n\t__skb_put(skb, xdpf->len);\n\tif (xdpf->metasize)\n\t\tskb_metadata_set(skb, xdpf->metasize);\n\n\t/* Essential SKB info: protocol and skb->dev */\n\tskb->protocol = eth_type_trans(skb, xdpf->dev_rx);\n\n\t/* Optional SKB info, currently missing:\n\t * - HW checksum info\t\t(skb->ip_summed)\n\t * - HW RX hash\t\t\t(skb_set_hash)\n\t * - RX ring dev queue index\t(skb_record_rx_queue)\n\t */\n\n\treturn skb;\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic struct sk_buff *cpu_map_build_skb(struct bpf_cpu_map_entry *rcpu,\n\t\t\t\t\t struct xdp_frame *xdpf)\n{\n\tunsigned int frame_size;\n\tvoid *pkt_data_start;\n\tstruct sk_buff *skb;\n\n\t/* build_skb need to place skb_shared_info after SKB end, and\n\t * also want to know the memory \"truesize\".  Thus, need to\n\t * know the memory frame size backing xdp_buff.\n\t *\n\t * XDP was designed to have PAGE_SIZE frames, but this\n\t * assumption is not longer true with ixgbe and i40e.  It\n\t * would be preferred to set frame_size to 2048 or 4096\n\t * depending on the driver.\n\t *   frame_size = 2048;\n\t *   frame_len  = frame_size - sizeof(*xdp_frame);\n\t *\n\t * Instead, with info avail, skb_shared_info in placed after\n\t * packet len.  This, unfortunately fakes the truesize.\n\t * Another disadvantage of this approach, the skb_shared_info\n\t * is not at a fixed memory location, with mixed length\n\t * packets, which is bad for cache-line hotness.\n\t */\n\tframe_size = SKB_DATA_ALIGN(xdpf->len) + xdpf->headroom +\n\t\tSKB_DATA_ALIGN(sizeof(struct skb_shared_info));\n\n\tpkt_data_start = xdpf->data - xdpf->headroom;\n\tskb = build_skb(pkt_data_start, frame_size);\n\tif (!skb)\n\t\treturn NULL;\n\n\tskb_reserve(skb, xdpf->headroom);\n\t__skb_put(skb, xdpf->len);\n\tif (xdpf->metasize)\n\t\tskb_metadata_set(skb, xdpf->metasize);\n\n\t/* Essential SKB info: protocol and skb->dev */\n\tskb->protocol = eth_type_trans(skb, xdpf->dev_rx);\n\n\t/* Optional SKB info, currently missing:\n\t * - HW checksum info\t\t(skb->ip_summed)\n\t * - HW RX hash\t\t\t(skb_set_hash)\n\t * - RX ring dev queue index\t(skb_record_rx_queue)\n\t */\n\n\treturn skb;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__ptr_ring_consume",
          "args": [
            "rcpu->queue"
          ],
          "line": 272
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_bh_disable",
          "args": [],
          "line": 266
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cond_resched",
          "args": [],
          "line": 262
        },
        "resolved": true,
        "details": {
          "function_name": "_cond_resched",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/core.c",
          "lines": "4957-4965",
          "snippet": "int __sched _cond_resched(void)\n{\n\tif (should_resched(0)) {\n\t\tpreempt_schedule_common();\n\t\treturn 1;\n\t}\n\trcu_all_qs();\n\treturn 0;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include <trace/events/sched.h>",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/kcov.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include <trace/events/sched.h>\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/kcov.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n\nstatic void __sched;\nstatic void __sched;\n\nint __sched _cond_resched(void)\n{\n\tif (should_resched(0)) {\n\t\tpreempt_schedule_common();\n\t\treturn 1;\n\t}\n\trcu_all_qs();\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__set_current_state",
          "args": [
            "TASK_RUNNING"
          ],
          "line": 259
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "schedule",
          "args": [],
          "line": 256
        },
        "resolved": true,
        "details": {
          "function_name": "audit_schedule_prune",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/audit_tree.c",
          "lines": "919-922",
          "snippet": "static void audit_schedule_prune(void)\n{\n\twake_up_process(prune_thread);\n}",
          "includes": [
            "#include <linux/slab.h>",
            "#include <linux/refcount.h>",
            "#include <linux/kthread.h>",
            "#include <linux/mount.h>",
            "#include <linux/namei.h>",
            "#include <linux/fsnotify_backend.h>",
            "#include \"audit.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static struct task_struct *prune_thread;",
            "static void audit_schedule_prune(void);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/slab.h>\n#include <linux/refcount.h>\n#include <linux/kthread.h>\n#include <linux/mount.h>\n#include <linux/namei.h>\n#include <linux/fsnotify_backend.h>\n#include \"audit.h\"\n\nstatic struct task_struct *prune_thread;\nstatic void audit_schedule_prune(void);\n\nstatic void audit_schedule_prune(void)\n{\n\twake_up_process(prune_thread);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__ptr_ring_empty",
          "args": [
            "rcpu->queue"
          ],
          "line": 255
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "set_current_state",
          "args": [
            "TASK_INTERRUPTIBLE"
          ],
          "line": 253
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__ptr_ring_empty",
          "args": [
            "rcpu->queue"
          ],
          "line": 252
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__ptr_ring_empty",
          "args": [
            "rcpu->queue"
          ],
          "line": 247
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kthread_should_stop",
          "args": [],
          "line": 247
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_should_stop",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/kthread.c",
          "lines": "98-101",
          "snippet": "bool kthread_should_stop(void)\n{\n\treturn test_bit(KTHREAD_SHOULD_STOP, &to_kthread(current)->flags);\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <uapi/linux/sched/types.h>\n\nbool kthread_should_stop(void)\n{\n\treturn test_bit(KTHREAD_SHOULD_STOP, &to_kthread(current)->flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "set_current_state",
          "args": [
            "TASK_INTERRUPTIBLE"
          ],
          "line": 240
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic int cpu_map_kthread_run(void *data)\n{\n\tstruct bpf_cpu_map_entry *rcpu = data;\n\n\tset_current_state(TASK_INTERRUPTIBLE);\n\n\t/* When kthread gives stop order, then rcpu have been disconnected\n\t * from map, thus no new packets can enter. Remaining in-flight\n\t * per CPU stored packets are flushed to this queue.  Wait honoring\n\t * kthread_stop signal until queue is empty.\n\t */\n\twhile (!kthread_should_stop() || !__ptr_ring_empty(rcpu->queue)) {\n\t\tunsigned int processed = 0, drops = 0, sched = 0;\n\t\tstruct xdp_frame *xdpf;\n\n\t\t/* Release CPU reschedule checks */\n\t\tif (__ptr_ring_empty(rcpu->queue)) {\n\t\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\t\t/* Recheck to avoid lost wake-up */\n\t\t\tif (__ptr_ring_empty(rcpu->queue)) {\n\t\t\t\tschedule();\n\t\t\t\tsched = 1;\n\t\t\t} else {\n\t\t\t\t__set_current_state(TASK_RUNNING);\n\t\t\t}\n\t\t} else {\n\t\t\tsched = cond_resched();\n\t\t}\n\n\t\t/* Process packets in rcpu->queue */\n\t\tlocal_bh_disable();\n\t\t/*\n\t\t * The bpf_cpu_map_entry is single consumer, with this\n\t\t * kthread CPU pinned. Lockless access to ptr_ring\n\t\t * consume side valid as no-resize allowed of queue.\n\t\t */\n\t\twhile ((xdpf = __ptr_ring_consume(rcpu->queue))) {\n\t\t\tstruct sk_buff *skb;\n\t\t\tint ret;\n\n\t\t\tskb = cpu_map_build_skb(rcpu, xdpf);\n\t\t\tif (!skb) {\n\t\t\t\txdp_return_frame(xdpf);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t/* Inject into network stack */\n\t\t\tret = netif_receive_skb_core(skb);\n\t\t\tif (ret == NET_RX_DROP)\n\t\t\t\tdrops++;\n\n\t\t\t/* Limit BH-disable period */\n\t\t\tif (++processed == 8)\n\t\t\t\tbreak;\n\t\t}\n\t\t/* Feedback loop via tracepoint */\n\t\ttrace_xdp_cpumap_kthread(rcpu->map_id, processed, drops, sched);\n\n\t\tlocal_bh_enable(); /* resched point, may call do_softirq() */\n\t}\n\t__set_current_state(TASK_RUNNING);\n\n\tput_cpu_map_entry(rcpu);\n\treturn 0;\n}"
  },
  {
    "function_name": "put_cpu_map_entry",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
    "lines": "225-234",
    "snippet": "static void put_cpu_map_entry(struct bpf_cpu_map_entry *rcpu)\n{\n\tif (atomic_dec_and_test(&rcpu->refcnt)) {\n\t\t/* The queue should be empty at this point */\n\t\t__cpu_map_ring_cleanup(rcpu->queue);\n\t\tptr_ring_cleanup(rcpu->queue, NULL);\n\t\tkfree(rcpu->queue);\n\t\tkfree(rcpu);\n\t}\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "rcpu"
          ],
          "line": 232
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/params.c",
          "lines": "73-86",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ptr_ring_cleanup",
          "args": [
            "rcpu->queue",
            "NULL"
          ],
          "line": 230
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__cpu_map_ring_cleanup",
          "args": [
            "rcpu->queue"
          ],
          "line": 229
        },
        "resolved": true,
        "details": {
          "function_name": "__cpu_map_ring_cleanup",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
          "lines": "211-223",
          "snippet": "static void __cpu_map_ring_cleanup(struct ptr_ring *ring)\n{\n\t/* The tear-down procedure should have made sure that queue is\n\t * empty.  See __cpu_map_entry_replace() and work-queue\n\t * invoked cpu_map_kthread_stop(). Catch any broken behaviour\n\t * gracefully and warn once.\n\t */\n\tstruct xdp_frame *xdpf;\n\n\twhile ((xdpf = ptr_ring_consume(ring)))\n\t\tif (WARN_ON_ONCE(xdpf))\n\t\t\txdp_return_frame(xdpf);\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic void __cpu_map_ring_cleanup(struct ptr_ring *ring)\n{\n\t/* The tear-down procedure should have made sure that queue is\n\t * empty.  See __cpu_map_entry_replace() and work-queue\n\t * invoked cpu_map_kthread_stop(). Catch any broken behaviour\n\t * gracefully and warn once.\n\t */\n\tstruct xdp_frame *xdpf;\n\n\twhile ((xdpf = ptr_ring_consume(ring)))\n\t\tif (WARN_ON_ONCE(xdpf))\n\t\t\txdp_return_frame(xdpf);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_dec_and_test",
          "args": [
            "&rcpu->refcnt"
          ],
          "line": 227
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic void put_cpu_map_entry(struct bpf_cpu_map_entry *rcpu)\n{\n\tif (atomic_dec_and_test(&rcpu->refcnt)) {\n\t\t/* The queue should be empty at this point */\n\t\t__cpu_map_ring_cleanup(rcpu->queue);\n\t\tptr_ring_cleanup(rcpu->queue, NULL);\n\t\tkfree(rcpu->queue);\n\t\tkfree(rcpu);\n\t}\n}"
  },
  {
    "function_name": "__cpu_map_ring_cleanup",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
    "lines": "211-223",
    "snippet": "static void __cpu_map_ring_cleanup(struct ptr_ring *ring)\n{\n\t/* The tear-down procedure should have made sure that queue is\n\t * empty.  See __cpu_map_entry_replace() and work-queue\n\t * invoked cpu_map_kthread_stop(). Catch any broken behaviour\n\t * gracefully and warn once.\n\t */\n\tstruct xdp_frame *xdpf;\n\n\twhile ((xdpf = ptr_ring_consume(ring)))\n\t\tif (WARN_ON_ONCE(xdpf))\n\t\t\txdp_return_frame(xdpf);\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "xdp_return_frame",
          "args": [
            "xdpf"
          ],
          "line": 222
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "xdpf"
          ],
          "line": 221
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ptr_ring_consume",
          "args": [
            "ring"
          ],
          "line": 220
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic void __cpu_map_ring_cleanup(struct ptr_ring *ring)\n{\n\t/* The tear-down procedure should have made sure that queue is\n\t * empty.  See __cpu_map_entry_replace() and work-queue\n\t * invoked cpu_map_kthread_stop(). Catch any broken behaviour\n\t * gracefully and warn once.\n\t */\n\tstruct xdp_frame *xdpf;\n\n\twhile ((xdpf = ptr_ring_consume(ring)))\n\t\tif (WARN_ON_ONCE(xdpf))\n\t\t\txdp_return_frame(xdpf);\n}"
  },
  {
    "function_name": "cpu_map_build_skb",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
    "lines": "162-209",
    "snippet": "static struct sk_buff *cpu_map_build_skb(struct bpf_cpu_map_entry *rcpu,\n\t\t\t\t\t struct xdp_frame *xdpf)\n{\n\tunsigned int frame_size;\n\tvoid *pkt_data_start;\n\tstruct sk_buff *skb;\n\n\t/* build_skb need to place skb_shared_info after SKB end, and\n\t * also want to know the memory \"truesize\".  Thus, need to\n\t * know the memory frame size backing xdp_buff.\n\t *\n\t * XDP was designed to have PAGE_SIZE frames, but this\n\t * assumption is not longer true with ixgbe and i40e.  It\n\t * would be preferred to set frame_size to 2048 or 4096\n\t * depending on the driver.\n\t *   frame_size = 2048;\n\t *   frame_len  = frame_size - sizeof(*xdp_frame);\n\t *\n\t * Instead, with info avail, skb_shared_info in placed after\n\t * packet len.  This, unfortunately fakes the truesize.\n\t * Another disadvantage of this approach, the skb_shared_info\n\t * is not at a fixed memory location, with mixed length\n\t * packets, which is bad for cache-line hotness.\n\t */\n\tframe_size = SKB_DATA_ALIGN(xdpf->len) + xdpf->headroom +\n\t\tSKB_DATA_ALIGN(sizeof(struct skb_shared_info));\n\n\tpkt_data_start = xdpf->data - xdpf->headroom;\n\tskb = build_skb(pkt_data_start, frame_size);\n\tif (!skb)\n\t\treturn NULL;\n\n\tskb_reserve(skb, xdpf->headroom);\n\t__skb_put(skb, xdpf->len);\n\tif (xdpf->metasize)\n\t\tskb_metadata_set(skb, xdpf->metasize);\n\n\t/* Essential SKB info: protocol and skb->dev */\n\tskb->protocol = eth_type_trans(skb, xdpf->dev_rx);\n\n\t/* Optional SKB info, currently missing:\n\t * - HW checksum info\t\t(skb->ip_summed)\n\t * - HW RX hash\t\t\t(skb_set_hash)\n\t * - RX ring dev queue index\t(skb_record_rx_queue)\n\t */\n\n\treturn skb;\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "eth_type_trans",
          "args": [
            "skb",
            "xdpf->dev_rx"
          ],
          "line": 200
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "skb_metadata_set",
          "args": [
            "skb",
            "xdpf->metasize"
          ],
          "line": 197
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__skb_put",
          "args": [
            "skb",
            "xdpf->len"
          ],
          "line": 195
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "skb_reserve",
          "args": [
            "skb",
            "xdpf->headroom"
          ],
          "line": 194
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "build_skb",
          "args": [
            "pkt_data_start",
            "frame_size"
          ],
          "line": 190
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_map_build_skb",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
          "lines": "162-209",
          "snippet": "static struct sk_buff *cpu_map_build_skb(struct bpf_cpu_map_entry *rcpu,\n\t\t\t\t\t struct xdp_frame *xdpf)\n{\n\tunsigned int frame_size;\n\tvoid *pkt_data_start;\n\tstruct sk_buff *skb;\n\n\t/* build_skb need to place skb_shared_info after SKB end, and\n\t * also want to know the memory \"truesize\".  Thus, need to\n\t * know the memory frame size backing xdp_buff.\n\t *\n\t * XDP was designed to have PAGE_SIZE frames, but this\n\t * assumption is not longer true with ixgbe and i40e.  It\n\t * would be preferred to set frame_size to 2048 or 4096\n\t * depending on the driver.\n\t *   frame_size = 2048;\n\t *   frame_len  = frame_size - sizeof(*xdp_frame);\n\t *\n\t * Instead, with info avail, skb_shared_info in placed after\n\t * packet len.  This, unfortunately fakes the truesize.\n\t * Another disadvantage of this approach, the skb_shared_info\n\t * is not at a fixed memory location, with mixed length\n\t * packets, which is bad for cache-line hotness.\n\t */\n\tframe_size = SKB_DATA_ALIGN(xdpf->len) + xdpf->headroom +\n\t\tSKB_DATA_ALIGN(sizeof(struct skb_shared_info));\n\n\tpkt_data_start = xdpf->data - xdpf->headroom;\n\tskb = build_skb(pkt_data_start, frame_size);\n\tif (!skb)\n\t\treturn NULL;\n\n\tskb_reserve(skb, xdpf->headroom);\n\t__skb_put(skb, xdpf->len);\n\tif (xdpf->metasize)\n\t\tskb_metadata_set(skb, xdpf->metasize);\n\n\t/* Essential SKB info: protocol and skb->dev */\n\tskb->protocol = eth_type_trans(skb, xdpf->dev_rx);\n\n\t/* Optional SKB info, currently missing:\n\t * - HW checksum info\t\t(skb->ip_summed)\n\t * - HW RX hash\t\t\t(skb_set_hash)\n\t * - RX ring dev queue index\t(skb_record_rx_queue)\n\t */\n\n\treturn skb;\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "SKB_DATA_ALIGN",
          "args": [
            "sizeof(struct skb_shared_info)"
          ],
          "line": 187
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "SKB_DATA_ALIGN",
          "args": [
            "xdpf->len"
          ],
          "line": 186
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic struct sk_buff *cpu_map_build_skb(struct bpf_cpu_map_entry *rcpu,\n\t\t\t\t\t struct xdp_frame *xdpf)\n{\n\tunsigned int frame_size;\n\tvoid *pkt_data_start;\n\tstruct sk_buff *skb;\n\n\t/* build_skb need to place skb_shared_info after SKB end, and\n\t * also want to know the memory \"truesize\".  Thus, need to\n\t * know the memory frame size backing xdp_buff.\n\t *\n\t * XDP was designed to have PAGE_SIZE frames, but this\n\t * assumption is not longer true with ixgbe and i40e.  It\n\t * would be preferred to set frame_size to 2048 or 4096\n\t * depending on the driver.\n\t *   frame_size = 2048;\n\t *   frame_len  = frame_size - sizeof(*xdp_frame);\n\t *\n\t * Instead, with info avail, skb_shared_info in placed after\n\t * packet len.  This, unfortunately fakes the truesize.\n\t * Another disadvantage of this approach, the skb_shared_info\n\t * is not at a fixed memory location, with mixed length\n\t * packets, which is bad for cache-line hotness.\n\t */\n\tframe_size = SKB_DATA_ALIGN(xdpf->len) + xdpf->headroom +\n\t\tSKB_DATA_ALIGN(sizeof(struct skb_shared_info));\n\n\tpkt_data_start = xdpf->data - xdpf->headroom;\n\tskb = build_skb(pkt_data_start, frame_size);\n\tif (!skb)\n\t\treturn NULL;\n\n\tskb_reserve(skb, xdpf->headroom);\n\t__skb_put(skb, xdpf->len);\n\tif (xdpf->metasize)\n\t\tskb_metadata_set(skb, xdpf->metasize);\n\n\t/* Essential SKB info: protocol and skb->dev */\n\tskb->protocol = eth_type_trans(skb, xdpf->dev_rx);\n\n\t/* Optional SKB info, currently missing:\n\t * - HW checksum info\t\t(skb->ip_summed)\n\t * - HW RX hash\t\t\t(skb_set_hash)\n\t * - RX ring dev queue index\t(skb_record_rx_queue)\n\t */\n\n\treturn skb;\n}"
  },
  {
    "function_name": "cpu_map_kthread_stop",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
    "lines": "147-160",
    "snippet": "static void cpu_map_kthread_stop(struct work_struct *work)\n{\n\tstruct bpf_cpu_map_entry *rcpu;\n\n\trcpu = container_of(work, struct bpf_cpu_map_entry, kthread_stop_wq);\n\n\t/* Wait for flush in __cpu_map_entry_free(), via full RCU barrier,\n\t * as it waits until all in-flight call_rcu() callbacks complete.\n\t */\n\trcu_barrier();\n\n\t/* kthread_stop will wake_up_process and wait for it to complete */\n\tkthread_stop(rcpu->kthread);\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kthread_stop",
          "args": [
            "rcpu->kthread"
          ],
          "line": 159
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_map_kthread_stop",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
          "lines": "147-160",
          "snippet": "static void cpu_map_kthread_stop(struct work_struct *work)\n{\n\tstruct bpf_cpu_map_entry *rcpu;\n\n\trcpu = container_of(work, struct bpf_cpu_map_entry, kthread_stop_wq);\n\n\t/* Wait for flush in __cpu_map_entry_free(), via full RCU barrier,\n\t * as it waits until all in-flight call_rcu() callbacks complete.\n\t */\n\trcu_barrier();\n\n\t/* kthread_stop will wake_up_process and wait for it to complete */\n\tkthread_stop(rcpu->kthread);\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "rcu_barrier",
          "args": [],
          "line": 156
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_barrier_tasks",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/update.c",
          "lines": "620-624",
          "snippet": "void rcu_barrier_tasks(void)\n{\n\t/* There is only one callback queue, so this is easy.  ;-) */\n\tsynchronize_rcu_tasks();\n}",
          "includes": [
            "#include \"rcu.h\"",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu.h\"\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nvoid rcu_barrier_tasks(void)\n{\n\t/* There is only one callback queue, so this is easy.  ;-) */\n\tsynchronize_rcu_tasks();\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "work",
            "structbpf_cpu_map_entry",
            "kthread_stop_wq"
          ],
          "line": 151
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic void cpu_map_kthread_stop(struct work_struct *work)\n{\n\tstruct bpf_cpu_map_entry *rcpu;\n\n\trcpu = container_of(work, struct bpf_cpu_map_entry, kthread_stop_wq);\n\n\t/* Wait for flush in __cpu_map_entry_free(), via full RCU barrier,\n\t * as it waits until all in-flight call_rcu() callbacks complete.\n\t */\n\trcu_barrier();\n\n\t/* kthread_stop will wake_up_process and wait for it to complete */\n\tkthread_stop(rcpu->kthread);\n}"
  },
  {
    "function_name": "get_cpu_map_entry",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
    "lines": "141-144",
    "snippet": "static void get_cpu_map_entry(struct bpf_cpu_map_entry *rcpu)\n{\n\tatomic_inc(&rcpu->refcnt);\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_inc",
          "args": [
            "&rcpu->refcnt"
          ],
          "line": 143
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic void get_cpu_map_entry(struct bpf_cpu_map_entry *rcpu)\n{\n\tatomic_inc(&rcpu->refcnt);\n}"
  },
  {
    "function_name": "cpu_map_alloc",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
    "lines": "79-139",
    "snippet": "static struct bpf_map *cpu_map_alloc(union bpf_attr *attr)\n{\n\tstruct bpf_cpu_map *cmap;\n\tint err = -ENOMEM;\n\tu64 cost;\n\tint ret;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn ERR_PTR(-EPERM);\n\n\t/* check sanity of attributes */\n\tif (attr->max_entries == 0 || attr->key_size != 4 ||\n\t    attr->value_size != 4 || attr->map_flags & ~BPF_F_NUMA_NODE)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tcmap = kzalloc(sizeof(*cmap), GFP_USER);\n\tif (!cmap)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tbpf_map_init_from_attr(&cmap->map, attr);\n\n\t/* Pre-limit array size based on NR_CPUS, not final CPU check */\n\tif (cmap->map.max_entries > NR_CPUS) {\n\t\terr = -E2BIG;\n\t\tgoto free_cmap;\n\t}\n\n\t/* make sure page count doesn't overflow */\n\tcost = (u64) cmap->map.max_entries * sizeof(struct bpf_cpu_map_entry *);\n\tcost += cpu_map_bitmap_size(attr) * num_possible_cpus();\n\tif (cost >= U32_MAX - PAGE_SIZE)\n\t\tgoto free_cmap;\n\tcmap->map.pages = round_up(cost, PAGE_SIZE) >> PAGE_SHIFT;\n\n\t/* Notice returns -EPERM on if map size is larger than memlock limit */\n\tret = bpf_map_precharge_memlock(cmap->map.pages);\n\tif (ret) {\n\t\terr = ret;\n\t\tgoto free_cmap;\n\t}\n\n\t/* A per cpu bitfield with a bit per possible CPU in map  */\n\tcmap->flush_needed = __alloc_percpu(cpu_map_bitmap_size(attr),\n\t\t\t\t\t    __alignof__(unsigned long));\n\tif (!cmap->flush_needed)\n\t\tgoto free_cmap;\n\n\t/* Alloc array for possible remote \"destination\" CPUs */\n\tcmap->cpu_map = bpf_map_area_alloc(cmap->map.max_entries *\n\t\t\t\t\t   sizeof(struct bpf_cpu_map_entry *),\n\t\t\t\t\t   cmap->map.numa_node);\n\tif (!cmap->cpu_map)\n\t\tgoto free_percpu;\n\n\treturn &cmap->map;\nfree_percpu:\n\tfree_percpu(cmap->flush_needed);\nfree_cmap:\n\tkfree(cmap);\n\treturn ERR_PTR(err);\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "err"
          ],
          "line": 138
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "cmap"
          ],
          "line": 137
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/params.c",
          "lines": "73-86",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_percpu",
          "args": [
            "cmap->flush_needed"
          ],
          "line": 135
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_array_free_percpu",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/arraymap.c",
          "lines": "27-35",
          "snippet": "static void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include <uapi/linux/btf.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/filter.h>",
            "#include <linux/mm.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include <uapi/linux/btf.h>\n#include <linux/perf_event.h>\n#include <linux/filter.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_area_alloc",
          "args": [
            "cmap->map.max_entries *\n\t\t\t\t\t   sizeof(struct bpf_cpu_map_entry *)",
            "cmap->map.numa_node"
          ],
          "line": 127
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_area_alloc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/syscall.c",
          "lines": "137-154",
          "snippet": "void *bpf_map_area_alloc(size_t size, int numa_node)\n{\n\t/* We definitely need __GFP_NORETRY, so OOM killer doesn't\n\t * trigger under memory pressure as we really just want to\n\t * fail instead.\n\t */\n\tconst gfp_t flags = __GFP_NOWARN | __GFP_NORETRY | __GFP_ZERO;\n\tvoid *area;\n\n\tif (size <= (PAGE_SIZE << PAGE_ALLOC_COSTLY_ORDER)) {\n\t\tarea = kmalloc_node(size, GFP_USER | flags, numa_node);\n\t\tif (area != NULL)\n\t\t\treturn area;\n\t}\n\n\treturn __vmalloc_node_flags_caller(size, numa_node, GFP_KERNEL | flags,\n\t\t\t\t\t   __builtin_return_address(0));\n}",
          "includes": [
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/version.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/version.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf.h>\n\nvoid *bpf_map_area_alloc(size_t size, int numa_node)\n{\n\t/* We definitely need __GFP_NORETRY, so OOM killer doesn't\n\t * trigger under memory pressure as we really just want to\n\t * fail instead.\n\t */\n\tconst gfp_t flags = __GFP_NOWARN | __GFP_NORETRY | __GFP_ZERO;\n\tvoid *area;\n\n\tif (size <= (PAGE_SIZE << PAGE_ALLOC_COSTLY_ORDER)) {\n\t\tarea = kmalloc_node(size, GFP_USER | flags, numa_node);\n\t\tif (area != NULL)\n\t\t\treturn area;\n\t}\n\n\treturn __vmalloc_node_flags_caller(size, numa_node, GFP_KERNEL | flags,\n\t\t\t\t\t   __builtin_return_address(0));\n}"
        }
      },
      {
        "call_info": {
          "callee": "__alloc_percpu",
          "args": [
            "cpu_map_bitmap_size(attr)",
            "__alignof__(unsigned long)"
          ],
          "line": 121
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_map_bitmap_size",
          "args": [
            "attr"
          ],
          "line": 121
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_map_bitmap_size",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
          "lines": "74-77",
          "snippet": "static u64 cpu_map_bitmap_size(const union bpf_attr *attr)\n{\n\treturn BITS_TO_LONGS(attr->max_entries) * sizeof(unsigned long);\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic u64 cpu_map_bitmap_size(const union bpf_attr *attr)\n{\n\treturn BITS_TO_LONGS(attr->max_entries) * sizeof(unsigned long);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_precharge_memlock",
          "args": [
            "cmap->map.pages"
          ],
          "line": 114
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_precharge_memlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/syscall.c",
          "lines": "171-182",
          "snippet": "int bpf_map_precharge_memlock(u32 pages)\n{\n\tstruct user_struct *user = get_current_user();\n\tunsigned long memlock_limit, cur;\n\n\tmemlock_limit = rlimit(RLIMIT_MEMLOCK) >> PAGE_SHIFT;\n\tcur = atomic_long_read(&user->locked_vm);\n\tfree_uid(user);\n\tif (cur + pages > memlock_limit)\n\t\treturn -EPERM;\n\treturn 0;\n}",
          "includes": [
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/version.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/version.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf.h>\n\nint bpf_map_precharge_memlock(u32 pages)\n{\n\tstruct user_struct *user = get_current_user();\n\tunsigned long memlock_limit, cur;\n\n\tmemlock_limit = rlimit(RLIMIT_MEMLOCK) >> PAGE_SHIFT;\n\tcur = atomic_long_read(&user->locked_vm);\n\tfree_uid(user);\n\tif (cur + pages > memlock_limit)\n\t\treturn -EPERM;\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "cost",
            "PAGE_SIZE"
          ],
          "line": 111
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "num_possible_cpus",
          "args": [],
          "line": 108
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_map_init_from_attr",
          "args": [
            "&cmap->map",
            "attr"
          ],
          "line": 98
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_init_from_attr",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/syscall.c",
          "lines": "161-169",
          "snippet": "void bpf_map_init_from_attr(struct bpf_map *map, union bpf_attr *attr)\n{\n\tmap->map_type = attr->map_type;\n\tmap->key_size = attr->key_size;\n\tmap->value_size = attr->value_size;\n\tmap->max_entries = attr->max_entries;\n\tmap->map_flags = attr->map_flags;\n\tmap->numa_node = bpf_map_attr_numa_node(attr);\n}",
          "includes": [
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/version.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/version.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf.h>\n\nvoid bpf_map_init_from_attr(struct bpf_map *map, union bpf_attr *attr)\n{\n\tmap->map_type = attr->map_type;\n\tmap->key_size = attr->key_size;\n\tmap->value_size = attr->value_size;\n\tmap->max_entries = attr->max_entries;\n\tmap->map_flags = attr->map_flags;\n\tmap->numa_node = bpf_map_attr_numa_node(attr);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-ENOMEM"
          ],
          "line": 96
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kzalloc",
          "args": [
            "sizeof(*cmap)",
            "GFP_USER"
          ],
          "line": 94
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-EINVAL"
          ],
          "line": 92
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-EPERM"
          ],
          "line": 87
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "capable",
          "args": [
            "CAP_SYS_ADMIN"
          ],
          "line": 86
        },
        "resolved": true,
        "details": {
          "function_name": "capable",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/capability.c",
          "lines": "429-432",
          "snippet": "bool capable(int cap)\n{\n\treturn ns_capable(&init_user_ns, cap);\n}",
          "includes": [
            "#include <linux/uaccess.h>",
            "#include <linux/user_namespace.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/security.h>",
            "#include <linux/export.h>",
            "#include <linux/mm.h>",
            "#include <linux/capability.h>",
            "#include <linux/audit.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/uaccess.h>\n#include <linux/user_namespace.h>\n#include <linux/pid_namespace.h>\n#include <linux/syscalls.h>\n#include <linux/security.h>\n#include <linux/export.h>\n#include <linux/mm.h>\n#include <linux/capability.h>\n#include <linux/audit.h>\n\nbool capable(int cap)\n{\n\treturn ns_capable(&init_user_ns, cap);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic struct bpf_map *cpu_map_alloc(union bpf_attr *attr)\n{\n\tstruct bpf_cpu_map *cmap;\n\tint err = -ENOMEM;\n\tu64 cost;\n\tint ret;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn ERR_PTR(-EPERM);\n\n\t/* check sanity of attributes */\n\tif (attr->max_entries == 0 || attr->key_size != 4 ||\n\t    attr->value_size != 4 || attr->map_flags & ~BPF_F_NUMA_NODE)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tcmap = kzalloc(sizeof(*cmap), GFP_USER);\n\tif (!cmap)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tbpf_map_init_from_attr(&cmap->map, attr);\n\n\t/* Pre-limit array size based on NR_CPUS, not final CPU check */\n\tif (cmap->map.max_entries > NR_CPUS) {\n\t\terr = -E2BIG;\n\t\tgoto free_cmap;\n\t}\n\n\t/* make sure page count doesn't overflow */\n\tcost = (u64) cmap->map.max_entries * sizeof(struct bpf_cpu_map_entry *);\n\tcost += cpu_map_bitmap_size(attr) * num_possible_cpus();\n\tif (cost >= U32_MAX - PAGE_SIZE)\n\t\tgoto free_cmap;\n\tcmap->map.pages = round_up(cost, PAGE_SIZE) >> PAGE_SHIFT;\n\n\t/* Notice returns -EPERM on if map size is larger than memlock limit */\n\tret = bpf_map_precharge_memlock(cmap->map.pages);\n\tif (ret) {\n\t\terr = ret;\n\t\tgoto free_cmap;\n\t}\n\n\t/* A per cpu bitfield with a bit per possible CPU in map  */\n\tcmap->flush_needed = __alloc_percpu(cpu_map_bitmap_size(attr),\n\t\t\t\t\t    __alignof__(unsigned long));\n\tif (!cmap->flush_needed)\n\t\tgoto free_cmap;\n\n\t/* Alloc array for possible remote \"destination\" CPUs */\n\tcmap->cpu_map = bpf_map_area_alloc(cmap->map.max_entries *\n\t\t\t\t\t   sizeof(struct bpf_cpu_map_entry *),\n\t\t\t\t\t   cmap->map.numa_node);\n\tif (!cmap->cpu_map)\n\t\tgoto free_percpu;\n\n\treturn &cmap->map;\nfree_percpu:\n\tfree_percpu(cmap->flush_needed);\nfree_cmap:\n\tkfree(cmap);\n\treturn ERR_PTR(err);\n}"
  },
  {
    "function_name": "cpu_map_bitmap_size",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/cpumap.c",
    "lines": "74-77",
    "snippet": "static u64 cpu_map_bitmap_size(const union bpf_attr *attr)\n{\n\treturn BITS_TO_LONGS(attr->max_entries) * sizeof(unsigned long);\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_core */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "BITS_TO_LONGS",
          "args": [
            "attr->max_entries"
          ],
          "line": 76
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_core */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n\nstatic u64 cpu_map_bitmap_size(const union bpf_attr *attr)\n{\n\treturn BITS_TO_LONGS(attr->max_entries) * sizeof(unsigned long);\n}"
  }
]