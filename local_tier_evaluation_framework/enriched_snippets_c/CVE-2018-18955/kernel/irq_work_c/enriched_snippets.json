[
  {
    "function_name": "irq_work_sync",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq_work.c",
    "lines": "188-194",
    "snippet": "void irq_work_sync(struct irq_work *work)\n{\n\tlockdep_assert_irqs_enabled();\n\n\twhile (work->flags & IRQ_WORK_BUSY)\n\t\tcpu_relax();\n}",
    "includes": [
      "#include <asm/processor.h>",
      "#include <linux/smp.h>",
      "#include <linux/notifier.h>",
      "#include <linux/cpu.h>",
      "#include <linux/tick.h>",
      "#include <linux/sched.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/hardirq.h>",
      "#include <linux/percpu.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/export.h>",
      "#include <linux/kernel.h>",
      "#include <linux/bug.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpu_relax",
          "args": [],
          "line": 193
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lockdep_assert_irqs_enabled",
          "args": [],
          "line": 190
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/processor.h>\n#include <linux/smp.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/tick.h>\n#include <linux/sched.h>\n#include <linux/irqflags.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/irq_work.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bug.h>\n\nvoid irq_work_sync(struct irq_work *work)\n{\n\tlockdep_assert_irqs_enabled();\n\n\twhile (work->flags & IRQ_WORK_BUSY)\n\t\tcpu_relax();\n}"
  },
  {
    "function_name": "irq_work_tick",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq_work.c",
    "lines": "175-182",
    "snippet": "void irq_work_tick(void)\n{\n\tstruct llist_head *raised = this_cpu_ptr(&raised_list);\n\n\tif (!llist_empty(raised) && !arch_irq_work_has_interrupt())\n\t\tirq_work_run_list(raised);\n\tirq_work_run_list(this_cpu_ptr(&lazy_list));\n}",
    "includes": [
      "#include <asm/processor.h>",
      "#include <linux/smp.h>",
      "#include <linux/notifier.h>",
      "#include <linux/cpu.h>",
      "#include <linux/tick.h>",
      "#include <linux/sched.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/hardirq.h>",
      "#include <linux/percpu.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/export.h>",
      "#include <linux/kernel.h>",
      "#include <linux/bug.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct llist_head, raised_list);",
      "static DEFINE_PER_CPU(struct llist_head, lazy_list);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "irq_work_run_list",
          "args": [
            "this_cpu_ptr(&lazy_list)"
          ],
          "line": 181
        },
        "resolved": true,
        "details": {
          "function_name": "irq_work_run_list",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq_work.c",
          "lines": "132-162",
          "snippet": "static void irq_work_run_list(struct llist_head *list)\n{\n\tstruct irq_work *work, *tmp;\n\tstruct llist_node *llnode;\n\tunsigned long flags;\n\n\tBUG_ON(!irqs_disabled());\n\n\tif (llist_empty(list))\n\t\treturn;\n\n\tllnode = llist_del_all(list);\n\tllist_for_each_entry_safe(work, tmp, llnode, llnode) {\n\t\t/*\n\t\t * Clear the PENDING bit, after this point the @work\n\t\t * can be re-used.\n\t\t * Make it immediately visible so that other CPUs trying\n\t\t * to claim that work don't rely on us to handle their data\n\t\t * while we are in the middle of the func.\n\t\t */\n\t\tflags = work->flags & ~IRQ_WORK_PENDING;\n\t\txchg(&work->flags, flags);\n\n\t\twork->func(work);\n\t\t/*\n\t\t * Clear the BUSY bit and return to the free state if\n\t\t * no-one else claimed it meanwhile.\n\t\t */\n\t\t(void)cmpxchg(&work->flags, flags, flags & ~IRQ_WORK_BUSY);\n\t}\n}",
          "includes": [
            "#include <asm/processor.h>",
            "#include <linux/smp.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/tick.h>",
            "#include <linux/sched.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/bug.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/processor.h>\n#include <linux/smp.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/tick.h>\n#include <linux/sched.h>\n#include <linux/irqflags.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/irq_work.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bug.h>\n\nstatic void irq_work_run_list(struct llist_head *list)\n{\n\tstruct irq_work *work, *tmp;\n\tstruct llist_node *llnode;\n\tunsigned long flags;\n\n\tBUG_ON(!irqs_disabled());\n\n\tif (llist_empty(list))\n\t\treturn;\n\n\tllnode = llist_del_all(list);\n\tllist_for_each_entry_safe(work, tmp, llnode, llnode) {\n\t\t/*\n\t\t * Clear the PENDING bit, after this point the @work\n\t\t * can be re-used.\n\t\t * Make it immediately visible so that other CPUs trying\n\t\t * to claim that work don't rely on us to handle their data\n\t\t * while we are in the middle of the func.\n\t\t */\n\t\tflags = work->flags & ~IRQ_WORK_PENDING;\n\t\txchg(&work->flags, flags);\n\n\t\twork->func(work);\n\t\t/*\n\t\t * Clear the BUSY bit and return to the free state if\n\t\t * no-one else claimed it meanwhile.\n\t\t */\n\t\t(void)cmpxchg(&work->flags, flags, flags & ~IRQ_WORK_BUSY);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "&lazy_list"
          ],
          "line": 181
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "arch_irq_work_has_interrupt",
          "args": [],
          "line": 179
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "llist_empty",
          "args": [
            "raised"
          ],
          "line": 179
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "&raised_list"
          ],
          "line": 177
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/processor.h>\n#include <linux/smp.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/tick.h>\n#include <linux/sched.h>\n#include <linux/irqflags.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/irq_work.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bug.h>\n\nstatic DEFINE_PER_CPU(struct llist_head, raised_list);\nstatic DEFINE_PER_CPU(struct llist_head, lazy_list);\n\nvoid irq_work_tick(void)\n{\n\tstruct llist_head *raised = this_cpu_ptr(&raised_list);\n\n\tif (!llist_empty(raised) && !arch_irq_work_has_interrupt())\n\t\tirq_work_run_list(raised);\n\tirq_work_run_list(this_cpu_ptr(&lazy_list));\n}"
  },
  {
    "function_name": "irq_work_run",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq_work.c",
    "lines": "168-172",
    "snippet": "void irq_work_run(void)\n{\n\tirq_work_run_list(this_cpu_ptr(&raised_list));\n\tirq_work_run_list(this_cpu_ptr(&lazy_list));\n}",
    "includes": [
      "#include <asm/processor.h>",
      "#include <linux/smp.h>",
      "#include <linux/notifier.h>",
      "#include <linux/cpu.h>",
      "#include <linux/tick.h>",
      "#include <linux/sched.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/hardirq.h>",
      "#include <linux/percpu.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/export.h>",
      "#include <linux/kernel.h>",
      "#include <linux/bug.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct llist_head, raised_list);",
      "static DEFINE_PER_CPU(struct llist_head, lazy_list);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "irq_work_run_list",
          "args": [
            "this_cpu_ptr(&lazy_list)"
          ],
          "line": 171
        },
        "resolved": true,
        "details": {
          "function_name": "irq_work_run_list",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq_work.c",
          "lines": "132-162",
          "snippet": "static void irq_work_run_list(struct llist_head *list)\n{\n\tstruct irq_work *work, *tmp;\n\tstruct llist_node *llnode;\n\tunsigned long flags;\n\n\tBUG_ON(!irqs_disabled());\n\n\tif (llist_empty(list))\n\t\treturn;\n\n\tllnode = llist_del_all(list);\n\tllist_for_each_entry_safe(work, tmp, llnode, llnode) {\n\t\t/*\n\t\t * Clear the PENDING bit, after this point the @work\n\t\t * can be re-used.\n\t\t * Make it immediately visible so that other CPUs trying\n\t\t * to claim that work don't rely on us to handle their data\n\t\t * while we are in the middle of the func.\n\t\t */\n\t\tflags = work->flags & ~IRQ_WORK_PENDING;\n\t\txchg(&work->flags, flags);\n\n\t\twork->func(work);\n\t\t/*\n\t\t * Clear the BUSY bit and return to the free state if\n\t\t * no-one else claimed it meanwhile.\n\t\t */\n\t\t(void)cmpxchg(&work->flags, flags, flags & ~IRQ_WORK_BUSY);\n\t}\n}",
          "includes": [
            "#include <asm/processor.h>",
            "#include <linux/smp.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/tick.h>",
            "#include <linux/sched.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/bug.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/processor.h>\n#include <linux/smp.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/tick.h>\n#include <linux/sched.h>\n#include <linux/irqflags.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/irq_work.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bug.h>\n\nstatic void irq_work_run_list(struct llist_head *list)\n{\n\tstruct irq_work *work, *tmp;\n\tstruct llist_node *llnode;\n\tunsigned long flags;\n\n\tBUG_ON(!irqs_disabled());\n\n\tif (llist_empty(list))\n\t\treturn;\n\n\tllnode = llist_del_all(list);\n\tllist_for_each_entry_safe(work, tmp, llnode, llnode) {\n\t\t/*\n\t\t * Clear the PENDING bit, after this point the @work\n\t\t * can be re-used.\n\t\t * Make it immediately visible so that other CPUs trying\n\t\t * to claim that work don't rely on us to handle their data\n\t\t * while we are in the middle of the func.\n\t\t */\n\t\tflags = work->flags & ~IRQ_WORK_PENDING;\n\t\txchg(&work->flags, flags);\n\n\t\twork->func(work);\n\t\t/*\n\t\t * Clear the BUSY bit and return to the free state if\n\t\t * no-one else claimed it meanwhile.\n\t\t */\n\t\t(void)cmpxchg(&work->flags, flags, flags & ~IRQ_WORK_BUSY);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "&lazy_list"
          ],
          "line": 171
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "&raised_list"
          ],
          "line": 170
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/processor.h>\n#include <linux/smp.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/tick.h>\n#include <linux/sched.h>\n#include <linux/irqflags.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/irq_work.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bug.h>\n\nstatic DEFINE_PER_CPU(struct llist_head, raised_list);\nstatic DEFINE_PER_CPU(struct llist_head, lazy_list);\n\nvoid irq_work_run(void)\n{\n\tirq_work_run_list(this_cpu_ptr(&raised_list));\n\tirq_work_run_list(this_cpu_ptr(&lazy_list));\n}"
  },
  {
    "function_name": "irq_work_run_list",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq_work.c",
    "lines": "132-162",
    "snippet": "static void irq_work_run_list(struct llist_head *list)\n{\n\tstruct irq_work *work, *tmp;\n\tstruct llist_node *llnode;\n\tunsigned long flags;\n\n\tBUG_ON(!irqs_disabled());\n\n\tif (llist_empty(list))\n\t\treturn;\n\n\tllnode = llist_del_all(list);\n\tllist_for_each_entry_safe(work, tmp, llnode, llnode) {\n\t\t/*\n\t\t * Clear the PENDING bit, after this point the @work\n\t\t * can be re-used.\n\t\t * Make it immediately visible so that other CPUs trying\n\t\t * to claim that work don't rely on us to handle their data\n\t\t * while we are in the middle of the func.\n\t\t */\n\t\tflags = work->flags & ~IRQ_WORK_PENDING;\n\t\txchg(&work->flags, flags);\n\n\t\twork->func(work);\n\t\t/*\n\t\t * Clear the BUSY bit and return to the free state if\n\t\t * no-one else claimed it meanwhile.\n\t\t */\n\t\t(void)cmpxchg(&work->flags, flags, flags & ~IRQ_WORK_BUSY);\n\t}\n}",
    "includes": [
      "#include <asm/processor.h>",
      "#include <linux/smp.h>",
      "#include <linux/notifier.h>",
      "#include <linux/cpu.h>",
      "#include <linux/tick.h>",
      "#include <linux/sched.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/hardirq.h>",
      "#include <linux/percpu.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/export.h>",
      "#include <linux/kernel.h>",
      "#include <linux/bug.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "cmpxchg",
          "args": [
            "&work->flags",
            "flags",
            "flags & ~IRQ_WORK_BUSY"
          ],
          "line": 160
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "work->func",
          "args": [
            "work"
          ],
          "line": 155
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "xchg",
          "args": [
            "&work->flags",
            "flags"
          ],
          "line": 153
        },
        "resolved": true,
        "details": {
          "function_name": "xchg_tail",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/qspinlock.c",
          "lines": "231-249",
          "snippet": "static __always_inline u32 xchg_tail(struct qspinlock *lock, u32 tail)\n{\n\tu32 old, new, val = atomic_read(&lock->val);\n\n\tfor (;;) {\n\t\tnew = (val & _Q_LOCKED_PENDING_MASK) | tail;\n\t\t/*\n\t\t * We can use relaxed semantics since the caller ensures that\n\t\t * the MCS node is properly initialized before updating the\n\t\t * tail.\n\t\t */\n\t\told = atomic_cmpxchg_relaxed(&lock->val, val, new);\n\t\tif (old == val)\n\t\t\tbreak;\n\n\t\tval = old;\n\t}\n\treturn old;\n}",
          "includes": [
            "#include \"qspinlock.c\"",
            "#include \"qspinlock_paravirt.h\"",
            "#include \"mcs_spinlock.h\"",
            "#include \"qspinlock_stat.h\"",
            "#include <asm/qspinlock.h>",
            "#include <asm/byteorder.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/mutex.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/cpumask.h>",
            "#include <linux/bug.h>",
            "#include <linux/smp.h>"
          ],
          "macros_used": [
            "#define _Q_LOCKED_PENDING_MASK (_Q_LOCKED_MASK | _Q_PENDING_MASK)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"qspinlock.c\"\n#include \"qspinlock_paravirt.h\"\n#include \"mcs_spinlock.h\"\n#include \"qspinlock_stat.h\"\n#include <asm/qspinlock.h>\n#include <asm/byteorder.h>\n#include <linux/prefetch.h>\n#include <linux/mutex.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/cpumask.h>\n#include <linux/bug.h>\n#include <linux/smp.h>\n\n#define _Q_LOCKED_PENDING_MASK (_Q_LOCKED_MASK | _Q_PENDING_MASK)\n\nstatic __always_inline u32 xchg_tail(struct qspinlock *lock, u32 tail)\n{\n\tu32 old, new, val = atomic_read(&lock->val);\n\n\tfor (;;) {\n\t\tnew = (val & _Q_LOCKED_PENDING_MASK) | tail;\n\t\t/*\n\t\t * We can use relaxed semantics since the caller ensures that\n\t\t * the MCS node is properly initialized before updating the\n\t\t * tail.\n\t\t */\n\t\told = atomic_cmpxchg_relaxed(&lock->val, val, new);\n\t\tif (old == val)\n\t\t\tbreak;\n\n\t\tval = old;\n\t}\n\treturn old;\n}"
        }
      },
      {
        "call_info": {
          "callee": "llist_for_each_entry_safe",
          "args": [
            "work",
            "tmp",
            "llnode",
            "llnode"
          ],
          "line": 144
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "llist_del_all",
          "args": [
            "list"
          ],
          "line": 143
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "llist_empty",
          "args": [
            "list"
          ],
          "line": 140
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "!irqs_disabled()"
          ],
          "line": 138
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "irqs_disabled",
          "args": [],
          "line": 138
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/processor.h>\n#include <linux/smp.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/tick.h>\n#include <linux/sched.h>\n#include <linux/irqflags.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/irq_work.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bug.h>\n\nstatic void irq_work_run_list(struct llist_head *list)\n{\n\tstruct irq_work *work, *tmp;\n\tstruct llist_node *llnode;\n\tunsigned long flags;\n\n\tBUG_ON(!irqs_disabled());\n\n\tif (llist_empty(list))\n\t\treturn;\n\n\tllnode = llist_del_all(list);\n\tllist_for_each_entry_safe(work, tmp, llnode, llnode) {\n\t\t/*\n\t\t * Clear the PENDING bit, after this point the @work\n\t\t * can be re-used.\n\t\t * Make it immediately visible so that other CPUs trying\n\t\t * to claim that work don't rely on us to handle their data\n\t\t * while we are in the middle of the func.\n\t\t */\n\t\tflags = work->flags & ~IRQ_WORK_PENDING;\n\t\txchg(&work->flags, flags);\n\n\t\twork->func(work);\n\t\t/*\n\t\t * Clear the BUSY bit and return to the free state if\n\t\t * no-one else claimed it meanwhile.\n\t\t */\n\t\t(void)cmpxchg(&work->flags, flags, flags & ~IRQ_WORK_BUSY);\n\t}\n}"
  },
  {
    "function_name": "irq_work_needs_cpu",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq_work.c",
    "lines": "115-130",
    "snippet": "bool irq_work_needs_cpu(void)\n{\n\tstruct llist_head *raised, *lazy;\n\n\traised = this_cpu_ptr(&raised_list);\n\tlazy = this_cpu_ptr(&lazy_list);\n\n\tif (llist_empty(raised) || arch_irq_work_has_interrupt())\n\t\tif (llist_empty(lazy))\n\t\t\treturn false;\n\n\t/* All work should have been flushed before going offline */\n\tWARN_ON_ONCE(cpu_is_offline(smp_processor_id()));\n\n\treturn true;\n}",
    "includes": [
      "#include <asm/processor.h>",
      "#include <linux/smp.h>",
      "#include <linux/notifier.h>",
      "#include <linux/cpu.h>",
      "#include <linux/tick.h>",
      "#include <linux/sched.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/hardirq.h>",
      "#include <linux/percpu.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/export.h>",
      "#include <linux/kernel.h>",
      "#include <linux/bug.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct llist_head, raised_list);",
      "static DEFINE_PER_CPU(struct llist_head, lazy_list);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "cpu_is_offline(smp_processor_id())"
          ],
          "line": 127
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_is_offline",
          "args": [
            "smp_processor_id()"
          ],
          "line": 127
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_processor_id",
          "args": [],
          "line": 127
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "llist_empty",
          "args": [
            "lazy"
          ],
          "line": 123
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "arch_irq_work_has_interrupt",
          "args": [],
          "line": 122
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "llist_empty",
          "args": [
            "raised"
          ],
          "line": 122
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "&lazy_list"
          ],
          "line": 120
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "&raised_list"
          ],
          "line": 119
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/processor.h>\n#include <linux/smp.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/tick.h>\n#include <linux/sched.h>\n#include <linux/irqflags.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/irq_work.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bug.h>\n\nstatic DEFINE_PER_CPU(struct llist_head, raised_list);\nstatic DEFINE_PER_CPU(struct llist_head, lazy_list);\n\nbool irq_work_needs_cpu(void)\n{\n\tstruct llist_head *raised, *lazy;\n\n\traised = this_cpu_ptr(&raised_list);\n\tlazy = this_cpu_ptr(&lazy_list);\n\n\tif (llist_empty(raised) || arch_irq_work_has_interrupt())\n\t\tif (llist_empty(lazy))\n\t\t\treturn false;\n\n\t/* All work should have been flushed before going offline */\n\tWARN_ON_ONCE(cpu_is_offline(smp_processor_id()));\n\n\treturn true;\n}"
  },
  {
    "function_name": "irq_work_queue",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq_work.c",
    "lines": "90-112",
    "snippet": "bool irq_work_queue(struct irq_work *work)\n{\n\t/* Only queue if not already pending */\n\tif (!irq_work_claim(work))\n\t\treturn false;\n\n\t/* Queue the entry and raise the IPI if needed. */\n\tpreempt_disable();\n\n\t/* If the work is \"lazy\", handle it from next tick if any */\n\tif (work->flags & IRQ_WORK_LAZY) {\n\t\tif (llist_add(&work->llnode, this_cpu_ptr(&lazy_list)) &&\n\t\t    tick_nohz_tick_stopped())\n\t\t\tarch_irq_work_raise();\n\t} else {\n\t\tif (llist_add(&work->llnode, this_cpu_ptr(&raised_list)))\n\t\t\tarch_irq_work_raise();\n\t}\n\n\tpreempt_enable();\n\n\treturn true;\n}",
    "includes": [
      "#include <asm/processor.h>",
      "#include <linux/smp.h>",
      "#include <linux/notifier.h>",
      "#include <linux/cpu.h>",
      "#include <linux/tick.h>",
      "#include <linux/sched.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/hardirq.h>",
      "#include <linux/percpu.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/export.h>",
      "#include <linux/kernel.h>",
      "#include <linux/bug.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct llist_head, raised_list);",
      "static DEFINE_PER_CPU(struct llist_head, lazy_list);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "preempt_enable",
          "args": [],
          "line": 109
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "arch_irq_work_raise",
          "args": [],
          "line": 106
        },
        "resolved": true,
        "details": {
          "function_name": "arch_irq_work_raise",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq_work.c",
          "lines": "52-57",
          "snippet": "void __weak arch_irq_work_raise(void)\n{\n\t/*\n\t * Lame architectures will get the timer tick callback\n\t */\n}",
          "includes": [
            "#include <asm/processor.h>",
            "#include <linux/smp.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/tick.h>",
            "#include <linux/sched.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/bug.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/processor.h>\n#include <linux/smp.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/tick.h>\n#include <linux/sched.h>\n#include <linux/irqflags.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/irq_work.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bug.h>\n\nvoid __weak arch_irq_work_raise(void)\n{\n\t/*\n\t * Lame architectures will get the timer tick callback\n\t */\n}"
        }
      },
      {
        "call_info": {
          "callee": "llist_add",
          "args": [
            "&work->llnode",
            "this_cpu_ptr(&raised_list)"
          ],
          "line": 105
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "&raised_list"
          ],
          "line": 105
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "tick_nohz_tick_stopped",
          "args": [],
          "line": 102
        },
        "resolved": true,
        "details": {
          "function_name": "tick_nohz_tick_stopped",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/time/tick-sched.c",
          "lines": "468-473",
          "snippet": "bool tick_nohz_tick_stopped(void)\n{\n\tstruct tick_sched *ts = this_cpu_ptr(&tick_cpu_sched);\n\n\treturn ts->tick_stopped;\n}",
          "includes": [
            "#include <trace/events/timer.h>",
            "#include \"tick-internal.h\"",
            "#include <asm/irq_regs.h>",
            "#include <linux/mm.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/module.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/profile.h>",
            "#include <linux/nmi.h>",
            "#include <linux/percpu.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/hrtimer.h>",
            "#include <linux/err.h>",
            "#include <linux/cpu.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(struct tick_sched, tick_cpu_sched);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/timer.h>\n#include \"tick-internal.h\"\n#include <asm/irq_regs.h>\n#include <linux/mm.h>\n#include <linux/context_tracking.h>\n#include <linux/posix-timers.h>\n#include <linux/irq_work.h>\n#include <linux/module.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/profile.h>\n#include <linux/nmi.h>\n#include <linux/percpu.h>\n#include <linux/kernel_stat.h>\n#include <linux/interrupt.h>\n#include <linux/hrtimer.h>\n#include <linux/err.h>\n#include <linux/cpu.h>\n\nstatic DEFINE_PER_CPU(struct tick_sched, tick_cpu_sched);\n\nbool tick_nohz_tick_stopped(void)\n{\n\tstruct tick_sched *ts = this_cpu_ptr(&tick_cpu_sched);\n\n\treturn ts->tick_stopped;\n}"
        }
      },
      {
        "call_info": {
          "callee": "llist_add",
          "args": [
            "&work->llnode",
            "this_cpu_ptr(&lazy_list)"
          ],
          "line": 101
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "&lazy_list"
          ],
          "line": 101
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "preempt_disable",
          "args": [],
          "line": 97
        },
        "resolved": true,
        "details": {
          "function_name": "schedule_preempt_disabled",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/core.c",
          "lines": "3571-3576",
          "snippet": "void __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}",
          "includes": [
            "#include \"features.h\"",
            "#include <trace/events/sched.h>",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/kcov.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include <trace/events/sched.h>\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/kcov.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n\nstatic void __sched;\nstatic void __sched;\n\nvoid __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "irq_work_claim",
          "args": [
            "work"
          ],
          "line": 93
        },
        "resolved": true,
        "details": {
          "function_name": "irq_work_claim",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq_work.c",
          "lines": "29-50",
          "snippet": "static bool irq_work_claim(struct irq_work *work)\n{\n\tunsigned long flags, oflags, nflags;\n\n\t/*\n\t * Start with our best wish as a premise but only trust any\n\t * flag value after cmpxchg() result.\n\t */\n\tflags = work->flags & ~IRQ_WORK_PENDING;\n\tfor (;;) {\n\t\tnflags = flags | IRQ_WORK_CLAIMED;\n\t\toflags = cmpxchg(&work->flags, flags, nflags);\n\t\tif (oflags == flags)\n\t\t\tbreak;\n\t\tif (oflags & IRQ_WORK_PENDING)\n\t\t\treturn false;\n\t\tflags = oflags;\n\t\tcpu_relax();\n\t}\n\n\treturn true;\n}",
          "includes": [
            "#include <asm/processor.h>",
            "#include <linux/smp.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/tick.h>",
            "#include <linux/sched.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/bug.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/processor.h>\n#include <linux/smp.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/tick.h>\n#include <linux/sched.h>\n#include <linux/irqflags.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/irq_work.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bug.h>\n\nstatic bool irq_work_claim(struct irq_work *work)\n{\n\tunsigned long flags, oflags, nflags;\n\n\t/*\n\t * Start with our best wish as a premise but only trust any\n\t * flag value after cmpxchg() result.\n\t */\n\tflags = work->flags & ~IRQ_WORK_PENDING;\n\tfor (;;) {\n\t\tnflags = flags | IRQ_WORK_CLAIMED;\n\t\toflags = cmpxchg(&work->flags, flags, nflags);\n\t\tif (oflags == flags)\n\t\t\tbreak;\n\t\tif (oflags & IRQ_WORK_PENDING)\n\t\t\treturn false;\n\t\tflags = oflags;\n\t\tcpu_relax();\n\t}\n\n\treturn true;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/processor.h>\n#include <linux/smp.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/tick.h>\n#include <linux/sched.h>\n#include <linux/irqflags.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/irq_work.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bug.h>\n\nstatic DEFINE_PER_CPU(struct llist_head, raised_list);\nstatic DEFINE_PER_CPU(struct llist_head, lazy_list);\n\nbool irq_work_queue(struct irq_work *work)\n{\n\t/* Only queue if not already pending */\n\tif (!irq_work_claim(work))\n\t\treturn false;\n\n\t/* Queue the entry and raise the IPI if needed. */\n\tpreempt_disable();\n\n\t/* If the work is \"lazy\", handle it from next tick if any */\n\tif (work->flags & IRQ_WORK_LAZY) {\n\t\tif (llist_add(&work->llnode, this_cpu_ptr(&lazy_list)) &&\n\t\t    tick_nohz_tick_stopped())\n\t\t\tarch_irq_work_raise();\n\t} else {\n\t\tif (llist_add(&work->llnode, this_cpu_ptr(&raised_list)))\n\t\t\tarch_irq_work_raise();\n\t}\n\n\tpreempt_enable();\n\n\treturn true;\n}"
  },
  {
    "function_name": "irq_work_queue_on",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq_work.c",
    "lines": "65-87",
    "snippet": "bool irq_work_queue_on(struct irq_work *work, int cpu)\n{\n\t/* All work should have been flushed before going offline */\n\tWARN_ON_ONCE(cpu_is_offline(cpu));\n\n#ifdef CONFIG_SMP\n\n\t/* Arch remote IPI send/receive backend aren't NMI safe */\n\tWARN_ON_ONCE(in_nmi());\n\n\t/* Only queue if not already pending */\n\tif (!irq_work_claim(work))\n\t\treturn false;\n\n\tif (llist_add(&work->llnode, &per_cpu(raised_list, cpu)))\n\t\tarch_send_call_function_single_ipi(cpu);\n\n#else /* #ifdef CONFIG_SMP */\n\tirq_work_queue(work);\n#endif /* #else #ifdef CONFIG_SMP */\n\n\treturn true;\n}",
    "includes": [
      "#include <asm/processor.h>",
      "#include <linux/smp.h>",
      "#include <linux/notifier.h>",
      "#include <linux/cpu.h>",
      "#include <linux/tick.h>",
      "#include <linux/sched.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/hardirq.h>",
      "#include <linux/percpu.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/export.h>",
      "#include <linux/kernel.h>",
      "#include <linux/bug.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct llist_head, raised_list);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "irq_work_queue",
          "args": [
            "work"
          ],
          "line": 83
        },
        "resolved": true,
        "details": {
          "function_name": "irq_work_queue",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq_work.c",
          "lines": "90-112",
          "snippet": "bool irq_work_queue(struct irq_work *work)\n{\n\t/* Only queue if not already pending */\n\tif (!irq_work_claim(work))\n\t\treturn false;\n\n\t/* Queue the entry and raise the IPI if needed. */\n\tpreempt_disable();\n\n\t/* If the work is \"lazy\", handle it from next tick if any */\n\tif (work->flags & IRQ_WORK_LAZY) {\n\t\tif (llist_add(&work->llnode, this_cpu_ptr(&lazy_list)) &&\n\t\t    tick_nohz_tick_stopped())\n\t\t\tarch_irq_work_raise();\n\t} else {\n\t\tif (llist_add(&work->llnode, this_cpu_ptr(&raised_list)))\n\t\t\tarch_irq_work_raise();\n\t}\n\n\tpreempt_enable();\n\n\treturn true;\n}",
          "includes": [
            "#include <asm/processor.h>",
            "#include <linux/smp.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/tick.h>",
            "#include <linux/sched.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/bug.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(struct llist_head, raised_list);",
            "static DEFINE_PER_CPU(struct llist_head, lazy_list);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/processor.h>\n#include <linux/smp.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/tick.h>\n#include <linux/sched.h>\n#include <linux/irqflags.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/irq_work.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bug.h>\n\nstatic DEFINE_PER_CPU(struct llist_head, raised_list);\nstatic DEFINE_PER_CPU(struct llist_head, lazy_list);\n\nbool irq_work_queue(struct irq_work *work)\n{\n\t/* Only queue if not already pending */\n\tif (!irq_work_claim(work))\n\t\treturn false;\n\n\t/* Queue the entry and raise the IPI if needed. */\n\tpreempt_disable();\n\n\t/* If the work is \"lazy\", handle it from next tick if any */\n\tif (work->flags & IRQ_WORK_LAZY) {\n\t\tif (llist_add(&work->llnode, this_cpu_ptr(&lazy_list)) &&\n\t\t    tick_nohz_tick_stopped())\n\t\t\tarch_irq_work_raise();\n\t} else {\n\t\tif (llist_add(&work->llnode, this_cpu_ptr(&raised_list)))\n\t\t\tarch_irq_work_raise();\n\t}\n\n\tpreempt_enable();\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "arch_send_call_function_single_ipi",
          "args": [
            "cpu"
          ],
          "line": 80
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "llist_add",
          "args": [
            "&work->llnode",
            "&per_cpu(raised_list, cpu)"
          ],
          "line": 79
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "per_cpu",
          "args": [
            "raised_list",
            "cpu"
          ],
          "line": 79
        },
        "resolved": true,
        "details": {
          "function_name": "kdb_per_cpu",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/debug/kdb/kdb_main.c",
          "lines": "2575-2640",
          "snippet": "static int kdb_per_cpu(int argc, const char **argv)\n{\n\tchar fmtstr[64];\n\tint cpu, diag, nextarg = 1;\n\tunsigned long addr, symaddr, val, bytesperword = 0, whichcpu = ~0UL;\n\n\tif (argc < 1 || argc > 3)\n\t\treturn KDB_ARGCOUNT;\n\n\tdiag = kdbgetaddrarg(argc, argv, &nextarg, &symaddr, NULL, NULL);\n\tif (diag)\n\t\treturn diag;\n\n\tif (argc >= 2) {\n\t\tdiag = kdbgetularg(argv[2], &bytesperword);\n\t\tif (diag)\n\t\t\treturn diag;\n\t}\n\tif (!bytesperword)\n\t\tbytesperword = KDB_WORD_SIZE;\n\telse if (bytesperword > KDB_WORD_SIZE)\n\t\treturn KDB_BADWIDTH;\n\tsprintf(fmtstr, \"%%0%dlx \", (int)(2*bytesperword));\n\tif (argc >= 3) {\n\t\tdiag = kdbgetularg(argv[3], &whichcpu);\n\t\tif (diag)\n\t\t\treturn diag;\n\t\tif (!cpu_online(whichcpu)) {\n\t\t\tkdb_printf(\"cpu %ld is not online\\n\", whichcpu);\n\t\t\treturn KDB_BADCPUNUM;\n\t\t}\n\t}\n\n\t/* Most architectures use __per_cpu_offset[cpu], some use\n\t * __per_cpu_offset(cpu), smp has no __per_cpu_offset.\n\t */\n#ifdef\t__per_cpu_offset\n#define KDB_PCU(cpu) __per_cpu_offset(cpu)\n#else\n#ifdef\tCONFIG_SMP\n#define KDB_PCU(cpu) __per_cpu_offset[cpu]\n#else\n#define KDB_PCU(cpu) 0\n#endif\n#endif\n\tfor_each_online_cpu(cpu) {\n\t\tif (KDB_FLAG(CMD_INTERRUPT))\n\t\t\treturn 0;\n\n\t\tif (whichcpu != ~0UL && whichcpu != cpu)\n\t\t\tcontinue;\n\t\taddr = symaddr + KDB_PCU(cpu);\n\t\tdiag = kdb_getword(&val, addr, bytesperword);\n\t\tif (diag) {\n\t\t\tkdb_printf(\"%5d \" kdb_bfd_vma_fmt0 \" - unable to \"\n\t\t\t\t   \"read, diag=%d\\n\", cpu, addr, diag);\n\t\t\tcontinue;\n\t\t}\n\t\tkdb_printf(\"%5d \", cpu);\n\t\tkdb_md_line(fmtstr, addr,\n\t\t\tbytesperword == KDB_WORD_SIZE,\n\t\t\t1, bytesperword, 1, 1, 0);\n\t}\n#undef KDB_PCU\n\treturn 0;\n}",
          "includes": [
            "#include \"kdb_private.h\"",
            "#include <linux/slab.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/kdebug.h>",
            "#include <linux/cpu.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/time.h>",
            "#include <linux/nmi.h>",
            "#include <linux/delay.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/notifier.h>",
            "#include <linux/kdb.h>",
            "#include <linux/kgdb.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/init.h>",
            "#include <linux/mm.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/atomic.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/utsname.h>",
            "#include <linux/smp.h>",
            "#include <linux/sysrq.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched.h>",
            "#include <linux/reboot.h>",
            "#include <linux/kmsg_dump.h>",
            "#include <linux/kernel.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/ctype.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kdb_private.h\"\n#include <linux/slab.h>\n#include <linux/uaccess.h>\n#include <linux/proc_fs.h>\n#include <linux/kdebug.h>\n#include <linux/cpu.h>\n#include <linux/sysctl.h>\n#include <linux/ptrace.h>\n#include <linux/time.h>\n#include <linux/nmi.h>\n#include <linux/delay.h>\n#include <linux/interrupt.h>\n#include <linux/notifier.h>\n#include <linux/kdb.h>\n#include <linux/kgdb.h>\n#include <linux/kallsyms.h>\n#include <linux/init.h>\n#include <linux/mm.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/atomic.h>\n#include <linux/vmalloc.h>\n#include <linux/utsname.h>\n#include <linux/smp.h>\n#include <linux/sysrq.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched.h>\n#include <linux/reboot.h>\n#include <linux/kmsg_dump.h>\n#include <linux/kernel.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/ctype.h>\n\nstatic int kdb_per_cpu(int argc, const char **argv)\n{\n\tchar fmtstr[64];\n\tint cpu, diag, nextarg = 1;\n\tunsigned long addr, symaddr, val, bytesperword = 0, whichcpu = ~0UL;\n\n\tif (argc < 1 || argc > 3)\n\t\treturn KDB_ARGCOUNT;\n\n\tdiag = kdbgetaddrarg(argc, argv, &nextarg, &symaddr, NULL, NULL);\n\tif (diag)\n\t\treturn diag;\n\n\tif (argc >= 2) {\n\t\tdiag = kdbgetularg(argv[2], &bytesperword);\n\t\tif (diag)\n\t\t\treturn diag;\n\t}\n\tif (!bytesperword)\n\t\tbytesperword = KDB_WORD_SIZE;\n\telse if (bytesperword > KDB_WORD_SIZE)\n\t\treturn KDB_BADWIDTH;\n\tsprintf(fmtstr, \"%%0%dlx \", (int)(2*bytesperword));\n\tif (argc >= 3) {\n\t\tdiag = kdbgetularg(argv[3], &whichcpu);\n\t\tif (diag)\n\t\t\treturn diag;\n\t\tif (!cpu_online(whichcpu)) {\n\t\t\tkdb_printf(\"cpu %ld is not online\\n\", whichcpu);\n\t\t\treturn KDB_BADCPUNUM;\n\t\t}\n\t}\n\n\t/* Most architectures use __per_cpu_offset[cpu], some use\n\t * __per_cpu_offset(cpu), smp has no __per_cpu_offset.\n\t */\n#ifdef\t__per_cpu_offset\n#define KDB_PCU(cpu) __per_cpu_offset(cpu)\n#else\n#ifdef\tCONFIG_SMP\n#define KDB_PCU(cpu) __per_cpu_offset[cpu]\n#else\n#define KDB_PCU(cpu) 0\n#endif\n#endif\n\tfor_each_online_cpu(cpu) {\n\t\tif (KDB_FLAG(CMD_INTERRUPT))\n\t\t\treturn 0;\n\n\t\tif (whichcpu != ~0UL && whichcpu != cpu)\n\t\t\tcontinue;\n\t\taddr = symaddr + KDB_PCU(cpu);\n\t\tdiag = kdb_getword(&val, addr, bytesperword);\n\t\tif (diag) {\n\t\t\tkdb_printf(\"%5d \" kdb_bfd_vma_fmt0 \" - unable to \"\n\t\t\t\t   \"read, diag=%d\\n\", cpu, addr, diag);\n\t\t\tcontinue;\n\t\t}\n\t\tkdb_printf(\"%5d \", cpu);\n\t\tkdb_md_line(fmtstr, addr,\n\t\t\tbytesperword == KDB_WORD_SIZE,\n\t\t\t1, bytesperword, 1, 1, 0);\n\t}\n#undef KDB_PCU\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "irq_work_claim",
          "args": [
            "work"
          ],
          "line": 76
        },
        "resolved": true,
        "details": {
          "function_name": "irq_work_claim",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq_work.c",
          "lines": "29-50",
          "snippet": "static bool irq_work_claim(struct irq_work *work)\n{\n\tunsigned long flags, oflags, nflags;\n\n\t/*\n\t * Start with our best wish as a premise but only trust any\n\t * flag value after cmpxchg() result.\n\t */\n\tflags = work->flags & ~IRQ_WORK_PENDING;\n\tfor (;;) {\n\t\tnflags = flags | IRQ_WORK_CLAIMED;\n\t\toflags = cmpxchg(&work->flags, flags, nflags);\n\t\tif (oflags == flags)\n\t\t\tbreak;\n\t\tif (oflags & IRQ_WORK_PENDING)\n\t\t\treturn false;\n\t\tflags = oflags;\n\t\tcpu_relax();\n\t}\n\n\treturn true;\n}",
          "includes": [
            "#include <asm/processor.h>",
            "#include <linux/smp.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/tick.h>",
            "#include <linux/sched.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/bug.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/processor.h>\n#include <linux/smp.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/tick.h>\n#include <linux/sched.h>\n#include <linux/irqflags.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/irq_work.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bug.h>\n\nstatic bool irq_work_claim(struct irq_work *work)\n{\n\tunsigned long flags, oflags, nflags;\n\n\t/*\n\t * Start with our best wish as a premise but only trust any\n\t * flag value after cmpxchg() result.\n\t */\n\tflags = work->flags & ~IRQ_WORK_PENDING;\n\tfor (;;) {\n\t\tnflags = flags | IRQ_WORK_CLAIMED;\n\t\toflags = cmpxchg(&work->flags, flags, nflags);\n\t\tif (oflags == flags)\n\t\t\tbreak;\n\t\tif (oflags & IRQ_WORK_PENDING)\n\t\t\treturn false;\n\t\tflags = oflags;\n\t\tcpu_relax();\n\t}\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "in_nmi()"
          ],
          "line": 73
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "in_nmi",
          "args": [],
          "line": 73
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "cpu_is_offline(cpu)"
          ],
          "line": 68
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_is_offline",
          "args": [
            "cpu"
          ],
          "line": 68
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/processor.h>\n#include <linux/smp.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/tick.h>\n#include <linux/sched.h>\n#include <linux/irqflags.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/irq_work.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bug.h>\n\nstatic DEFINE_PER_CPU(struct llist_head, raised_list);\n\nbool irq_work_queue_on(struct irq_work *work, int cpu)\n{\n\t/* All work should have been flushed before going offline */\n\tWARN_ON_ONCE(cpu_is_offline(cpu));\n\n#ifdef CONFIG_SMP\n\n\t/* Arch remote IPI send/receive backend aren't NMI safe */\n\tWARN_ON_ONCE(in_nmi());\n\n\t/* Only queue if not already pending */\n\tif (!irq_work_claim(work))\n\t\treturn false;\n\n\tif (llist_add(&work->llnode, &per_cpu(raised_list, cpu)))\n\t\tarch_send_call_function_single_ipi(cpu);\n\n#else /* #ifdef CONFIG_SMP */\n\tirq_work_queue(work);\n#endif /* #else #ifdef CONFIG_SMP */\n\n\treturn true;\n}"
  },
  {
    "function_name": "arch_irq_work_raise",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq_work.c",
    "lines": "52-57",
    "snippet": "void __weak arch_irq_work_raise(void)\n{\n\t/*\n\t * Lame architectures will get the timer tick callback\n\t */\n}",
    "includes": [
      "#include <asm/processor.h>",
      "#include <linux/smp.h>",
      "#include <linux/notifier.h>",
      "#include <linux/cpu.h>",
      "#include <linux/tick.h>",
      "#include <linux/sched.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/hardirq.h>",
      "#include <linux/percpu.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/export.h>",
      "#include <linux/kernel.h>",
      "#include <linux/bug.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include <asm/processor.h>\n#include <linux/smp.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/tick.h>\n#include <linux/sched.h>\n#include <linux/irqflags.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/irq_work.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bug.h>\n\nvoid __weak arch_irq_work_raise(void)\n{\n\t/*\n\t * Lame architectures will get the timer tick callback\n\t */\n}"
  },
  {
    "function_name": "irq_work_claim",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq_work.c",
    "lines": "29-50",
    "snippet": "static bool irq_work_claim(struct irq_work *work)\n{\n\tunsigned long flags, oflags, nflags;\n\n\t/*\n\t * Start with our best wish as a premise but only trust any\n\t * flag value after cmpxchg() result.\n\t */\n\tflags = work->flags & ~IRQ_WORK_PENDING;\n\tfor (;;) {\n\t\tnflags = flags | IRQ_WORK_CLAIMED;\n\t\toflags = cmpxchg(&work->flags, flags, nflags);\n\t\tif (oflags == flags)\n\t\t\tbreak;\n\t\tif (oflags & IRQ_WORK_PENDING)\n\t\t\treturn false;\n\t\tflags = oflags;\n\t\tcpu_relax();\n\t}\n\n\treturn true;\n}",
    "includes": [
      "#include <asm/processor.h>",
      "#include <linux/smp.h>",
      "#include <linux/notifier.h>",
      "#include <linux/cpu.h>",
      "#include <linux/tick.h>",
      "#include <linux/sched.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/hardirq.h>",
      "#include <linux/percpu.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/export.h>",
      "#include <linux/kernel.h>",
      "#include <linux/bug.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpu_relax",
          "args": [],
          "line": 46
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cmpxchg",
          "args": [
            "&work->flags",
            "flags",
            "nflags"
          ],
          "line": 40
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/processor.h>\n#include <linux/smp.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/tick.h>\n#include <linux/sched.h>\n#include <linux/irqflags.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/irq_work.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bug.h>\n\nstatic bool irq_work_claim(struct irq_work *work)\n{\n\tunsigned long flags, oflags, nflags;\n\n\t/*\n\t * Start with our best wish as a premise but only trust any\n\t * flag value after cmpxchg() result.\n\t */\n\tflags = work->flags & ~IRQ_WORK_PENDING;\n\tfor (;;) {\n\t\tnflags = flags | IRQ_WORK_CLAIMED;\n\t\toflags = cmpxchg(&work->flags, flags, nflags);\n\t\tif (oflags == flags)\n\t\t\tbreak;\n\t\tif (oflags & IRQ_WORK_PENDING)\n\t\t\treturn false;\n\t\tflags = oflags;\n\t\tcpu_relax();\n\t}\n\n\treturn true;\n}"
  }
]