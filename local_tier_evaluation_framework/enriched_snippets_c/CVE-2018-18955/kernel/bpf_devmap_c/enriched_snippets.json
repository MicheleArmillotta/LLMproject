[
  {
    "function_name": "dev_map_init",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
    "lines": "535-542",
    "snippet": "static int __init dev_map_init(void)\n{\n\t/* Assure tracepoint shadow struct _bpf_dtab_netdev is in sync */\n\tBUILD_BUG_ON(offsetof(struct bpf_dtab_netdev, dev) !=\n\t\t     offsetof(struct _bpf_dtab_netdev, dev));\n\tregister_netdevice_notifier(&dev_map_notifier);\n\treturn 0;\n}",
    "includes": [
      "#include <trace/events/xdp.h>",
      "#include <linux/filter.h>",
      "#include <net/xdp.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static struct notifier_block dev_map_notifier = {\n\t.notifier_call = dev_map_notification,\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "register_netdevice_notifier",
          "args": [
            "&dev_map_notifier"
          ],
          "line": 540
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUILD_BUG_ON",
          "args": [
            "offsetof(struct bpf_dtab_netdev, dev) !=\n\t\t     offsetof(struct _bpf_dtab_netdev, dev)"
          ],
          "line": 538
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\nstatic struct notifier_block dev_map_notifier = {\n\t.notifier_call = dev_map_notification,\n};\n\nstatic int __init dev_map_init(void)\n{\n\t/* Assure tracepoint shadow struct _bpf_dtab_netdev is in sync */\n\tBUILD_BUG_ON(offsetof(struct bpf_dtab_netdev, dev) !=\n\t\t     offsetof(struct _bpf_dtab_netdev, dev));\n\tregister_netdevice_notifier(&dev_map_notifier);\n\treturn 0;\n}"
  },
  {
    "function_name": "dev_map_notification",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
    "lines": "495-529",
    "snippet": "static int dev_map_notification(struct notifier_block *notifier,\n\t\t\t\tulong event, void *ptr)\n{\n\tstruct net_device *netdev = netdev_notifier_info_to_dev(ptr);\n\tstruct bpf_dtab *dtab;\n\tint i;\n\n\tswitch (event) {\n\tcase NETDEV_UNREGISTER:\n\t\t/* This rcu_read_lock/unlock pair is needed because\n\t\t * dev_map_list is an RCU list AND to ensure a delete\n\t\t * operation does not free a netdev_map entry while we\n\t\t * are comparing it against the netdev being unregistered.\n\t\t */\n\t\trcu_read_lock();\n\t\tlist_for_each_entry_rcu(dtab, &dev_map_list, list) {\n\t\t\tfor (i = 0; i < dtab->map.max_entries; i++) {\n\t\t\t\tstruct bpf_dtab_netdev *dev, *odev;\n\n\t\t\t\tdev = READ_ONCE(dtab->netdev_map[i]);\n\t\t\t\tif (!dev || netdev != dev->dev)\n\t\t\t\t\tcontinue;\n\t\t\t\todev = cmpxchg(&dtab->netdev_map[i], dev, NULL);\n\t\t\t\tif (dev == odev)\n\t\t\t\t\tcall_rcu(&dev->rcu,\n\t\t\t\t\t\t __dev_map_entry_free);\n\t\t\t}\n\t\t}\n\t\trcu_read_unlock();\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\treturn NOTIFY_OK;\n}",
    "includes": [
      "#include <trace/events/xdp.h>",
      "#include <linux/filter.h>",
      "#include <net/xdp.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static LIST_HEAD(dev_map_list);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 523
        },
        "resolved": true,
        "details": {
          "function_name": "__rcu_read_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/tree_plugin.h",
          "lines": "419-441",
          "snippet": "void __rcu_read_unlock(void)\n{\n\tstruct task_struct *t = current;\n\n\tif (t->rcu_read_lock_nesting != 1) {\n\t\t--t->rcu_read_lock_nesting;\n\t} else {\n\t\tbarrier();  /* critical section before exit code. */\n\t\tt->rcu_read_lock_nesting = INT_MIN;\n\t\tbarrier();  /* assign before ->rcu_read_unlock_special load */\n\t\tif (unlikely(READ_ONCE(t->rcu_read_unlock_special.s)))\n\t\t\trcu_read_unlock_special(t);\n\t\tbarrier();  /* ->rcu_read_unlock_special load before assign */\n\t\tt->rcu_read_lock_nesting = 0;\n\t}\n#ifdef CONFIG_PROVE_LOCKING\n\t{\n\t\tint rrln = READ_ONCE(t->rcu_read_lock_nesting);\n\n\t\tWARN_ON_ONCE(rrln < 0 && rrln > INT_MIN / 2);\n\t}\n#endif /* #ifdef CONFIG_PROVE_LOCKING */\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"../time/tick-internal.h\"",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/oom.h>",
            "#include <linux/gfp.h>",
            "#include <linux/delay.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"../time/tick-internal.h\"\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/isolation.h>\n#include <linux/smpboot.h>\n#include <linux/sched/debug.h>\n#include <linux/oom.h>\n#include <linux/gfp.h>\n#include <linux/delay.h>\n\nvoid __rcu_read_unlock(void)\n{\n\tstruct task_struct *t = current;\n\n\tif (t->rcu_read_lock_nesting != 1) {\n\t\t--t->rcu_read_lock_nesting;\n\t} else {\n\t\tbarrier();  /* critical section before exit code. */\n\t\tt->rcu_read_lock_nesting = INT_MIN;\n\t\tbarrier();  /* assign before ->rcu_read_unlock_special load */\n\t\tif (unlikely(READ_ONCE(t->rcu_read_unlock_special.s)))\n\t\t\trcu_read_unlock_special(t);\n\t\tbarrier();  /* ->rcu_read_unlock_special load before assign */\n\t\tt->rcu_read_lock_nesting = 0;\n\t}\n#ifdef CONFIG_PROVE_LOCKING\n\t{\n\t\tint rrln = READ_ONCE(t->rcu_read_lock_nesting);\n\n\t\tWARN_ON_ONCE(rrln < 0 && rrln > INT_MIN / 2);\n\t}\n#endif /* #ifdef CONFIG_PROVE_LOCKING */\n}"
        }
      },
      {
        "call_info": {
          "callee": "call_rcu",
          "args": [
            "&dev->rcu",
            "__dev_map_entry_free"
          ],
          "line": 519
        },
        "resolved": true,
        "details": {
          "function_name": "call_rcu_tasks",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/update.c",
          "lines": "552-567",
          "snippet": "void call_rcu_tasks(struct rcu_head *rhp, rcu_callback_t func)\n{\n\tunsigned long flags;\n\tbool needwake;\n\n\trhp->next = NULL;\n\trhp->func = func;\n\traw_spin_lock_irqsave(&rcu_tasks_cbs_lock, flags);\n\tneedwake = !rcu_tasks_cbs_head;\n\t*rcu_tasks_cbs_tail = rhp;\n\trcu_tasks_cbs_tail = &rhp->next;\n\traw_spin_unlock_irqrestore(&rcu_tasks_cbs_lock, flags);\n\t/* We can't create the thread unless interrupts are enabled. */\n\tif (needwake && READ_ONCE(rcu_tasks_kthread_ptr))\n\t\twake_up(&rcu_tasks_cbs_wq);\n}",
          "includes": [
            "#include \"rcu.h\"",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu.h\"\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nvoid call_rcu_tasks(struct rcu_head *rhp, rcu_callback_t func)\n{\n\tunsigned long flags;\n\tbool needwake;\n\n\trhp->next = NULL;\n\trhp->func = func;\n\traw_spin_lock_irqsave(&rcu_tasks_cbs_lock, flags);\n\tneedwake = !rcu_tasks_cbs_head;\n\t*rcu_tasks_cbs_tail = rhp;\n\trcu_tasks_cbs_tail = &rhp->next;\n\traw_spin_unlock_irqrestore(&rcu_tasks_cbs_lock, flags);\n\t/* We can't create the thread unless interrupts are enabled. */\n\tif (needwake && READ_ONCE(rcu_tasks_kthread_ptr))\n\t\twake_up(&rcu_tasks_cbs_wq);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cmpxchg",
          "args": [
            "&dtab->netdev_map[i]",
            "dev",
            "NULL"
          ],
          "line": 517
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "dtab->netdev_map[i]"
          ],
          "line": 514
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_for_each_entry_rcu",
          "args": [
            "dtab",
            "&dev_map_list",
            "list"
          ],
          "line": 510
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 509
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_bh_held",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/update.c",
          "lines": "300-309",
          "snippet": "int rcu_read_lock_bh_held(void)\n{\n\tif (!debug_lockdep_rcu_enabled())\n\t\treturn 1;\n\tif (!rcu_is_watching())\n\t\treturn 0;\n\tif (!rcu_lockdep_current_cpu_online())\n\t\treturn 0;\n\treturn in_softirq() || irqs_disabled();\n}",
          "includes": [
            "#include \"rcu.h\"",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu.h\"\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_bh_held(void)\n{\n\tif (!debug_lockdep_rcu_enabled())\n\t\treturn 1;\n\tif (!rcu_is_watching())\n\t\treturn 0;\n\tif (!rcu_lockdep_current_cpu_online())\n\t\treturn 0;\n\treturn in_softirq() || irqs_disabled();\n}"
        }
      },
      {
        "call_info": {
          "callee": "netdev_notifier_info_to_dev",
          "args": [
            "ptr"
          ],
          "line": 498
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\nstatic LIST_HEAD(dev_map_list);\n\nstatic int dev_map_notification(struct notifier_block *notifier,\n\t\t\t\tulong event, void *ptr)\n{\n\tstruct net_device *netdev = netdev_notifier_info_to_dev(ptr);\n\tstruct bpf_dtab *dtab;\n\tint i;\n\n\tswitch (event) {\n\tcase NETDEV_UNREGISTER:\n\t\t/* This rcu_read_lock/unlock pair is needed because\n\t\t * dev_map_list is an RCU list AND to ensure a delete\n\t\t * operation does not free a netdev_map entry while we\n\t\t * are comparing it against the netdev being unregistered.\n\t\t */\n\t\trcu_read_lock();\n\t\tlist_for_each_entry_rcu(dtab, &dev_map_list, list) {\n\t\t\tfor (i = 0; i < dtab->map.max_entries; i++) {\n\t\t\t\tstruct bpf_dtab_netdev *dev, *odev;\n\n\t\t\t\tdev = READ_ONCE(dtab->netdev_map[i]);\n\t\t\t\tif (!dev || netdev != dev->dev)\n\t\t\t\t\tcontinue;\n\t\t\t\todev = cmpxchg(&dtab->netdev_map[i], dev, NULL);\n\t\t\t\tif (dev == odev)\n\t\t\t\t\tcall_rcu(&dev->rcu,\n\t\t\t\t\t\t __dev_map_entry_free);\n\t\t\t}\n\t\t}\n\t\trcu_read_unlock();\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\treturn NOTIFY_OK;\n}"
  },
  {
    "function_name": "dev_map_update_elem",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
    "lines": "432-483",
    "snippet": "static int dev_map_update_elem(struct bpf_map *map, void *key, void *value,\n\t\t\t\tu64 map_flags)\n{\n\tstruct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);\n\tstruct net *net = current->nsproxy->net_ns;\n\tgfp_t gfp = GFP_ATOMIC | __GFP_NOWARN;\n\tstruct bpf_dtab_netdev *dev, *old_dev;\n\tu32 i = *(u32 *)key;\n\tu32 ifindex = *(u32 *)value;\n\n\tif (unlikely(map_flags > BPF_EXIST))\n\t\treturn -EINVAL;\n\tif (unlikely(i >= dtab->map.max_entries))\n\t\treturn -E2BIG;\n\tif (unlikely(map_flags == BPF_NOEXIST))\n\t\treturn -EEXIST;\n\n\tif (!ifindex) {\n\t\tdev = NULL;\n\t} else {\n\t\tdev = kmalloc_node(sizeof(*dev), gfp, map->numa_node);\n\t\tif (!dev)\n\t\t\treturn -ENOMEM;\n\n\t\tdev->bulkq = __alloc_percpu_gfp(sizeof(*dev->bulkq),\n\t\t\t\t\t\tsizeof(void *), gfp);\n\t\tif (!dev->bulkq) {\n\t\t\tkfree(dev);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tdev->dev = dev_get_by_index(net, ifindex);\n\t\tif (!dev->dev) {\n\t\t\tfree_percpu(dev->bulkq);\n\t\t\tkfree(dev);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tdev->bit = i;\n\t\tdev->dtab = dtab;\n\t}\n\n\t/* Use call_rcu() here to ensure rcu critical sections have completed\n\t * Remembering the driver side flush operation will happen before the\n\t * net device is removed.\n\t */\n\told_dev = xchg(&dtab->netdev_map[i], dev);\n\tif (old_dev)\n\t\tcall_rcu(&old_dev->rcu, __dev_map_entry_free);\n\n\treturn 0;\n}",
    "includes": [
      "#include <trace/events/xdp.h>",
      "#include <linux/filter.h>",
      "#include <net/xdp.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "call_rcu",
          "args": [
            "&old_dev->rcu",
            "__dev_map_entry_free"
          ],
          "line": 480
        },
        "resolved": true,
        "details": {
          "function_name": "call_rcu_tasks",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/update.c",
          "lines": "552-567",
          "snippet": "void call_rcu_tasks(struct rcu_head *rhp, rcu_callback_t func)\n{\n\tunsigned long flags;\n\tbool needwake;\n\n\trhp->next = NULL;\n\trhp->func = func;\n\traw_spin_lock_irqsave(&rcu_tasks_cbs_lock, flags);\n\tneedwake = !rcu_tasks_cbs_head;\n\t*rcu_tasks_cbs_tail = rhp;\n\trcu_tasks_cbs_tail = &rhp->next;\n\traw_spin_unlock_irqrestore(&rcu_tasks_cbs_lock, flags);\n\t/* We can't create the thread unless interrupts are enabled. */\n\tif (needwake && READ_ONCE(rcu_tasks_kthread_ptr))\n\t\twake_up(&rcu_tasks_cbs_wq);\n}",
          "includes": [
            "#include \"rcu.h\"",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu.h\"\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nvoid call_rcu_tasks(struct rcu_head *rhp, rcu_callback_t func)\n{\n\tunsigned long flags;\n\tbool needwake;\n\n\trhp->next = NULL;\n\trhp->func = func;\n\traw_spin_lock_irqsave(&rcu_tasks_cbs_lock, flags);\n\tneedwake = !rcu_tasks_cbs_head;\n\t*rcu_tasks_cbs_tail = rhp;\n\trcu_tasks_cbs_tail = &rhp->next;\n\traw_spin_unlock_irqrestore(&rcu_tasks_cbs_lock, flags);\n\t/* We can't create the thread unless interrupts are enabled. */\n\tif (needwake && READ_ONCE(rcu_tasks_kthread_ptr))\n\t\twake_up(&rcu_tasks_cbs_wq);\n}"
        }
      },
      {
        "call_info": {
          "callee": "xchg",
          "args": [
            "&dtab->netdev_map[i]",
            "dev"
          ],
          "line": 478
        },
        "resolved": true,
        "details": {
          "function_name": "xchg_tail",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/qspinlock.c",
          "lines": "231-249",
          "snippet": "static __always_inline u32 xchg_tail(struct qspinlock *lock, u32 tail)\n{\n\tu32 old, new, val = atomic_read(&lock->val);\n\n\tfor (;;) {\n\t\tnew = (val & _Q_LOCKED_PENDING_MASK) | tail;\n\t\t/*\n\t\t * We can use relaxed semantics since the caller ensures that\n\t\t * the MCS node is properly initialized before updating the\n\t\t * tail.\n\t\t */\n\t\told = atomic_cmpxchg_relaxed(&lock->val, val, new);\n\t\tif (old == val)\n\t\t\tbreak;\n\n\t\tval = old;\n\t}\n\treturn old;\n}",
          "includes": [
            "#include \"qspinlock.c\"",
            "#include \"qspinlock_paravirt.h\"",
            "#include \"mcs_spinlock.h\"",
            "#include \"qspinlock_stat.h\"",
            "#include <asm/qspinlock.h>",
            "#include <asm/byteorder.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/mutex.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/cpumask.h>",
            "#include <linux/bug.h>",
            "#include <linux/smp.h>"
          ],
          "macros_used": [
            "#define _Q_LOCKED_PENDING_MASK (_Q_LOCKED_MASK | _Q_PENDING_MASK)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"qspinlock.c\"\n#include \"qspinlock_paravirt.h\"\n#include \"mcs_spinlock.h\"\n#include \"qspinlock_stat.h\"\n#include <asm/qspinlock.h>\n#include <asm/byteorder.h>\n#include <linux/prefetch.h>\n#include <linux/mutex.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/cpumask.h>\n#include <linux/bug.h>\n#include <linux/smp.h>\n\n#define _Q_LOCKED_PENDING_MASK (_Q_LOCKED_MASK | _Q_PENDING_MASK)\n\nstatic __always_inline u32 xchg_tail(struct qspinlock *lock, u32 tail)\n{\n\tu32 old, new, val = atomic_read(&lock->val);\n\n\tfor (;;) {\n\t\tnew = (val & _Q_LOCKED_PENDING_MASK) | tail;\n\t\t/*\n\t\t * We can use relaxed semantics since the caller ensures that\n\t\t * the MCS node is properly initialized before updating the\n\t\t * tail.\n\t\t */\n\t\told = atomic_cmpxchg_relaxed(&lock->val, val, new);\n\t\tif (old == val)\n\t\t\tbreak;\n\n\t\tval = old;\n\t}\n\treturn old;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "dev"
          ],
          "line": 466
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/params.c",
          "lines": "73-86",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_percpu",
          "args": [
            "dev->bulkq"
          ],
          "line": 465
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_array_free_percpu",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/arraymap.c",
          "lines": "27-35",
          "snippet": "static void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include <uapi/linux/btf.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/filter.h>",
            "#include <linux/mm.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include <uapi/linux/btf.h>\n#include <linux/perf_event.h>\n#include <linux/filter.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "dev_get_by_index",
          "args": [
            "net",
            "ifindex"
          ],
          "line": 463
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__alloc_percpu_gfp",
          "args": [
            "sizeof(*dev->bulkq)",
            "sizeof(void *)",
            "gfp"
          ],
          "line": 456
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kmalloc_node",
          "args": [
            "sizeof(*dev)",
            "gfp",
            "map->numa_node"
          ],
          "line": 452
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "map_flags == BPF_NOEXIST"
          ],
          "line": 446
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "i >= dtab->map.max_entries"
          ],
          "line": 444
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "map_flags > BPF_EXIST"
          ],
          "line": 442
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_dtab",
            "map"
          ],
          "line": 435
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\nstatic int dev_map_update_elem(struct bpf_map *map, void *key, void *value,\n\t\t\t\tu64 map_flags)\n{\n\tstruct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);\n\tstruct net *net = current->nsproxy->net_ns;\n\tgfp_t gfp = GFP_ATOMIC | __GFP_NOWARN;\n\tstruct bpf_dtab_netdev *dev, *old_dev;\n\tu32 i = *(u32 *)key;\n\tu32 ifindex = *(u32 *)value;\n\n\tif (unlikely(map_flags > BPF_EXIST))\n\t\treturn -EINVAL;\n\tif (unlikely(i >= dtab->map.max_entries))\n\t\treturn -E2BIG;\n\tif (unlikely(map_flags == BPF_NOEXIST))\n\t\treturn -EEXIST;\n\n\tif (!ifindex) {\n\t\tdev = NULL;\n\t} else {\n\t\tdev = kmalloc_node(sizeof(*dev), gfp, map->numa_node);\n\t\tif (!dev)\n\t\t\treturn -ENOMEM;\n\n\t\tdev->bulkq = __alloc_percpu_gfp(sizeof(*dev->bulkq),\n\t\t\t\t\t\tsizeof(void *), gfp);\n\t\tif (!dev->bulkq) {\n\t\t\tkfree(dev);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tdev->dev = dev_get_by_index(net, ifindex);\n\t\tif (!dev->dev) {\n\t\t\tfree_percpu(dev->bulkq);\n\t\t\tkfree(dev);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tdev->bit = i;\n\t\tdev->dtab = dtab;\n\t}\n\n\t/* Use call_rcu() here to ensure rcu critical sections have completed\n\t * Remembering the driver side flush operation will happen before the\n\t * net device is removed.\n\t */\n\told_dev = xchg(&dtab->netdev_map[i], dev);\n\tif (old_dev)\n\t\tcall_rcu(&old_dev->rcu, __dev_map_entry_free);\n\n\treturn 0;\n}"
  },
  {
    "function_name": "dev_map_delete_elem",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
    "lines": "409-430",
    "snippet": "static int dev_map_delete_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);\n\tstruct bpf_dtab_netdev *old_dev;\n\tint k = *(u32 *)key;\n\n\tif (k >= map->max_entries)\n\t\treturn -EINVAL;\n\n\t/* Use call_rcu() here to ensure any rcu critical sections have\n\t * completed, but this does not guarantee a flush has happened\n\t * yet. Because driver side rcu_read_lock/unlock only protects the\n\t * running XDP program. However, for pending flush operations the\n\t * dev and ctx are stored in another per cpu map. And additionally,\n\t * the driver tear down ensures all soft irqs are complete before\n\t * removing the net device in the case of dev_put equals zero.\n\t */\n\told_dev = xchg(&dtab->netdev_map[k], NULL);\n\tif (old_dev)\n\t\tcall_rcu(&old_dev->rcu, __dev_map_entry_free);\n\treturn 0;\n}",
    "includes": [
      "#include <trace/events/xdp.h>",
      "#include <linux/filter.h>",
      "#include <net/xdp.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "call_rcu",
          "args": [
            "&old_dev->rcu",
            "__dev_map_entry_free"
          ],
          "line": 428
        },
        "resolved": true,
        "details": {
          "function_name": "call_rcu_tasks",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/update.c",
          "lines": "552-567",
          "snippet": "void call_rcu_tasks(struct rcu_head *rhp, rcu_callback_t func)\n{\n\tunsigned long flags;\n\tbool needwake;\n\n\trhp->next = NULL;\n\trhp->func = func;\n\traw_spin_lock_irqsave(&rcu_tasks_cbs_lock, flags);\n\tneedwake = !rcu_tasks_cbs_head;\n\t*rcu_tasks_cbs_tail = rhp;\n\trcu_tasks_cbs_tail = &rhp->next;\n\traw_spin_unlock_irqrestore(&rcu_tasks_cbs_lock, flags);\n\t/* We can't create the thread unless interrupts are enabled. */\n\tif (needwake && READ_ONCE(rcu_tasks_kthread_ptr))\n\t\twake_up(&rcu_tasks_cbs_wq);\n}",
          "includes": [
            "#include \"rcu.h\"",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu.h\"\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nvoid call_rcu_tasks(struct rcu_head *rhp, rcu_callback_t func)\n{\n\tunsigned long flags;\n\tbool needwake;\n\n\trhp->next = NULL;\n\trhp->func = func;\n\traw_spin_lock_irqsave(&rcu_tasks_cbs_lock, flags);\n\tneedwake = !rcu_tasks_cbs_head;\n\t*rcu_tasks_cbs_tail = rhp;\n\trcu_tasks_cbs_tail = &rhp->next;\n\traw_spin_unlock_irqrestore(&rcu_tasks_cbs_lock, flags);\n\t/* We can't create the thread unless interrupts are enabled. */\n\tif (needwake && READ_ONCE(rcu_tasks_kthread_ptr))\n\t\twake_up(&rcu_tasks_cbs_wq);\n}"
        }
      },
      {
        "call_info": {
          "callee": "xchg",
          "args": [
            "&dtab->netdev_map[k]",
            "NULL"
          ],
          "line": 426
        },
        "resolved": true,
        "details": {
          "function_name": "xchg_tail",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/qspinlock.c",
          "lines": "231-249",
          "snippet": "static __always_inline u32 xchg_tail(struct qspinlock *lock, u32 tail)\n{\n\tu32 old, new, val = atomic_read(&lock->val);\n\n\tfor (;;) {\n\t\tnew = (val & _Q_LOCKED_PENDING_MASK) | tail;\n\t\t/*\n\t\t * We can use relaxed semantics since the caller ensures that\n\t\t * the MCS node is properly initialized before updating the\n\t\t * tail.\n\t\t */\n\t\told = atomic_cmpxchg_relaxed(&lock->val, val, new);\n\t\tif (old == val)\n\t\t\tbreak;\n\n\t\tval = old;\n\t}\n\treturn old;\n}",
          "includes": [
            "#include \"qspinlock.c\"",
            "#include \"qspinlock_paravirt.h\"",
            "#include \"mcs_spinlock.h\"",
            "#include \"qspinlock_stat.h\"",
            "#include <asm/qspinlock.h>",
            "#include <asm/byteorder.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/mutex.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/cpumask.h>",
            "#include <linux/bug.h>",
            "#include <linux/smp.h>"
          ],
          "macros_used": [
            "#define _Q_LOCKED_PENDING_MASK (_Q_LOCKED_MASK | _Q_PENDING_MASK)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"qspinlock.c\"\n#include \"qspinlock_paravirt.h\"\n#include \"mcs_spinlock.h\"\n#include \"qspinlock_stat.h\"\n#include <asm/qspinlock.h>\n#include <asm/byteorder.h>\n#include <linux/prefetch.h>\n#include <linux/mutex.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/cpumask.h>\n#include <linux/bug.h>\n#include <linux/smp.h>\n\n#define _Q_LOCKED_PENDING_MASK (_Q_LOCKED_MASK | _Q_PENDING_MASK)\n\nstatic __always_inline u32 xchg_tail(struct qspinlock *lock, u32 tail)\n{\n\tu32 old, new, val = atomic_read(&lock->val);\n\n\tfor (;;) {\n\t\tnew = (val & _Q_LOCKED_PENDING_MASK) | tail;\n\t\t/*\n\t\t * We can use relaxed semantics since the caller ensures that\n\t\t * the MCS node is properly initialized before updating the\n\t\t * tail.\n\t\t */\n\t\told = atomic_cmpxchg_relaxed(&lock->val, val, new);\n\t\tif (old == val)\n\t\t\tbreak;\n\n\t\tval = old;\n\t}\n\treturn old;\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_dtab",
            "map"
          ],
          "line": 411
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\nstatic int dev_map_delete_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);\n\tstruct bpf_dtab_netdev *old_dev;\n\tint k = *(u32 *)key;\n\n\tif (k >= map->max_entries)\n\t\treturn -EINVAL;\n\n\t/* Use call_rcu() here to ensure any rcu critical sections have\n\t * completed, but this does not guarantee a flush has happened\n\t * yet. Because driver side rcu_read_lock/unlock only protects the\n\t * running XDP program. However, for pending flush operations the\n\t * dev and ctx are stored in another per cpu map. And additionally,\n\t * the driver tear down ensures all soft irqs are complete before\n\t * removing the net device in the case of dev_put equals zero.\n\t */\n\told_dev = xchg(&dtab->netdev_map[k], NULL);\n\tif (old_dev)\n\t\tcall_rcu(&old_dev->rcu, __dev_map_entry_free);\n\treturn 0;\n}"
  },
  {
    "function_name": "__dev_map_entry_free",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
    "lines": "398-407",
    "snippet": "static void __dev_map_entry_free(struct rcu_head *rcu)\n{\n\tstruct bpf_dtab_netdev *dev;\n\n\tdev = container_of(rcu, struct bpf_dtab_netdev, rcu);\n\tdev_map_flush_old(dev);\n\tfree_percpu(dev->bulkq);\n\tdev_put(dev->dev);\n\tkfree(dev);\n}",
    "includes": [
      "#include <trace/events/xdp.h>",
      "#include <linux/filter.h>",
      "#include <net/xdp.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "dev"
          ],
          "line": 406
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/params.c",
          "lines": "73-86",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "dev_put",
          "args": [
            "dev->dev"
          ],
          "line": 405
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "free_percpu",
          "args": [
            "dev->bulkq"
          ],
          "line": 404
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_array_free_percpu",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/arraymap.c",
          "lines": "27-35",
          "snippet": "static void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include <uapi/linux/btf.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/filter.h>",
            "#include <linux/mm.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include <uapi/linux/btf.h>\n#include <linux/perf_event.h>\n#include <linux/filter.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "dev_map_flush_old",
          "args": [
            "dev"
          ],
          "line": 403
        },
        "resolved": true,
        "details": {
          "function_name": "dev_map_flush_old",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
          "lines": "380-396",
          "snippet": "static void dev_map_flush_old(struct bpf_dtab_netdev *dev)\n{\n\tif (dev->dev->netdev_ops->ndo_xdp_xmit) {\n\t\tstruct xdp_bulk_queue *bq;\n\t\tunsigned long *bitmap;\n\n\t\tint cpu;\n\n\t\tfor_each_online_cpu(cpu) {\n\t\t\tbitmap = per_cpu_ptr(dev->dtab->flush_needed, cpu);\n\t\t\t__clear_bit(dev->bit, bitmap);\n\n\t\t\tbq = per_cpu_ptr(dev->bulkq, cpu);\n\t\t\tbq_xmit_all(dev, bq, XDP_XMIT_FLUSH, false);\n\t\t}\n\t}\n}",
          "includes": [
            "#include <trace/events/xdp.h>",
            "#include <linux/filter.h>",
            "#include <net/xdp.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\nstatic void dev_map_flush_old(struct bpf_dtab_netdev *dev)\n{\n\tif (dev->dev->netdev_ops->ndo_xdp_xmit) {\n\t\tstruct xdp_bulk_queue *bq;\n\t\tunsigned long *bitmap;\n\n\t\tint cpu;\n\n\t\tfor_each_online_cpu(cpu) {\n\t\t\tbitmap = per_cpu_ptr(dev->dtab->flush_needed, cpu);\n\t\t\t__clear_bit(dev->bit, bitmap);\n\n\t\t\tbq = per_cpu_ptr(dev->bulkq, cpu);\n\t\t\tbq_xmit_all(dev, bq, XDP_XMIT_FLUSH, false);\n\t\t}\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "rcu",
            "structbpf_dtab_netdev",
            "rcu"
          ],
          "line": 402
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\nstatic void __dev_map_entry_free(struct rcu_head *rcu)\n{\n\tstruct bpf_dtab_netdev *dev;\n\n\tdev = container_of(rcu, struct bpf_dtab_netdev, rcu);\n\tdev_map_flush_old(dev);\n\tfree_percpu(dev->bulkq);\n\tdev_put(dev->dev);\n\tkfree(dev);\n}"
  },
  {
    "function_name": "dev_map_flush_old",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
    "lines": "380-396",
    "snippet": "static void dev_map_flush_old(struct bpf_dtab_netdev *dev)\n{\n\tif (dev->dev->netdev_ops->ndo_xdp_xmit) {\n\t\tstruct xdp_bulk_queue *bq;\n\t\tunsigned long *bitmap;\n\n\t\tint cpu;\n\n\t\tfor_each_online_cpu(cpu) {\n\t\t\tbitmap = per_cpu_ptr(dev->dtab->flush_needed, cpu);\n\t\t\t__clear_bit(dev->bit, bitmap);\n\n\t\t\tbq = per_cpu_ptr(dev->bulkq, cpu);\n\t\t\tbq_xmit_all(dev, bq, XDP_XMIT_FLUSH, false);\n\t\t}\n\t}\n}",
    "includes": [
      "#include <trace/events/xdp.h>",
      "#include <linux/filter.h>",
      "#include <net/xdp.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bq_xmit_all",
          "args": [
            "dev",
            "bq",
            "XDP_XMIT_FLUSH",
            "false"
          ],
          "line": 393
        },
        "resolved": true,
        "details": {
          "function_name": "bq_xmit_all",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
          "lines": "220-266",
          "snippet": "static int bq_xmit_all(struct bpf_dtab_netdev *obj,\n\t\t       struct xdp_bulk_queue *bq, u32 flags,\n\t\t       bool in_napi_ctx)\n{\n\tstruct net_device *dev = obj->dev;\n\tint sent = 0, drops = 0, err = 0;\n\tint i;\n\n\tif (unlikely(!bq->count))\n\t\treturn 0;\n\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\n\t\tprefetch(xdpf);\n\t}\n\n\tsent = dev->netdev_ops->ndo_xdp_xmit(dev, bq->count, bq->q, flags);\n\tif (sent < 0) {\n\t\terr = sent;\n\t\tsent = 0;\n\t\tgoto error;\n\t}\n\tdrops = bq->count - sent;\nout:\n\tbq->count = 0;\n\n\ttrace_xdp_devmap_xmit(&obj->dtab->map, obj->bit,\n\t\t\t      sent, drops, bq->dev_rx, dev, err);\n\tbq->dev_rx = NULL;\n\treturn 0;\nerror:\n\t/* If ndo_xdp_xmit fails with an errno, no frames have been\n\t * xmit'ed and it's our responsibility to them free all.\n\t */\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\n\t\t/* RX path under NAPI protection, can return frames faster */\n\t\tif (likely(in_napi_ctx))\n\t\t\txdp_return_frame_rx_napi(xdpf);\n\t\telse\n\t\t\txdp_return_frame(xdpf);\n\t\tdrops++;\n\t}\n\tgoto out;\n}",
          "includes": [
            "#include <trace/events/xdp.h>",
            "#include <linux/filter.h>",
            "#include <net/xdp.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\nstatic int bq_xmit_all(struct bpf_dtab_netdev *obj,\n\t\t       struct xdp_bulk_queue *bq, u32 flags,\n\t\t       bool in_napi_ctx)\n{\n\tstruct net_device *dev = obj->dev;\n\tint sent = 0, drops = 0, err = 0;\n\tint i;\n\n\tif (unlikely(!bq->count))\n\t\treturn 0;\n\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\n\t\tprefetch(xdpf);\n\t}\n\n\tsent = dev->netdev_ops->ndo_xdp_xmit(dev, bq->count, bq->q, flags);\n\tif (sent < 0) {\n\t\terr = sent;\n\t\tsent = 0;\n\t\tgoto error;\n\t}\n\tdrops = bq->count - sent;\nout:\n\tbq->count = 0;\n\n\ttrace_xdp_devmap_xmit(&obj->dtab->map, obj->bit,\n\t\t\t      sent, drops, bq->dev_rx, dev, err);\n\tbq->dev_rx = NULL;\n\treturn 0;\nerror:\n\t/* If ndo_xdp_xmit fails with an errno, no frames have been\n\t * xmit'ed and it's our responsibility to them free all.\n\t */\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\n\t\t/* RX path under NAPI protection, can return frames faster */\n\t\tif (likely(in_napi_ctx))\n\t\t\txdp_return_frame_rx_napi(xdpf);\n\t\telse\n\t\t\txdp_return_frame(xdpf);\n\t\tdrops++;\n\t}\n\tgoto out;\n}"
        }
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "dev->bulkq",
            "cpu"
          ],
          "line": 392
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__clear_bit",
          "args": [
            "dev->bit",
            "bitmap"
          ],
          "line": 390
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "dev->dtab->flush_needed",
            "cpu"
          ],
          "line": 389
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\nstatic void dev_map_flush_old(struct bpf_dtab_netdev *dev)\n{\n\tif (dev->dev->netdev_ops->ndo_xdp_xmit) {\n\t\tstruct xdp_bulk_queue *bq;\n\t\tunsigned long *bitmap;\n\n\t\tint cpu;\n\n\t\tfor_each_online_cpu(cpu) {\n\t\t\tbitmap = per_cpu_ptr(dev->dtab->flush_needed, cpu);\n\t\t\t__clear_bit(dev->bit, bitmap);\n\n\t\t\tbq = per_cpu_ptr(dev->bulkq, cpu);\n\t\t\tbq_xmit_all(dev, bq, XDP_XMIT_FLUSH, false);\n\t\t}\n\t}\n}"
  },
  {
    "function_name": "dev_map_lookup_elem",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
    "lines": "372-378",
    "snippet": "static void *dev_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_dtab_netdev *obj = __dev_map_lookup_elem(map, *(u32 *)key);\n\tstruct net_device *dev = obj ? obj->dev : NULL;\n\n\treturn dev ? &dev->ifindex : NULL;\n}",
    "includes": [
      "#include <trace/events/xdp.h>",
      "#include <linux/filter.h>",
      "#include <net/xdp.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__dev_map_lookup_elem",
          "args": [
            "map",
            "*(u32 *)key"
          ],
          "line": 374
        },
        "resolved": true,
        "details": {
          "function_name": "__dev_map_lookup_elem",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
          "lines": "302-312",
          "snippet": "struct bpf_dtab_netdev *__dev_map_lookup_elem(struct bpf_map *map, u32 key)\n{\n\tstruct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);\n\tstruct bpf_dtab_netdev *obj;\n\n\tif (key >= map->max_entries)\n\t\treturn NULL;\n\n\tobj = READ_ONCE(dtab->netdev_map[key]);\n\treturn obj;\n}",
          "includes": [
            "#include <trace/events/xdp.h>",
            "#include <linux/filter.h>",
            "#include <net/xdp.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\nstruct bpf_dtab_netdev *__dev_map_lookup_elem(struct bpf_map *map, u32 key)\n{\n\tstruct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);\n\tstruct bpf_dtab_netdev *obj;\n\n\tif (key >= map->max_entries)\n\t\treturn NULL;\n\n\tobj = READ_ONCE(dtab->netdev_map[key]);\n\treturn obj;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\nstatic void *dev_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_dtab_netdev *obj = __dev_map_lookup_elem(map, *(u32 *)key);\n\tstruct net_device *dev = obj ? obj->dev : NULL;\n\n\treturn dev ? &dev->ifindex : NULL;\n}"
  },
  {
    "function_name": "dev_map_generic_redirect",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
    "lines": "358-370",
    "snippet": "int dev_map_generic_redirect(struct bpf_dtab_netdev *dst, struct sk_buff *skb,\n\t\t\t     struct bpf_prog *xdp_prog)\n{\n\tint err;\n\n\terr = xdp_ok_fwd_dev(dst->dev, skb->len);\n\tif (unlikely(err))\n\t\treturn err;\n\tskb->dev = dst->dev;\n\tgeneric_xdp_tx(skb, xdp_prog);\n\n\treturn 0;\n}",
    "includes": [
      "#include <trace/events/xdp.h>",
      "#include <linux/filter.h>",
      "#include <net/xdp.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "generic_xdp_tx",
          "args": [
            "skb",
            "xdp_prog"
          ],
          "line": 367
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "err"
          ],
          "line": 364
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "xdp_ok_fwd_dev",
          "args": [
            "dst->dev",
            "skb->len"
          ],
          "line": 363
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\nint dev_map_generic_redirect(struct bpf_dtab_netdev *dst, struct sk_buff *skb,\n\t\t\t     struct bpf_prog *xdp_prog)\n{\n\tint err;\n\n\terr = xdp_ok_fwd_dev(dst->dev, skb->len);\n\tif (unlikely(err))\n\t\treturn err;\n\tskb->dev = dst->dev;\n\tgeneric_xdp_tx(skb, xdp_prog);\n\n\treturn 0;\n}"
  },
  {
    "function_name": "dev_map_enqueue",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
    "lines": "337-356",
    "snippet": "int dev_map_enqueue(struct bpf_dtab_netdev *dst, struct xdp_buff *xdp,\n\t\t    struct net_device *dev_rx)\n{\n\tstruct net_device *dev = dst->dev;\n\tstruct xdp_frame *xdpf;\n\tint err;\n\n\tif (!dev->netdev_ops->ndo_xdp_xmit)\n\t\treturn -EOPNOTSUPP;\n\n\terr = xdp_ok_fwd_dev(dev, xdp->data_end - xdp->data);\n\tif (unlikely(err))\n\t\treturn err;\n\n\txdpf = convert_to_xdp_frame(xdp);\n\tif (unlikely(!xdpf))\n\t\treturn -EOVERFLOW;\n\n\treturn bq_enqueue(dst, xdpf, dev_rx);\n}",
    "includes": [
      "#include <trace/events/xdp.h>",
      "#include <linux/filter.h>",
      "#include <net/xdp.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bq_enqueue",
          "args": [
            "dst",
            "xdpf",
            "dev_rx"
          ],
          "line": 355
        },
        "resolved": true,
        "details": {
          "function_name": "bq_enqueue",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
          "lines": "317-335",
          "snippet": "static int bq_enqueue(struct bpf_dtab_netdev *obj, struct xdp_frame *xdpf,\n\t\t      struct net_device *dev_rx)\n\n{\n\tstruct xdp_bulk_queue *bq = this_cpu_ptr(obj->bulkq);\n\n\tif (unlikely(bq->count == DEV_MAP_BULK_SIZE))\n\t\tbq_xmit_all(obj, bq, 0, true);\n\n\t/* Ingress dev_rx will be the same for all xdp_frame's in\n\t * bulk_queue, because bq stored per-CPU and must be flushed\n\t * from net_device drivers NAPI func end.\n\t */\n\tif (!bq->dev_rx)\n\t\tbq->dev_rx = dev_rx;\n\n\tbq->q[bq->count++] = xdpf;\n\treturn 0;\n}",
          "includes": [
            "#include <trace/events/xdp.h>",
            "#include <linux/filter.h>",
            "#include <net/xdp.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [
            "#define DEV_MAP_BULK_SIZE 16"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\n#define DEV_MAP_BULK_SIZE 16\n\nstatic int bq_enqueue(struct bpf_dtab_netdev *obj, struct xdp_frame *xdpf,\n\t\t      struct net_device *dev_rx)\n\n{\n\tstruct xdp_bulk_queue *bq = this_cpu_ptr(obj->bulkq);\n\n\tif (unlikely(bq->count == DEV_MAP_BULK_SIZE))\n\t\tbq_xmit_all(obj, bq, 0, true);\n\n\t/* Ingress dev_rx will be the same for all xdp_frame's in\n\t * bulk_queue, because bq stored per-CPU and must be flushed\n\t * from net_device drivers NAPI func end.\n\t */\n\tif (!bq->dev_rx)\n\t\tbq->dev_rx = dev_rx;\n\n\tbq->q[bq->count++] = xdpf;\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!xdpf"
          ],
          "line": 352
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "convert_to_xdp_frame",
          "args": [
            "xdp"
          ],
          "line": 351
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "err"
          ],
          "line": 348
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "xdp_ok_fwd_dev",
          "args": [
            "dev",
            "xdp->data_end - xdp->data"
          ],
          "line": 347
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\nint dev_map_enqueue(struct bpf_dtab_netdev *dst, struct xdp_buff *xdp,\n\t\t    struct net_device *dev_rx)\n{\n\tstruct net_device *dev = dst->dev;\n\tstruct xdp_frame *xdpf;\n\tint err;\n\n\tif (!dev->netdev_ops->ndo_xdp_xmit)\n\t\treturn -EOPNOTSUPP;\n\n\terr = xdp_ok_fwd_dev(dev, xdp->data_end - xdp->data);\n\tif (unlikely(err))\n\t\treturn err;\n\n\txdpf = convert_to_xdp_frame(xdp);\n\tif (unlikely(!xdpf))\n\t\treturn -EOVERFLOW;\n\n\treturn bq_enqueue(dst, xdpf, dev_rx);\n}"
  },
  {
    "function_name": "bq_enqueue",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
    "lines": "317-335",
    "snippet": "static int bq_enqueue(struct bpf_dtab_netdev *obj, struct xdp_frame *xdpf,\n\t\t      struct net_device *dev_rx)\n\n{\n\tstruct xdp_bulk_queue *bq = this_cpu_ptr(obj->bulkq);\n\n\tif (unlikely(bq->count == DEV_MAP_BULK_SIZE))\n\t\tbq_xmit_all(obj, bq, 0, true);\n\n\t/* Ingress dev_rx will be the same for all xdp_frame's in\n\t * bulk_queue, because bq stored per-CPU and must be flushed\n\t * from net_device drivers NAPI func end.\n\t */\n\tif (!bq->dev_rx)\n\t\tbq->dev_rx = dev_rx;\n\n\tbq->q[bq->count++] = xdpf;\n\treturn 0;\n}",
    "includes": [
      "#include <trace/events/xdp.h>",
      "#include <linux/filter.h>",
      "#include <net/xdp.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [
      "#define DEV_MAP_BULK_SIZE 16"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bq_xmit_all",
          "args": [
            "obj",
            "bq",
            "0",
            "true"
          ],
          "line": 324
        },
        "resolved": true,
        "details": {
          "function_name": "bq_xmit_all",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
          "lines": "220-266",
          "snippet": "static int bq_xmit_all(struct bpf_dtab_netdev *obj,\n\t\t       struct xdp_bulk_queue *bq, u32 flags,\n\t\t       bool in_napi_ctx)\n{\n\tstruct net_device *dev = obj->dev;\n\tint sent = 0, drops = 0, err = 0;\n\tint i;\n\n\tif (unlikely(!bq->count))\n\t\treturn 0;\n\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\n\t\tprefetch(xdpf);\n\t}\n\n\tsent = dev->netdev_ops->ndo_xdp_xmit(dev, bq->count, bq->q, flags);\n\tif (sent < 0) {\n\t\terr = sent;\n\t\tsent = 0;\n\t\tgoto error;\n\t}\n\tdrops = bq->count - sent;\nout:\n\tbq->count = 0;\n\n\ttrace_xdp_devmap_xmit(&obj->dtab->map, obj->bit,\n\t\t\t      sent, drops, bq->dev_rx, dev, err);\n\tbq->dev_rx = NULL;\n\treturn 0;\nerror:\n\t/* If ndo_xdp_xmit fails with an errno, no frames have been\n\t * xmit'ed and it's our responsibility to them free all.\n\t */\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\n\t\t/* RX path under NAPI protection, can return frames faster */\n\t\tif (likely(in_napi_ctx))\n\t\t\txdp_return_frame_rx_napi(xdpf);\n\t\telse\n\t\t\txdp_return_frame(xdpf);\n\t\tdrops++;\n\t}\n\tgoto out;\n}",
          "includes": [
            "#include <trace/events/xdp.h>",
            "#include <linux/filter.h>",
            "#include <net/xdp.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\nstatic int bq_xmit_all(struct bpf_dtab_netdev *obj,\n\t\t       struct xdp_bulk_queue *bq, u32 flags,\n\t\t       bool in_napi_ctx)\n{\n\tstruct net_device *dev = obj->dev;\n\tint sent = 0, drops = 0, err = 0;\n\tint i;\n\n\tif (unlikely(!bq->count))\n\t\treturn 0;\n\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\n\t\tprefetch(xdpf);\n\t}\n\n\tsent = dev->netdev_ops->ndo_xdp_xmit(dev, bq->count, bq->q, flags);\n\tif (sent < 0) {\n\t\terr = sent;\n\t\tsent = 0;\n\t\tgoto error;\n\t}\n\tdrops = bq->count - sent;\nout:\n\tbq->count = 0;\n\n\ttrace_xdp_devmap_xmit(&obj->dtab->map, obj->bit,\n\t\t\t      sent, drops, bq->dev_rx, dev, err);\n\tbq->dev_rx = NULL;\n\treturn 0;\nerror:\n\t/* If ndo_xdp_xmit fails with an errno, no frames have been\n\t * xmit'ed and it's our responsibility to them free all.\n\t */\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\n\t\t/* RX path under NAPI protection, can return frames faster */\n\t\tif (likely(in_napi_ctx))\n\t\t\txdp_return_frame_rx_napi(xdpf);\n\t\telse\n\t\t\txdp_return_frame(xdpf);\n\t\tdrops++;\n\t}\n\tgoto out;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "bq->count == DEV_MAP_BULK_SIZE"
          ],
          "line": 323
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "obj->bulkq"
          ],
          "line": 321
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\n#define DEV_MAP_BULK_SIZE 16\n\nstatic int bq_enqueue(struct bpf_dtab_netdev *obj, struct xdp_frame *xdpf,\n\t\t      struct net_device *dev_rx)\n\n{\n\tstruct xdp_bulk_queue *bq = this_cpu_ptr(obj->bulkq);\n\n\tif (unlikely(bq->count == DEV_MAP_BULK_SIZE))\n\t\tbq_xmit_all(obj, bq, 0, true);\n\n\t/* Ingress dev_rx will be the same for all xdp_frame's in\n\t * bulk_queue, because bq stored per-CPU and must be flushed\n\t * from net_device drivers NAPI func end.\n\t */\n\tif (!bq->dev_rx)\n\t\tbq->dev_rx = dev_rx;\n\n\tbq->q[bq->count++] = xdpf;\n\treturn 0;\n}"
  },
  {
    "function_name": "__dev_map_lookup_elem",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
    "lines": "302-312",
    "snippet": "struct bpf_dtab_netdev *__dev_map_lookup_elem(struct bpf_map *map, u32 key)\n{\n\tstruct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);\n\tstruct bpf_dtab_netdev *obj;\n\n\tif (key >= map->max_entries)\n\t\treturn NULL;\n\n\tobj = READ_ONCE(dtab->netdev_map[key]);\n\treturn obj;\n}",
    "includes": [
      "#include <trace/events/xdp.h>",
      "#include <linux/filter.h>",
      "#include <net/xdp.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "dtab->netdev_map[key]"
          ],
          "line": 310
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_dtab",
            "map"
          ],
          "line": 304
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\nstruct bpf_dtab_netdev *__dev_map_lookup_elem(struct bpf_map *map, u32 key)\n{\n\tstruct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);\n\tstruct bpf_dtab_netdev *obj;\n\n\tif (key >= map->max_entries)\n\t\treturn NULL;\n\n\tobj = READ_ONCE(dtab->netdev_map[key]);\n\treturn obj;\n}"
  },
  {
    "function_name": "__dev_map_flush",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
    "lines": "275-296",
    "snippet": "void __dev_map_flush(struct bpf_map *map)\n{\n\tstruct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);\n\tunsigned long *bitmap = this_cpu_ptr(dtab->flush_needed);\n\tu32 bit;\n\n\tfor_each_set_bit(bit, bitmap, map->max_entries) {\n\t\tstruct bpf_dtab_netdev *dev = READ_ONCE(dtab->netdev_map[bit]);\n\t\tstruct xdp_bulk_queue *bq;\n\n\t\t/* This is possible if the dev entry is removed by user space\n\t\t * between xdp redirect and flush op.\n\t\t */\n\t\tif (unlikely(!dev))\n\t\t\tcontinue;\n\n\t\t__clear_bit(bit, bitmap);\n\n\t\tbq = this_cpu_ptr(dev->bulkq);\n\t\tbq_xmit_all(dev, bq, XDP_XMIT_FLUSH, true);\n\t}\n}",
    "includes": [
      "#include <trace/events/xdp.h>",
      "#include <linux/filter.h>",
      "#include <net/xdp.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bq_xmit_all",
          "args": [
            "dev",
            "bq",
            "XDP_XMIT_FLUSH",
            "true"
          ],
          "line": 294
        },
        "resolved": true,
        "details": {
          "function_name": "bq_xmit_all",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
          "lines": "220-266",
          "snippet": "static int bq_xmit_all(struct bpf_dtab_netdev *obj,\n\t\t       struct xdp_bulk_queue *bq, u32 flags,\n\t\t       bool in_napi_ctx)\n{\n\tstruct net_device *dev = obj->dev;\n\tint sent = 0, drops = 0, err = 0;\n\tint i;\n\n\tif (unlikely(!bq->count))\n\t\treturn 0;\n\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\n\t\tprefetch(xdpf);\n\t}\n\n\tsent = dev->netdev_ops->ndo_xdp_xmit(dev, bq->count, bq->q, flags);\n\tif (sent < 0) {\n\t\terr = sent;\n\t\tsent = 0;\n\t\tgoto error;\n\t}\n\tdrops = bq->count - sent;\nout:\n\tbq->count = 0;\n\n\ttrace_xdp_devmap_xmit(&obj->dtab->map, obj->bit,\n\t\t\t      sent, drops, bq->dev_rx, dev, err);\n\tbq->dev_rx = NULL;\n\treturn 0;\nerror:\n\t/* If ndo_xdp_xmit fails with an errno, no frames have been\n\t * xmit'ed and it's our responsibility to them free all.\n\t */\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\n\t\t/* RX path under NAPI protection, can return frames faster */\n\t\tif (likely(in_napi_ctx))\n\t\t\txdp_return_frame_rx_napi(xdpf);\n\t\telse\n\t\t\txdp_return_frame(xdpf);\n\t\tdrops++;\n\t}\n\tgoto out;\n}",
          "includes": [
            "#include <trace/events/xdp.h>",
            "#include <linux/filter.h>",
            "#include <net/xdp.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\nstatic int bq_xmit_all(struct bpf_dtab_netdev *obj,\n\t\t       struct xdp_bulk_queue *bq, u32 flags,\n\t\t       bool in_napi_ctx)\n{\n\tstruct net_device *dev = obj->dev;\n\tint sent = 0, drops = 0, err = 0;\n\tint i;\n\n\tif (unlikely(!bq->count))\n\t\treturn 0;\n\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\n\t\tprefetch(xdpf);\n\t}\n\n\tsent = dev->netdev_ops->ndo_xdp_xmit(dev, bq->count, bq->q, flags);\n\tif (sent < 0) {\n\t\terr = sent;\n\t\tsent = 0;\n\t\tgoto error;\n\t}\n\tdrops = bq->count - sent;\nout:\n\tbq->count = 0;\n\n\ttrace_xdp_devmap_xmit(&obj->dtab->map, obj->bit,\n\t\t\t      sent, drops, bq->dev_rx, dev, err);\n\tbq->dev_rx = NULL;\n\treturn 0;\nerror:\n\t/* If ndo_xdp_xmit fails with an errno, no frames have been\n\t * xmit'ed and it's our responsibility to them free all.\n\t */\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\n\t\t/* RX path under NAPI protection, can return frames faster */\n\t\tif (likely(in_napi_ctx))\n\t\t\txdp_return_frame_rx_napi(xdpf);\n\t\telse\n\t\t\txdp_return_frame(xdpf);\n\t\tdrops++;\n\t}\n\tgoto out;\n}"
        }
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "dev->bulkq"
          ],
          "line": 293
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__clear_bit",
          "args": [
            "bit",
            "bitmap"
          ],
          "line": 291
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!dev"
          ],
          "line": 288
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "dtab->netdev_map[bit]"
          ],
          "line": 282
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "for_each_set_bit",
          "args": [
            "bit",
            "bitmap",
            "map->max_entries"
          ],
          "line": 281
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "dtab->flush_needed"
          ],
          "line": 278
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_dtab",
            "map"
          ],
          "line": 277
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\nvoid __dev_map_flush(struct bpf_map *map)\n{\n\tstruct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);\n\tunsigned long *bitmap = this_cpu_ptr(dtab->flush_needed);\n\tu32 bit;\n\n\tfor_each_set_bit(bit, bitmap, map->max_entries) {\n\t\tstruct bpf_dtab_netdev *dev = READ_ONCE(dtab->netdev_map[bit]);\n\t\tstruct xdp_bulk_queue *bq;\n\n\t\t/* This is possible if the dev entry is removed by user space\n\t\t * between xdp redirect and flush op.\n\t\t */\n\t\tif (unlikely(!dev))\n\t\t\tcontinue;\n\n\t\t__clear_bit(bit, bitmap);\n\n\t\tbq = this_cpu_ptr(dev->bulkq);\n\t\tbq_xmit_all(dev, bq, XDP_XMIT_FLUSH, true);\n\t}\n}"
  },
  {
    "function_name": "bq_xmit_all",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
    "lines": "220-266",
    "snippet": "static int bq_xmit_all(struct bpf_dtab_netdev *obj,\n\t\t       struct xdp_bulk_queue *bq, u32 flags,\n\t\t       bool in_napi_ctx)\n{\n\tstruct net_device *dev = obj->dev;\n\tint sent = 0, drops = 0, err = 0;\n\tint i;\n\n\tif (unlikely(!bq->count))\n\t\treturn 0;\n\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\n\t\tprefetch(xdpf);\n\t}\n\n\tsent = dev->netdev_ops->ndo_xdp_xmit(dev, bq->count, bq->q, flags);\n\tif (sent < 0) {\n\t\terr = sent;\n\t\tsent = 0;\n\t\tgoto error;\n\t}\n\tdrops = bq->count - sent;\nout:\n\tbq->count = 0;\n\n\ttrace_xdp_devmap_xmit(&obj->dtab->map, obj->bit,\n\t\t\t      sent, drops, bq->dev_rx, dev, err);\n\tbq->dev_rx = NULL;\n\treturn 0;\nerror:\n\t/* If ndo_xdp_xmit fails with an errno, no frames have been\n\t * xmit'ed and it's our responsibility to them free all.\n\t */\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\n\t\t/* RX path under NAPI protection, can return frames faster */\n\t\tif (likely(in_napi_ctx))\n\t\t\txdp_return_frame_rx_napi(xdpf);\n\t\telse\n\t\t\txdp_return_frame(xdpf);\n\t\tdrops++;\n\t}\n\tgoto out;\n}",
    "includes": [
      "#include <trace/events/xdp.h>",
      "#include <linux/filter.h>",
      "#include <net/xdp.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "xdp_return_frame",
          "args": [
            "xdpf"
          ],
          "line": 262
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "xdp_return_frame_rx_napi",
          "args": [
            "xdpf"
          ],
          "line": 260
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "in_napi_ctx"
          ],
          "line": 259
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_xdp_devmap_xmit",
          "args": [
            "&obj->dtab->map",
            "obj->bit",
            "sent",
            "drops",
            "bq->dev_rx",
            "dev",
            "err"
          ],
          "line": 247
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "dev->netdev_ops->ndo_xdp_xmit",
          "args": [
            "dev",
            "bq->count",
            "bq->q",
            "flags"
          ],
          "line": 237
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "prefetch",
          "args": [
            "xdpf"
          ],
          "line": 234
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!bq->count"
          ],
          "line": 228
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\nstatic int bq_xmit_all(struct bpf_dtab_netdev *obj,\n\t\t       struct xdp_bulk_queue *bq, u32 flags,\n\t\t       bool in_napi_ctx)\n{\n\tstruct net_device *dev = obj->dev;\n\tint sent = 0, drops = 0, err = 0;\n\tint i;\n\n\tif (unlikely(!bq->count))\n\t\treturn 0;\n\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\n\t\tprefetch(xdpf);\n\t}\n\n\tsent = dev->netdev_ops->ndo_xdp_xmit(dev, bq->count, bq->q, flags);\n\tif (sent < 0) {\n\t\terr = sent;\n\t\tsent = 0;\n\t\tgoto error;\n\t}\n\tdrops = bq->count - sent;\nout:\n\tbq->count = 0;\n\n\ttrace_xdp_devmap_xmit(&obj->dtab->map, obj->bit,\n\t\t\t      sent, drops, bq->dev_rx, dev, err);\n\tbq->dev_rx = NULL;\n\treturn 0;\nerror:\n\t/* If ndo_xdp_xmit fails with an errno, no frames have been\n\t * xmit'ed and it's our responsibility to them free all.\n\t */\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\n\t\t/* RX path under NAPI protection, can return frames faster */\n\t\tif (likely(in_napi_ctx))\n\t\t\txdp_return_frame_rx_napi(xdpf);\n\t\telse\n\t\t\txdp_return_frame(xdpf);\n\t\tdrops++;\n\t}\n\tgoto out;\n}"
  },
  {
    "function_name": "__dev_map_insert_ctx",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
    "lines": "212-218",
    "snippet": "void __dev_map_insert_ctx(struct bpf_map *map, u32 bit)\n{\n\tstruct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);\n\tunsigned long *bitmap = this_cpu_ptr(dtab->flush_needed);\n\n\t__set_bit(bit, bitmap);\n}",
    "includes": [
      "#include <trace/events/xdp.h>",
      "#include <linux/filter.h>",
      "#include <net/xdp.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__set_bit",
          "args": [
            "bit",
            "bitmap"
          ],
          "line": 217
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "dtab->flush_needed"
          ],
          "line": 215
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_dtab",
            "map"
          ],
          "line": 214
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\nvoid __dev_map_insert_ctx(struct bpf_map *map, u32 bit)\n{\n\tstruct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);\n\tunsigned long *bitmap = this_cpu_ptr(dtab->flush_needed);\n\n\t__set_bit(bit, bitmap);\n}"
  },
  {
    "function_name": "dev_map_get_next_key",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
    "lines": "195-210",
    "snippet": "static int dev_map_get_next_key(struct bpf_map *map, void *key, void *next_key)\n{\n\tstruct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);\n\tu32 index = key ? *(u32 *)key : U32_MAX;\n\tu32 *next = next_key;\n\n\tif (index >= dtab->map.max_entries) {\n\t\t*next = 0;\n\t\treturn 0;\n\t}\n\n\tif (index == dtab->map.max_entries - 1)\n\t\treturn -ENOENT;\n\t*next = index + 1;\n\treturn 0;\n}",
    "includes": [
      "#include <trace/events/xdp.h>",
      "#include <linux/filter.h>",
      "#include <net/xdp.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_dtab",
            "map"
          ],
          "line": 197
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\nstatic int dev_map_get_next_key(struct bpf_map *map, void *key, void *next_key)\n{\n\tstruct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);\n\tu32 index = key ? *(u32 *)key : U32_MAX;\n\tu32 *next = next_key;\n\n\tif (index >= dtab->map.max_entries) {\n\t\t*next = 0;\n\t\treturn 0;\n\t}\n\n\tif (index == dtab->map.max_entries - 1)\n\t\treturn -ENOENT;\n\t*next = index + 1;\n\treturn 0;\n}"
  },
  {
    "function_name": "dev_map_free",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
    "lines": "147-193",
    "snippet": "static void dev_map_free(struct bpf_map *map)\n{\n\tstruct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);\n\tint i, cpu;\n\n\t/* At this point bpf_prog->aux->refcnt == 0 and this map->refcnt == 0,\n\t * so the programs (can be more than one that used this map) were\n\t * disconnected from events. Wait for outstanding critical sections in\n\t * these programs to complete. The rcu critical section only guarantees\n\t * no further reads against netdev_map. It does __not__ ensure pending\n\t * flush operations (if any) are complete.\n\t */\n\n\tspin_lock(&dev_map_lock);\n\tlist_del_rcu(&dtab->list);\n\tspin_unlock(&dev_map_lock);\n\n\tbpf_clear_redirect_map(map);\n\tsynchronize_rcu();\n\n\t/* To ensure all pending flush operations have completed wait for flush\n\t * bitmap to indicate all flush_needed bits to be zero on _all_ cpus.\n\t * Because the above synchronize_rcu() ensures the map is disconnected\n\t * from the program we can assume no new bits will be set.\n\t */\n\tfor_each_online_cpu(cpu) {\n\t\tunsigned long *bitmap = per_cpu_ptr(dtab->flush_needed, cpu);\n\n\t\twhile (!bitmap_empty(bitmap, dtab->map.max_entries))\n\t\t\tcond_resched();\n\t}\n\n\tfor (i = 0; i < dtab->map.max_entries; i++) {\n\t\tstruct bpf_dtab_netdev *dev;\n\n\t\tdev = dtab->netdev_map[i];\n\t\tif (!dev)\n\t\t\tcontinue;\n\n\t\tdev_put(dev->dev);\n\t\tkfree(dev);\n\t}\n\n\tfree_percpu(dtab->flush_needed);\n\tbpf_map_area_free(dtab->netdev_map);\n\tkfree(dtab);\n}",
    "includes": [
      "#include <trace/events/xdp.h>",
      "#include <linux/filter.h>",
      "#include <net/xdp.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_SPINLOCK(dev_map_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "dtab"
          ],
          "line": 192
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/params.c",
          "lines": "73-86",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_area_free",
          "args": [
            "dtab->netdev_map"
          ],
          "line": 191
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_area_free",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/syscall.c",
          "lines": "156-159",
          "snippet": "void bpf_map_area_free(void *area)\n{\n\tkvfree(area);\n}",
          "includes": [
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/version.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/version.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf.h>\n\nvoid bpf_map_area_free(void *area)\n{\n\tkvfree(area);\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_percpu",
          "args": [
            "dtab->flush_needed"
          ],
          "line": 190
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_array_free_percpu",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/arraymap.c",
          "lines": "27-35",
          "snippet": "static void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include <uapi/linux/btf.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/filter.h>",
            "#include <linux/mm.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include <uapi/linux/btf.h>\n#include <linux/perf_event.h>\n#include <linux/filter.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "dev_put",
          "args": [
            "dev->dev"
          ],
          "line": 186
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cond_resched",
          "args": [],
          "line": 176
        },
        "resolved": true,
        "details": {
          "function_name": "_cond_resched",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/core.c",
          "lines": "4957-4965",
          "snippet": "int __sched _cond_resched(void)\n{\n\tif (should_resched(0)) {\n\t\tpreempt_schedule_common();\n\t\treturn 1;\n\t}\n\trcu_all_qs();\n\treturn 0;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include <trace/events/sched.h>",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/kcov.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include <trace/events/sched.h>\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/kcov.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n\nstatic void __sched;\nstatic void __sched;\n\nint __sched _cond_resched(void)\n{\n\tif (should_resched(0)) {\n\t\tpreempt_schedule_common();\n\t\treturn 1;\n\t}\n\trcu_all_qs();\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "bitmap_empty",
          "args": [
            "bitmap",
            "dtab->map.max_entries"
          ],
          "line": 175
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "dtab->flush_needed",
            "cpu"
          ],
          "line": 173
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "synchronize_rcu",
          "args": [],
          "line": 165
        },
        "resolved": true,
        "details": {
          "function_name": "synchronize_rcu_tasks",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/update.c",
          "lines": "603-611",
          "snippet": "void synchronize_rcu_tasks(void)\n{\n\t/* Complain if the scheduler has not started.  */\n\tRCU_LOCKDEP_WARN(rcu_scheduler_active == RCU_SCHEDULER_INACTIVE,\n\t\t\t \"synchronize_rcu_tasks called too soon\");\n\n\t/* Wait for the grace period. */\n\twait_rcu_gp(call_rcu_tasks);\n}",
          "includes": [
            "#include \"rcu.h\"",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu.h\"\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nvoid synchronize_rcu_tasks(void)\n{\n\t/* Complain if the scheduler has not started.  */\n\tRCU_LOCKDEP_WARN(rcu_scheduler_active == RCU_SCHEDULER_INACTIVE,\n\t\t\t \"synchronize_rcu_tasks called too soon\");\n\n\t/* Wait for the grace period. */\n\twait_rcu_gp(call_rcu_tasks);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_clear_redirect_map",
          "args": [
            "map"
          ],
          "line": 164
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_unlock",
          "args": [
            "&dev_map_lock"
          ],
          "line": 162
        },
        "resolved": true,
        "details": {
          "function_name": "__pv_queued_spin_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/qspinlock_paravirt.h",
          "lines": "546-560",
          "snippet": "__visible void __pv_queued_spin_unlock(struct qspinlock *lock)\n{\n\tu8 locked;\n\n\t/*\n\t * We must not unlock if SLOW, because in that case we must first\n\t * unhash. Otherwise it would be possible to have multiple @lock\n\t * entries, which would be BAD.\n\t */\n\tlocked = cmpxchg_release(&lock->locked, _Q_LOCKED_VAL, 0);\n\tif (likely(locked == _Q_LOCKED_VAL))\n\t\treturn;\n\n\t__pv_queued_spin_unlock_slowpath(lock, locked);\n}",
          "includes": [
            "#include <asm/qspinlock_paravirt.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/memblock.h>",
            "#include <linux/hash.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/qspinlock_paravirt.h>\n#include <linux/debug_locks.h>\n#include <linux/memblock.h>\n#include <linux/hash.h>\n\n__visible void __pv_queued_spin_unlock(struct qspinlock *lock)\n{\n\tu8 locked;\n\n\t/*\n\t * We must not unlock if SLOW, because in that case we must first\n\t * unhash. Otherwise it would be possible to have multiple @lock\n\t * entries, which would be BAD.\n\t */\n\tlocked = cmpxchg_release(&lock->locked, _Q_LOCKED_VAL, 0);\n\tif (likely(locked == _Q_LOCKED_VAL))\n\t\treturn;\n\n\t__pv_queued_spin_unlock_slowpath(lock, locked);\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_del_rcu",
          "args": [
            "&dtab->list"
          ],
          "line": 161
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_lock",
          "args": [
            "&dev_map_lock"
          ],
          "line": 160
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "166-169",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_dtab",
            "map"
          ],
          "line": 149
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\nstatic DEFINE_SPINLOCK(dev_map_lock);\n\nstatic void dev_map_free(struct bpf_map *map)\n{\n\tstruct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);\n\tint i, cpu;\n\n\t/* At this point bpf_prog->aux->refcnt == 0 and this map->refcnt == 0,\n\t * so the programs (can be more than one that used this map) were\n\t * disconnected from events. Wait for outstanding critical sections in\n\t * these programs to complete. The rcu critical section only guarantees\n\t * no further reads against netdev_map. It does __not__ ensure pending\n\t * flush operations (if any) are complete.\n\t */\n\n\tspin_lock(&dev_map_lock);\n\tlist_del_rcu(&dtab->list);\n\tspin_unlock(&dev_map_lock);\n\n\tbpf_clear_redirect_map(map);\n\tsynchronize_rcu();\n\n\t/* To ensure all pending flush operations have completed wait for flush\n\t * bitmap to indicate all flush_needed bits to be zero on _all_ cpus.\n\t * Because the above synchronize_rcu() ensures the map is disconnected\n\t * from the program we can assume no new bits will be set.\n\t */\n\tfor_each_online_cpu(cpu) {\n\t\tunsigned long *bitmap = per_cpu_ptr(dtab->flush_needed, cpu);\n\n\t\twhile (!bitmap_empty(bitmap, dtab->map.max_entries))\n\t\t\tcond_resched();\n\t}\n\n\tfor (i = 0; i < dtab->map.max_entries; i++) {\n\t\tstruct bpf_dtab_netdev *dev;\n\n\t\tdev = dtab->netdev_map[i];\n\t\tif (!dev)\n\t\t\tcontinue;\n\n\t\tdev_put(dev->dev);\n\t\tkfree(dev);\n\t}\n\n\tfree_percpu(dtab->flush_needed);\n\tbpf_map_area_free(dtab->netdev_map);\n\tkfree(dtab);\n}"
  },
  {
    "function_name": "dev_map_alloc",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
    "lines": "88-145",
    "snippet": "static struct bpf_map *dev_map_alloc(union bpf_attr *attr)\n{\n\tstruct bpf_dtab *dtab;\n\tint err = -EINVAL;\n\tu64 cost;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn ERR_PTR(-EPERM);\n\n\t/* check sanity of attributes */\n\tif (attr->max_entries == 0 || attr->key_size != 4 ||\n\t    attr->value_size != 4 || attr->map_flags & ~DEV_CREATE_FLAG_MASK)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tdtab = kzalloc(sizeof(*dtab), GFP_USER);\n\tif (!dtab)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tbpf_map_init_from_attr(&dtab->map, attr);\n\n\t/* make sure page count doesn't overflow */\n\tcost = (u64) dtab->map.max_entries * sizeof(struct bpf_dtab_netdev *);\n\tcost += dev_map_bitmap_size(attr) * num_possible_cpus();\n\tif (cost >= U32_MAX - PAGE_SIZE)\n\t\tgoto free_dtab;\n\n\tdtab->map.pages = round_up(cost, PAGE_SIZE) >> PAGE_SHIFT;\n\n\t/* if map size is larger than memlock limit, reject it early */\n\terr = bpf_map_precharge_memlock(dtab->map.pages);\n\tif (err)\n\t\tgoto free_dtab;\n\n\terr = -ENOMEM;\n\n\t/* A per cpu bitfield with a bit per possible net device */\n\tdtab->flush_needed = __alloc_percpu_gfp(dev_map_bitmap_size(attr),\n\t\t\t\t\t\t__alignof__(unsigned long),\n\t\t\t\t\t\tGFP_KERNEL | __GFP_NOWARN);\n\tif (!dtab->flush_needed)\n\t\tgoto free_dtab;\n\n\tdtab->netdev_map = bpf_map_area_alloc(dtab->map.max_entries *\n\t\t\t\t\t      sizeof(struct bpf_dtab_netdev *),\n\t\t\t\t\t      dtab->map.numa_node);\n\tif (!dtab->netdev_map)\n\t\tgoto free_dtab;\n\n\tspin_lock(&dev_map_lock);\n\tlist_add_tail_rcu(&dtab->list, &dev_map_list);\n\tspin_unlock(&dev_map_lock);\n\n\treturn &dtab->map;\nfree_dtab:\n\tfree_percpu(dtab->flush_needed);\n\tkfree(dtab);\n\treturn ERR_PTR(err);\n}",
    "includes": [
      "#include <trace/events/xdp.h>",
      "#include <linux/filter.h>",
      "#include <net/xdp.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [
      "#define DEV_CREATE_FLAG_MASK \\\n\t(BPF_F_NUMA_NODE | BPF_F_RDONLY | BPF_F_WRONLY)"
    ],
    "globals_used": [
      "static DEFINE_SPINLOCK(dev_map_lock);",
      "static LIST_HEAD(dev_map_list);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "err"
          ],
          "line": 144
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "dtab"
          ],
          "line": 143
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/params.c",
          "lines": "73-86",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_percpu",
          "args": [
            "dtab->flush_needed"
          ],
          "line": 142
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_array_free_percpu",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/arraymap.c",
          "lines": "27-35",
          "snippet": "static void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include <uapi/linux/btf.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/filter.h>",
            "#include <linux/mm.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include <uapi/linux/btf.h>\n#include <linux/perf_event.h>\n#include <linux/filter.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "spin_unlock",
          "args": [
            "&dev_map_lock"
          ],
          "line": 138
        },
        "resolved": true,
        "details": {
          "function_name": "__pv_queued_spin_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/qspinlock_paravirt.h",
          "lines": "546-560",
          "snippet": "__visible void __pv_queued_spin_unlock(struct qspinlock *lock)\n{\n\tu8 locked;\n\n\t/*\n\t * We must not unlock if SLOW, because in that case we must first\n\t * unhash. Otherwise it would be possible to have multiple @lock\n\t * entries, which would be BAD.\n\t */\n\tlocked = cmpxchg_release(&lock->locked, _Q_LOCKED_VAL, 0);\n\tif (likely(locked == _Q_LOCKED_VAL))\n\t\treturn;\n\n\t__pv_queued_spin_unlock_slowpath(lock, locked);\n}",
          "includes": [
            "#include <asm/qspinlock_paravirt.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/memblock.h>",
            "#include <linux/hash.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/qspinlock_paravirt.h>\n#include <linux/debug_locks.h>\n#include <linux/memblock.h>\n#include <linux/hash.h>\n\n__visible void __pv_queued_spin_unlock(struct qspinlock *lock)\n{\n\tu8 locked;\n\n\t/*\n\t * We must not unlock if SLOW, because in that case we must first\n\t * unhash. Otherwise it would be possible to have multiple @lock\n\t * entries, which would be BAD.\n\t */\n\tlocked = cmpxchg_release(&lock->locked, _Q_LOCKED_VAL, 0);\n\tif (likely(locked == _Q_LOCKED_VAL))\n\t\treturn;\n\n\t__pv_queued_spin_unlock_slowpath(lock, locked);\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_add_tail_rcu",
          "args": [
            "&dtab->list",
            "&dev_map_list"
          ],
          "line": 137
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_lock",
          "args": [
            "&dev_map_lock"
          ],
          "line": 136
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "166-169",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_area_alloc",
          "args": [
            "dtab->map.max_entries *\n\t\t\t\t\t      sizeof(struct bpf_dtab_netdev *)",
            "dtab->map.numa_node"
          ],
          "line": 130
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_area_alloc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/syscall.c",
          "lines": "137-154",
          "snippet": "void *bpf_map_area_alloc(size_t size, int numa_node)\n{\n\t/* We definitely need __GFP_NORETRY, so OOM killer doesn't\n\t * trigger under memory pressure as we really just want to\n\t * fail instead.\n\t */\n\tconst gfp_t flags = __GFP_NOWARN | __GFP_NORETRY | __GFP_ZERO;\n\tvoid *area;\n\n\tif (size <= (PAGE_SIZE << PAGE_ALLOC_COSTLY_ORDER)) {\n\t\tarea = kmalloc_node(size, GFP_USER | flags, numa_node);\n\t\tif (area != NULL)\n\t\t\treturn area;\n\t}\n\n\treturn __vmalloc_node_flags_caller(size, numa_node, GFP_KERNEL | flags,\n\t\t\t\t\t   __builtin_return_address(0));\n}",
          "includes": [
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/version.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/version.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf.h>\n\nvoid *bpf_map_area_alloc(size_t size, int numa_node)\n{\n\t/* We definitely need __GFP_NORETRY, so OOM killer doesn't\n\t * trigger under memory pressure as we really just want to\n\t * fail instead.\n\t */\n\tconst gfp_t flags = __GFP_NOWARN | __GFP_NORETRY | __GFP_ZERO;\n\tvoid *area;\n\n\tif (size <= (PAGE_SIZE << PAGE_ALLOC_COSTLY_ORDER)) {\n\t\tarea = kmalloc_node(size, GFP_USER | flags, numa_node);\n\t\tif (area != NULL)\n\t\t\treturn area;\n\t}\n\n\treturn __vmalloc_node_flags_caller(size, numa_node, GFP_KERNEL | flags,\n\t\t\t\t\t   __builtin_return_address(0));\n}"
        }
      },
      {
        "call_info": {
          "callee": "__alloc_percpu_gfp",
          "args": [
            "dev_map_bitmap_size(attr)",
            "__alignof__(unsigned long)",
            "GFP_KERNEL | __GFP_NOWARN"
          ],
          "line": 124
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "dev_map_bitmap_size",
          "args": [
            "attr"
          ],
          "line": 124
        },
        "resolved": true,
        "details": {
          "function_name": "dev_map_bitmap_size",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
          "lines": "83-86",
          "snippet": "static u64 dev_map_bitmap_size(const union bpf_attr *attr)\n{\n\treturn BITS_TO_LONGS((u64) attr->max_entries) * sizeof(unsigned long);\n}",
          "includes": [
            "#include <trace/events/xdp.h>",
            "#include <linux/filter.h>",
            "#include <net/xdp.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\nstatic u64 dev_map_bitmap_size(const union bpf_attr *attr)\n{\n\treturn BITS_TO_LONGS((u64) attr->max_entries) * sizeof(unsigned long);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_precharge_memlock",
          "args": [
            "dtab->map.pages"
          ],
          "line": 117
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_precharge_memlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/syscall.c",
          "lines": "171-182",
          "snippet": "int bpf_map_precharge_memlock(u32 pages)\n{\n\tstruct user_struct *user = get_current_user();\n\tunsigned long memlock_limit, cur;\n\n\tmemlock_limit = rlimit(RLIMIT_MEMLOCK) >> PAGE_SHIFT;\n\tcur = atomic_long_read(&user->locked_vm);\n\tfree_uid(user);\n\tif (cur + pages > memlock_limit)\n\t\treturn -EPERM;\n\treturn 0;\n}",
          "includes": [
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/version.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/version.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf.h>\n\nint bpf_map_precharge_memlock(u32 pages)\n{\n\tstruct user_struct *user = get_current_user();\n\tunsigned long memlock_limit, cur;\n\n\tmemlock_limit = rlimit(RLIMIT_MEMLOCK) >> PAGE_SHIFT;\n\tcur = atomic_long_read(&user->locked_vm);\n\tfree_uid(user);\n\tif (cur + pages > memlock_limit)\n\t\treturn -EPERM;\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "cost",
            "PAGE_SIZE"
          ],
          "line": 114
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "num_possible_cpus",
          "args": [],
          "line": 110
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_map_init_from_attr",
          "args": [
            "&dtab->map",
            "attr"
          ],
          "line": 106
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_init_from_attr",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/syscall.c",
          "lines": "161-169",
          "snippet": "void bpf_map_init_from_attr(struct bpf_map *map, union bpf_attr *attr)\n{\n\tmap->map_type = attr->map_type;\n\tmap->key_size = attr->key_size;\n\tmap->value_size = attr->value_size;\n\tmap->max_entries = attr->max_entries;\n\tmap->map_flags = attr->map_flags;\n\tmap->numa_node = bpf_map_attr_numa_node(attr);\n}",
          "includes": [
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/version.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/version.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf.h>\n\nvoid bpf_map_init_from_attr(struct bpf_map *map, union bpf_attr *attr)\n{\n\tmap->map_type = attr->map_type;\n\tmap->key_size = attr->key_size;\n\tmap->value_size = attr->value_size;\n\tmap->max_entries = attr->max_entries;\n\tmap->map_flags = attr->map_flags;\n\tmap->numa_node = bpf_map_attr_numa_node(attr);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-ENOMEM"
          ],
          "line": 104
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kzalloc",
          "args": [
            "sizeof(*dtab)",
            "GFP_USER"
          ],
          "line": 102
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-EINVAL"
          ],
          "line": 100
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-EPERM"
          ],
          "line": 95
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "capable",
          "args": [
            "CAP_NET_ADMIN"
          ],
          "line": 94
        },
        "resolved": true,
        "details": {
          "function_name": "capable",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/capability.c",
          "lines": "429-432",
          "snippet": "bool capable(int cap)\n{\n\treturn ns_capable(&init_user_ns, cap);\n}",
          "includes": [
            "#include <linux/uaccess.h>",
            "#include <linux/user_namespace.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/security.h>",
            "#include <linux/export.h>",
            "#include <linux/mm.h>",
            "#include <linux/capability.h>",
            "#include <linux/audit.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/uaccess.h>\n#include <linux/user_namespace.h>\n#include <linux/pid_namespace.h>\n#include <linux/syscalls.h>\n#include <linux/security.h>\n#include <linux/export.h>\n#include <linux/mm.h>\n#include <linux/capability.h>\n#include <linux/audit.h>\n\nbool capable(int cap)\n{\n\treturn ns_capable(&init_user_ns, cap);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\n#define DEV_CREATE_FLAG_MASK \\\n\t(BPF_F_NUMA_NODE | BPF_F_RDONLY | BPF_F_WRONLY)\n\nstatic DEFINE_SPINLOCK(dev_map_lock);\nstatic LIST_HEAD(dev_map_list);\n\nstatic struct bpf_map *dev_map_alloc(union bpf_attr *attr)\n{\n\tstruct bpf_dtab *dtab;\n\tint err = -EINVAL;\n\tu64 cost;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn ERR_PTR(-EPERM);\n\n\t/* check sanity of attributes */\n\tif (attr->max_entries == 0 || attr->key_size != 4 ||\n\t    attr->value_size != 4 || attr->map_flags & ~DEV_CREATE_FLAG_MASK)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tdtab = kzalloc(sizeof(*dtab), GFP_USER);\n\tif (!dtab)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tbpf_map_init_from_attr(&dtab->map, attr);\n\n\t/* make sure page count doesn't overflow */\n\tcost = (u64) dtab->map.max_entries * sizeof(struct bpf_dtab_netdev *);\n\tcost += dev_map_bitmap_size(attr) * num_possible_cpus();\n\tif (cost >= U32_MAX - PAGE_SIZE)\n\t\tgoto free_dtab;\n\n\tdtab->map.pages = round_up(cost, PAGE_SIZE) >> PAGE_SHIFT;\n\n\t/* if map size is larger than memlock limit, reject it early */\n\terr = bpf_map_precharge_memlock(dtab->map.pages);\n\tif (err)\n\t\tgoto free_dtab;\n\n\terr = -ENOMEM;\n\n\t/* A per cpu bitfield with a bit per possible net device */\n\tdtab->flush_needed = __alloc_percpu_gfp(dev_map_bitmap_size(attr),\n\t\t\t\t\t\t__alignof__(unsigned long),\n\t\t\t\t\t\tGFP_KERNEL | __GFP_NOWARN);\n\tif (!dtab->flush_needed)\n\t\tgoto free_dtab;\n\n\tdtab->netdev_map = bpf_map_area_alloc(dtab->map.max_entries *\n\t\t\t\t\t      sizeof(struct bpf_dtab_netdev *),\n\t\t\t\t\t      dtab->map.numa_node);\n\tif (!dtab->netdev_map)\n\t\tgoto free_dtab;\n\n\tspin_lock(&dev_map_lock);\n\tlist_add_tail_rcu(&dtab->list, &dev_map_list);\n\tspin_unlock(&dev_map_lock);\n\n\treturn &dtab->map;\nfree_dtab:\n\tfree_percpu(dtab->flush_needed);\n\tkfree(dtab);\n\treturn ERR_PTR(err);\n}"
  },
  {
    "function_name": "dev_map_bitmap_size",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/devmap.c",
    "lines": "83-86",
    "snippet": "static u64 dev_map_bitmap_size(const union bpf_attr *attr)\n{\n\treturn BITS_TO_LONGS((u64) attr->max_entries) * sizeof(unsigned long);\n}",
    "includes": [
      "#include <trace/events/xdp.h>",
      "#include <linux/filter.h>",
      "#include <net/xdp.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "BITS_TO_LONGS",
          "args": [
            "(u64) attr->max_entries"
          ],
          "line": 85
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/xdp.h>\n#include <linux/filter.h>\n#include <net/xdp.h>\n#include <linux/bpf.h>\n\nstatic u64 dev_map_bitmap_size(const union bpf_attr *attr)\n{\n\treturn BITS_TO_LONGS((u64) attr->max_entries) * sizeof(unsigned long);\n}"
  }
]