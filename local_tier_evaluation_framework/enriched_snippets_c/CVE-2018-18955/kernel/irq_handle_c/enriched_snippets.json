[
  {
    "function_name": "set_handle_irq",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/handle.c",
    "lines": "214-221",
    "snippet": "int __init set_handle_irq(void (*handle_irq)(struct pt_regs *))\n{\n\tif (handle_arch_irq)\n\t\treturn -EBUSY;\n\n\thandle_arch_irq = handle_irq;\n\treturn 0;\n}",
    "includes": [
      "#include \"internals.h\"",
      "#include <trace/events/irq.h>",
      "#include <linux/kernel_stat.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/sched.h>",
      "#include <linux/random.h>",
      "#include <linux/irq.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"internals.h\"\n#include <trace/events/irq.h>\n#include <linux/kernel_stat.h>\n#include <linux/interrupt.h>\n#include <linux/sched.h>\n#include <linux/random.h>\n#include <linux/irq.h>\n\nint __init set_handle_irq(void (*handle_irq)(struct pt_regs *))\n{\n\tif (handle_arch_irq)\n\t\treturn -EBUSY;\n\n\thandle_arch_irq = handle_irq;\n\treturn 0;\n}"
  },
  {
    "function_name": "handle_irq_event",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/handle.c",
    "lines": "198-211",
    "snippet": "irqreturn_t handle_irq_event(struct irq_desc *desc)\n{\n\tirqreturn_t ret;\n\n\tdesc->istate &= ~IRQS_PENDING;\n\tirqd_set(&desc->irq_data, IRQD_IRQ_INPROGRESS);\n\traw_spin_unlock(&desc->lock);\n\n\tret = handle_irq_event_percpu(desc);\n\n\traw_spin_lock(&desc->lock);\n\tirqd_clear(&desc->irq_data, IRQD_IRQ_INPROGRESS);\n\treturn ret;\n}",
    "includes": [
      "#include \"internals.h\"",
      "#include <trace/events/irq.h>",
      "#include <linux/kernel_stat.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/sched.h>",
      "#include <linux/random.h>",
      "#include <linux/irq.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "irqd_clear",
          "args": [
            "&desc->irq_data",
            "IRQD_IRQ_INPROGRESS"
          ],
          "line": 209
        },
        "resolved": true,
        "details": {
          "function_name": "irqd_clear",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/internals.h",
          "lines": "218-221",
          "snippet": "static inline void irqd_clear(struct irq_data *d, unsigned int mask)\n{\n\t__irqd_to_state(d) &= ~mask;\n}",
          "includes": [
            "#include <linux/debugfs.h>",
            "#include \"settings.h\"",
            "#include \"debug.h\"",
            "#include <linux/sched/clock.h>",
            "#include <linux/pm_runtime.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/irqdesc.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/debugfs.h>\n#include \"settings.h\"\n#include \"debug.h\"\n#include <linux/sched/clock.h>\n#include <linux/pm_runtime.h>\n#include <linux/kernel_stat.h>\n#include <linux/irqdesc.h>\n\nstatic inline void irqd_clear(struct irq_data *d, unsigned int mask)\n{\n\t__irqd_to_state(d) &= ~mask;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock",
          "args": [
            "&desc->lock"
          ],
          "line": 208
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "166-169",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "handle_irq_event_percpu",
          "args": [
            "desc"
          ],
          "line": 206
        },
        "resolved": true,
        "details": {
          "function_name": "handle_irq_event_percpu",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/handle.c",
          "lines": "184-196",
          "snippet": "irqreturn_t handle_irq_event_percpu(struct irq_desc *desc)\n{\n\tirqreturn_t retval;\n\tunsigned int flags = 0;\n\n\tretval = __handle_irq_event_percpu(desc, &flags);\n\n\tadd_interrupt_randomness(desc->irq_data.irq, flags);\n\n\tif (!noirqdebug)\n\t\tnote_interrupt(desc, retval);\n\treturn retval;\n}",
          "includes": [
            "#include \"internals.h\"",
            "#include <trace/events/irq.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/sched.h>",
            "#include <linux/random.h>",
            "#include <linux/irq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internals.h\"\n#include <trace/events/irq.h>\n#include <linux/kernel_stat.h>\n#include <linux/interrupt.h>\n#include <linux/sched.h>\n#include <linux/random.h>\n#include <linux/irq.h>\n\nirqreturn_t handle_irq_event_percpu(struct irq_desc *desc)\n{\n\tirqreturn_t retval;\n\tunsigned int flags = 0;\n\n\tretval = __handle_irq_event_percpu(desc, &flags);\n\n\tadd_interrupt_randomness(desc->irq_data.irq, flags);\n\n\tif (!noirqdebug)\n\t\tnote_interrupt(desc, retval);\n\treturn retval;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock",
          "args": [
            "&desc->lock"
          ],
          "line": 204
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "198-201",
          "snippet": "void __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "irqd_set",
          "args": [
            "&desc->irq_data",
            "IRQD_IRQ_INPROGRESS"
          ],
          "line": 203
        },
        "resolved": true,
        "details": {
          "function_name": "irqd_set",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/internals.h",
          "lines": "223-226",
          "snippet": "static inline void irqd_set(struct irq_data *d, unsigned int mask)\n{\n\t__irqd_to_state(d) |= mask;\n}",
          "includes": [
            "#include <linux/debugfs.h>",
            "#include \"settings.h\"",
            "#include \"debug.h\"",
            "#include <linux/sched/clock.h>",
            "#include <linux/pm_runtime.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/irqdesc.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/debugfs.h>\n#include \"settings.h\"\n#include \"debug.h\"\n#include <linux/sched/clock.h>\n#include <linux/pm_runtime.h>\n#include <linux/kernel_stat.h>\n#include <linux/irqdesc.h>\n\nstatic inline void irqd_set(struct irq_data *d, unsigned int mask)\n{\n\t__irqd_to_state(d) |= mask;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"internals.h\"\n#include <trace/events/irq.h>\n#include <linux/kernel_stat.h>\n#include <linux/interrupt.h>\n#include <linux/sched.h>\n#include <linux/random.h>\n#include <linux/irq.h>\n\nirqreturn_t handle_irq_event(struct irq_desc *desc)\n{\n\tirqreturn_t ret;\n\n\tdesc->istate &= ~IRQS_PENDING;\n\tirqd_set(&desc->irq_data, IRQD_IRQ_INPROGRESS);\n\traw_spin_unlock(&desc->lock);\n\n\tret = handle_irq_event_percpu(desc);\n\n\traw_spin_lock(&desc->lock);\n\tirqd_clear(&desc->irq_data, IRQD_IRQ_INPROGRESS);\n\treturn ret;\n}"
  },
  {
    "function_name": "handle_irq_event_percpu",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/handle.c",
    "lines": "184-196",
    "snippet": "irqreturn_t handle_irq_event_percpu(struct irq_desc *desc)\n{\n\tirqreturn_t retval;\n\tunsigned int flags = 0;\n\n\tretval = __handle_irq_event_percpu(desc, &flags);\n\n\tadd_interrupt_randomness(desc->irq_data.irq, flags);\n\n\tif (!noirqdebug)\n\t\tnote_interrupt(desc, retval);\n\treturn retval;\n}",
    "includes": [
      "#include \"internals.h\"",
      "#include <trace/events/irq.h>",
      "#include <linux/kernel_stat.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/sched.h>",
      "#include <linux/random.h>",
      "#include <linux/irq.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "note_interrupt",
          "args": [
            "desc",
            "retval"
          ],
          "line": 194
        },
        "resolved": true,
        "details": {
          "function_name": "note_interrupt",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/spurious.c",
          "lines": "271-427",
          "snippet": "void note_interrupt(struct irq_desc *desc, irqreturn_t action_ret)\n{\n\tunsigned int irq;\n\n\tif (desc->istate & IRQS_POLL_INPROGRESS ||\n\t    irq_settings_is_polled(desc))\n\t\treturn;\n\n\tif (bad_action_ret(action_ret)) {\n\t\treport_bad_irq(desc, action_ret);\n\t\treturn;\n\t}\n\n\t/*\n\t * We cannot call note_interrupt from the threaded handler\n\t * because we need to look at the compound of all handlers\n\t * (primary and threaded). Aside of that in the threaded\n\t * shared case we have no serialization against an incoming\n\t * hardware interrupt while we are dealing with a threaded\n\t * result.\n\t *\n\t * So in case a thread is woken, we just note the fact and\n\t * defer the analysis to the next hardware interrupt.\n\t *\n\t * The threaded handlers store whether they sucessfully\n\t * handled an interrupt and we check whether that number\n\t * changed versus the last invocation.\n\t *\n\t * We could handle all interrupts with the delayed by one\n\t * mechanism, but for the non forced threaded case we'd just\n\t * add pointless overhead to the straight hardirq interrupts\n\t * for the sake of a few lines less code.\n\t */\n\tif (action_ret & IRQ_WAKE_THREAD) {\n\t\t/*\n\t\t * There is a thread woken. Check whether one of the\n\t\t * shared primary handlers returned IRQ_HANDLED. If\n\t\t * not we defer the spurious detection to the next\n\t\t * interrupt.\n\t\t */\n\t\tif (action_ret == IRQ_WAKE_THREAD) {\n\t\t\tint handled;\n\t\t\t/*\n\t\t\t * We use bit 31 of thread_handled_last to\n\t\t\t * denote the deferred spurious detection\n\t\t\t * active. No locking necessary as\n\t\t\t * thread_handled_last is only accessed here\n\t\t\t * and we have the guarantee that hard\n\t\t\t * interrupts are not reentrant.\n\t\t\t */\n\t\t\tif (!(desc->threads_handled_last & SPURIOUS_DEFERRED)) {\n\t\t\t\tdesc->threads_handled_last |= SPURIOUS_DEFERRED;\n\t\t\t\treturn;\n\t\t\t}\n\t\t\t/*\n\t\t\t * Check whether one of the threaded handlers\n\t\t\t * returned IRQ_HANDLED since the last\n\t\t\t * interrupt happened.\n\t\t\t *\n\t\t\t * For simplicity we just set bit 31, as it is\n\t\t\t * set in threads_handled_last as well. So we\n\t\t\t * avoid extra masking. And we really do not\n\t\t\t * care about the high bits of the handled\n\t\t\t * count. We just care about the count being\n\t\t\t * different than the one we saw before.\n\t\t\t */\n\t\t\thandled = atomic_read(&desc->threads_handled);\n\t\t\thandled |= SPURIOUS_DEFERRED;\n\t\t\tif (handled != desc->threads_handled_last) {\n\t\t\t\taction_ret = IRQ_HANDLED;\n\t\t\t\t/*\n\t\t\t\t * Note: We keep the SPURIOUS_DEFERRED\n\t\t\t\t * bit set. We are handling the\n\t\t\t\t * previous invocation right now.\n\t\t\t\t * Keep it for the current one, so the\n\t\t\t\t * next hardware interrupt will\n\t\t\t\t * account for it.\n\t\t\t\t */\n\t\t\t\tdesc->threads_handled_last = handled;\n\t\t\t} else {\n\t\t\t\t/*\n\t\t\t\t * None of the threaded handlers felt\n\t\t\t\t * responsible for the last interrupt\n\t\t\t\t *\n\t\t\t\t * We keep the SPURIOUS_DEFERRED bit\n\t\t\t\t * set in threads_handled_last as we\n\t\t\t\t * need to account for the current\n\t\t\t\t * interrupt as well.\n\t\t\t\t */\n\t\t\t\taction_ret = IRQ_NONE;\n\t\t\t}\n\t\t} else {\n\t\t\t/*\n\t\t\t * One of the primary handlers returned\n\t\t\t * IRQ_HANDLED. So we don't care about the\n\t\t\t * threaded handlers on the same line. Clear\n\t\t\t * the deferred detection bit.\n\t\t\t *\n\t\t\t * In theory we could/should check whether the\n\t\t\t * deferred bit is set and take the result of\n\t\t\t * the previous run into account here as\n\t\t\t * well. But it's really not worth the\n\t\t\t * trouble. If every other interrupt is\n\t\t\t * handled we never trigger the spurious\n\t\t\t * detector. And if this is just the one out\n\t\t\t * of 100k unhandled ones which is handled\n\t\t\t * then we merily delay the spurious detection\n\t\t\t * by one hard interrupt. Not a real problem.\n\t\t\t */\n\t\t\tdesc->threads_handled_last &= ~SPURIOUS_DEFERRED;\n\t\t}\n\t}\n\n\tif (unlikely(action_ret == IRQ_NONE)) {\n\t\t/*\n\t\t * If we are seeing only the odd spurious IRQ caused by\n\t\t * bus asynchronicity then don't eventually trigger an error,\n\t\t * otherwise the counter becomes a doomsday timer for otherwise\n\t\t * working systems\n\t\t */\n\t\tif (time_after(jiffies, desc->last_unhandled + HZ/10))\n\t\t\tdesc->irqs_unhandled = 1;\n\t\telse\n\t\t\tdesc->irqs_unhandled++;\n\t\tdesc->last_unhandled = jiffies;\n\t}\n\n\tirq = irq_desc_get_irq(desc);\n\tif (unlikely(try_misrouted_irq(irq, desc, action_ret))) {\n\t\tint ok = misrouted_irq(irq);\n\t\tif (action_ret == IRQ_NONE)\n\t\t\tdesc->irqs_unhandled -= ok;\n\t}\n\n\tdesc->irq_count++;\n\tif (likely(desc->irq_count < 100000))\n\t\treturn;\n\n\tdesc->irq_count = 0;\n\tif (unlikely(desc->irqs_unhandled > 99900)) {\n\t\t/*\n\t\t * The interrupt is stuck\n\t\t */\n\t\t__report_bad_irq(desc, action_ret);\n\t\t/*\n\t\t * Now kill the IRQ\n\t\t */\n\t\tprintk(KERN_EMERG \"Disabling IRQ #%d\\n\", irq);\n\t\tdesc->istate |= IRQS_SPURIOUS_DISABLED;\n\t\tdesc->depth++;\n\t\tirq_disable(desc);\n\n\t\tmod_timer(&poll_spurious_irq_timer,\n\t\t\t  jiffies + POLL_SPURIOUS_IRQ_INTERVAL);\n\t}\n\tdesc->irqs_unhandled = 0;\n}",
          "includes": [
            "#include \"internals.h\"",
            "#include <linux/timer.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/module.h>",
            "#include <linux/irq.h>",
            "#include <linux/jiffies.h>"
          ],
          "macros_used": [
            "#define SPURIOUS_DEFERRED\t0x80000000",
            "#define POLL_SPURIOUS_IRQ_INTERVAL (HZ/10)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internals.h\"\n#include <linux/timer.h>\n#include <linux/moduleparam.h>\n#include <linux/interrupt.h>\n#include <linux/module.h>\n#include <linux/irq.h>\n#include <linux/jiffies.h>\n\n#define SPURIOUS_DEFERRED\t0x80000000\n#define POLL_SPURIOUS_IRQ_INTERVAL (HZ/10)\n\nvoid note_interrupt(struct irq_desc *desc, irqreturn_t action_ret)\n{\n\tunsigned int irq;\n\n\tif (desc->istate & IRQS_POLL_INPROGRESS ||\n\t    irq_settings_is_polled(desc))\n\t\treturn;\n\n\tif (bad_action_ret(action_ret)) {\n\t\treport_bad_irq(desc, action_ret);\n\t\treturn;\n\t}\n\n\t/*\n\t * We cannot call note_interrupt from the threaded handler\n\t * because we need to look at the compound of all handlers\n\t * (primary and threaded). Aside of that in the threaded\n\t * shared case we have no serialization against an incoming\n\t * hardware interrupt while we are dealing with a threaded\n\t * result.\n\t *\n\t * So in case a thread is woken, we just note the fact and\n\t * defer the analysis to the next hardware interrupt.\n\t *\n\t * The threaded handlers store whether they sucessfully\n\t * handled an interrupt and we check whether that number\n\t * changed versus the last invocation.\n\t *\n\t * We could handle all interrupts with the delayed by one\n\t * mechanism, but for the non forced threaded case we'd just\n\t * add pointless overhead to the straight hardirq interrupts\n\t * for the sake of a few lines less code.\n\t */\n\tif (action_ret & IRQ_WAKE_THREAD) {\n\t\t/*\n\t\t * There is a thread woken. Check whether one of the\n\t\t * shared primary handlers returned IRQ_HANDLED. If\n\t\t * not we defer the spurious detection to the next\n\t\t * interrupt.\n\t\t */\n\t\tif (action_ret == IRQ_WAKE_THREAD) {\n\t\t\tint handled;\n\t\t\t/*\n\t\t\t * We use bit 31 of thread_handled_last to\n\t\t\t * denote the deferred spurious detection\n\t\t\t * active. No locking necessary as\n\t\t\t * thread_handled_last is only accessed here\n\t\t\t * and we have the guarantee that hard\n\t\t\t * interrupts are not reentrant.\n\t\t\t */\n\t\t\tif (!(desc->threads_handled_last & SPURIOUS_DEFERRED)) {\n\t\t\t\tdesc->threads_handled_last |= SPURIOUS_DEFERRED;\n\t\t\t\treturn;\n\t\t\t}\n\t\t\t/*\n\t\t\t * Check whether one of the threaded handlers\n\t\t\t * returned IRQ_HANDLED since the last\n\t\t\t * interrupt happened.\n\t\t\t *\n\t\t\t * For simplicity we just set bit 31, as it is\n\t\t\t * set in threads_handled_last as well. So we\n\t\t\t * avoid extra masking. And we really do not\n\t\t\t * care about the high bits of the handled\n\t\t\t * count. We just care about the count being\n\t\t\t * different than the one we saw before.\n\t\t\t */\n\t\t\thandled = atomic_read(&desc->threads_handled);\n\t\t\thandled |= SPURIOUS_DEFERRED;\n\t\t\tif (handled != desc->threads_handled_last) {\n\t\t\t\taction_ret = IRQ_HANDLED;\n\t\t\t\t/*\n\t\t\t\t * Note: We keep the SPURIOUS_DEFERRED\n\t\t\t\t * bit set. We are handling the\n\t\t\t\t * previous invocation right now.\n\t\t\t\t * Keep it for the current one, so the\n\t\t\t\t * next hardware interrupt will\n\t\t\t\t * account for it.\n\t\t\t\t */\n\t\t\t\tdesc->threads_handled_last = handled;\n\t\t\t} else {\n\t\t\t\t/*\n\t\t\t\t * None of the threaded handlers felt\n\t\t\t\t * responsible for the last interrupt\n\t\t\t\t *\n\t\t\t\t * We keep the SPURIOUS_DEFERRED bit\n\t\t\t\t * set in threads_handled_last as we\n\t\t\t\t * need to account for the current\n\t\t\t\t * interrupt as well.\n\t\t\t\t */\n\t\t\t\taction_ret = IRQ_NONE;\n\t\t\t}\n\t\t} else {\n\t\t\t/*\n\t\t\t * One of the primary handlers returned\n\t\t\t * IRQ_HANDLED. So we don't care about the\n\t\t\t * threaded handlers on the same line. Clear\n\t\t\t * the deferred detection bit.\n\t\t\t *\n\t\t\t * In theory we could/should check whether the\n\t\t\t * deferred bit is set and take the result of\n\t\t\t * the previous run into account here as\n\t\t\t * well. But it's really not worth the\n\t\t\t * trouble. If every other interrupt is\n\t\t\t * handled we never trigger the spurious\n\t\t\t * detector. And if this is just the one out\n\t\t\t * of 100k unhandled ones which is handled\n\t\t\t * then we merily delay the spurious detection\n\t\t\t * by one hard interrupt. Not a real problem.\n\t\t\t */\n\t\t\tdesc->threads_handled_last &= ~SPURIOUS_DEFERRED;\n\t\t}\n\t}\n\n\tif (unlikely(action_ret == IRQ_NONE)) {\n\t\t/*\n\t\t * If we are seeing only the odd spurious IRQ caused by\n\t\t * bus asynchronicity then don't eventually trigger an error,\n\t\t * otherwise the counter becomes a doomsday timer for otherwise\n\t\t * working systems\n\t\t */\n\t\tif (time_after(jiffies, desc->last_unhandled + HZ/10))\n\t\t\tdesc->irqs_unhandled = 1;\n\t\telse\n\t\t\tdesc->irqs_unhandled++;\n\t\tdesc->last_unhandled = jiffies;\n\t}\n\n\tirq = irq_desc_get_irq(desc);\n\tif (unlikely(try_misrouted_irq(irq, desc, action_ret))) {\n\t\tint ok = misrouted_irq(irq);\n\t\tif (action_ret == IRQ_NONE)\n\t\t\tdesc->irqs_unhandled -= ok;\n\t}\n\n\tdesc->irq_count++;\n\tif (likely(desc->irq_count < 100000))\n\t\treturn;\n\n\tdesc->irq_count = 0;\n\tif (unlikely(desc->irqs_unhandled > 99900)) {\n\t\t/*\n\t\t * The interrupt is stuck\n\t\t */\n\t\t__report_bad_irq(desc, action_ret);\n\t\t/*\n\t\t * Now kill the IRQ\n\t\t */\n\t\tprintk(KERN_EMERG \"Disabling IRQ #%d\\n\", irq);\n\t\tdesc->istate |= IRQS_SPURIOUS_DISABLED;\n\t\tdesc->depth++;\n\t\tirq_disable(desc);\n\n\t\tmod_timer(&poll_spurious_irq_timer,\n\t\t\t  jiffies + POLL_SPURIOUS_IRQ_INTERVAL);\n\t}\n\tdesc->irqs_unhandled = 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "add_interrupt_randomness",
          "args": [
            "desc->irq_data.irq",
            "flags"
          ],
          "line": 191
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__handle_irq_event_percpu",
          "args": [
            "desc",
            "&flags"
          ],
          "line": 189
        },
        "resolved": true,
        "details": {
          "function_name": "__handle_irq_event_percpu",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/handle.c",
          "lines": "137-182",
          "snippet": "irqreturn_t __handle_irq_event_percpu(struct irq_desc *desc, unsigned int *flags)\n{\n\tirqreturn_t retval = IRQ_NONE;\n\tunsigned int irq = desc->irq_data.irq;\n\tstruct irqaction *action;\n\n\trecord_irq_time(desc);\n\n\tfor_each_action_of_desc(desc, action) {\n\t\tirqreturn_t res;\n\n\t\ttrace_irq_handler_entry(irq, action);\n\t\tres = action->handler(irq, action->dev_id);\n\t\ttrace_irq_handler_exit(irq, action, res);\n\n\t\tif (WARN_ONCE(!irqs_disabled(),\"irq %u handler %pF enabled interrupts\\n\",\n\t\t\t      irq, action->handler))\n\t\t\tlocal_irq_disable();\n\n\t\tswitch (res) {\n\t\tcase IRQ_WAKE_THREAD:\n\t\t\t/*\n\t\t\t * Catch drivers which return WAKE_THREAD but\n\t\t\t * did not set up a thread function\n\t\t\t */\n\t\t\tif (unlikely(!action->thread_fn)) {\n\t\t\t\twarn_no_thread(irq, action);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t__irq_wake_thread(desc, action);\n\n\t\t\t/* Fall through to add to randomness */\n\t\tcase IRQ_HANDLED:\n\t\t\t*flags |= action->flags;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\tretval |= res;\n\t}\n\n\treturn retval;\n}",
          "includes": [
            "#include \"internals.h\"",
            "#include <trace/events/irq.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/sched.h>",
            "#include <linux/random.h>",
            "#include <linux/irq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internals.h\"\n#include <trace/events/irq.h>\n#include <linux/kernel_stat.h>\n#include <linux/interrupt.h>\n#include <linux/sched.h>\n#include <linux/random.h>\n#include <linux/irq.h>\n\nirqreturn_t __handle_irq_event_percpu(struct irq_desc *desc, unsigned int *flags)\n{\n\tirqreturn_t retval = IRQ_NONE;\n\tunsigned int irq = desc->irq_data.irq;\n\tstruct irqaction *action;\n\n\trecord_irq_time(desc);\n\n\tfor_each_action_of_desc(desc, action) {\n\t\tirqreturn_t res;\n\n\t\ttrace_irq_handler_entry(irq, action);\n\t\tres = action->handler(irq, action->dev_id);\n\t\ttrace_irq_handler_exit(irq, action, res);\n\n\t\tif (WARN_ONCE(!irqs_disabled(),\"irq %u handler %pF enabled interrupts\\n\",\n\t\t\t      irq, action->handler))\n\t\t\tlocal_irq_disable();\n\n\t\tswitch (res) {\n\t\tcase IRQ_WAKE_THREAD:\n\t\t\t/*\n\t\t\t * Catch drivers which return WAKE_THREAD but\n\t\t\t * did not set up a thread function\n\t\t\t */\n\t\t\tif (unlikely(!action->thread_fn)) {\n\t\t\t\twarn_no_thread(irq, action);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t__irq_wake_thread(desc, action);\n\n\t\t\t/* Fall through to add to randomness */\n\t\tcase IRQ_HANDLED:\n\t\t\t*flags |= action->flags;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\tretval |= res;\n\t}\n\n\treturn retval;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"internals.h\"\n#include <trace/events/irq.h>\n#include <linux/kernel_stat.h>\n#include <linux/interrupt.h>\n#include <linux/sched.h>\n#include <linux/random.h>\n#include <linux/irq.h>\n\nirqreturn_t handle_irq_event_percpu(struct irq_desc *desc)\n{\n\tirqreturn_t retval;\n\tunsigned int flags = 0;\n\n\tretval = __handle_irq_event_percpu(desc, &flags);\n\n\tadd_interrupt_randomness(desc->irq_data.irq, flags);\n\n\tif (!noirqdebug)\n\t\tnote_interrupt(desc, retval);\n\treturn retval;\n}"
  },
  {
    "function_name": "__handle_irq_event_percpu",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/handle.c",
    "lines": "137-182",
    "snippet": "irqreturn_t __handle_irq_event_percpu(struct irq_desc *desc, unsigned int *flags)\n{\n\tirqreturn_t retval = IRQ_NONE;\n\tunsigned int irq = desc->irq_data.irq;\n\tstruct irqaction *action;\n\n\trecord_irq_time(desc);\n\n\tfor_each_action_of_desc(desc, action) {\n\t\tirqreturn_t res;\n\n\t\ttrace_irq_handler_entry(irq, action);\n\t\tres = action->handler(irq, action->dev_id);\n\t\ttrace_irq_handler_exit(irq, action, res);\n\n\t\tif (WARN_ONCE(!irqs_disabled(),\"irq %u handler %pF enabled interrupts\\n\",\n\t\t\t      irq, action->handler))\n\t\t\tlocal_irq_disable();\n\n\t\tswitch (res) {\n\t\tcase IRQ_WAKE_THREAD:\n\t\t\t/*\n\t\t\t * Catch drivers which return WAKE_THREAD but\n\t\t\t * did not set up a thread function\n\t\t\t */\n\t\t\tif (unlikely(!action->thread_fn)) {\n\t\t\t\twarn_no_thread(irq, action);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t__irq_wake_thread(desc, action);\n\n\t\t\t/* Fall through to add to randomness */\n\t\tcase IRQ_HANDLED:\n\t\t\t*flags |= action->flags;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\tretval |= res;\n\t}\n\n\treturn retval;\n}",
    "includes": [
      "#include \"internals.h\"",
      "#include <trace/events/irq.h>",
      "#include <linux/kernel_stat.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/sched.h>",
      "#include <linux/random.h>",
      "#include <linux/irq.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__irq_wake_thread",
          "args": [
            "desc",
            "action"
          ],
          "line": 167
        },
        "resolved": true,
        "details": {
          "function_name": "__irq_wake_thread",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/handle.c",
          "lines": "59-135",
          "snippet": "void __irq_wake_thread(struct irq_desc *desc, struct irqaction *action)\n{\n\t/*\n\t * In case the thread crashed and was killed we just pretend that\n\t * we handled the interrupt. The hardirq handler has disabled the\n\t * device interrupt, so no irq storm is lurking.\n\t */\n\tif (action->thread->flags & PF_EXITING)\n\t\treturn;\n\n\t/*\n\t * Wake up the handler thread for this action. If the\n\t * RUNTHREAD bit is already set, nothing to do.\n\t */\n\tif (test_and_set_bit(IRQTF_RUNTHREAD, &action->thread_flags))\n\t\treturn;\n\n\t/*\n\t * It's safe to OR the mask lockless here. We have only two\n\t * places which write to threads_oneshot: This code and the\n\t * irq thread.\n\t *\n\t * This code is the hard irq context and can never run on two\n\t * cpus in parallel. If it ever does we have more serious\n\t * problems than this bitmask.\n\t *\n\t * The irq threads of this irq which clear their \"running\" bit\n\t * in threads_oneshot are serialized via desc->lock against\n\t * each other and they are serialized against this code by\n\t * IRQS_INPROGRESS.\n\t *\n\t * Hard irq handler:\n\t *\n\t *\tspin_lock(desc->lock);\n\t *\tdesc->state |= IRQS_INPROGRESS;\n\t *\tspin_unlock(desc->lock);\n\t *\tset_bit(IRQTF_RUNTHREAD, &action->thread_flags);\n\t *\tdesc->threads_oneshot |= mask;\n\t *\tspin_lock(desc->lock);\n\t *\tdesc->state &= ~IRQS_INPROGRESS;\n\t *\tspin_unlock(desc->lock);\n\t *\n\t * irq thread:\n\t *\n\t * again:\n\t *\tspin_lock(desc->lock);\n\t *\tif (desc->state & IRQS_INPROGRESS) {\n\t *\t\tspin_unlock(desc->lock);\n\t *\t\twhile(desc->state & IRQS_INPROGRESS)\n\t *\t\t\tcpu_relax();\n\t *\t\tgoto again;\n\t *\t}\n\t *\tif (!test_bit(IRQTF_RUNTHREAD, &action->thread_flags))\n\t *\t\tdesc->threads_oneshot &= ~mask;\n\t *\tspin_unlock(desc->lock);\n\t *\n\t * So either the thread waits for us to clear IRQS_INPROGRESS\n\t * or we are waiting in the flow handler for desc->lock to be\n\t * released before we reach this point. The thread also checks\n\t * IRQTF_RUNTHREAD under desc->lock. If set it leaves\n\t * threads_oneshot untouched and runs the thread another time.\n\t */\n\tdesc->threads_oneshot |= action->thread_mask;\n\n\t/*\n\t * We increment the threads_active counter in case we wake up\n\t * the irq thread. The irq thread decrements the counter when\n\t * it returns from the handler or in the exit path and wakes\n\t * up waiters which are stuck in synchronize_irq() when the\n\t * active count becomes zero. synchronize_irq() is serialized\n\t * against this code (hard irq handler) via IRQS_INPROGRESS\n\t * like the finalize_oneshot() code. See comment above.\n\t */\n\tatomic_inc(&desc->threads_active);\n\n\twake_up_process(action->thread);\n}",
          "includes": [
            "#include \"internals.h\"",
            "#include <trace/events/irq.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/sched.h>",
            "#include <linux/random.h>",
            "#include <linux/irq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internals.h\"\n#include <trace/events/irq.h>\n#include <linux/kernel_stat.h>\n#include <linux/interrupt.h>\n#include <linux/sched.h>\n#include <linux/random.h>\n#include <linux/irq.h>\n\nvoid __irq_wake_thread(struct irq_desc *desc, struct irqaction *action)\n{\n\t/*\n\t * In case the thread crashed and was killed we just pretend that\n\t * we handled the interrupt. The hardirq handler has disabled the\n\t * device interrupt, so no irq storm is lurking.\n\t */\n\tif (action->thread->flags & PF_EXITING)\n\t\treturn;\n\n\t/*\n\t * Wake up the handler thread for this action. If the\n\t * RUNTHREAD bit is already set, nothing to do.\n\t */\n\tif (test_and_set_bit(IRQTF_RUNTHREAD, &action->thread_flags))\n\t\treturn;\n\n\t/*\n\t * It's safe to OR the mask lockless here. We have only two\n\t * places which write to threads_oneshot: This code and the\n\t * irq thread.\n\t *\n\t * This code is the hard irq context and can never run on two\n\t * cpus in parallel. If it ever does we have more serious\n\t * problems than this bitmask.\n\t *\n\t * The irq threads of this irq which clear their \"running\" bit\n\t * in threads_oneshot are serialized via desc->lock against\n\t * each other and they are serialized against this code by\n\t * IRQS_INPROGRESS.\n\t *\n\t * Hard irq handler:\n\t *\n\t *\tspin_lock(desc->lock);\n\t *\tdesc->state |= IRQS_INPROGRESS;\n\t *\tspin_unlock(desc->lock);\n\t *\tset_bit(IRQTF_RUNTHREAD, &action->thread_flags);\n\t *\tdesc->threads_oneshot |= mask;\n\t *\tspin_lock(desc->lock);\n\t *\tdesc->state &= ~IRQS_INPROGRESS;\n\t *\tspin_unlock(desc->lock);\n\t *\n\t * irq thread:\n\t *\n\t * again:\n\t *\tspin_lock(desc->lock);\n\t *\tif (desc->state & IRQS_INPROGRESS) {\n\t *\t\tspin_unlock(desc->lock);\n\t *\t\twhile(desc->state & IRQS_INPROGRESS)\n\t *\t\t\tcpu_relax();\n\t *\t\tgoto again;\n\t *\t}\n\t *\tif (!test_bit(IRQTF_RUNTHREAD, &action->thread_flags))\n\t *\t\tdesc->threads_oneshot &= ~mask;\n\t *\tspin_unlock(desc->lock);\n\t *\n\t * So either the thread waits for us to clear IRQS_INPROGRESS\n\t * or we are waiting in the flow handler for desc->lock to be\n\t * released before we reach this point. The thread also checks\n\t * IRQTF_RUNTHREAD under desc->lock. If set it leaves\n\t * threads_oneshot untouched and runs the thread another time.\n\t */\n\tdesc->threads_oneshot |= action->thread_mask;\n\n\t/*\n\t * We increment the threads_active counter in case we wake up\n\t * the irq thread. The irq thread decrements the counter when\n\t * it returns from the handler or in the exit path and wakes\n\t * up waiters which are stuck in synchronize_irq() when the\n\t * active count becomes zero. synchronize_irq() is serialized\n\t * against this code (hard irq handler) via IRQS_INPROGRESS\n\t * like the finalize_oneshot() code. See comment above.\n\t */\n\tatomic_inc(&desc->threads_active);\n\n\twake_up_process(action->thread);\n}"
        }
      },
      {
        "call_info": {
          "callee": "warn_no_thread",
          "args": [
            "irq",
            "action"
          ],
          "line": 163
        },
        "resolved": true,
        "details": {
          "function_name": "warn_no_thread",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/handle.c",
          "lines": "50-57",
          "snippet": "static void warn_no_thread(unsigned int irq, struct irqaction *action)\n{\n\tif (test_and_set_bit(IRQTF_WARNED, &action->thread_flags))\n\t\treturn;\n\n\tprintk(KERN_WARNING \"IRQ %d device %s returned IRQ_WAKE_THREAD \"\n\t       \"but no thread function available.\", irq, action->name);\n}",
          "includes": [
            "#include \"internals.h\"",
            "#include <trace/events/irq.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/sched.h>",
            "#include <linux/random.h>",
            "#include <linux/irq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internals.h\"\n#include <trace/events/irq.h>\n#include <linux/kernel_stat.h>\n#include <linux/interrupt.h>\n#include <linux/sched.h>\n#include <linux/random.h>\n#include <linux/irq.h>\n\nstatic void warn_no_thread(unsigned int irq, struct irqaction *action)\n{\n\tif (test_and_set_bit(IRQTF_WARNED, &action->thread_flags))\n\t\treturn;\n\n\tprintk(KERN_WARNING \"IRQ %d device %s returned IRQ_WAKE_THREAD \"\n\t       \"but no thread function available.\", irq, action->name);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!action->thread_fn"
          ],
          "line": 162
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_irq_disable",
          "args": [],
          "line": 154
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ONCE",
          "args": [
            "!irqs_disabled()",
            "\"irq %u handler %pF enabled interrupts\\n\"",
            "irq",
            "action->handler"
          ],
          "line": 152
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "irqs_disabled",
          "args": [],
          "line": 152
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_irq_handler_exit",
          "args": [
            "irq",
            "action",
            "res"
          ],
          "line": 150
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "action->handler",
          "args": [
            "irq",
            "action->dev_id"
          ],
          "line": 149
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_irq_handler_entry",
          "args": [
            "irq",
            "action"
          ],
          "line": 148
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "for_each_action_of_desc",
          "args": [
            "desc",
            "action"
          ],
          "line": 145
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "record_irq_time",
          "args": [
            "desc"
          ],
          "line": 143
        },
        "resolved": true,
        "details": {
          "function_name": "record_irq_time",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/internals.h",
          "lines": "376-376",
          "snippet": "static inline void record_irq_time(struct irq_desc *desc) {}",
          "includes": [
            "#include <linux/debugfs.h>",
            "#include \"settings.h\"",
            "#include \"debug.h\"",
            "#include <linux/sched/clock.h>",
            "#include <linux/pm_runtime.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/irqdesc.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern void __disable_irq(struct irq_desc *desc);",
            "extern void __enable_irq(struct irq_desc *desc);",
            "extern int irq_activate(struct irq_desc *desc);",
            "extern void irq_shutdown(struct irq_desc *desc);",
            "extern void irq_enable(struct irq_desc *desc);",
            "extern void irq_disable(struct irq_desc *desc);",
            "extern void mask_irq(struct irq_desc *desc);",
            "extern void unmask_irq(struct irq_desc *desc);",
            "extern void unmask_threaded_irq(struct irq_desc *desc);",
            "irqreturn_t handle_irq_event_percpu(struct irq_desc *desc);",
            "irqreturn_t handle_irq_event(struct irq_desc *desc);",
            "void check_irq_resend(struct irq_desc *desc);",
            "bool irq_wait_for_poll(struct irq_desc *desc);",
            "extern void irq_set_thread_affinity(struct irq_desc *desc);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/debugfs.h>\n#include \"settings.h\"\n#include \"debug.h\"\n#include <linux/sched/clock.h>\n#include <linux/pm_runtime.h>\n#include <linux/kernel_stat.h>\n#include <linux/irqdesc.h>\n\nextern void __disable_irq(struct irq_desc *desc);\nextern void __enable_irq(struct irq_desc *desc);\nextern int irq_activate(struct irq_desc *desc);\nextern void irq_shutdown(struct irq_desc *desc);\nextern void irq_enable(struct irq_desc *desc);\nextern void irq_disable(struct irq_desc *desc);\nextern void mask_irq(struct irq_desc *desc);\nextern void unmask_irq(struct irq_desc *desc);\nextern void unmask_threaded_irq(struct irq_desc *desc);\nirqreturn_t handle_irq_event_percpu(struct irq_desc *desc);\nirqreturn_t handle_irq_event(struct irq_desc *desc);\nvoid check_irq_resend(struct irq_desc *desc);\nbool irq_wait_for_poll(struct irq_desc *desc);\nextern void irq_set_thread_affinity(struct irq_desc *desc);\n\nstatic inline void record_irq_time(struct irq_desc *desc) {}"
        }
      }
    ],
    "contextual_snippet": "#include \"internals.h\"\n#include <trace/events/irq.h>\n#include <linux/kernel_stat.h>\n#include <linux/interrupt.h>\n#include <linux/sched.h>\n#include <linux/random.h>\n#include <linux/irq.h>\n\nirqreturn_t __handle_irq_event_percpu(struct irq_desc *desc, unsigned int *flags)\n{\n\tirqreturn_t retval = IRQ_NONE;\n\tunsigned int irq = desc->irq_data.irq;\n\tstruct irqaction *action;\n\n\trecord_irq_time(desc);\n\n\tfor_each_action_of_desc(desc, action) {\n\t\tirqreturn_t res;\n\n\t\ttrace_irq_handler_entry(irq, action);\n\t\tres = action->handler(irq, action->dev_id);\n\t\ttrace_irq_handler_exit(irq, action, res);\n\n\t\tif (WARN_ONCE(!irqs_disabled(),\"irq %u handler %pF enabled interrupts\\n\",\n\t\t\t      irq, action->handler))\n\t\t\tlocal_irq_disable();\n\n\t\tswitch (res) {\n\t\tcase IRQ_WAKE_THREAD:\n\t\t\t/*\n\t\t\t * Catch drivers which return WAKE_THREAD but\n\t\t\t * did not set up a thread function\n\t\t\t */\n\t\t\tif (unlikely(!action->thread_fn)) {\n\t\t\t\twarn_no_thread(irq, action);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t__irq_wake_thread(desc, action);\n\n\t\t\t/* Fall through to add to randomness */\n\t\tcase IRQ_HANDLED:\n\t\t\t*flags |= action->flags;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\tretval |= res;\n\t}\n\n\treturn retval;\n}"
  },
  {
    "function_name": "__irq_wake_thread",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/handle.c",
    "lines": "59-135",
    "snippet": "void __irq_wake_thread(struct irq_desc *desc, struct irqaction *action)\n{\n\t/*\n\t * In case the thread crashed and was killed we just pretend that\n\t * we handled the interrupt. The hardirq handler has disabled the\n\t * device interrupt, so no irq storm is lurking.\n\t */\n\tif (action->thread->flags & PF_EXITING)\n\t\treturn;\n\n\t/*\n\t * Wake up the handler thread for this action. If the\n\t * RUNTHREAD bit is already set, nothing to do.\n\t */\n\tif (test_and_set_bit(IRQTF_RUNTHREAD, &action->thread_flags))\n\t\treturn;\n\n\t/*\n\t * It's safe to OR the mask lockless here. We have only two\n\t * places which write to threads_oneshot: This code and the\n\t * irq thread.\n\t *\n\t * This code is the hard irq context and can never run on two\n\t * cpus in parallel. If it ever does we have more serious\n\t * problems than this bitmask.\n\t *\n\t * The irq threads of this irq which clear their \"running\" bit\n\t * in threads_oneshot are serialized via desc->lock against\n\t * each other and they are serialized against this code by\n\t * IRQS_INPROGRESS.\n\t *\n\t * Hard irq handler:\n\t *\n\t *\tspin_lock(desc->lock);\n\t *\tdesc->state |= IRQS_INPROGRESS;\n\t *\tspin_unlock(desc->lock);\n\t *\tset_bit(IRQTF_RUNTHREAD, &action->thread_flags);\n\t *\tdesc->threads_oneshot |= mask;\n\t *\tspin_lock(desc->lock);\n\t *\tdesc->state &= ~IRQS_INPROGRESS;\n\t *\tspin_unlock(desc->lock);\n\t *\n\t * irq thread:\n\t *\n\t * again:\n\t *\tspin_lock(desc->lock);\n\t *\tif (desc->state & IRQS_INPROGRESS) {\n\t *\t\tspin_unlock(desc->lock);\n\t *\t\twhile(desc->state & IRQS_INPROGRESS)\n\t *\t\t\tcpu_relax();\n\t *\t\tgoto again;\n\t *\t}\n\t *\tif (!test_bit(IRQTF_RUNTHREAD, &action->thread_flags))\n\t *\t\tdesc->threads_oneshot &= ~mask;\n\t *\tspin_unlock(desc->lock);\n\t *\n\t * So either the thread waits for us to clear IRQS_INPROGRESS\n\t * or we are waiting in the flow handler for desc->lock to be\n\t * released before we reach this point. The thread also checks\n\t * IRQTF_RUNTHREAD under desc->lock. If set it leaves\n\t * threads_oneshot untouched and runs the thread another time.\n\t */\n\tdesc->threads_oneshot |= action->thread_mask;\n\n\t/*\n\t * We increment the threads_active counter in case we wake up\n\t * the irq thread. The irq thread decrements the counter when\n\t * it returns from the handler or in the exit path and wakes\n\t * up waiters which are stuck in synchronize_irq() when the\n\t * active count becomes zero. synchronize_irq() is serialized\n\t * against this code (hard irq handler) via IRQS_INPROGRESS\n\t * like the finalize_oneshot() code. See comment above.\n\t */\n\tatomic_inc(&desc->threads_active);\n\n\twake_up_process(action->thread);\n}",
    "includes": [
      "#include \"internals.h\"",
      "#include <trace/events/irq.h>",
      "#include <linux/kernel_stat.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/sched.h>",
      "#include <linux/random.h>",
      "#include <linux/irq.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "wake_up_process",
          "args": [
            "action->thread"
          ],
          "line": 134
        },
        "resolved": true,
        "details": {
          "function_name": "wake_up_process",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/core.c",
          "lines": "2127-2130",
          "snippet": "int wake_up_process(struct task_struct *p)\n{\n\treturn try_to_wake_up(p, TASK_NORMAL, 0);\n}",
          "includes": [
            "#include \"features.h\"",
            "#include <trace/events/sched.h>",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/kcov.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include <trace/events/sched.h>\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/kcov.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n\nstatic __always_inline struct;\n\nint wake_up_process(struct task_struct *p)\n{\n\treturn try_to_wake_up(p, TASK_NORMAL, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_inc",
          "args": [
            "&desc->threads_active"
          ],
          "line": 132
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "test_and_set_bit",
          "args": [
            "IRQTF_RUNTHREAD",
            "&action->thread_flags"
          ],
          "line": 73
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"internals.h\"\n#include <trace/events/irq.h>\n#include <linux/kernel_stat.h>\n#include <linux/interrupt.h>\n#include <linux/sched.h>\n#include <linux/random.h>\n#include <linux/irq.h>\n\nvoid __irq_wake_thread(struct irq_desc *desc, struct irqaction *action)\n{\n\t/*\n\t * In case the thread crashed and was killed we just pretend that\n\t * we handled the interrupt. The hardirq handler has disabled the\n\t * device interrupt, so no irq storm is lurking.\n\t */\n\tif (action->thread->flags & PF_EXITING)\n\t\treturn;\n\n\t/*\n\t * Wake up the handler thread for this action. If the\n\t * RUNTHREAD bit is already set, nothing to do.\n\t */\n\tif (test_and_set_bit(IRQTF_RUNTHREAD, &action->thread_flags))\n\t\treturn;\n\n\t/*\n\t * It's safe to OR the mask lockless here. We have only two\n\t * places which write to threads_oneshot: This code and the\n\t * irq thread.\n\t *\n\t * This code is the hard irq context and can never run on two\n\t * cpus in parallel. If it ever does we have more serious\n\t * problems than this bitmask.\n\t *\n\t * The irq threads of this irq which clear their \"running\" bit\n\t * in threads_oneshot are serialized via desc->lock against\n\t * each other and they are serialized against this code by\n\t * IRQS_INPROGRESS.\n\t *\n\t * Hard irq handler:\n\t *\n\t *\tspin_lock(desc->lock);\n\t *\tdesc->state |= IRQS_INPROGRESS;\n\t *\tspin_unlock(desc->lock);\n\t *\tset_bit(IRQTF_RUNTHREAD, &action->thread_flags);\n\t *\tdesc->threads_oneshot |= mask;\n\t *\tspin_lock(desc->lock);\n\t *\tdesc->state &= ~IRQS_INPROGRESS;\n\t *\tspin_unlock(desc->lock);\n\t *\n\t * irq thread:\n\t *\n\t * again:\n\t *\tspin_lock(desc->lock);\n\t *\tif (desc->state & IRQS_INPROGRESS) {\n\t *\t\tspin_unlock(desc->lock);\n\t *\t\twhile(desc->state & IRQS_INPROGRESS)\n\t *\t\t\tcpu_relax();\n\t *\t\tgoto again;\n\t *\t}\n\t *\tif (!test_bit(IRQTF_RUNTHREAD, &action->thread_flags))\n\t *\t\tdesc->threads_oneshot &= ~mask;\n\t *\tspin_unlock(desc->lock);\n\t *\n\t * So either the thread waits for us to clear IRQS_INPROGRESS\n\t * or we are waiting in the flow handler for desc->lock to be\n\t * released before we reach this point. The thread also checks\n\t * IRQTF_RUNTHREAD under desc->lock. If set it leaves\n\t * threads_oneshot untouched and runs the thread another time.\n\t */\n\tdesc->threads_oneshot |= action->thread_mask;\n\n\t/*\n\t * We increment the threads_active counter in case we wake up\n\t * the irq thread. The irq thread decrements the counter when\n\t * it returns from the handler or in the exit path and wakes\n\t * up waiters which are stuck in synchronize_irq() when the\n\t * active count becomes zero. synchronize_irq() is serialized\n\t * against this code (hard irq handler) via IRQS_INPROGRESS\n\t * like the finalize_oneshot() code. See comment above.\n\t */\n\tatomic_inc(&desc->threads_active);\n\n\twake_up_process(action->thread);\n}"
  },
  {
    "function_name": "warn_no_thread",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/handle.c",
    "lines": "50-57",
    "snippet": "static void warn_no_thread(unsigned int irq, struct irqaction *action)\n{\n\tif (test_and_set_bit(IRQTF_WARNED, &action->thread_flags))\n\t\treturn;\n\n\tprintk(KERN_WARNING \"IRQ %d device %s returned IRQ_WAKE_THREAD \"\n\t       \"but no thread function available.\", irq, action->name);\n}",
    "includes": [
      "#include \"internals.h\"",
      "#include <trace/events/irq.h>",
      "#include <linux/kernel_stat.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/sched.h>",
      "#include <linux/random.h>",
      "#include <linux/irq.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "printk",
          "args": [
            "KERN_WARNING \"IRQ %d device %s returned IRQ_WAKE_THREAD \"\n\t       \"but no thread function available.\"",
            "irq",
            "action->name"
          ],
          "line": 55
        },
        "resolved": true,
        "details": {
          "function_name": "__warn_printk",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/panic.c",
          "lines": "590-599",
          "snippet": "void __warn_printk(const char *fmt, ...)\n{\n\tva_list args;\n\n\tpr_warn(CUT_HERE);\n\n\tva_start(args, fmt);\n\tvprintk(fmt, args);\n\tva_end(args);\n}",
          "includes": [
            "#include <asm/sections.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/bug.h>",
            "#include <linux/console.h>",
            "#include <linux/nmi.h>",
            "#include <linux/init.h>",
            "#include <linux/sysrq.h>",
            "#include <linux/sched.h>",
            "#include <linux/kexec.h>",
            "#include <linux/delay.h>",
            "#include <linux/reboot.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/random.h>",
            "#include <linux/module.h>",
            "#include <linux/notifier.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/kmsg_dump.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/debug_locks.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/sections.h>\n#include <linux/debugfs.h>\n#include <linux/ratelimit.h>\n#include <linux/bug.h>\n#include <linux/console.h>\n#include <linux/nmi.h>\n#include <linux/init.h>\n#include <linux/sysrq.h>\n#include <linux/sched.h>\n#include <linux/kexec.h>\n#include <linux/delay.h>\n#include <linux/reboot.h>\n#include <linux/ftrace.h>\n#include <linux/random.h>\n#include <linux/module.h>\n#include <linux/notifier.h>\n#include <linux/kallsyms.h>\n#include <linux/kmsg_dump.h>\n#include <linux/interrupt.h>\n#include <linux/sched/debug.h>\n#include <linux/debug_locks.h>\n\nvoid __warn_printk(const char *fmt, ...)\n{\n\tva_list args;\n\n\tpr_warn(CUT_HERE);\n\n\tva_start(args, fmt);\n\tvprintk(fmt, args);\n\tva_end(args);\n}"
        }
      },
      {
        "call_info": {
          "callee": "test_and_set_bit",
          "args": [
            "IRQTF_WARNED",
            "&action->thread_flags"
          ],
          "line": 52
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"internals.h\"\n#include <trace/events/irq.h>\n#include <linux/kernel_stat.h>\n#include <linux/interrupt.h>\n#include <linux/sched.h>\n#include <linux/random.h>\n#include <linux/irq.h>\n\nstatic void warn_no_thread(unsigned int irq, struct irqaction *action)\n{\n\tif (test_and_set_bit(IRQTF_WARNED, &action->thread_flags))\n\t\treturn;\n\n\tprintk(KERN_WARNING \"IRQ %d device %s returned IRQ_WAKE_THREAD \"\n\t       \"but no thread function available.\", irq, action->name);\n}"
  },
  {
    "function_name": "no_action",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/handle.c",
    "lines": "44-47",
    "snippet": "irqreturn_t no_action(int cpl, void *dev_id)\n{\n\treturn IRQ_NONE;\n}",
    "includes": [
      "#include \"internals.h\"",
      "#include <trace/events/irq.h>",
      "#include <linux/kernel_stat.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/sched.h>",
      "#include <linux/random.h>",
      "#include <linux/irq.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"internals.h\"\n#include <trace/events/irq.h>\n#include <linux/kernel_stat.h>\n#include <linux/interrupt.h>\n#include <linux/sched.h>\n#include <linux/random.h>\n#include <linux/irq.h>\n\nirqreturn_t no_action(int cpl, void *dev_id)\n{\n\treturn IRQ_NONE;\n}"
  },
  {
    "function_name": "handle_bad_irq",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/handle.c",
    "lines": "31-38",
    "snippet": "void handle_bad_irq(struct irq_desc *desc)\n{\n\tunsigned int irq = irq_desc_get_irq(desc);\n\n\tprint_irq_desc(irq, desc);\n\tkstat_incr_irqs_this_cpu(desc);\n\tack_bad_irq(irq);\n}",
    "includes": [
      "#include \"internals.h\"",
      "#include <trace/events/irq.h>",
      "#include <linux/kernel_stat.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/sched.h>",
      "#include <linux/random.h>",
      "#include <linux/irq.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "ack_bad_irq",
          "args": [
            "irq"
          ],
          "line": 37
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kstat_incr_irqs_this_cpu",
          "args": [
            "desc"
          ],
          "line": 36
        },
        "resolved": true,
        "details": {
          "function_name": "kstat_incr_irqs_this_cpu",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/internals.h",
          "lines": "245-249",
          "snippet": "static inline void kstat_incr_irqs_this_cpu(struct irq_desc *desc)\n{\n\t__this_cpu_inc(*desc->kstat_irqs);\n\t__this_cpu_inc(kstat.irqs_sum);\n}",
          "includes": [
            "#include <linux/debugfs.h>",
            "#include \"settings.h\"",
            "#include \"debug.h\"",
            "#include <linux/sched/clock.h>",
            "#include <linux/pm_runtime.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/irqdesc.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern void __disable_irq(struct irq_desc *desc);",
            "extern void __enable_irq(struct irq_desc *desc);",
            "extern int irq_activate(struct irq_desc *desc);",
            "extern void irq_shutdown(struct irq_desc *desc);",
            "extern void irq_enable(struct irq_desc *desc);",
            "extern void irq_disable(struct irq_desc *desc);",
            "extern void mask_irq(struct irq_desc *desc);",
            "extern void unmask_irq(struct irq_desc *desc);",
            "extern void unmask_threaded_irq(struct irq_desc *desc);",
            "irqreturn_t handle_irq_event_percpu(struct irq_desc *desc);",
            "irqreturn_t handle_irq_event(struct irq_desc *desc);",
            "void check_irq_resend(struct irq_desc *desc);",
            "bool irq_wait_for_poll(struct irq_desc *desc);",
            "extern void irq_set_thread_affinity(struct irq_desc *desc);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/debugfs.h>\n#include \"settings.h\"\n#include \"debug.h\"\n#include <linux/sched/clock.h>\n#include <linux/pm_runtime.h>\n#include <linux/kernel_stat.h>\n#include <linux/irqdesc.h>\n\nextern void __disable_irq(struct irq_desc *desc);\nextern void __enable_irq(struct irq_desc *desc);\nextern int irq_activate(struct irq_desc *desc);\nextern void irq_shutdown(struct irq_desc *desc);\nextern void irq_enable(struct irq_desc *desc);\nextern void irq_disable(struct irq_desc *desc);\nextern void mask_irq(struct irq_desc *desc);\nextern void unmask_irq(struct irq_desc *desc);\nextern void unmask_threaded_irq(struct irq_desc *desc);\nirqreturn_t handle_irq_event_percpu(struct irq_desc *desc);\nirqreturn_t handle_irq_event(struct irq_desc *desc);\nvoid check_irq_resend(struct irq_desc *desc);\nbool irq_wait_for_poll(struct irq_desc *desc);\nextern void irq_set_thread_affinity(struct irq_desc *desc);\n\nstatic inline void kstat_incr_irqs_this_cpu(struct irq_desc *desc)\n{\n\t__this_cpu_inc(*desc->kstat_irqs);\n\t__this_cpu_inc(kstat.irqs_sum);\n}"
        }
      },
      {
        "call_info": {
          "callee": "print_irq_desc",
          "args": [
            "irq",
            "desc"
          ],
          "line": 35
        },
        "resolved": true,
        "details": {
          "function_name": "print_irq_desc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/debug.h",
          "lines": "11-45",
          "snippet": "static inline void print_irq_desc(unsigned int irq, struct irq_desc *desc)\n{\n\tstatic DEFINE_RATELIMIT_STATE(ratelimit, 5 * HZ, 5);\n\n\tif (!__ratelimit(&ratelimit))\n\t\treturn;\n\n\tprintk(\"irq %d, desc: %p, depth: %d, count: %d, unhandled: %d\\n\",\n\t\tirq, desc, desc->depth, desc->irq_count, desc->irqs_unhandled);\n\tprintk(\"->handle_irq():  %p, %pS\\n\",\n\t\tdesc->handle_irq, desc->handle_irq);\n\tprintk(\"->irq_data.chip(): %p, %pS\\n\",\n\t\tdesc->irq_data.chip, desc->irq_data.chip);\n\tprintk(\"->action(): %p\\n\", desc->action);\n\tif (desc->action) {\n\t\tprintk(\"->action->handler(): %p, %pS\\n\",\n\t\t\tdesc->action->handler, desc->action->handler);\n\t}\n\n\t___P(IRQ_LEVEL);\n\t___P(IRQ_PER_CPU);\n\t___P(IRQ_NOPROBE);\n\t___P(IRQ_NOREQUEST);\n\t___P(IRQ_NOTHREAD);\n\t___P(IRQ_NOAUTOEN);\n\n\t___PS(IRQS_AUTODETECT);\n\t___PS(IRQS_REPLAY);\n\t___PS(IRQS_WAITING);\n\t___PS(IRQS_PENDING);\n\n\t___PD(IRQS_INPROGRESS);\n\t___PD(IRQS_DISABLED);\n\t___PD(IRQS_MASKED);\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static inline void print_irq_desc(unsigned int irq, struct irq_desc *desc)\n{\n\tstatic DEFINE_RATELIMIT_STATE(ratelimit, 5 * HZ, 5);\n\n\tif (!__ratelimit(&ratelimit))\n\t\treturn;\n\n\tprintk(\"irq %d, desc: %p, depth: %d, count: %d, unhandled: %d\\n\",\n\t\tirq, desc, desc->depth, desc->irq_count, desc->irqs_unhandled);\n\tprintk(\"->handle_irq():  %p, %pS\\n\",\n\t\tdesc->handle_irq, desc->handle_irq);\n\tprintk(\"->irq_data.chip(): %p, %pS\\n\",\n\t\tdesc->irq_data.chip, desc->irq_data.chip);\n\tprintk(\"->action(): %p\\n\", desc->action);\n\tif (desc->action) {\n\t\tprintk(\"->action->handler(): %p, %pS\\n\",\n\t\t\tdesc->action->handler, desc->action->handler);\n\t}\n\n\t___P(IRQ_LEVEL);\n\t___P(IRQ_PER_CPU);\n\t___P(IRQ_NOPROBE);\n\t___P(IRQ_NOREQUEST);\n\t___P(IRQ_NOTHREAD);\n\t___P(IRQ_NOAUTOEN);\n\n\t___PS(IRQS_AUTODETECT);\n\t___PS(IRQS_REPLAY);\n\t___PS(IRQS_WAITING);\n\t___PS(IRQS_PENDING);\n\n\t___PD(IRQS_INPROGRESS);\n\t___PD(IRQS_DISABLED);\n\t___PD(IRQS_MASKED);\n}"
        }
      },
      {
        "call_info": {
          "callee": "irq_desc_get_irq",
          "args": [
            "desc"
          ],
          "line": 33
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"internals.h\"\n#include <trace/events/irq.h>\n#include <linux/kernel_stat.h>\n#include <linux/interrupt.h>\n#include <linux/sched.h>\n#include <linux/random.h>\n#include <linux/irq.h>\n\nvoid handle_bad_irq(struct irq_desc *desc)\n{\n\tunsigned int irq = irq_desc_get_irq(desc);\n\n\tprint_irq_desc(irq, desc);\n\tkstat_incr_irqs_this_cpu(desc);\n\tack_bad_irq(irq);\n}"
  }
]