[
  {
    "function_name": "hardlockup_detector_perf_init",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/watchdog_hld.c",
    "lines": "284-295",
    "snippet": "int __init hardlockup_detector_perf_init(void)\n{\n\tint ret = hardlockup_detector_event_create();\n\n\tif (ret) {\n\t\tpr_info(\"Perf NMI watchdog permanently disabled\\n\");\n\t} else {\n\t\tperf_event_release_kernel(this_cpu_read(watchdog_ev));\n\t\tthis_cpu_write(watchdog_ev, NULL);\n\t}\n\treturn ret;\n}",
    "includes": [
      "#include <linux/perf_event.h>",
      "#include <asm/irq_regs.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/module.h>",
      "#include <linux/atomic.h>",
      "#include <linux/nmi.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct perf_event *, watchdog_ev);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "this_cpu_write",
          "args": [
            "watchdog_ev",
            "NULL"
          ],
          "line": 292
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "perf_event_release_kernel",
          "args": [
            "this_cpu_read(watchdog_ev)"
          ],
          "line": 291
        },
        "resolved": true,
        "details": {
          "function_name": "perf_event_release_kernel",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/events/core.c",
          "lines": "4540-4640",
          "snippet": "int perf_event_release_kernel(struct perf_event *event)\n{\n\tstruct perf_event_context *ctx = event->ctx;\n\tstruct perf_event *child, *tmp;\n\tLIST_HEAD(free_list);\n\n\t/*\n\t * If we got here through err_file: fput(event_file); we will not have\n\t * attached to a context yet.\n\t */\n\tif (!ctx) {\n\t\tWARN_ON_ONCE(event->attach_state &\n\t\t\t\t(PERF_ATTACH_CONTEXT|PERF_ATTACH_GROUP));\n\t\tgoto no_ctx;\n\t}\n\n\tif (!is_kernel_event(event))\n\t\tperf_remove_from_owner(event);\n\n\tctx = perf_event_ctx_lock(event);\n\tWARN_ON_ONCE(ctx->parent_ctx);\n\tperf_remove_from_context(event, DETACH_GROUP);\n\n\traw_spin_lock_irq(&ctx->lock);\n\t/*\n\t * Mark this event as STATE_DEAD, there is no external reference to it\n\t * anymore.\n\t *\n\t * Anybody acquiring event->child_mutex after the below loop _must_\n\t * also see this, most importantly inherit_event() which will avoid\n\t * placing more children on the list.\n\t *\n\t * Thus this guarantees that we will in fact observe and kill _ALL_\n\t * child events.\n\t */\n\tevent->state = PERF_EVENT_STATE_DEAD;\n\traw_spin_unlock_irq(&ctx->lock);\n\n\tperf_event_ctx_unlock(event, ctx);\n\nagain:\n\tmutex_lock(&event->child_mutex);\n\tlist_for_each_entry(child, &event->child_list, child_list) {\n\n\t\t/*\n\t\t * Cannot change, child events are not migrated, see the\n\t\t * comment with perf_event_ctx_lock_nested().\n\t\t */\n\t\tctx = READ_ONCE(child->ctx);\n\t\t/*\n\t\t * Since child_mutex nests inside ctx::mutex, we must jump\n\t\t * through hoops. We start by grabbing a reference on the ctx.\n\t\t *\n\t\t * Since the event cannot get freed while we hold the\n\t\t * child_mutex, the context must also exist and have a !0\n\t\t * reference count.\n\t\t */\n\t\tget_ctx(ctx);\n\n\t\t/*\n\t\t * Now that we have a ctx ref, we can drop child_mutex, and\n\t\t * acquire ctx::mutex without fear of it going away. Then we\n\t\t * can re-acquire child_mutex.\n\t\t */\n\t\tmutex_unlock(&event->child_mutex);\n\t\tmutex_lock(&ctx->mutex);\n\t\tmutex_lock(&event->child_mutex);\n\n\t\t/*\n\t\t * Now that we hold ctx::mutex and child_mutex, revalidate our\n\t\t * state, if child is still the first entry, it didn't get freed\n\t\t * and we can continue doing so.\n\t\t */\n\t\ttmp = list_first_entry_or_null(&event->child_list,\n\t\t\t\t\t       struct perf_event, child_list);\n\t\tif (tmp == child) {\n\t\t\tperf_remove_from_context(child, DETACH_GROUP);\n\t\t\tlist_move(&child->child_list, &free_list);\n\t\t\t/*\n\t\t\t * This matches the refcount bump in inherit_event();\n\t\t\t * this can't be the last reference.\n\t\t\t */\n\t\t\tput_event(event);\n\t\t}\n\n\t\tmutex_unlock(&event->child_mutex);\n\t\tmutex_unlock(&ctx->mutex);\n\t\tput_ctx(ctx);\n\t\tgoto again;\n\t}\n\tmutex_unlock(&event->child_mutex);\n\n\tlist_for_each_entry_safe(child, tmp, &free_list, child_list) {\n\t\tlist_del(&child->child_list);\n\t\tfree_event(child);\n\t}\n\nno_ctx:\n\tput_event(event); /* Must be the 'last' reference */\n\treturn 0;\n}",
          "includes": [
            "#include <asm/irq_regs.h>",
            "#include \"internal.h\"",
            "#include <linux/mount.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/parser.h>",
            "#include <linux/namei.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/compat.h>",
            "#include <linux/mman.h>",
            "#include <linux/module.h>",
            "#include <linux/mm_types.h>",
            "#include <linux/hw_breakpoint.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/rculist.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/device.h>",
            "#include <linux/vmstat.h>",
            "#include <linux/reboot.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/percpu.h>",
            "#include <linux/dcache.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/tick.h>",
            "#include <linux/hash.h>",
            "#include <linux/slab.h>",
            "#include <linux/poll.h>",
            "#include <linux/file.h>",
            "#include <linux/idr.h>",
            "#include <linux/smp.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/fs.h>"
          ],
          "macros_used": [
            "#define DETACH_GROUP\t0x01UL"
          ],
          "globals_used": [
            "static void update_context_time(struct perf_event_context *ctx);",
            "static u64 perf_event_time(struct perf_event *event);",
            "static __must_check struct",
            "static void perf_log_itrace_start(struct perf_event *event);",
            "static void perf_event_free_filter(struct perf_event *event);",
            "static void perf_event_free_bpf_prog(struct perf_event *event);",
            "static void perf_pmu_output_stop(struct perf_event *event);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/irq_regs.h>\n#include \"internal.h\"\n#include <linux/mount.h>\n#include <linux/proc_ns.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/clock.h>\n#include <linux/parser.h>\n#include <linux/namei.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/compat.h>\n#include <linux/mman.h>\n#include <linux/module.h>\n#include <linux/mm_types.h>\n#include <linux/hw_breakpoint.h>\n#include <linux/trace_events.h>\n#include <linux/perf_event.h>\n#include <linux/cgroup.h>\n#include <linux/kernel_stat.h>\n#include <linux/anon_inodes.h>\n#include <linux/syscalls.h>\n#include <linux/uaccess.h>\n#include <linux/rculist.h>\n#include <linux/hardirq.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/device.h>\n#include <linux/vmstat.h>\n#include <linux/reboot.h>\n#include <linux/ptrace.h>\n#include <linux/percpu.h>\n#include <linux/dcache.h>\n#include <linux/sysfs.h>\n#include <linux/tick.h>\n#include <linux/hash.h>\n#include <linux/slab.h>\n#include <linux/poll.h>\n#include <linux/file.h>\n#include <linux/idr.h>\n#include <linux/smp.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/fs.h>\n\n#define DETACH_GROUP\t0x01UL\n\nstatic void update_context_time(struct perf_event_context *ctx);\nstatic u64 perf_event_time(struct perf_event *event);\nstatic __must_check struct;\nstatic void perf_log_itrace_start(struct perf_event *event);\nstatic void perf_event_free_filter(struct perf_event *event);\nstatic void perf_event_free_bpf_prog(struct perf_event *event);\nstatic void perf_pmu_output_stop(struct perf_event *event);\n\nint perf_event_release_kernel(struct perf_event *event)\n{\n\tstruct perf_event_context *ctx = event->ctx;\n\tstruct perf_event *child, *tmp;\n\tLIST_HEAD(free_list);\n\n\t/*\n\t * If we got here through err_file: fput(event_file); we will not have\n\t * attached to a context yet.\n\t */\n\tif (!ctx) {\n\t\tWARN_ON_ONCE(event->attach_state &\n\t\t\t\t(PERF_ATTACH_CONTEXT|PERF_ATTACH_GROUP));\n\t\tgoto no_ctx;\n\t}\n\n\tif (!is_kernel_event(event))\n\t\tperf_remove_from_owner(event);\n\n\tctx = perf_event_ctx_lock(event);\n\tWARN_ON_ONCE(ctx->parent_ctx);\n\tperf_remove_from_context(event, DETACH_GROUP);\n\n\traw_spin_lock_irq(&ctx->lock);\n\t/*\n\t * Mark this event as STATE_DEAD, there is no external reference to it\n\t * anymore.\n\t *\n\t * Anybody acquiring event->child_mutex after the below loop _must_\n\t * also see this, most importantly inherit_event() which will avoid\n\t * placing more children on the list.\n\t *\n\t * Thus this guarantees that we will in fact observe and kill _ALL_\n\t * child events.\n\t */\n\tevent->state = PERF_EVENT_STATE_DEAD;\n\traw_spin_unlock_irq(&ctx->lock);\n\n\tperf_event_ctx_unlock(event, ctx);\n\nagain:\n\tmutex_lock(&event->child_mutex);\n\tlist_for_each_entry(child, &event->child_list, child_list) {\n\n\t\t/*\n\t\t * Cannot change, child events are not migrated, see the\n\t\t * comment with perf_event_ctx_lock_nested().\n\t\t */\n\t\tctx = READ_ONCE(child->ctx);\n\t\t/*\n\t\t * Since child_mutex nests inside ctx::mutex, we must jump\n\t\t * through hoops. We start by grabbing a reference on the ctx.\n\t\t *\n\t\t * Since the event cannot get freed while we hold the\n\t\t * child_mutex, the context must also exist and have a !0\n\t\t * reference count.\n\t\t */\n\t\tget_ctx(ctx);\n\n\t\t/*\n\t\t * Now that we have a ctx ref, we can drop child_mutex, and\n\t\t * acquire ctx::mutex without fear of it going away. Then we\n\t\t * can re-acquire child_mutex.\n\t\t */\n\t\tmutex_unlock(&event->child_mutex);\n\t\tmutex_lock(&ctx->mutex);\n\t\tmutex_lock(&event->child_mutex);\n\n\t\t/*\n\t\t * Now that we hold ctx::mutex and child_mutex, revalidate our\n\t\t * state, if child is still the first entry, it didn't get freed\n\t\t * and we can continue doing so.\n\t\t */\n\t\ttmp = list_first_entry_or_null(&event->child_list,\n\t\t\t\t\t       struct perf_event, child_list);\n\t\tif (tmp == child) {\n\t\t\tperf_remove_from_context(child, DETACH_GROUP);\n\t\t\tlist_move(&child->child_list, &free_list);\n\t\t\t/*\n\t\t\t * This matches the refcount bump in inherit_event();\n\t\t\t * this can't be the last reference.\n\t\t\t */\n\t\t\tput_event(event);\n\t\t}\n\n\t\tmutex_unlock(&event->child_mutex);\n\t\tmutex_unlock(&ctx->mutex);\n\t\tput_ctx(ctx);\n\t\tgoto again;\n\t}\n\tmutex_unlock(&event->child_mutex);\n\n\tlist_for_each_entry_safe(child, tmp, &free_list, child_list) {\n\t\tlist_del(&child->child_list);\n\t\tfree_event(child);\n\t}\n\nno_ctx:\n\tput_event(event); /* Must be the 'last' reference */\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "this_cpu_read",
          "args": [
            "watchdog_ev"
          ],
          "line": 291
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"Perf NMI watchdog permanently disabled\\n\""
          ],
          "line": 289
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hardlockup_detector_event_create",
          "args": [],
          "line": 286
        },
        "resolved": true,
        "details": {
          "function_name": "hardlockup_detector_event_create",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/watchdog_hld.c",
          "lines": "165-184",
          "snippet": "static int hardlockup_detector_event_create(void)\n{\n\tunsigned int cpu = smp_processor_id();\n\tstruct perf_event_attr *wd_attr;\n\tstruct perf_event *evt;\n\n\twd_attr = &wd_hw_attr;\n\twd_attr->sample_period = hw_nmi_get_sample_period(watchdog_thresh);\n\n\t/* Try to register using hardware perf events */\n\tevt = perf_event_create_kernel_counter(wd_attr, cpu, NULL,\n\t\t\t\t\t       watchdog_overflow_callback, NULL);\n\tif (IS_ERR(evt)) {\n\t\tpr_debug(\"Perf event create on CPU %d failed with %ld\\n\", cpu,\n\t\t\t PTR_ERR(evt));\n\t\treturn PTR_ERR(evt);\n\t}\n\tthis_cpu_write(watchdog_ev, evt);\n\treturn 0;\n}",
          "includes": [
            "#include <linux/perf_event.h>",
            "#include <asm/irq_regs.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/module.h>",
            "#include <linux/atomic.h>",
            "#include <linux/nmi.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(struct perf_event *, watchdog_ev);",
            "static struct perf_event_attr wd_hw_attr = {\n\t.type\t\t= PERF_TYPE_HARDWARE,\n\t.config\t\t= PERF_COUNT_HW_CPU_CYCLES,\n\t.size\t\t= sizeof(struct perf_event_attr),\n\t.pinned\t\t= 1,\n\t.disabled\t= 1,\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/perf_event.h>\n#include <asm/irq_regs.h>\n#include <linux/sched/debug.h>\n#include <linux/module.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n\nstatic DEFINE_PER_CPU(struct perf_event *, watchdog_ev);\nstatic struct perf_event_attr wd_hw_attr = {\n\t.type\t\t= PERF_TYPE_HARDWARE,\n\t.config\t\t= PERF_COUNT_HW_CPU_CYCLES,\n\t.size\t\t= sizeof(struct perf_event_attr),\n\t.pinned\t\t= 1,\n\t.disabled\t= 1,\n};\n\nstatic int hardlockup_detector_event_create(void)\n{\n\tunsigned int cpu = smp_processor_id();\n\tstruct perf_event_attr *wd_attr;\n\tstruct perf_event *evt;\n\n\twd_attr = &wd_hw_attr;\n\twd_attr->sample_period = hw_nmi_get_sample_period(watchdog_thresh);\n\n\t/* Try to register using hardware perf events */\n\tevt = perf_event_create_kernel_counter(wd_attr, cpu, NULL,\n\t\t\t\t\t       watchdog_overflow_callback, NULL);\n\tif (IS_ERR(evt)) {\n\t\tpr_debug(\"Perf event create on CPU %d failed with %ld\\n\", cpu,\n\t\t\t PTR_ERR(evt));\n\t\treturn PTR_ERR(evt);\n\t}\n\tthis_cpu_write(watchdog_ev, evt);\n\treturn 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/perf_event.h>\n#include <asm/irq_regs.h>\n#include <linux/sched/debug.h>\n#include <linux/module.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n\nstatic DEFINE_PER_CPU(struct perf_event *, watchdog_ev);\n\nint __init hardlockup_detector_perf_init(void)\n{\n\tint ret = hardlockup_detector_event_create();\n\n\tif (ret) {\n\t\tpr_info(\"Perf NMI watchdog permanently disabled\\n\");\n\t} else {\n\t\tperf_event_release_kernel(this_cpu_read(watchdog_ev));\n\t\tthis_cpu_write(watchdog_ev, NULL);\n\t}\n\treturn ret;\n}"
  },
  {
    "function_name": "hardlockup_detector_perf_restart",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/watchdog_hld.c",
    "lines": "264-279",
    "snippet": "void __init hardlockup_detector_perf_restart(void)\n{\n\tint cpu;\n\n\tlockdep_assert_cpus_held();\n\n\tif (!(watchdog_enabled & NMI_WATCHDOG_ENABLED))\n\t\treturn;\n\n\tfor_each_online_cpu(cpu) {\n\t\tstruct perf_event *event = per_cpu(watchdog_ev, cpu);\n\n\t\tif (event)\n\t\t\tperf_event_enable(event);\n\t}\n}",
    "includes": [
      "#include <linux/perf_event.h>",
      "#include <asm/irq_regs.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/module.h>",
      "#include <linux/atomic.h>",
      "#include <linux/nmi.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct perf_event *, watchdog_ev);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "perf_event_enable",
          "args": [
            "event"
          ],
          "line": 277
        },
        "resolved": true,
        "details": {
          "function_name": "perf_event_enable_on_exec",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/events/core.c",
          "lines": "3767-3805",
          "snippet": "static void perf_event_enable_on_exec(int ctxn)\n{\n\tstruct perf_event_context *ctx, *clone_ctx = NULL;\n\tenum event_type_t event_type = 0;\n\tstruct perf_cpu_context *cpuctx;\n\tstruct perf_event *event;\n\tunsigned long flags;\n\tint enabled = 0;\n\n\tlocal_irq_save(flags);\n\tctx = current->perf_event_ctxp[ctxn];\n\tif (!ctx || !ctx->nr_events)\n\t\tgoto out;\n\n\tcpuctx = __get_cpu_context(ctx);\n\tperf_ctx_lock(cpuctx, ctx);\n\tctx_sched_out(ctx, cpuctx, EVENT_TIME);\n\tlist_for_each_entry(event, &ctx->event_list, event_entry) {\n\t\tenabled |= event_enable_on_exec(event, ctx);\n\t\tevent_type |= get_event_type(event);\n\t}\n\n\t/*\n\t * Unclone and reschedule this context if we enabled any event.\n\t */\n\tif (enabled) {\n\t\tclone_ctx = unclone_ctx(ctx);\n\t\tctx_resched(cpuctx, ctx, event_type);\n\t} else {\n\t\tctx_sched_in(ctx, cpuctx, EVENT_TIME, current);\n\t}\n\tperf_ctx_unlock(cpuctx, ctx);\n\nout:\n\tlocal_irq_restore(flags);\n\n\tif (clone_ctx)\n\t\tput_ctx(clone_ctx);\n}",
          "includes": [
            "#include <asm/irq_regs.h>",
            "#include \"internal.h\"",
            "#include <linux/mount.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/parser.h>",
            "#include <linux/namei.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/compat.h>",
            "#include <linux/mman.h>",
            "#include <linux/module.h>",
            "#include <linux/mm_types.h>",
            "#include <linux/hw_breakpoint.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/rculist.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/device.h>",
            "#include <linux/vmstat.h>",
            "#include <linux/reboot.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/percpu.h>",
            "#include <linux/dcache.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/tick.h>",
            "#include <linux/hash.h>",
            "#include <linux/slab.h>",
            "#include <linux/poll.h>",
            "#include <linux/file.h>",
            "#include <linux/idr.h>",
            "#include <linux/smp.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/fs.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static bool perf_rotate_context(struct perf_cpu_context *cpuctx);",
            "static void cpu_ctx_sched_out(struct perf_cpu_context *cpuctx,\n\t\t\t      enum event_type_t event_type);",
            "static void update_context_time(struct perf_event_context *ctx);",
            "static u64 perf_event_time(struct perf_event *event);",
            "static __always_inline enum",
            "static __must_check struct",
            "static void perf_log_itrace_start(struct perf_event *event);",
            "static void ctx_sched_out(struct perf_event_context *ctx,\n\t\t\t  struct perf_cpu_context *cpuctx,\n\t\t\t  enum event_type_t event_type);",
            "static void perf_event_free_filter(struct perf_event *event);",
            "static void perf_event_free_bpf_prog(struct perf_event *event);",
            "static void perf_pmu_output_stop(struct perf_event *event);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/irq_regs.h>\n#include \"internal.h\"\n#include <linux/mount.h>\n#include <linux/proc_ns.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/clock.h>\n#include <linux/parser.h>\n#include <linux/namei.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/compat.h>\n#include <linux/mman.h>\n#include <linux/module.h>\n#include <linux/mm_types.h>\n#include <linux/hw_breakpoint.h>\n#include <linux/trace_events.h>\n#include <linux/perf_event.h>\n#include <linux/cgroup.h>\n#include <linux/kernel_stat.h>\n#include <linux/anon_inodes.h>\n#include <linux/syscalls.h>\n#include <linux/uaccess.h>\n#include <linux/rculist.h>\n#include <linux/hardirq.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/device.h>\n#include <linux/vmstat.h>\n#include <linux/reboot.h>\n#include <linux/ptrace.h>\n#include <linux/percpu.h>\n#include <linux/dcache.h>\n#include <linux/sysfs.h>\n#include <linux/tick.h>\n#include <linux/hash.h>\n#include <linux/slab.h>\n#include <linux/poll.h>\n#include <linux/file.h>\n#include <linux/idr.h>\n#include <linux/smp.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/fs.h>\n\nstatic bool perf_rotate_context(struct perf_cpu_context *cpuctx);\nstatic void cpu_ctx_sched_out(struct perf_cpu_context *cpuctx,\n\t\t\t      enum event_type_t event_type);\nstatic void update_context_time(struct perf_event_context *ctx);\nstatic u64 perf_event_time(struct perf_event *event);\nstatic __always_inline enum;\nstatic __must_check struct;\nstatic void perf_log_itrace_start(struct perf_event *event);\nstatic void ctx_sched_out(struct perf_event_context *ctx,\n\t\t\t  struct perf_cpu_context *cpuctx,\n\t\t\t  enum event_type_t event_type);\nstatic void perf_event_free_filter(struct perf_event *event);\nstatic void perf_event_free_bpf_prog(struct perf_event *event);\nstatic void perf_pmu_output_stop(struct perf_event *event);\n\nstatic void perf_event_enable_on_exec(int ctxn)\n{\n\tstruct perf_event_context *ctx, *clone_ctx = NULL;\n\tenum event_type_t event_type = 0;\n\tstruct perf_cpu_context *cpuctx;\n\tstruct perf_event *event;\n\tunsigned long flags;\n\tint enabled = 0;\n\n\tlocal_irq_save(flags);\n\tctx = current->perf_event_ctxp[ctxn];\n\tif (!ctx || !ctx->nr_events)\n\t\tgoto out;\n\n\tcpuctx = __get_cpu_context(ctx);\n\tperf_ctx_lock(cpuctx, ctx);\n\tctx_sched_out(ctx, cpuctx, EVENT_TIME);\n\tlist_for_each_entry(event, &ctx->event_list, event_entry) {\n\t\tenabled |= event_enable_on_exec(event, ctx);\n\t\tevent_type |= get_event_type(event);\n\t}\n\n\t/*\n\t * Unclone and reschedule this context if we enabled any event.\n\t */\n\tif (enabled) {\n\t\tclone_ctx = unclone_ctx(ctx);\n\t\tctx_resched(cpuctx, ctx, event_type);\n\t} else {\n\t\tctx_sched_in(ctx, cpuctx, EVENT_TIME, current);\n\t}\n\tperf_ctx_unlock(cpuctx, ctx);\n\nout:\n\tlocal_irq_restore(flags);\n\n\tif (clone_ctx)\n\t\tput_ctx(clone_ctx);\n}"
        }
      },
      {
        "call_info": {
          "callee": "per_cpu",
          "args": [
            "watchdog_ev",
            "cpu"
          ],
          "line": 274
        },
        "resolved": true,
        "details": {
          "function_name": "kdb_per_cpu",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/debug/kdb/kdb_main.c",
          "lines": "2575-2640",
          "snippet": "static int kdb_per_cpu(int argc, const char **argv)\n{\n\tchar fmtstr[64];\n\tint cpu, diag, nextarg = 1;\n\tunsigned long addr, symaddr, val, bytesperword = 0, whichcpu = ~0UL;\n\n\tif (argc < 1 || argc > 3)\n\t\treturn KDB_ARGCOUNT;\n\n\tdiag = kdbgetaddrarg(argc, argv, &nextarg, &symaddr, NULL, NULL);\n\tif (diag)\n\t\treturn diag;\n\n\tif (argc >= 2) {\n\t\tdiag = kdbgetularg(argv[2], &bytesperword);\n\t\tif (diag)\n\t\t\treturn diag;\n\t}\n\tif (!bytesperword)\n\t\tbytesperword = KDB_WORD_SIZE;\n\telse if (bytesperword > KDB_WORD_SIZE)\n\t\treturn KDB_BADWIDTH;\n\tsprintf(fmtstr, \"%%0%dlx \", (int)(2*bytesperword));\n\tif (argc >= 3) {\n\t\tdiag = kdbgetularg(argv[3], &whichcpu);\n\t\tif (diag)\n\t\t\treturn diag;\n\t\tif (!cpu_online(whichcpu)) {\n\t\t\tkdb_printf(\"cpu %ld is not online\\n\", whichcpu);\n\t\t\treturn KDB_BADCPUNUM;\n\t\t}\n\t}\n\n\t/* Most architectures use __per_cpu_offset[cpu], some use\n\t * __per_cpu_offset(cpu), smp has no __per_cpu_offset.\n\t */\n#ifdef\t__per_cpu_offset\n#define KDB_PCU(cpu) __per_cpu_offset(cpu)\n#else\n#ifdef\tCONFIG_SMP\n#define KDB_PCU(cpu) __per_cpu_offset[cpu]\n#else\n#define KDB_PCU(cpu) 0\n#endif\n#endif\n\tfor_each_online_cpu(cpu) {\n\t\tif (KDB_FLAG(CMD_INTERRUPT))\n\t\t\treturn 0;\n\n\t\tif (whichcpu != ~0UL && whichcpu != cpu)\n\t\t\tcontinue;\n\t\taddr = symaddr + KDB_PCU(cpu);\n\t\tdiag = kdb_getword(&val, addr, bytesperword);\n\t\tif (diag) {\n\t\t\tkdb_printf(\"%5d \" kdb_bfd_vma_fmt0 \" - unable to \"\n\t\t\t\t   \"read, diag=%d\\n\", cpu, addr, diag);\n\t\t\tcontinue;\n\t\t}\n\t\tkdb_printf(\"%5d \", cpu);\n\t\tkdb_md_line(fmtstr, addr,\n\t\t\tbytesperword == KDB_WORD_SIZE,\n\t\t\t1, bytesperword, 1, 1, 0);\n\t}\n#undef KDB_PCU\n\treturn 0;\n}",
          "includes": [
            "#include \"kdb_private.h\"",
            "#include <linux/slab.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/kdebug.h>",
            "#include <linux/cpu.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/time.h>",
            "#include <linux/nmi.h>",
            "#include <linux/delay.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/notifier.h>",
            "#include <linux/kdb.h>",
            "#include <linux/kgdb.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/init.h>",
            "#include <linux/mm.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/atomic.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/utsname.h>",
            "#include <linux/smp.h>",
            "#include <linux/sysrq.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched.h>",
            "#include <linux/reboot.h>",
            "#include <linux/kmsg_dump.h>",
            "#include <linux/kernel.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/ctype.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kdb_private.h\"\n#include <linux/slab.h>\n#include <linux/uaccess.h>\n#include <linux/proc_fs.h>\n#include <linux/kdebug.h>\n#include <linux/cpu.h>\n#include <linux/sysctl.h>\n#include <linux/ptrace.h>\n#include <linux/time.h>\n#include <linux/nmi.h>\n#include <linux/delay.h>\n#include <linux/interrupt.h>\n#include <linux/notifier.h>\n#include <linux/kdb.h>\n#include <linux/kgdb.h>\n#include <linux/kallsyms.h>\n#include <linux/init.h>\n#include <linux/mm.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/atomic.h>\n#include <linux/vmalloc.h>\n#include <linux/utsname.h>\n#include <linux/smp.h>\n#include <linux/sysrq.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched.h>\n#include <linux/reboot.h>\n#include <linux/kmsg_dump.h>\n#include <linux/kernel.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/ctype.h>\n\nstatic int kdb_per_cpu(int argc, const char **argv)\n{\n\tchar fmtstr[64];\n\tint cpu, diag, nextarg = 1;\n\tunsigned long addr, symaddr, val, bytesperword = 0, whichcpu = ~0UL;\n\n\tif (argc < 1 || argc > 3)\n\t\treturn KDB_ARGCOUNT;\n\n\tdiag = kdbgetaddrarg(argc, argv, &nextarg, &symaddr, NULL, NULL);\n\tif (diag)\n\t\treturn diag;\n\n\tif (argc >= 2) {\n\t\tdiag = kdbgetularg(argv[2], &bytesperword);\n\t\tif (diag)\n\t\t\treturn diag;\n\t}\n\tif (!bytesperword)\n\t\tbytesperword = KDB_WORD_SIZE;\n\telse if (bytesperword > KDB_WORD_SIZE)\n\t\treturn KDB_BADWIDTH;\n\tsprintf(fmtstr, \"%%0%dlx \", (int)(2*bytesperword));\n\tif (argc >= 3) {\n\t\tdiag = kdbgetularg(argv[3], &whichcpu);\n\t\tif (diag)\n\t\t\treturn diag;\n\t\tif (!cpu_online(whichcpu)) {\n\t\t\tkdb_printf(\"cpu %ld is not online\\n\", whichcpu);\n\t\t\treturn KDB_BADCPUNUM;\n\t\t}\n\t}\n\n\t/* Most architectures use __per_cpu_offset[cpu], some use\n\t * __per_cpu_offset(cpu), smp has no __per_cpu_offset.\n\t */\n#ifdef\t__per_cpu_offset\n#define KDB_PCU(cpu) __per_cpu_offset(cpu)\n#else\n#ifdef\tCONFIG_SMP\n#define KDB_PCU(cpu) __per_cpu_offset[cpu]\n#else\n#define KDB_PCU(cpu) 0\n#endif\n#endif\n\tfor_each_online_cpu(cpu) {\n\t\tif (KDB_FLAG(CMD_INTERRUPT))\n\t\t\treturn 0;\n\n\t\tif (whichcpu != ~0UL && whichcpu != cpu)\n\t\t\tcontinue;\n\t\taddr = symaddr + KDB_PCU(cpu);\n\t\tdiag = kdb_getword(&val, addr, bytesperword);\n\t\tif (diag) {\n\t\t\tkdb_printf(\"%5d \" kdb_bfd_vma_fmt0 \" - unable to \"\n\t\t\t\t   \"read, diag=%d\\n\", cpu, addr, diag);\n\t\t\tcontinue;\n\t\t}\n\t\tkdb_printf(\"%5d \", cpu);\n\t\tkdb_md_line(fmtstr, addr,\n\t\t\tbytesperword == KDB_WORD_SIZE,\n\t\t\t1, bytesperword, 1, 1, 0);\n\t}\n#undef KDB_PCU\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "lockdep_assert_cpus_held",
          "args": [],
          "line": 268
        },
        "resolved": true,
        "details": {
          "function_name": "lockdep_assert_cpus_held",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/cpu.c",
          "lines": "313-316",
          "snippet": "void lockdep_assert_cpus_held(void)\n{\n\tpercpu_rwsem_assert_held(&cpu_hotplug_lock);\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <trace/events/cpuhp.h>",
            "#include <trace/events/power.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/slab.h>",
            "#include <linux/relay.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/nmi.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/suspend.h>",
            "#include <linux/gfp.h>",
            "#include <linux/mutex.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/kthread.h>",
            "#include <linux/bug.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/unistd.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/notifier.h>",
            "#include <linux/init.h>",
            "#include <linux/smp.h>",
            "#include <linux/proc_fs.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <trace/events/cpuhp.h>\n#include <trace/events/power.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/slab.h>\n#include <linux/relay.h>\n#include <linux/smpboot.h>\n#include <linux/nmi.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/lockdep.h>\n#include <linux/suspend.h>\n#include <linux/gfp.h>\n#include <linux/mutex.h>\n#include <linux/stop_machine.h>\n#include <linux/kthread.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/unistd.h>\n#include <linux/sched/task.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/signal.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/smp.h>\n#include <linux/proc_fs.h>\n\nvoid lockdep_assert_cpus_held(void)\n{\n\tpercpu_rwsem_assert_held(&cpu_hotplug_lock);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/perf_event.h>\n#include <asm/irq_regs.h>\n#include <linux/sched/debug.h>\n#include <linux/module.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n\nstatic DEFINE_PER_CPU(struct perf_event *, watchdog_ev);\n\nvoid __init hardlockup_detector_perf_restart(void)\n{\n\tint cpu;\n\n\tlockdep_assert_cpus_held();\n\n\tif (!(watchdog_enabled & NMI_WATCHDOG_ENABLED))\n\t\treturn;\n\n\tfor_each_online_cpu(cpu) {\n\t\tstruct perf_event *event = per_cpu(watchdog_ev, cpu);\n\n\t\tif (event)\n\t\t\tperf_event_enable(event);\n\t}\n}"
  },
  {
    "function_name": "hardlockup_detector_perf_stop",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/watchdog_hld.c",
    "lines": "245-257",
    "snippet": "void __init hardlockup_detector_perf_stop(void)\n{\n\tint cpu;\n\n\tlockdep_assert_cpus_held();\n\n\tfor_each_online_cpu(cpu) {\n\t\tstruct perf_event *event = per_cpu(watchdog_ev, cpu);\n\n\t\tif (event)\n\t\t\tperf_event_disable(event);\n\t}\n}",
    "includes": [
      "#include <linux/perf_event.h>",
      "#include <asm/irq_regs.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/module.h>",
      "#include <linux/atomic.h>",
      "#include <linux/nmi.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct perf_event *, watchdog_ev);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "perf_event_disable",
          "args": [
            "event"
          ],
          "line": 255
        },
        "resolved": true,
        "details": {
          "function_name": "perf_event_disable_inatomic",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/events/core.c",
          "lines": "2197-2201",
          "snippet": "void perf_event_disable_inatomic(struct perf_event *event)\n{\n\tevent->pending_disable = 1;\n\tirq_work_queue(&event->pending);\n}",
          "includes": [
            "#include <asm/irq_regs.h>",
            "#include \"internal.h\"",
            "#include <linux/mount.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/parser.h>",
            "#include <linux/namei.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/compat.h>",
            "#include <linux/mman.h>",
            "#include <linux/module.h>",
            "#include <linux/mm_types.h>",
            "#include <linux/hw_breakpoint.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/rculist.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/device.h>",
            "#include <linux/vmstat.h>",
            "#include <linux/reboot.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/percpu.h>",
            "#include <linux/dcache.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/tick.h>",
            "#include <linux/hash.h>",
            "#include <linux/slab.h>",
            "#include <linux/poll.h>",
            "#include <linux/file.h>",
            "#include <linux/idr.h>",
            "#include <linux/smp.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/fs.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static u64 perf_event_time(struct perf_event *event);",
            "static __must_check struct",
            "static void perf_log_itrace_start(struct perf_event *event);",
            "static void perf_event_free_filter(struct perf_event *event);",
            "static void perf_event_free_bpf_prog(struct perf_event *event);",
            "static void perf_pmu_output_stop(struct perf_event *event);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/irq_regs.h>\n#include \"internal.h\"\n#include <linux/mount.h>\n#include <linux/proc_ns.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/clock.h>\n#include <linux/parser.h>\n#include <linux/namei.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/compat.h>\n#include <linux/mman.h>\n#include <linux/module.h>\n#include <linux/mm_types.h>\n#include <linux/hw_breakpoint.h>\n#include <linux/trace_events.h>\n#include <linux/perf_event.h>\n#include <linux/cgroup.h>\n#include <linux/kernel_stat.h>\n#include <linux/anon_inodes.h>\n#include <linux/syscalls.h>\n#include <linux/uaccess.h>\n#include <linux/rculist.h>\n#include <linux/hardirq.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/device.h>\n#include <linux/vmstat.h>\n#include <linux/reboot.h>\n#include <linux/ptrace.h>\n#include <linux/percpu.h>\n#include <linux/dcache.h>\n#include <linux/sysfs.h>\n#include <linux/tick.h>\n#include <linux/hash.h>\n#include <linux/slab.h>\n#include <linux/poll.h>\n#include <linux/file.h>\n#include <linux/idr.h>\n#include <linux/smp.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/fs.h>\n\nstatic u64 perf_event_time(struct perf_event *event);\nstatic __must_check struct;\nstatic void perf_log_itrace_start(struct perf_event *event);\nstatic void perf_event_free_filter(struct perf_event *event);\nstatic void perf_event_free_bpf_prog(struct perf_event *event);\nstatic void perf_pmu_output_stop(struct perf_event *event);\n\nvoid perf_event_disable_inatomic(struct perf_event *event)\n{\n\tevent->pending_disable = 1;\n\tirq_work_queue(&event->pending);\n}"
        }
      },
      {
        "call_info": {
          "callee": "per_cpu",
          "args": [
            "watchdog_ev",
            "cpu"
          ],
          "line": 252
        },
        "resolved": true,
        "details": {
          "function_name": "kdb_per_cpu",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/debug/kdb/kdb_main.c",
          "lines": "2575-2640",
          "snippet": "static int kdb_per_cpu(int argc, const char **argv)\n{\n\tchar fmtstr[64];\n\tint cpu, diag, nextarg = 1;\n\tunsigned long addr, symaddr, val, bytesperword = 0, whichcpu = ~0UL;\n\n\tif (argc < 1 || argc > 3)\n\t\treturn KDB_ARGCOUNT;\n\n\tdiag = kdbgetaddrarg(argc, argv, &nextarg, &symaddr, NULL, NULL);\n\tif (diag)\n\t\treturn diag;\n\n\tif (argc >= 2) {\n\t\tdiag = kdbgetularg(argv[2], &bytesperword);\n\t\tif (diag)\n\t\t\treturn diag;\n\t}\n\tif (!bytesperword)\n\t\tbytesperword = KDB_WORD_SIZE;\n\telse if (bytesperword > KDB_WORD_SIZE)\n\t\treturn KDB_BADWIDTH;\n\tsprintf(fmtstr, \"%%0%dlx \", (int)(2*bytesperword));\n\tif (argc >= 3) {\n\t\tdiag = kdbgetularg(argv[3], &whichcpu);\n\t\tif (diag)\n\t\t\treturn diag;\n\t\tif (!cpu_online(whichcpu)) {\n\t\t\tkdb_printf(\"cpu %ld is not online\\n\", whichcpu);\n\t\t\treturn KDB_BADCPUNUM;\n\t\t}\n\t}\n\n\t/* Most architectures use __per_cpu_offset[cpu], some use\n\t * __per_cpu_offset(cpu), smp has no __per_cpu_offset.\n\t */\n#ifdef\t__per_cpu_offset\n#define KDB_PCU(cpu) __per_cpu_offset(cpu)\n#else\n#ifdef\tCONFIG_SMP\n#define KDB_PCU(cpu) __per_cpu_offset[cpu]\n#else\n#define KDB_PCU(cpu) 0\n#endif\n#endif\n\tfor_each_online_cpu(cpu) {\n\t\tif (KDB_FLAG(CMD_INTERRUPT))\n\t\t\treturn 0;\n\n\t\tif (whichcpu != ~0UL && whichcpu != cpu)\n\t\t\tcontinue;\n\t\taddr = symaddr + KDB_PCU(cpu);\n\t\tdiag = kdb_getword(&val, addr, bytesperword);\n\t\tif (diag) {\n\t\t\tkdb_printf(\"%5d \" kdb_bfd_vma_fmt0 \" - unable to \"\n\t\t\t\t   \"read, diag=%d\\n\", cpu, addr, diag);\n\t\t\tcontinue;\n\t\t}\n\t\tkdb_printf(\"%5d \", cpu);\n\t\tkdb_md_line(fmtstr, addr,\n\t\t\tbytesperword == KDB_WORD_SIZE,\n\t\t\t1, bytesperword, 1, 1, 0);\n\t}\n#undef KDB_PCU\n\treturn 0;\n}",
          "includes": [
            "#include \"kdb_private.h\"",
            "#include <linux/slab.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/kdebug.h>",
            "#include <linux/cpu.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/time.h>",
            "#include <linux/nmi.h>",
            "#include <linux/delay.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/notifier.h>",
            "#include <linux/kdb.h>",
            "#include <linux/kgdb.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/init.h>",
            "#include <linux/mm.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/atomic.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/utsname.h>",
            "#include <linux/smp.h>",
            "#include <linux/sysrq.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched.h>",
            "#include <linux/reboot.h>",
            "#include <linux/kmsg_dump.h>",
            "#include <linux/kernel.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/ctype.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kdb_private.h\"\n#include <linux/slab.h>\n#include <linux/uaccess.h>\n#include <linux/proc_fs.h>\n#include <linux/kdebug.h>\n#include <linux/cpu.h>\n#include <linux/sysctl.h>\n#include <linux/ptrace.h>\n#include <linux/time.h>\n#include <linux/nmi.h>\n#include <linux/delay.h>\n#include <linux/interrupt.h>\n#include <linux/notifier.h>\n#include <linux/kdb.h>\n#include <linux/kgdb.h>\n#include <linux/kallsyms.h>\n#include <linux/init.h>\n#include <linux/mm.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/atomic.h>\n#include <linux/vmalloc.h>\n#include <linux/utsname.h>\n#include <linux/smp.h>\n#include <linux/sysrq.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched.h>\n#include <linux/reboot.h>\n#include <linux/kmsg_dump.h>\n#include <linux/kernel.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/ctype.h>\n\nstatic int kdb_per_cpu(int argc, const char **argv)\n{\n\tchar fmtstr[64];\n\tint cpu, diag, nextarg = 1;\n\tunsigned long addr, symaddr, val, bytesperword = 0, whichcpu = ~0UL;\n\n\tif (argc < 1 || argc > 3)\n\t\treturn KDB_ARGCOUNT;\n\n\tdiag = kdbgetaddrarg(argc, argv, &nextarg, &symaddr, NULL, NULL);\n\tif (diag)\n\t\treturn diag;\n\n\tif (argc >= 2) {\n\t\tdiag = kdbgetularg(argv[2], &bytesperword);\n\t\tif (diag)\n\t\t\treturn diag;\n\t}\n\tif (!bytesperword)\n\t\tbytesperword = KDB_WORD_SIZE;\n\telse if (bytesperword > KDB_WORD_SIZE)\n\t\treturn KDB_BADWIDTH;\n\tsprintf(fmtstr, \"%%0%dlx \", (int)(2*bytesperword));\n\tif (argc >= 3) {\n\t\tdiag = kdbgetularg(argv[3], &whichcpu);\n\t\tif (diag)\n\t\t\treturn diag;\n\t\tif (!cpu_online(whichcpu)) {\n\t\t\tkdb_printf(\"cpu %ld is not online\\n\", whichcpu);\n\t\t\treturn KDB_BADCPUNUM;\n\t\t}\n\t}\n\n\t/* Most architectures use __per_cpu_offset[cpu], some use\n\t * __per_cpu_offset(cpu), smp has no __per_cpu_offset.\n\t */\n#ifdef\t__per_cpu_offset\n#define KDB_PCU(cpu) __per_cpu_offset(cpu)\n#else\n#ifdef\tCONFIG_SMP\n#define KDB_PCU(cpu) __per_cpu_offset[cpu]\n#else\n#define KDB_PCU(cpu) 0\n#endif\n#endif\n\tfor_each_online_cpu(cpu) {\n\t\tif (KDB_FLAG(CMD_INTERRUPT))\n\t\t\treturn 0;\n\n\t\tif (whichcpu != ~0UL && whichcpu != cpu)\n\t\t\tcontinue;\n\t\taddr = symaddr + KDB_PCU(cpu);\n\t\tdiag = kdb_getword(&val, addr, bytesperword);\n\t\tif (diag) {\n\t\t\tkdb_printf(\"%5d \" kdb_bfd_vma_fmt0 \" - unable to \"\n\t\t\t\t   \"read, diag=%d\\n\", cpu, addr, diag);\n\t\t\tcontinue;\n\t\t}\n\t\tkdb_printf(\"%5d \", cpu);\n\t\tkdb_md_line(fmtstr, addr,\n\t\t\tbytesperword == KDB_WORD_SIZE,\n\t\t\t1, bytesperword, 1, 1, 0);\n\t}\n#undef KDB_PCU\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "lockdep_assert_cpus_held",
          "args": [],
          "line": 249
        },
        "resolved": true,
        "details": {
          "function_name": "lockdep_assert_cpus_held",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/cpu.c",
          "lines": "313-316",
          "snippet": "void lockdep_assert_cpus_held(void)\n{\n\tpercpu_rwsem_assert_held(&cpu_hotplug_lock);\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <trace/events/cpuhp.h>",
            "#include <trace/events/power.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/slab.h>",
            "#include <linux/relay.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/nmi.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/suspend.h>",
            "#include <linux/gfp.h>",
            "#include <linux/mutex.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/kthread.h>",
            "#include <linux/bug.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/unistd.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/notifier.h>",
            "#include <linux/init.h>",
            "#include <linux/smp.h>",
            "#include <linux/proc_fs.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <trace/events/cpuhp.h>\n#include <trace/events/power.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/slab.h>\n#include <linux/relay.h>\n#include <linux/smpboot.h>\n#include <linux/nmi.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/lockdep.h>\n#include <linux/suspend.h>\n#include <linux/gfp.h>\n#include <linux/mutex.h>\n#include <linux/stop_machine.h>\n#include <linux/kthread.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/unistd.h>\n#include <linux/sched/task.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/signal.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/smp.h>\n#include <linux/proc_fs.h>\n\nvoid lockdep_assert_cpus_held(void)\n{\n\tpercpu_rwsem_assert_held(&cpu_hotplug_lock);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/perf_event.h>\n#include <asm/irq_regs.h>\n#include <linux/sched/debug.h>\n#include <linux/module.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n\nstatic DEFINE_PER_CPU(struct perf_event *, watchdog_ev);\n\nvoid __init hardlockup_detector_perf_stop(void)\n{\n\tint cpu;\n\n\tlockdep_assert_cpus_held();\n\n\tfor_each_online_cpu(cpu) {\n\t\tstruct perf_event *event = per_cpu(watchdog_ev, cpu);\n\n\t\tif (event)\n\t\t\tperf_event_disable(event);\n\t}\n}"
  },
  {
    "function_name": "hardlockup_detector_perf_cleanup",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/watchdog_hld.c",
    "lines": "222-238",
    "snippet": "void hardlockup_detector_perf_cleanup(void)\n{\n\tint cpu;\n\n\tfor_each_cpu(cpu, &dead_events_mask) {\n\t\tstruct perf_event *event = per_cpu(dead_event, cpu);\n\n\t\t/*\n\t\t * Required because for_each_cpu() reports  unconditionally\n\t\t * CPU0 as set on UP kernels. Sigh.\n\t\t */\n\t\tif (event)\n\t\t\tperf_event_release_kernel(event);\n\t\tper_cpu(dead_event, cpu) = NULL;\n\t}\n\tcpumask_clear(&dead_events_mask);\n}",
    "includes": [
      "#include <linux/perf_event.h>",
      "#include <asm/irq_regs.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/module.h>",
      "#include <linux/atomic.h>",
      "#include <linux/nmi.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct perf_event *, dead_event);",
      "static struct cpumask dead_events_mask;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpumask_clear",
          "args": [
            "&dead_events_mask"
          ],
          "line": 237
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "per_cpu",
          "args": [
            "dead_event",
            "cpu"
          ],
          "line": 235
        },
        "resolved": true,
        "details": {
          "function_name": "kdb_per_cpu",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/debug/kdb/kdb_main.c",
          "lines": "2575-2640",
          "snippet": "static int kdb_per_cpu(int argc, const char **argv)\n{\n\tchar fmtstr[64];\n\tint cpu, diag, nextarg = 1;\n\tunsigned long addr, symaddr, val, bytesperword = 0, whichcpu = ~0UL;\n\n\tif (argc < 1 || argc > 3)\n\t\treturn KDB_ARGCOUNT;\n\n\tdiag = kdbgetaddrarg(argc, argv, &nextarg, &symaddr, NULL, NULL);\n\tif (diag)\n\t\treturn diag;\n\n\tif (argc >= 2) {\n\t\tdiag = kdbgetularg(argv[2], &bytesperword);\n\t\tif (diag)\n\t\t\treturn diag;\n\t}\n\tif (!bytesperword)\n\t\tbytesperword = KDB_WORD_SIZE;\n\telse if (bytesperword > KDB_WORD_SIZE)\n\t\treturn KDB_BADWIDTH;\n\tsprintf(fmtstr, \"%%0%dlx \", (int)(2*bytesperword));\n\tif (argc >= 3) {\n\t\tdiag = kdbgetularg(argv[3], &whichcpu);\n\t\tif (diag)\n\t\t\treturn diag;\n\t\tif (!cpu_online(whichcpu)) {\n\t\t\tkdb_printf(\"cpu %ld is not online\\n\", whichcpu);\n\t\t\treturn KDB_BADCPUNUM;\n\t\t}\n\t}\n\n\t/* Most architectures use __per_cpu_offset[cpu], some use\n\t * __per_cpu_offset(cpu), smp has no __per_cpu_offset.\n\t */\n#ifdef\t__per_cpu_offset\n#define KDB_PCU(cpu) __per_cpu_offset(cpu)\n#else\n#ifdef\tCONFIG_SMP\n#define KDB_PCU(cpu) __per_cpu_offset[cpu]\n#else\n#define KDB_PCU(cpu) 0\n#endif\n#endif\n\tfor_each_online_cpu(cpu) {\n\t\tif (KDB_FLAG(CMD_INTERRUPT))\n\t\t\treturn 0;\n\n\t\tif (whichcpu != ~0UL && whichcpu != cpu)\n\t\t\tcontinue;\n\t\taddr = symaddr + KDB_PCU(cpu);\n\t\tdiag = kdb_getword(&val, addr, bytesperword);\n\t\tif (diag) {\n\t\t\tkdb_printf(\"%5d \" kdb_bfd_vma_fmt0 \" - unable to \"\n\t\t\t\t   \"read, diag=%d\\n\", cpu, addr, diag);\n\t\t\tcontinue;\n\t\t}\n\t\tkdb_printf(\"%5d \", cpu);\n\t\tkdb_md_line(fmtstr, addr,\n\t\t\tbytesperword == KDB_WORD_SIZE,\n\t\t\t1, bytesperword, 1, 1, 0);\n\t}\n#undef KDB_PCU\n\treturn 0;\n}",
          "includes": [
            "#include \"kdb_private.h\"",
            "#include <linux/slab.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/kdebug.h>",
            "#include <linux/cpu.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/time.h>",
            "#include <linux/nmi.h>",
            "#include <linux/delay.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/notifier.h>",
            "#include <linux/kdb.h>",
            "#include <linux/kgdb.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/init.h>",
            "#include <linux/mm.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/atomic.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/utsname.h>",
            "#include <linux/smp.h>",
            "#include <linux/sysrq.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched.h>",
            "#include <linux/reboot.h>",
            "#include <linux/kmsg_dump.h>",
            "#include <linux/kernel.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/ctype.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kdb_private.h\"\n#include <linux/slab.h>\n#include <linux/uaccess.h>\n#include <linux/proc_fs.h>\n#include <linux/kdebug.h>\n#include <linux/cpu.h>\n#include <linux/sysctl.h>\n#include <linux/ptrace.h>\n#include <linux/time.h>\n#include <linux/nmi.h>\n#include <linux/delay.h>\n#include <linux/interrupt.h>\n#include <linux/notifier.h>\n#include <linux/kdb.h>\n#include <linux/kgdb.h>\n#include <linux/kallsyms.h>\n#include <linux/init.h>\n#include <linux/mm.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/atomic.h>\n#include <linux/vmalloc.h>\n#include <linux/utsname.h>\n#include <linux/smp.h>\n#include <linux/sysrq.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched.h>\n#include <linux/reboot.h>\n#include <linux/kmsg_dump.h>\n#include <linux/kernel.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/ctype.h>\n\nstatic int kdb_per_cpu(int argc, const char **argv)\n{\n\tchar fmtstr[64];\n\tint cpu, diag, nextarg = 1;\n\tunsigned long addr, symaddr, val, bytesperword = 0, whichcpu = ~0UL;\n\n\tif (argc < 1 || argc > 3)\n\t\treturn KDB_ARGCOUNT;\n\n\tdiag = kdbgetaddrarg(argc, argv, &nextarg, &symaddr, NULL, NULL);\n\tif (diag)\n\t\treturn diag;\n\n\tif (argc >= 2) {\n\t\tdiag = kdbgetularg(argv[2], &bytesperword);\n\t\tif (diag)\n\t\t\treturn diag;\n\t}\n\tif (!bytesperword)\n\t\tbytesperword = KDB_WORD_SIZE;\n\telse if (bytesperword > KDB_WORD_SIZE)\n\t\treturn KDB_BADWIDTH;\n\tsprintf(fmtstr, \"%%0%dlx \", (int)(2*bytesperword));\n\tif (argc >= 3) {\n\t\tdiag = kdbgetularg(argv[3], &whichcpu);\n\t\tif (diag)\n\t\t\treturn diag;\n\t\tif (!cpu_online(whichcpu)) {\n\t\t\tkdb_printf(\"cpu %ld is not online\\n\", whichcpu);\n\t\t\treturn KDB_BADCPUNUM;\n\t\t}\n\t}\n\n\t/* Most architectures use __per_cpu_offset[cpu], some use\n\t * __per_cpu_offset(cpu), smp has no __per_cpu_offset.\n\t */\n#ifdef\t__per_cpu_offset\n#define KDB_PCU(cpu) __per_cpu_offset(cpu)\n#else\n#ifdef\tCONFIG_SMP\n#define KDB_PCU(cpu) __per_cpu_offset[cpu]\n#else\n#define KDB_PCU(cpu) 0\n#endif\n#endif\n\tfor_each_online_cpu(cpu) {\n\t\tif (KDB_FLAG(CMD_INTERRUPT))\n\t\t\treturn 0;\n\n\t\tif (whichcpu != ~0UL && whichcpu != cpu)\n\t\t\tcontinue;\n\t\taddr = symaddr + KDB_PCU(cpu);\n\t\tdiag = kdb_getword(&val, addr, bytesperword);\n\t\tif (diag) {\n\t\t\tkdb_printf(\"%5d \" kdb_bfd_vma_fmt0 \" - unable to \"\n\t\t\t\t   \"read, diag=%d\\n\", cpu, addr, diag);\n\t\t\tcontinue;\n\t\t}\n\t\tkdb_printf(\"%5d \", cpu);\n\t\tkdb_md_line(fmtstr, addr,\n\t\t\tbytesperword == KDB_WORD_SIZE,\n\t\t\t1, bytesperword, 1, 1, 0);\n\t}\n#undef KDB_PCU\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "perf_event_release_kernel",
          "args": [
            "event"
          ],
          "line": 234
        },
        "resolved": true,
        "details": {
          "function_name": "perf_event_release_kernel",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/events/core.c",
          "lines": "4540-4640",
          "snippet": "int perf_event_release_kernel(struct perf_event *event)\n{\n\tstruct perf_event_context *ctx = event->ctx;\n\tstruct perf_event *child, *tmp;\n\tLIST_HEAD(free_list);\n\n\t/*\n\t * If we got here through err_file: fput(event_file); we will not have\n\t * attached to a context yet.\n\t */\n\tif (!ctx) {\n\t\tWARN_ON_ONCE(event->attach_state &\n\t\t\t\t(PERF_ATTACH_CONTEXT|PERF_ATTACH_GROUP));\n\t\tgoto no_ctx;\n\t}\n\n\tif (!is_kernel_event(event))\n\t\tperf_remove_from_owner(event);\n\n\tctx = perf_event_ctx_lock(event);\n\tWARN_ON_ONCE(ctx->parent_ctx);\n\tperf_remove_from_context(event, DETACH_GROUP);\n\n\traw_spin_lock_irq(&ctx->lock);\n\t/*\n\t * Mark this event as STATE_DEAD, there is no external reference to it\n\t * anymore.\n\t *\n\t * Anybody acquiring event->child_mutex after the below loop _must_\n\t * also see this, most importantly inherit_event() which will avoid\n\t * placing more children on the list.\n\t *\n\t * Thus this guarantees that we will in fact observe and kill _ALL_\n\t * child events.\n\t */\n\tevent->state = PERF_EVENT_STATE_DEAD;\n\traw_spin_unlock_irq(&ctx->lock);\n\n\tperf_event_ctx_unlock(event, ctx);\n\nagain:\n\tmutex_lock(&event->child_mutex);\n\tlist_for_each_entry(child, &event->child_list, child_list) {\n\n\t\t/*\n\t\t * Cannot change, child events are not migrated, see the\n\t\t * comment with perf_event_ctx_lock_nested().\n\t\t */\n\t\tctx = READ_ONCE(child->ctx);\n\t\t/*\n\t\t * Since child_mutex nests inside ctx::mutex, we must jump\n\t\t * through hoops. We start by grabbing a reference on the ctx.\n\t\t *\n\t\t * Since the event cannot get freed while we hold the\n\t\t * child_mutex, the context must also exist and have a !0\n\t\t * reference count.\n\t\t */\n\t\tget_ctx(ctx);\n\n\t\t/*\n\t\t * Now that we have a ctx ref, we can drop child_mutex, and\n\t\t * acquire ctx::mutex without fear of it going away. Then we\n\t\t * can re-acquire child_mutex.\n\t\t */\n\t\tmutex_unlock(&event->child_mutex);\n\t\tmutex_lock(&ctx->mutex);\n\t\tmutex_lock(&event->child_mutex);\n\n\t\t/*\n\t\t * Now that we hold ctx::mutex and child_mutex, revalidate our\n\t\t * state, if child is still the first entry, it didn't get freed\n\t\t * and we can continue doing so.\n\t\t */\n\t\ttmp = list_first_entry_or_null(&event->child_list,\n\t\t\t\t\t       struct perf_event, child_list);\n\t\tif (tmp == child) {\n\t\t\tperf_remove_from_context(child, DETACH_GROUP);\n\t\t\tlist_move(&child->child_list, &free_list);\n\t\t\t/*\n\t\t\t * This matches the refcount bump in inherit_event();\n\t\t\t * this can't be the last reference.\n\t\t\t */\n\t\t\tput_event(event);\n\t\t}\n\n\t\tmutex_unlock(&event->child_mutex);\n\t\tmutex_unlock(&ctx->mutex);\n\t\tput_ctx(ctx);\n\t\tgoto again;\n\t}\n\tmutex_unlock(&event->child_mutex);\n\n\tlist_for_each_entry_safe(child, tmp, &free_list, child_list) {\n\t\tlist_del(&child->child_list);\n\t\tfree_event(child);\n\t}\n\nno_ctx:\n\tput_event(event); /* Must be the 'last' reference */\n\treturn 0;\n}",
          "includes": [
            "#include <asm/irq_regs.h>",
            "#include \"internal.h\"",
            "#include <linux/mount.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/parser.h>",
            "#include <linux/namei.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/compat.h>",
            "#include <linux/mman.h>",
            "#include <linux/module.h>",
            "#include <linux/mm_types.h>",
            "#include <linux/hw_breakpoint.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/rculist.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/device.h>",
            "#include <linux/vmstat.h>",
            "#include <linux/reboot.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/percpu.h>",
            "#include <linux/dcache.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/tick.h>",
            "#include <linux/hash.h>",
            "#include <linux/slab.h>",
            "#include <linux/poll.h>",
            "#include <linux/file.h>",
            "#include <linux/idr.h>",
            "#include <linux/smp.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/fs.h>"
          ],
          "macros_used": [
            "#define DETACH_GROUP\t0x01UL"
          ],
          "globals_used": [
            "static void update_context_time(struct perf_event_context *ctx);",
            "static u64 perf_event_time(struct perf_event *event);",
            "static __must_check struct",
            "static void perf_log_itrace_start(struct perf_event *event);",
            "static void perf_event_free_filter(struct perf_event *event);",
            "static void perf_event_free_bpf_prog(struct perf_event *event);",
            "static void perf_pmu_output_stop(struct perf_event *event);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/irq_regs.h>\n#include \"internal.h\"\n#include <linux/mount.h>\n#include <linux/proc_ns.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/clock.h>\n#include <linux/parser.h>\n#include <linux/namei.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/compat.h>\n#include <linux/mman.h>\n#include <linux/module.h>\n#include <linux/mm_types.h>\n#include <linux/hw_breakpoint.h>\n#include <linux/trace_events.h>\n#include <linux/perf_event.h>\n#include <linux/cgroup.h>\n#include <linux/kernel_stat.h>\n#include <linux/anon_inodes.h>\n#include <linux/syscalls.h>\n#include <linux/uaccess.h>\n#include <linux/rculist.h>\n#include <linux/hardirq.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/device.h>\n#include <linux/vmstat.h>\n#include <linux/reboot.h>\n#include <linux/ptrace.h>\n#include <linux/percpu.h>\n#include <linux/dcache.h>\n#include <linux/sysfs.h>\n#include <linux/tick.h>\n#include <linux/hash.h>\n#include <linux/slab.h>\n#include <linux/poll.h>\n#include <linux/file.h>\n#include <linux/idr.h>\n#include <linux/smp.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/fs.h>\n\n#define DETACH_GROUP\t0x01UL\n\nstatic void update_context_time(struct perf_event_context *ctx);\nstatic u64 perf_event_time(struct perf_event *event);\nstatic __must_check struct;\nstatic void perf_log_itrace_start(struct perf_event *event);\nstatic void perf_event_free_filter(struct perf_event *event);\nstatic void perf_event_free_bpf_prog(struct perf_event *event);\nstatic void perf_pmu_output_stop(struct perf_event *event);\n\nint perf_event_release_kernel(struct perf_event *event)\n{\n\tstruct perf_event_context *ctx = event->ctx;\n\tstruct perf_event *child, *tmp;\n\tLIST_HEAD(free_list);\n\n\t/*\n\t * If we got here through err_file: fput(event_file); we will not have\n\t * attached to a context yet.\n\t */\n\tif (!ctx) {\n\t\tWARN_ON_ONCE(event->attach_state &\n\t\t\t\t(PERF_ATTACH_CONTEXT|PERF_ATTACH_GROUP));\n\t\tgoto no_ctx;\n\t}\n\n\tif (!is_kernel_event(event))\n\t\tperf_remove_from_owner(event);\n\n\tctx = perf_event_ctx_lock(event);\n\tWARN_ON_ONCE(ctx->parent_ctx);\n\tperf_remove_from_context(event, DETACH_GROUP);\n\n\traw_spin_lock_irq(&ctx->lock);\n\t/*\n\t * Mark this event as STATE_DEAD, there is no external reference to it\n\t * anymore.\n\t *\n\t * Anybody acquiring event->child_mutex after the below loop _must_\n\t * also see this, most importantly inherit_event() which will avoid\n\t * placing more children on the list.\n\t *\n\t * Thus this guarantees that we will in fact observe and kill _ALL_\n\t * child events.\n\t */\n\tevent->state = PERF_EVENT_STATE_DEAD;\n\traw_spin_unlock_irq(&ctx->lock);\n\n\tperf_event_ctx_unlock(event, ctx);\n\nagain:\n\tmutex_lock(&event->child_mutex);\n\tlist_for_each_entry(child, &event->child_list, child_list) {\n\n\t\t/*\n\t\t * Cannot change, child events are not migrated, see the\n\t\t * comment with perf_event_ctx_lock_nested().\n\t\t */\n\t\tctx = READ_ONCE(child->ctx);\n\t\t/*\n\t\t * Since child_mutex nests inside ctx::mutex, we must jump\n\t\t * through hoops. We start by grabbing a reference on the ctx.\n\t\t *\n\t\t * Since the event cannot get freed while we hold the\n\t\t * child_mutex, the context must also exist and have a !0\n\t\t * reference count.\n\t\t */\n\t\tget_ctx(ctx);\n\n\t\t/*\n\t\t * Now that we have a ctx ref, we can drop child_mutex, and\n\t\t * acquire ctx::mutex without fear of it going away. Then we\n\t\t * can re-acquire child_mutex.\n\t\t */\n\t\tmutex_unlock(&event->child_mutex);\n\t\tmutex_lock(&ctx->mutex);\n\t\tmutex_lock(&event->child_mutex);\n\n\t\t/*\n\t\t * Now that we hold ctx::mutex and child_mutex, revalidate our\n\t\t * state, if child is still the first entry, it didn't get freed\n\t\t * and we can continue doing so.\n\t\t */\n\t\ttmp = list_first_entry_or_null(&event->child_list,\n\t\t\t\t\t       struct perf_event, child_list);\n\t\tif (tmp == child) {\n\t\t\tperf_remove_from_context(child, DETACH_GROUP);\n\t\t\tlist_move(&child->child_list, &free_list);\n\t\t\t/*\n\t\t\t * This matches the refcount bump in inherit_event();\n\t\t\t * this can't be the last reference.\n\t\t\t */\n\t\t\tput_event(event);\n\t\t}\n\n\t\tmutex_unlock(&event->child_mutex);\n\t\tmutex_unlock(&ctx->mutex);\n\t\tput_ctx(ctx);\n\t\tgoto again;\n\t}\n\tmutex_unlock(&event->child_mutex);\n\n\tlist_for_each_entry_safe(child, tmp, &free_list, child_list) {\n\t\tlist_del(&child->child_list);\n\t\tfree_event(child);\n\t}\n\nno_ctx:\n\tput_event(event); /* Must be the 'last' reference */\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "for_each_cpu",
          "args": [
            "cpu",
            "&dead_events_mask"
          ],
          "line": 226
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/perf_event.h>\n#include <asm/irq_regs.h>\n#include <linux/sched/debug.h>\n#include <linux/module.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n\nstatic DEFINE_PER_CPU(struct perf_event *, dead_event);\nstatic struct cpumask dead_events_mask;\n\nvoid hardlockup_detector_perf_cleanup(void)\n{\n\tint cpu;\n\n\tfor_each_cpu(cpu, &dead_events_mask) {\n\t\tstruct perf_event *event = per_cpu(dead_event, cpu);\n\n\t\t/*\n\t\t * Required because for_each_cpu() reports  unconditionally\n\t\t * CPU0 as set on UP kernels. Sigh.\n\t\t */\n\t\tif (event)\n\t\t\tperf_event_release_kernel(event);\n\t\tper_cpu(dead_event, cpu) = NULL;\n\t}\n\tcpumask_clear(&dead_events_mask);\n}"
  },
  {
    "function_name": "hardlockup_detector_perf_disable",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/watchdog_hld.c",
    "lines": "204-215",
    "snippet": "void hardlockup_detector_perf_disable(void)\n{\n\tstruct perf_event *event = this_cpu_read(watchdog_ev);\n\n\tif (event) {\n\t\tperf_event_disable(event);\n\t\tthis_cpu_write(watchdog_ev, NULL);\n\t\tthis_cpu_write(dead_event, event);\n\t\tcpumask_set_cpu(smp_processor_id(), &dead_events_mask);\n\t\tatomic_dec(&watchdog_cpus);\n\t}\n}",
    "includes": [
      "#include <linux/perf_event.h>",
      "#include <asm/irq_regs.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/module.h>",
      "#include <linux/atomic.h>",
      "#include <linux/nmi.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct perf_event *, watchdog_ev);",
      "static DEFINE_PER_CPU(struct perf_event *, dead_event);",
      "static struct cpumask dead_events_mask;",
      "static atomic_t watchdog_cpus = ATOMIC_INIT(0);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_dec",
          "args": [
            "&watchdog_cpus"
          ],
          "line": 213
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_set_cpu",
          "args": [
            "smp_processor_id()",
            "&dead_events_mask"
          ],
          "line": 212
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_processor_id",
          "args": [],
          "line": 212
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_write",
          "args": [
            "dead_event",
            "event"
          ],
          "line": 211
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_write",
          "args": [
            "watchdog_ev",
            "NULL"
          ],
          "line": 210
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "perf_event_disable",
          "args": [
            "event"
          ],
          "line": 209
        },
        "resolved": true,
        "details": {
          "function_name": "perf_event_disable_inatomic",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/events/core.c",
          "lines": "2197-2201",
          "snippet": "void perf_event_disable_inatomic(struct perf_event *event)\n{\n\tevent->pending_disable = 1;\n\tirq_work_queue(&event->pending);\n}",
          "includes": [
            "#include <asm/irq_regs.h>",
            "#include \"internal.h\"",
            "#include <linux/mount.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/parser.h>",
            "#include <linux/namei.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/compat.h>",
            "#include <linux/mman.h>",
            "#include <linux/module.h>",
            "#include <linux/mm_types.h>",
            "#include <linux/hw_breakpoint.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/rculist.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/device.h>",
            "#include <linux/vmstat.h>",
            "#include <linux/reboot.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/percpu.h>",
            "#include <linux/dcache.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/tick.h>",
            "#include <linux/hash.h>",
            "#include <linux/slab.h>",
            "#include <linux/poll.h>",
            "#include <linux/file.h>",
            "#include <linux/idr.h>",
            "#include <linux/smp.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/fs.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static u64 perf_event_time(struct perf_event *event);",
            "static __must_check struct",
            "static void perf_log_itrace_start(struct perf_event *event);",
            "static void perf_event_free_filter(struct perf_event *event);",
            "static void perf_event_free_bpf_prog(struct perf_event *event);",
            "static void perf_pmu_output_stop(struct perf_event *event);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/irq_regs.h>\n#include \"internal.h\"\n#include <linux/mount.h>\n#include <linux/proc_ns.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/clock.h>\n#include <linux/parser.h>\n#include <linux/namei.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/compat.h>\n#include <linux/mman.h>\n#include <linux/module.h>\n#include <linux/mm_types.h>\n#include <linux/hw_breakpoint.h>\n#include <linux/trace_events.h>\n#include <linux/perf_event.h>\n#include <linux/cgroup.h>\n#include <linux/kernel_stat.h>\n#include <linux/anon_inodes.h>\n#include <linux/syscalls.h>\n#include <linux/uaccess.h>\n#include <linux/rculist.h>\n#include <linux/hardirq.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/device.h>\n#include <linux/vmstat.h>\n#include <linux/reboot.h>\n#include <linux/ptrace.h>\n#include <linux/percpu.h>\n#include <linux/dcache.h>\n#include <linux/sysfs.h>\n#include <linux/tick.h>\n#include <linux/hash.h>\n#include <linux/slab.h>\n#include <linux/poll.h>\n#include <linux/file.h>\n#include <linux/idr.h>\n#include <linux/smp.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/fs.h>\n\nstatic u64 perf_event_time(struct perf_event *event);\nstatic __must_check struct;\nstatic void perf_log_itrace_start(struct perf_event *event);\nstatic void perf_event_free_filter(struct perf_event *event);\nstatic void perf_event_free_bpf_prog(struct perf_event *event);\nstatic void perf_pmu_output_stop(struct perf_event *event);\n\nvoid perf_event_disable_inatomic(struct perf_event *event)\n{\n\tevent->pending_disable = 1;\n\tirq_work_queue(&event->pending);\n}"
        }
      },
      {
        "call_info": {
          "callee": "this_cpu_read",
          "args": [
            "watchdog_ev"
          ],
          "line": 206
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/perf_event.h>\n#include <asm/irq_regs.h>\n#include <linux/sched/debug.h>\n#include <linux/module.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n\nstatic DEFINE_PER_CPU(struct perf_event *, watchdog_ev);\nstatic DEFINE_PER_CPU(struct perf_event *, dead_event);\nstatic struct cpumask dead_events_mask;\nstatic atomic_t watchdog_cpus = ATOMIC_INIT(0);\n\nvoid hardlockup_detector_perf_disable(void)\n{\n\tstruct perf_event *event = this_cpu_read(watchdog_ev);\n\n\tif (event) {\n\t\tperf_event_disable(event);\n\t\tthis_cpu_write(watchdog_ev, NULL);\n\t\tthis_cpu_write(dead_event, event);\n\t\tcpumask_set_cpu(smp_processor_id(), &dead_events_mask);\n\t\tatomic_dec(&watchdog_cpus);\n\t}\n}"
  },
  {
    "function_name": "hardlockup_detector_perf_enable",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/watchdog_hld.c",
    "lines": "189-199",
    "snippet": "void hardlockup_detector_perf_enable(void)\n{\n\tif (hardlockup_detector_event_create())\n\t\treturn;\n\n\t/* use original value for check */\n\tif (!atomic_fetch_inc(&watchdog_cpus))\n\t\tpr_info(\"Enabled. Permanently consumes one hw-PMU counter.\\n\");\n\n\tperf_event_enable(this_cpu_read(watchdog_ev));\n}",
    "includes": [
      "#include <linux/perf_event.h>",
      "#include <asm/irq_regs.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/module.h>",
      "#include <linux/atomic.h>",
      "#include <linux/nmi.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct perf_event *, watchdog_ev);",
      "static atomic_t watchdog_cpus = ATOMIC_INIT(0);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "perf_event_enable",
          "args": [
            "this_cpu_read(watchdog_ev)"
          ],
          "line": 198
        },
        "resolved": true,
        "details": {
          "function_name": "perf_event_enable_on_exec",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/events/core.c",
          "lines": "3767-3805",
          "snippet": "static void perf_event_enable_on_exec(int ctxn)\n{\n\tstruct perf_event_context *ctx, *clone_ctx = NULL;\n\tenum event_type_t event_type = 0;\n\tstruct perf_cpu_context *cpuctx;\n\tstruct perf_event *event;\n\tunsigned long flags;\n\tint enabled = 0;\n\n\tlocal_irq_save(flags);\n\tctx = current->perf_event_ctxp[ctxn];\n\tif (!ctx || !ctx->nr_events)\n\t\tgoto out;\n\n\tcpuctx = __get_cpu_context(ctx);\n\tperf_ctx_lock(cpuctx, ctx);\n\tctx_sched_out(ctx, cpuctx, EVENT_TIME);\n\tlist_for_each_entry(event, &ctx->event_list, event_entry) {\n\t\tenabled |= event_enable_on_exec(event, ctx);\n\t\tevent_type |= get_event_type(event);\n\t}\n\n\t/*\n\t * Unclone and reschedule this context if we enabled any event.\n\t */\n\tif (enabled) {\n\t\tclone_ctx = unclone_ctx(ctx);\n\t\tctx_resched(cpuctx, ctx, event_type);\n\t} else {\n\t\tctx_sched_in(ctx, cpuctx, EVENT_TIME, current);\n\t}\n\tperf_ctx_unlock(cpuctx, ctx);\n\nout:\n\tlocal_irq_restore(flags);\n\n\tif (clone_ctx)\n\t\tput_ctx(clone_ctx);\n}",
          "includes": [
            "#include <asm/irq_regs.h>",
            "#include \"internal.h\"",
            "#include <linux/mount.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/parser.h>",
            "#include <linux/namei.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/compat.h>",
            "#include <linux/mman.h>",
            "#include <linux/module.h>",
            "#include <linux/mm_types.h>",
            "#include <linux/hw_breakpoint.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/rculist.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/device.h>",
            "#include <linux/vmstat.h>",
            "#include <linux/reboot.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/percpu.h>",
            "#include <linux/dcache.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/tick.h>",
            "#include <linux/hash.h>",
            "#include <linux/slab.h>",
            "#include <linux/poll.h>",
            "#include <linux/file.h>",
            "#include <linux/idr.h>",
            "#include <linux/smp.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/fs.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static bool perf_rotate_context(struct perf_cpu_context *cpuctx);",
            "static void cpu_ctx_sched_out(struct perf_cpu_context *cpuctx,\n\t\t\t      enum event_type_t event_type);",
            "static void update_context_time(struct perf_event_context *ctx);",
            "static u64 perf_event_time(struct perf_event *event);",
            "static __always_inline enum",
            "static __must_check struct",
            "static void perf_log_itrace_start(struct perf_event *event);",
            "static void ctx_sched_out(struct perf_event_context *ctx,\n\t\t\t  struct perf_cpu_context *cpuctx,\n\t\t\t  enum event_type_t event_type);",
            "static void perf_event_free_filter(struct perf_event *event);",
            "static void perf_event_free_bpf_prog(struct perf_event *event);",
            "static void perf_pmu_output_stop(struct perf_event *event);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/irq_regs.h>\n#include \"internal.h\"\n#include <linux/mount.h>\n#include <linux/proc_ns.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/clock.h>\n#include <linux/parser.h>\n#include <linux/namei.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/compat.h>\n#include <linux/mman.h>\n#include <linux/module.h>\n#include <linux/mm_types.h>\n#include <linux/hw_breakpoint.h>\n#include <linux/trace_events.h>\n#include <linux/perf_event.h>\n#include <linux/cgroup.h>\n#include <linux/kernel_stat.h>\n#include <linux/anon_inodes.h>\n#include <linux/syscalls.h>\n#include <linux/uaccess.h>\n#include <linux/rculist.h>\n#include <linux/hardirq.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/device.h>\n#include <linux/vmstat.h>\n#include <linux/reboot.h>\n#include <linux/ptrace.h>\n#include <linux/percpu.h>\n#include <linux/dcache.h>\n#include <linux/sysfs.h>\n#include <linux/tick.h>\n#include <linux/hash.h>\n#include <linux/slab.h>\n#include <linux/poll.h>\n#include <linux/file.h>\n#include <linux/idr.h>\n#include <linux/smp.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/fs.h>\n\nstatic bool perf_rotate_context(struct perf_cpu_context *cpuctx);\nstatic void cpu_ctx_sched_out(struct perf_cpu_context *cpuctx,\n\t\t\t      enum event_type_t event_type);\nstatic void update_context_time(struct perf_event_context *ctx);\nstatic u64 perf_event_time(struct perf_event *event);\nstatic __always_inline enum;\nstatic __must_check struct;\nstatic void perf_log_itrace_start(struct perf_event *event);\nstatic void ctx_sched_out(struct perf_event_context *ctx,\n\t\t\t  struct perf_cpu_context *cpuctx,\n\t\t\t  enum event_type_t event_type);\nstatic void perf_event_free_filter(struct perf_event *event);\nstatic void perf_event_free_bpf_prog(struct perf_event *event);\nstatic void perf_pmu_output_stop(struct perf_event *event);\n\nstatic void perf_event_enable_on_exec(int ctxn)\n{\n\tstruct perf_event_context *ctx, *clone_ctx = NULL;\n\tenum event_type_t event_type = 0;\n\tstruct perf_cpu_context *cpuctx;\n\tstruct perf_event *event;\n\tunsigned long flags;\n\tint enabled = 0;\n\n\tlocal_irq_save(flags);\n\tctx = current->perf_event_ctxp[ctxn];\n\tif (!ctx || !ctx->nr_events)\n\t\tgoto out;\n\n\tcpuctx = __get_cpu_context(ctx);\n\tperf_ctx_lock(cpuctx, ctx);\n\tctx_sched_out(ctx, cpuctx, EVENT_TIME);\n\tlist_for_each_entry(event, &ctx->event_list, event_entry) {\n\t\tenabled |= event_enable_on_exec(event, ctx);\n\t\tevent_type |= get_event_type(event);\n\t}\n\n\t/*\n\t * Unclone and reschedule this context if we enabled any event.\n\t */\n\tif (enabled) {\n\t\tclone_ctx = unclone_ctx(ctx);\n\t\tctx_resched(cpuctx, ctx, event_type);\n\t} else {\n\t\tctx_sched_in(ctx, cpuctx, EVENT_TIME, current);\n\t}\n\tperf_ctx_unlock(cpuctx, ctx);\n\nout:\n\tlocal_irq_restore(flags);\n\n\tif (clone_ctx)\n\t\tput_ctx(clone_ctx);\n}"
        }
      },
      {
        "call_info": {
          "callee": "this_cpu_read",
          "args": [
            "watchdog_ev"
          ],
          "line": 198
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"Enabled. Permanently consumes one hw-PMU counter.\\n\""
          ],
          "line": 196
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_fetch_inc",
          "args": [
            "&watchdog_cpus"
          ],
          "line": 195
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hardlockup_detector_event_create",
          "args": [],
          "line": 191
        },
        "resolved": true,
        "details": {
          "function_name": "hardlockup_detector_event_create",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/watchdog_hld.c",
          "lines": "165-184",
          "snippet": "static int hardlockup_detector_event_create(void)\n{\n\tunsigned int cpu = smp_processor_id();\n\tstruct perf_event_attr *wd_attr;\n\tstruct perf_event *evt;\n\n\twd_attr = &wd_hw_attr;\n\twd_attr->sample_period = hw_nmi_get_sample_period(watchdog_thresh);\n\n\t/* Try to register using hardware perf events */\n\tevt = perf_event_create_kernel_counter(wd_attr, cpu, NULL,\n\t\t\t\t\t       watchdog_overflow_callback, NULL);\n\tif (IS_ERR(evt)) {\n\t\tpr_debug(\"Perf event create on CPU %d failed with %ld\\n\", cpu,\n\t\t\t PTR_ERR(evt));\n\t\treturn PTR_ERR(evt);\n\t}\n\tthis_cpu_write(watchdog_ev, evt);\n\treturn 0;\n}",
          "includes": [
            "#include <linux/perf_event.h>",
            "#include <asm/irq_regs.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/module.h>",
            "#include <linux/atomic.h>",
            "#include <linux/nmi.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(struct perf_event *, watchdog_ev);",
            "static struct perf_event_attr wd_hw_attr = {\n\t.type\t\t= PERF_TYPE_HARDWARE,\n\t.config\t\t= PERF_COUNT_HW_CPU_CYCLES,\n\t.size\t\t= sizeof(struct perf_event_attr),\n\t.pinned\t\t= 1,\n\t.disabled\t= 1,\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/perf_event.h>\n#include <asm/irq_regs.h>\n#include <linux/sched/debug.h>\n#include <linux/module.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n\nstatic DEFINE_PER_CPU(struct perf_event *, watchdog_ev);\nstatic struct perf_event_attr wd_hw_attr = {\n\t.type\t\t= PERF_TYPE_HARDWARE,\n\t.config\t\t= PERF_COUNT_HW_CPU_CYCLES,\n\t.size\t\t= sizeof(struct perf_event_attr),\n\t.pinned\t\t= 1,\n\t.disabled\t= 1,\n};\n\nstatic int hardlockup_detector_event_create(void)\n{\n\tunsigned int cpu = smp_processor_id();\n\tstruct perf_event_attr *wd_attr;\n\tstruct perf_event *evt;\n\n\twd_attr = &wd_hw_attr;\n\twd_attr->sample_period = hw_nmi_get_sample_period(watchdog_thresh);\n\n\t/* Try to register using hardware perf events */\n\tevt = perf_event_create_kernel_counter(wd_attr, cpu, NULL,\n\t\t\t\t\t       watchdog_overflow_callback, NULL);\n\tif (IS_ERR(evt)) {\n\t\tpr_debug(\"Perf event create on CPU %d failed with %ld\\n\", cpu,\n\t\t\t PTR_ERR(evt));\n\t\treturn PTR_ERR(evt);\n\t}\n\tthis_cpu_write(watchdog_ev, evt);\n\treturn 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/perf_event.h>\n#include <asm/irq_regs.h>\n#include <linux/sched/debug.h>\n#include <linux/module.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n\nstatic DEFINE_PER_CPU(struct perf_event *, watchdog_ev);\nstatic atomic_t watchdog_cpus = ATOMIC_INIT(0);\n\nvoid hardlockup_detector_perf_enable(void)\n{\n\tif (hardlockup_detector_event_create())\n\t\treturn;\n\n\t/* use original value for check */\n\tif (!atomic_fetch_inc(&watchdog_cpus))\n\t\tpr_info(\"Enabled. Permanently consumes one hw-PMU counter.\\n\");\n\n\tperf_event_enable(this_cpu_read(watchdog_ev));\n}"
  },
  {
    "function_name": "hardlockup_detector_event_create",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/watchdog_hld.c",
    "lines": "165-184",
    "snippet": "static int hardlockup_detector_event_create(void)\n{\n\tunsigned int cpu = smp_processor_id();\n\tstruct perf_event_attr *wd_attr;\n\tstruct perf_event *evt;\n\n\twd_attr = &wd_hw_attr;\n\twd_attr->sample_period = hw_nmi_get_sample_period(watchdog_thresh);\n\n\t/* Try to register using hardware perf events */\n\tevt = perf_event_create_kernel_counter(wd_attr, cpu, NULL,\n\t\t\t\t\t       watchdog_overflow_callback, NULL);\n\tif (IS_ERR(evt)) {\n\t\tpr_debug(\"Perf event create on CPU %d failed with %ld\\n\", cpu,\n\t\t\t PTR_ERR(evt));\n\t\treturn PTR_ERR(evt);\n\t}\n\tthis_cpu_write(watchdog_ev, evt);\n\treturn 0;\n}",
    "includes": [
      "#include <linux/perf_event.h>",
      "#include <asm/irq_regs.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/module.h>",
      "#include <linux/atomic.h>",
      "#include <linux/nmi.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct perf_event *, watchdog_ev);",
      "static struct perf_event_attr wd_hw_attr = {\n\t.type\t\t= PERF_TYPE_HARDWARE,\n\t.config\t\t= PERF_COUNT_HW_CPU_CYCLES,\n\t.size\t\t= sizeof(struct perf_event_attr),\n\t.pinned\t\t= 1,\n\t.disabled\t= 1,\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "this_cpu_write",
          "args": [
            "watchdog_ev",
            "evt"
          ],
          "line": 182
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "PTR_ERR",
          "args": [
            "evt"
          ],
          "line": 180
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_debug",
          "args": [
            "\"Perf event create on CPU %d failed with %ld\\n\"",
            "cpu",
            "PTR_ERR(evt)"
          ],
          "line": 178
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "PTR_ERR",
          "args": [
            "evt"
          ],
          "line": 179
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ERR",
          "args": [
            "evt"
          ],
          "line": 177
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "perf_event_create_kernel_counter",
          "args": [
            "wd_attr",
            "cpu",
            "NULL",
            "watchdog_overflow_callback",
            "NULL"
          ],
          "line": 175
        },
        "resolved": true,
        "details": {
          "function_name": "perf_event_create_kernel_counter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/events/core.c",
          "lines": "10853-10924",
          "snippet": "struct perf_event *\nperf_event_create_kernel_counter(struct perf_event_attr *attr, int cpu,\n\t\t\t\t struct task_struct *task,\n\t\t\t\t perf_overflow_handler_t overflow_handler,\n\t\t\t\t void *context)\n{\n\tstruct perf_event_context *ctx;\n\tstruct perf_event *event;\n\tint err;\n\n\t/*\n\t * Get the target context (task or percpu):\n\t */\n\n\tevent = perf_event_alloc(attr, cpu, task, NULL, NULL,\n\t\t\t\t overflow_handler, context, -1);\n\tif (IS_ERR(event)) {\n\t\terr = PTR_ERR(event);\n\t\tgoto err;\n\t}\n\n\t/* Mark owner so we could distinguish it from user events. */\n\tevent->owner = TASK_TOMBSTONE;\n\n\tctx = find_get_context(event->pmu, task, event);\n\tif (IS_ERR(ctx)) {\n\t\terr = PTR_ERR(ctx);\n\t\tgoto err_free;\n\t}\n\n\tWARN_ON_ONCE(ctx->parent_ctx);\n\tmutex_lock(&ctx->mutex);\n\tif (ctx->task == TASK_TOMBSTONE) {\n\t\terr = -ESRCH;\n\t\tgoto err_unlock;\n\t}\n\n\tif (!task) {\n\t\t/*\n\t\t * Check if the @cpu we're creating an event for is online.\n\t\t *\n\t\t * We use the perf_cpu_context::ctx::mutex to serialize against\n\t\t * the hotplug notifiers. See perf_event_{init,exit}_cpu().\n\t\t */\n\t\tstruct perf_cpu_context *cpuctx =\n\t\t\tcontainer_of(ctx, struct perf_cpu_context, ctx);\n\t\tif (!cpuctx->online) {\n\t\t\terr = -ENODEV;\n\t\t\tgoto err_unlock;\n\t\t}\n\t}\n\n\tif (!exclusive_event_installable(event, ctx)) {\n\t\terr = -EBUSY;\n\t\tgoto err_unlock;\n\t}\n\n\tperf_install_in_context(ctx, event, cpu);\n\tperf_unpin_context(ctx);\n\tmutex_unlock(&ctx->mutex);\n\n\treturn event;\n\nerr_unlock:\n\tmutex_unlock(&ctx->mutex);\n\tperf_unpin_context(ctx);\n\tput_ctx(ctx);\nerr_free:\n\tfree_event(event);\nerr:\n\treturn ERR_PTR(err);\n}",
          "includes": [
            "#include <asm/irq_regs.h>",
            "#include \"internal.h\"",
            "#include <linux/mount.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/parser.h>",
            "#include <linux/namei.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/compat.h>",
            "#include <linux/mman.h>",
            "#include <linux/module.h>",
            "#include <linux/mm_types.h>",
            "#include <linux/hw_breakpoint.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/rculist.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/device.h>",
            "#include <linux/vmstat.h>",
            "#include <linux/reboot.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/percpu.h>",
            "#include <linux/dcache.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/tick.h>",
            "#include <linux/hash.h>",
            "#include <linux/slab.h>",
            "#include <linux/poll.h>",
            "#include <linux/file.h>",
            "#include <linux/idr.h>",
            "#include <linux/smp.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/fs.h>"
          ],
          "macros_used": [
            "#define TASK_TOMBSTONE ((void *)-1L)"
          ],
          "globals_used": [
            "static bool perf_rotate_context(struct perf_cpu_context *cpuctx);",
            "static void cpu_ctx_sched_in(struct perf_cpu_context *cpuctx,\n\t\t\t     enum event_type_t event_type,\n\t\t\t     struct task_struct *task);",
            "static void update_context_time(struct perf_event_context *ctx);",
            "static u64 perf_event_time(struct perf_event *event);",
            "static __must_check struct",
            "static void perf_log_itrace_start(struct perf_event *event);",
            "static void\nctx_sched_in(struct perf_event_context *ctx,\n\t     struct perf_cpu_context *cpuctx,\n\t     enum event_type_t event_type,\n\t     struct task_struct *task);",
            "static void perf_event_free_filter(struct perf_event *event);",
            "static void perf_event_free_bpf_prog(struct perf_event *event);",
            "static int perf_copy_attr(struct perf_event_attr __user *uattr,\n\t\t\t  struct perf_event_attr *attr);",
            "static void perf_pmu_output_stop(struct perf_event *event);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/irq_regs.h>\n#include \"internal.h\"\n#include <linux/mount.h>\n#include <linux/proc_ns.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/clock.h>\n#include <linux/parser.h>\n#include <linux/namei.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/compat.h>\n#include <linux/mman.h>\n#include <linux/module.h>\n#include <linux/mm_types.h>\n#include <linux/hw_breakpoint.h>\n#include <linux/trace_events.h>\n#include <linux/perf_event.h>\n#include <linux/cgroup.h>\n#include <linux/kernel_stat.h>\n#include <linux/anon_inodes.h>\n#include <linux/syscalls.h>\n#include <linux/uaccess.h>\n#include <linux/rculist.h>\n#include <linux/hardirq.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/device.h>\n#include <linux/vmstat.h>\n#include <linux/reboot.h>\n#include <linux/ptrace.h>\n#include <linux/percpu.h>\n#include <linux/dcache.h>\n#include <linux/sysfs.h>\n#include <linux/tick.h>\n#include <linux/hash.h>\n#include <linux/slab.h>\n#include <linux/poll.h>\n#include <linux/file.h>\n#include <linux/idr.h>\n#include <linux/smp.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/fs.h>\n\n#define TASK_TOMBSTONE ((void *)-1L)\n\nstatic bool perf_rotate_context(struct perf_cpu_context *cpuctx);\nstatic void cpu_ctx_sched_in(struct perf_cpu_context *cpuctx,\n\t\t\t     enum event_type_t event_type,\n\t\t\t     struct task_struct *task);\nstatic void update_context_time(struct perf_event_context *ctx);\nstatic u64 perf_event_time(struct perf_event *event);\nstatic __must_check struct;\nstatic void perf_log_itrace_start(struct perf_event *event);\nstatic void\nctx_sched_in(struct perf_event_context *ctx,\n\t     struct perf_cpu_context *cpuctx,\n\t     enum event_type_t event_type,\n\t     struct task_struct *task);\nstatic void perf_event_free_filter(struct perf_event *event);\nstatic void perf_event_free_bpf_prog(struct perf_event *event);\nstatic int perf_copy_attr(struct perf_event_attr __user *uattr,\n\t\t\t  struct perf_event_attr *attr);\nstatic void perf_pmu_output_stop(struct perf_event *event);\n\nstruct perf_event *\nperf_event_create_kernel_counter(struct perf_event_attr *attr, int cpu,\n\t\t\t\t struct task_struct *task,\n\t\t\t\t perf_overflow_handler_t overflow_handler,\n\t\t\t\t void *context)\n{\n\tstruct perf_event_context *ctx;\n\tstruct perf_event *event;\n\tint err;\n\n\t/*\n\t * Get the target context (task or percpu):\n\t */\n\n\tevent = perf_event_alloc(attr, cpu, task, NULL, NULL,\n\t\t\t\t overflow_handler, context, -1);\n\tif (IS_ERR(event)) {\n\t\terr = PTR_ERR(event);\n\t\tgoto err;\n\t}\n\n\t/* Mark owner so we could distinguish it from user events. */\n\tevent->owner = TASK_TOMBSTONE;\n\n\tctx = find_get_context(event->pmu, task, event);\n\tif (IS_ERR(ctx)) {\n\t\terr = PTR_ERR(ctx);\n\t\tgoto err_free;\n\t}\n\n\tWARN_ON_ONCE(ctx->parent_ctx);\n\tmutex_lock(&ctx->mutex);\n\tif (ctx->task == TASK_TOMBSTONE) {\n\t\terr = -ESRCH;\n\t\tgoto err_unlock;\n\t}\n\n\tif (!task) {\n\t\t/*\n\t\t * Check if the @cpu we're creating an event for is online.\n\t\t *\n\t\t * We use the perf_cpu_context::ctx::mutex to serialize against\n\t\t * the hotplug notifiers. See perf_event_{init,exit}_cpu().\n\t\t */\n\t\tstruct perf_cpu_context *cpuctx =\n\t\t\tcontainer_of(ctx, struct perf_cpu_context, ctx);\n\t\tif (!cpuctx->online) {\n\t\t\terr = -ENODEV;\n\t\t\tgoto err_unlock;\n\t\t}\n\t}\n\n\tif (!exclusive_event_installable(event, ctx)) {\n\t\terr = -EBUSY;\n\t\tgoto err_unlock;\n\t}\n\n\tperf_install_in_context(ctx, event, cpu);\n\tperf_unpin_context(ctx);\n\tmutex_unlock(&ctx->mutex);\n\n\treturn event;\n\nerr_unlock:\n\tmutex_unlock(&ctx->mutex);\n\tperf_unpin_context(ctx);\n\tput_ctx(ctx);\nerr_free:\n\tfree_event(event);\nerr:\n\treturn ERR_PTR(err);\n}"
        }
      },
      {
        "call_info": {
          "callee": "hw_nmi_get_sample_period",
          "args": [
            "watchdog_thresh"
          ],
          "line": 172
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_processor_id",
          "args": [],
          "line": 167
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/perf_event.h>\n#include <asm/irq_regs.h>\n#include <linux/sched/debug.h>\n#include <linux/module.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n\nstatic DEFINE_PER_CPU(struct perf_event *, watchdog_ev);\nstatic struct perf_event_attr wd_hw_attr = {\n\t.type\t\t= PERF_TYPE_HARDWARE,\n\t.config\t\t= PERF_COUNT_HW_CPU_CYCLES,\n\t.size\t\t= sizeof(struct perf_event_attr),\n\t.pinned\t\t= 1,\n\t.disabled\t= 1,\n};\n\nstatic int hardlockup_detector_event_create(void)\n{\n\tunsigned int cpu = smp_processor_id();\n\tstruct perf_event_attr *wd_attr;\n\tstruct perf_event *evt;\n\n\twd_attr = &wd_hw_attr;\n\twd_attr->sample_period = hw_nmi_get_sample_period(watchdog_thresh);\n\n\t/* Try to register using hardware perf events */\n\tevt = perf_event_create_kernel_counter(wd_attr, cpu, NULL,\n\t\t\t\t\t       watchdog_overflow_callback, NULL);\n\tif (IS_ERR(evt)) {\n\t\tpr_debug(\"Perf event create on CPU %d failed with %ld\\n\", cpu,\n\t\t\t PTR_ERR(evt));\n\t\treturn PTR_ERR(evt);\n\t}\n\tthis_cpu_write(watchdog_ev, evt);\n\treturn 0;\n}"
  },
  {
    "function_name": "watchdog_overflow_callback",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/watchdog_hld.c",
    "lines": "110-163",
    "snippet": "static void watchdog_overflow_callback(struct perf_event *event,\n\t\t\t\t       struct perf_sample_data *data,\n\t\t\t\t       struct pt_regs *regs)\n{\n\t/* Ensure the watchdog never gets throttled */\n\tevent->hw.interrupts = 0;\n\n\tif (__this_cpu_read(watchdog_nmi_touch) == true) {\n\t\t__this_cpu_write(watchdog_nmi_touch, false);\n\t\treturn;\n\t}\n\n\tif (!watchdog_check_timestamp())\n\t\treturn;\n\n\t/* check for a hardlockup\n\t * This is done by making sure our timer interrupt\n\t * is incrementing.  The timer interrupt should have\n\t * fired multiple times before we overflow'd.  If it hasn't\n\t * then this is a good indication the cpu is stuck\n\t */\n\tif (is_hardlockup()) {\n\t\tint this_cpu = smp_processor_id();\n\n\t\t/* only print hardlockups once */\n\t\tif (__this_cpu_read(hard_watchdog_warn) == true)\n\t\t\treturn;\n\n\t\tpr_emerg(\"Watchdog detected hard LOCKUP on cpu %d\", this_cpu);\n\t\tprint_modules();\n\t\tprint_irqtrace_events(current);\n\t\tif (regs)\n\t\t\tshow_regs(regs);\n\t\telse\n\t\t\tdump_stack();\n\n\t\t/*\n\t\t * Perform all-CPU dump only once to avoid multiple hardlockups\n\t\t * generating interleaving traces\n\t\t */\n\t\tif (sysctl_hardlockup_all_cpu_backtrace &&\n\t\t\t\t!test_and_set_bit(0, &hardlockup_allcpu_dumped))\n\t\t\ttrigger_allbutself_cpu_backtrace();\n\n\t\tif (hardlockup_panic)\n\t\t\tnmi_panic(regs, \"Hard LOCKUP\");\n\n\t\t__this_cpu_write(hard_watchdog_warn, true);\n\t\treturn;\n\t}\n\n\t__this_cpu_write(hard_watchdog_warn, false);\n\treturn;\n}",
    "includes": [
      "#include <linux/perf_event.h>",
      "#include <asm/irq_regs.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/module.h>",
      "#include <linux/atomic.h>",
      "#include <linux/nmi.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(bool, hard_watchdog_warn);",
      "static DEFINE_PER_CPU(bool, watchdog_nmi_touch);",
      "static unsigned long hardlockup_allcpu_dumped;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "__this_cpu_write",
          "args": [
            "hard_watchdog_warn",
            "false"
          ],
          "line": 161
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__this_cpu_write",
          "args": [
            "hard_watchdog_warn",
            "true"
          ],
          "line": 157
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "nmi_panic",
          "args": [
            "regs",
            "\"Hard LOCKUP\""
          ],
          "line": 155
        },
        "resolved": true,
        "details": {
          "function_name": "nmi_panic",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/panic.c",
          "lines": "113-124",
          "snippet": "void nmi_panic(struct pt_regs *regs, const char *msg)\n{\n\tint old_cpu, cpu;\n\n\tcpu = raw_smp_processor_id();\n\told_cpu = atomic_cmpxchg(&panic_cpu, PANIC_CPU_INVALID, cpu);\n\n\tif (old_cpu == PANIC_CPU_INVALID)\n\t\tpanic(\"%s\", msg);\n\telse if (old_cpu != cpu)\n\t\tnmi_panic_self_stop(regs);\n}",
          "includes": [
            "#include <asm/sections.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/bug.h>",
            "#include <linux/console.h>",
            "#include <linux/nmi.h>",
            "#include <linux/init.h>",
            "#include <linux/sysrq.h>",
            "#include <linux/sched.h>",
            "#include <linux/kexec.h>",
            "#include <linux/delay.h>",
            "#include <linux/reboot.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/random.h>",
            "#include <linux/module.h>",
            "#include <linux/notifier.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/kmsg_dump.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/debug_locks.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "atomic_t panic_cpu = ATOMIC_INIT(PANIC_CPU_INVALID);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/sections.h>\n#include <linux/debugfs.h>\n#include <linux/ratelimit.h>\n#include <linux/bug.h>\n#include <linux/console.h>\n#include <linux/nmi.h>\n#include <linux/init.h>\n#include <linux/sysrq.h>\n#include <linux/sched.h>\n#include <linux/kexec.h>\n#include <linux/delay.h>\n#include <linux/reboot.h>\n#include <linux/ftrace.h>\n#include <linux/random.h>\n#include <linux/module.h>\n#include <linux/notifier.h>\n#include <linux/kallsyms.h>\n#include <linux/kmsg_dump.h>\n#include <linux/interrupt.h>\n#include <linux/sched/debug.h>\n#include <linux/debug_locks.h>\n\natomic_t panic_cpu = ATOMIC_INIT(PANIC_CPU_INVALID);\n\nvoid nmi_panic(struct pt_regs *regs, const char *msg)\n{\n\tint old_cpu, cpu;\n\n\tcpu = raw_smp_processor_id();\n\told_cpu = atomic_cmpxchg(&panic_cpu, PANIC_CPU_INVALID, cpu);\n\n\tif (old_cpu == PANIC_CPU_INVALID)\n\t\tpanic(\"%s\", msg);\n\telse if (old_cpu != cpu)\n\t\tnmi_panic_self_stop(regs);\n}"
        }
      },
      {
        "call_info": {
          "callee": "trigger_allbutself_cpu_backtrace",
          "args": [],
          "line": 152
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "test_and_set_bit",
          "args": [
            "0",
            "&hardlockup_allcpu_dumped"
          ],
          "line": 151
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "dump_stack",
          "args": [],
          "line": 144
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "show_regs",
          "args": [
            "regs"
          ],
          "line": 142
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "print_irqtrace_events",
          "args": [
            "current"
          ],
          "line": 140
        },
        "resolved": true,
        "details": {
          "function_name": "print_irqtrace_events",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/lockdep.c",
          "lines": "2606-2621",
          "snippet": "void print_irqtrace_events(struct task_struct *curr)\n{\n\tprintk(\"irq event stamp: %u\\n\", curr->irq_events);\n\tprintk(\"hardirqs last  enabled at (%u): [<%px>] %pS\\n\",\n\t\tcurr->hardirq_enable_event, (void *)curr->hardirq_enable_ip,\n\t\t(void *)curr->hardirq_enable_ip);\n\tprintk(\"hardirqs last disabled at (%u): [<%px>] %pS\\n\",\n\t\tcurr->hardirq_disable_event, (void *)curr->hardirq_disable_ip,\n\t\t(void *)curr->hardirq_disable_ip);\n\tprintk(\"softirqs last  enabled at (%u): [<%px>] %pS\\n\",\n\t\tcurr->softirq_enable_event, (void *)curr->softirq_enable_ip,\n\t\t(void *)curr->softirq_enable_ip);\n\tprintk(\"softirqs last disabled at (%u): [<%px>] %pS\\n\",\n\t\tcurr->softirq_disable_event, (void *)curr->softirq_disable_ip,\n\t\t(void *)curr->softirq_disable_ip);\n}",
          "includes": [
            "#include \"lockdep_states.h\"",
            "#include \"lockdep_states.h\"",
            "#include \"lockdep_states.h\"",
            "#include \"lockdep_states.h\"",
            "#include <trace/events/lock.h>",
            "#include \"lockdep_internals.h\"",
            "#include <asm/sections.h>",
            "#include <linux/nmi.h>",
            "#include <linux/jhash.h>",
            "#include <linux/random.h>",
            "#include <linux/gfp.h>",
            "#include <linux/bitops.h>",
            "#include <linux/stringify.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/hash.h>",
            "#include <linux/utsname.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/stacktrace.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/module.h>",
            "#include <linux/delay.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"lockdep_states.h\"\n#include \"lockdep_states.h\"\n#include \"lockdep_states.h\"\n#include \"lockdep_states.h\"\n#include <trace/events/lock.h>\n#include \"lockdep_internals.h\"\n#include <asm/sections.h>\n#include <linux/nmi.h>\n#include <linux/jhash.h>\n#include <linux/random.h>\n#include <linux/gfp.h>\n#include <linux/bitops.h>\n#include <linux/stringify.h>\n#include <linux/ftrace.h>\n#include <linux/hash.h>\n#include <linux/utsname.h>\n#include <linux/irqflags.h>\n#include <linux/debug_locks.h>\n#include <linux/stacktrace.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/seq_file.h>\n#include <linux/proc_fs.h>\n#include <linux/module.h>\n#include <linux/delay.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/task.h>\n#include <linux/sched/clock.h>\n#include <linux/sched.h>\n#include <linux/mutex.h>\n\nvoid print_irqtrace_events(struct task_struct *curr)\n{\n\tprintk(\"irq event stamp: %u\\n\", curr->irq_events);\n\tprintk(\"hardirqs last  enabled at (%u): [<%px>] %pS\\n\",\n\t\tcurr->hardirq_enable_event, (void *)curr->hardirq_enable_ip,\n\t\t(void *)curr->hardirq_enable_ip);\n\tprintk(\"hardirqs last disabled at (%u): [<%px>] %pS\\n\",\n\t\tcurr->hardirq_disable_event, (void *)curr->hardirq_disable_ip,\n\t\t(void *)curr->hardirq_disable_ip);\n\tprintk(\"softirqs last  enabled at (%u): [<%px>] %pS\\n\",\n\t\tcurr->softirq_enable_event, (void *)curr->softirq_enable_ip,\n\t\t(void *)curr->softirq_enable_ip);\n\tprintk(\"softirqs last disabled at (%u): [<%px>] %pS\\n\",\n\t\tcurr->softirq_disable_event, (void *)curr->softirq_disable_ip,\n\t\t(void *)curr->softirq_disable_ip);\n}"
        }
      },
      {
        "call_info": {
          "callee": "print_modules",
          "args": [],
          "line": 139
        },
        "resolved": true,
        "details": {
          "function_name": "print_modules",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/module.c",
          "lines": "4377-4394",
          "snippet": "void print_modules(void)\n{\n\tstruct module *mod;\n\tchar buf[MODULE_FLAGS_BUF_SIZE];\n\n\tprintk(KERN_DEFAULT \"Modules linked in:\");\n\t/* Most callers should already have preempt disabled, but make sure */\n\tpreempt_disable();\n\tlist_for_each_entry_rcu(mod, &modules, list) {\n\t\tif (mod->state == MODULE_STATE_UNFORMED)\n\t\t\tcontinue;\n\t\tpr_cont(\" %s%s\", mod->name, module_flags(mod, buf));\n\t}\n\tpreempt_enable();\n\tif (last_unloaded_module[0])\n\t\tpr_cont(\" [last unloaded: %s]\", last_unloaded_module);\n\tpr_cont(\"\\n\");\n}",
          "includes": [
            "#include <trace/events/module.h>",
            "#include \"module-internal.h\"",
            "#include <uapi/linux/module.h>",
            "#include <linux/audit.h>",
            "#include <linux/dynamic_debug.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/pfn.h>",
            "#include <linux/jump_label.h>",
            "#include <linux/kmemleak.h>",
            "#include <linux/percpu.h>",
            "#include <linux/async.h>",
            "#include <linux/livepatch.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/tracepoint.h>",
            "#include <asm/sections.h>",
            "#include <linux/license.h>",
            "#include <asm/mmu_context.h>",
            "#include <linux/set_memory.h>",
            "#include <asm/cacheflush.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/rculist.h>",
            "#include <linux/mutex.h>",
            "#include <linux/string.h>",
            "#include <linux/device.h>",
            "#include <linux/sched.h>",
            "#include <linux/notifier.h>",
            "#include <linux/vermagic.h>",
            "#include <linux/err.h>",
            "#include <linux/errno.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/cpu.h>",
            "#include <linux/capability.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/fcntl.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/security.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/elf.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/slab.h>",
            "#include <linux/kernel.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/init.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/moduleloader.h>",
            "#include <linux/extable.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [
            "#define MODULE_FLAGS_BUF_SIZE (TAINT_FLAGS_COUNT + 4)"
          ],
          "globals_used": [
            "static LIST_HEAD(modules);",
            "static char last_unloaded_module[MODULE_NAME_LEN+1];"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/module.h>\n#include \"module-internal.h\"\n#include <uapi/linux/module.h>\n#include <linux/audit.h>\n#include <linux/dynamic_debug.h>\n#include <linux/bsearch.h>\n#include <linux/pfn.h>\n#include <linux/jump_label.h>\n#include <linux/kmemleak.h>\n#include <linux/percpu.h>\n#include <linux/async.h>\n#include <linux/livepatch.h>\n#include <linux/ftrace.h>\n#include <linux/tracepoint.h>\n#include <asm/sections.h>\n#include <linux/license.h>\n#include <asm/mmu_context.h>\n#include <linux/set_memory.h>\n#include <asm/cacheflush.h>\n#include <linux/uaccess.h>\n#include <linux/rculist.h>\n#include <linux/mutex.h>\n#include <linux/string.h>\n#include <linux/device.h>\n#include <linux/sched.h>\n#include <linux/notifier.h>\n#include <linux/vermagic.h>\n#include <linux/err.h>\n#include <linux/errno.h>\n#include <linux/moduleparam.h>\n#include <linux/cpu.h>\n#include <linux/capability.h>\n#include <linux/rcupdate.h>\n#include <linux/fcntl.h>\n#include <linux/syscalls.h>\n#include <linux/seq_file.h>\n#include <linux/security.h>\n#include <linux/proc_fs.h>\n#include <linux/elf.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/sysfs.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/kallsyms.h>\n#include <linux/init.h>\n#include <linux/trace_events.h>\n#include <linux/moduleloader.h>\n#include <linux/extable.h>\n#include <linux/export.h>\n\n#define MODULE_FLAGS_BUF_SIZE (TAINT_FLAGS_COUNT + 4)\n\nstatic LIST_HEAD(modules);\nstatic char last_unloaded_module[MODULE_NAME_LEN+1];\n\nvoid print_modules(void)\n{\n\tstruct module *mod;\n\tchar buf[MODULE_FLAGS_BUF_SIZE];\n\n\tprintk(KERN_DEFAULT \"Modules linked in:\");\n\t/* Most callers should already have preempt disabled, but make sure */\n\tpreempt_disable();\n\tlist_for_each_entry_rcu(mod, &modules, list) {\n\t\tif (mod->state == MODULE_STATE_UNFORMED)\n\t\t\tcontinue;\n\t\tpr_cont(\" %s%s\", mod->name, module_flags(mod, buf));\n\t}\n\tpreempt_enable();\n\tif (last_unloaded_module[0])\n\t\tpr_cont(\" [last unloaded: %s]\", last_unloaded_module);\n\tpr_cont(\"\\n\");\n}"
        }
      },
      {
        "call_info": {
          "callee": "pr_emerg",
          "args": [
            "\"Watchdog detected hard LOCKUP on cpu %d\"",
            "this_cpu"
          ],
          "line": 138
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__this_cpu_read",
          "args": [
            "hard_watchdog_warn"
          ],
          "line": 135
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_processor_id",
          "args": [],
          "line": 132
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "is_hardlockup",
          "args": [],
          "line": 131
        },
        "resolved": true,
        "details": {
          "function_name": "is_hardlockup",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/watchdog.c",
          "lines": "317-326",
          "snippet": "bool is_hardlockup(void)\n{\n\tunsigned long hrint = __this_cpu_read(hrtimer_interrupts);\n\n\tif (__this_cpu_read(hrtimer_interrupts_saved) == hrint)\n\t\treturn true;\n\n\t__this_cpu_write(hrtimer_interrupts_saved, hrint);\n\treturn false;\n}",
          "includes": [
            "#include <linux/kvm_para.h>",
            "#include <asm/irq_regs.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/tick.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/module.h>",
            "#include <linux/init.h>",
            "#include <linux/nmi.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kvm_para.h>\n#include <asm/irq_regs.h>\n#include <linux/stop_machine.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/clock.h>\n#include <linux/tick.h>\n#include <linux/sysctl.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/nmi.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n\nbool is_hardlockup(void)\n{\n\tunsigned long hrint = __this_cpu_read(hrtimer_interrupts);\n\n\tif (__this_cpu_read(hrtimer_interrupts_saved) == hrint)\n\t\treturn true;\n\n\t__this_cpu_write(hrtimer_interrupts_saved, hrint);\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "watchdog_check_timestamp",
          "args": [],
          "line": 122
        },
        "resolved": true,
        "details": {
          "function_name": "watchdog_check_timestamp",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/watchdog_hld.c",
          "lines": "95-98",
          "snippet": "static inline bool watchdog_check_timestamp(void)\n{\n\treturn true;\n}",
          "includes": [
            "#include <linux/perf_event.h>",
            "#include <asm/irq_regs.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/module.h>",
            "#include <linux/atomic.h>",
            "#include <linux/nmi.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/perf_event.h>\n#include <asm/irq_regs.h>\n#include <linux/sched/debug.h>\n#include <linux/module.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n\nstatic inline bool watchdog_check_timestamp(void)\n{\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__this_cpu_write",
          "args": [
            "watchdog_nmi_touch",
            "false"
          ],
          "line": 118
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__this_cpu_read",
          "args": [
            "watchdog_nmi_touch"
          ],
          "line": 117
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/perf_event.h>\n#include <asm/irq_regs.h>\n#include <linux/sched/debug.h>\n#include <linux/module.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n\nstatic DEFINE_PER_CPU(bool, hard_watchdog_warn);\nstatic DEFINE_PER_CPU(bool, watchdog_nmi_touch);\nstatic unsigned long hardlockup_allcpu_dumped;\n\nstatic void watchdog_overflow_callback(struct perf_event *event,\n\t\t\t\t       struct perf_sample_data *data,\n\t\t\t\t       struct pt_regs *regs)\n{\n\t/* Ensure the watchdog never gets throttled */\n\tevent->hw.interrupts = 0;\n\n\tif (__this_cpu_read(watchdog_nmi_touch) == true) {\n\t\t__this_cpu_write(watchdog_nmi_touch, false);\n\t\treturn;\n\t}\n\n\tif (!watchdog_check_timestamp())\n\t\treturn;\n\n\t/* check for a hardlockup\n\t * This is done by making sure our timer interrupt\n\t * is incrementing.  The timer interrupt should have\n\t * fired multiple times before we overflow'd.  If it hasn't\n\t * then this is a good indication the cpu is stuck\n\t */\n\tif (is_hardlockup()) {\n\t\tint this_cpu = smp_processor_id();\n\n\t\t/* only print hardlockups once */\n\t\tif (__this_cpu_read(hard_watchdog_warn) == true)\n\t\t\treturn;\n\n\t\tpr_emerg(\"Watchdog detected hard LOCKUP on cpu %d\", this_cpu);\n\t\tprint_modules();\n\t\tprint_irqtrace_events(current);\n\t\tif (regs)\n\t\t\tshow_regs(regs);\n\t\telse\n\t\t\tdump_stack();\n\n\t\t/*\n\t\t * Perform all-CPU dump only once to avoid multiple hardlockups\n\t\t * generating interleaving traces\n\t\t */\n\t\tif (sysctl_hardlockup_all_cpu_backtrace &&\n\t\t\t\t!test_and_set_bit(0, &hardlockup_allcpu_dumped))\n\t\t\ttrigger_allbutself_cpu_backtrace();\n\n\t\tif (hardlockup_panic)\n\t\t\tnmi_panic(regs, \"Hard LOCKUP\");\n\n\t\t__this_cpu_write(hard_watchdog_warn, true);\n\t\treturn;\n\t}\n\n\t__this_cpu_write(hard_watchdog_warn, false);\n\treturn;\n}"
  },
  {
    "function_name": "watchdog_check_timestamp",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/watchdog_hld.c",
    "lines": "95-98",
    "snippet": "static inline bool watchdog_check_timestamp(void)\n{\n\treturn true;\n}",
    "includes": [
      "#include <linux/perf_event.h>",
      "#include <asm/irq_regs.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/module.h>",
      "#include <linux/atomic.h>",
      "#include <linux/nmi.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include <linux/perf_event.h>\n#include <asm/irq_regs.h>\n#include <linux/sched/debug.h>\n#include <linux/module.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n\nstatic inline bool watchdog_check_timestamp(void)\n{\n\treturn true;\n}"
  },
  {
    "function_name": "watchdog_check_timestamp",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/watchdog_hld.c",
    "lines": "76-93",
    "snippet": "static bool watchdog_check_timestamp(void)\n{\n\tktime_t delta, now = ktime_get_mono_fast_ns();\n\n\tdelta = now - __this_cpu_read(last_timestamp);\n\tif (delta < watchdog_hrtimer_sample_threshold) {\n\t\t/*\n\t\t * If ktime is jiffies based, a stalled timer would prevent\n\t\t * jiffies from being incremented and the filter would look\n\t\t * at a stale timestamp and never trigger.\n\t\t */\n\t\tif (__this_cpu_inc_return(nmi_rearmed) < 10)\n\t\t\treturn false;\n\t}\n\t__this_cpu_write(nmi_rearmed, 0);\n\t__this_cpu_write(last_timestamp, now);\n\treturn true;\n}",
    "includes": [
      "#include <linux/perf_event.h>",
      "#include <asm/irq_regs.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/module.h>",
      "#include <linux/atomic.h>",
      "#include <linux/nmi.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__this_cpu_write",
          "args": [
            "last_timestamp",
            "now"
          ],
          "line": 91
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__this_cpu_write",
          "args": [
            "nmi_rearmed",
            "0"
          ],
          "line": 90
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__this_cpu_inc_return",
          "args": [
            "nmi_rearmed"
          ],
          "line": 87
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__this_cpu_read",
          "args": [
            "last_timestamp"
          ],
          "line": 80
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ktime_get_mono_fast_ns",
          "args": [],
          "line": 78
        },
        "resolved": true,
        "details": {
          "function_name": "ktime_get_mono_fast_ns",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/time/timekeeping.c",
          "lines": "469-472",
          "snippet": "u64 ktime_get_mono_fast_ns(void)\n{\n\treturn __ktime_get_fast_ns(&tk_fast_mono);\n}",
          "includes": [
            "#include \"timekeeping_internal.h\"",
            "#include \"ntp_internal.h\"",
            "#include \"tick-internal.h\"",
            "#include <linux/compiler.h>",
            "#include <linux/pvclock_gtod.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/tick.h>",
            "#include <linux/time.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/clocksource.h>",
            "#include <linux/syscore_ops.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mm.h>",
            "#include <linux/init.h>",
            "#include <linux/percpu.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/module.h>",
            "#include <linux/timekeeper_internal.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"timekeeping_internal.h\"\n#include \"ntp_internal.h\"\n#include \"tick-internal.h\"\n#include <linux/compiler.h>\n#include <linux/pvclock_gtod.h>\n#include <linux/stop_machine.h>\n#include <linux/tick.h>\n#include <linux/time.h>\n#include <linux/jiffies.h>\n#include <linux/clocksource.h>\n#include <linux/syscore_ops.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched.h>\n#include <linux/nmi.h>\n#include <linux/mm.h>\n#include <linux/init.h>\n#include <linux/percpu.h>\n#include <linux/interrupt.h>\n#include <linux/module.h>\n#include <linux/timekeeper_internal.h>\n\nu64 ktime_get_mono_fast_ns(void)\n{\n\treturn __ktime_get_fast_ns(&tk_fast_mono);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/perf_event.h>\n#include <asm/irq_regs.h>\n#include <linux/sched/debug.h>\n#include <linux/module.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n\nstatic bool watchdog_check_timestamp(void)\n{\n\tktime_t delta, now = ktime_get_mono_fast_ns();\n\n\tdelta = now - __this_cpu_read(last_timestamp);\n\tif (delta < watchdog_hrtimer_sample_threshold) {\n\t\t/*\n\t\t * If ktime is jiffies based, a stalled timer would prevent\n\t\t * jiffies from being incremented and the filter would look\n\t\t * at a stale timestamp and never trigger.\n\t\t */\n\t\tif (__this_cpu_inc_return(nmi_rearmed) < 10)\n\t\t\treturn false;\n\t}\n\t__this_cpu_write(nmi_rearmed, 0);\n\t__this_cpu_write(last_timestamp, now);\n\treturn true;\n}"
  },
  {
    "function_name": "watchdog_update_hrtimer_threshold",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/watchdog_hld.c",
    "lines": "50-74",
    "snippet": "void watchdog_update_hrtimer_threshold(u64 period)\n{\n\t/*\n\t * The hrtimer runs with a period of (watchdog_threshold * 2) / 5\n\t *\n\t * So it runs effectively with 2.5 times the rate of the NMI\n\t * watchdog. That means the hrtimer should fire 2-3 times before\n\t * the NMI watchdog expires. The NMI watchdog on x86 is based on\n\t * unhalted CPU cycles, so if Turbo-Mode is enabled the CPU cycles\n\t * might run way faster than expected and the NMI fires in a\n\t * smaller period than the one deduced from the nominal CPU\n\t * frequency. Depending on the Turbo-Mode factor this might be fast\n\t * enough to get the NMI period smaller than the hrtimer watchdog\n\t * period and trigger false positives.\n\t *\n\t * The sample threshold is used to check in the NMI handler whether\n\t * the minimum time between two NMI samples has elapsed. That\n\t * prevents false positives.\n\t *\n\t * Set this to 4/5 of the actual watchdog threshold period so the\n\t * hrtimer is guaranteed to fire at least once within the real\n\t * watchdog threshold.\n\t */\n\twatchdog_hrtimer_sample_threshold = period * 2;\n}",
    "includes": [
      "#include <linux/perf_event.h>",
      "#include <asm/irq_regs.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/module.h>",
      "#include <linux/atomic.h>",
      "#include <linux/nmi.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include <linux/perf_event.h>\n#include <asm/irq_regs.h>\n#include <linux/sched/debug.h>\n#include <linux/module.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n\nvoid watchdog_update_hrtimer_threshold(u64 period)\n{\n\t/*\n\t * The hrtimer runs with a period of (watchdog_threshold * 2) / 5\n\t *\n\t * So it runs effectively with 2.5 times the rate of the NMI\n\t * watchdog. That means the hrtimer should fire 2-3 times before\n\t * the NMI watchdog expires. The NMI watchdog on x86 is based on\n\t * unhalted CPU cycles, so if Turbo-Mode is enabled the CPU cycles\n\t * might run way faster than expected and the NMI fires in a\n\t * smaller period than the one deduced from the nominal CPU\n\t * frequency. Depending on the Turbo-Mode factor this might be fast\n\t * enough to get the NMI period smaller than the hrtimer watchdog\n\t * period and trigger false positives.\n\t *\n\t * The sample threshold is used to check in the NMI handler whether\n\t * the minimum time between two NMI samples has elapsed. That\n\t * prevents false positives.\n\t *\n\t * Set this to 4/5 of the actual watchdog threshold period so the\n\t * hrtimer is guaranteed to fire at least once within the real\n\t * watchdog threshold.\n\t */\n\twatchdog_hrtimer_sample_threshold = period * 2;\n}"
  },
  {
    "function_name": "arch_touch_nmi_watchdog",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/watchdog_hld.c",
    "lines": "32-42",
    "snippet": "notrace void arch_touch_nmi_watchdog(void)\n{\n\t/*\n\t * Using __raw here because some code paths have\n\t * preemption enabled.  If preemption is enabled\n\t * then interrupts should be enabled too, in which\n\t * case we shouldn't have to worry about the watchdog\n\t * going off.\n\t */\n\traw_cpu_write(watchdog_nmi_touch, true);\n}",
    "includes": [
      "#include <linux/perf_event.h>",
      "#include <asm/irq_regs.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/module.h>",
      "#include <linux/atomic.h>",
      "#include <linux/nmi.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(bool, watchdog_nmi_touch);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_cpu_write",
          "args": [
            "watchdog_nmi_touch",
            "true"
          ],
          "line": 41
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/perf_event.h>\n#include <asm/irq_regs.h>\n#include <linux/sched/debug.h>\n#include <linux/module.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n\nstatic DEFINE_PER_CPU(bool, watchdog_nmi_touch);\n\nnotrace void arch_touch_nmi_watchdog(void)\n{\n\t/*\n\t * Using __raw here because some code paths have\n\t * preemption enabled.  If preemption is enabled\n\t * then interrupts should be enabled too, in which\n\t * case we shouldn't have to worry about the watchdog\n\t * going off.\n\t */\n\traw_cpu_write(watchdog_nmi_touch, true);\n}"
  }
]