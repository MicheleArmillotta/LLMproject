[
  {
    "function_name": "irq_affinity_online_cpu",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/cpuhotplug.c",
    "lines": "201-216",
    "snippet": "int irq_affinity_online_cpu(unsigned int cpu)\n{\n\tstruct irq_desc *desc;\n\tunsigned int irq;\n\n\tirq_lock_sparse();\n\tfor_each_active_irq(irq) {\n\t\tdesc = irq_to_desc(irq);\n\t\traw_spin_lock_irq(&desc->lock);\n\t\tirq_restore_affinity_of_irq(desc, cpu);\n\t\traw_spin_unlock_irq(&desc->lock);\n\t}\n\tirq_unlock_sparse();\n\n\treturn 0;\n}",
    "includes": [
      "#include \"internals.h\"",
      "#include <linux/irq.h>",
      "#include <linux/ratelimit.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "irq_unlock_sparse",
          "args": [],
          "line": 213
        },
        "resolved": true,
        "details": {
          "function_name": "irq_unlock_sparse",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/irqdesc.c",
          "lines": "367-370",
          "snippet": "void irq_unlock_sparse(void)\n{\n\tmutex_unlock(&sparse_irq_lock);\n}",
          "includes": [
            "#include \"internals.h\"",
            "#include <linux/sysfs.h>",
            "#include <linux/irqdomain.h>",
            "#include <linux/bitmap.h>",
            "#include <linux/radix-tree.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>",
            "#include <linux/irq.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_MUTEX(sparse_irq_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"internals.h\"\n#include <linux/sysfs.h>\n#include <linux/irqdomain.h>\n#include <linux/bitmap.h>\n#include <linux/radix-tree.h>\n#include <linux/kernel_stat.h>\n#include <linux/interrupt.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n#include <linux/irq.h>\n\nstatic DEFINE_MUTEX(sparse_irq_lock);\n\nvoid irq_unlock_sparse(void)\n{\n\tmutex_unlock(&sparse_irq_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_irq",
          "args": [
            "&desc->lock"
          ],
          "line": 211
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_irq",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "190-193",
          "snippet": "void __lockfunc _raw_spin_unlock_irq(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_irq(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_irq(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_irq(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "irq_restore_affinity_of_irq",
          "args": [
            "desc",
            "cpu"
          ],
          "line": 210
        },
        "resolved": true,
        "details": {
          "function_name": "irq_restore_affinity_of_irq",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/cpuhotplug.c",
          "lines": "174-195",
          "snippet": "static void irq_restore_affinity_of_irq(struct irq_desc *desc, unsigned int cpu)\n{\n\tstruct irq_data *data = irq_desc_get_irq_data(desc);\n\tconst struct cpumask *affinity = irq_data_get_affinity_mask(data);\n\n\tif (!irqd_affinity_is_managed(data) || !desc->action ||\n\t    !irq_data_get_irq_chip(data) || !cpumask_test_cpu(cpu, affinity))\n\t\treturn;\n\n\tif (irqd_is_managed_and_shutdown(data)) {\n\t\tirq_startup(desc, IRQ_RESEND, IRQ_START_COND);\n\t\treturn;\n\t}\n\n\t/*\n\t * If the interrupt can only be directed to a single target\n\t * CPU then it is already assigned to a CPU in the affinity\n\t * mask. No point in trying to move it around.\n\t */\n\tif (!irqd_is_single_target(data))\n\t\tirq_set_affinity_locked(data, affinity, false);\n}",
          "includes": [
            "#include \"internals.h\"",
            "#include <linux/irq.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/interrupt.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internals.h\"\n#include <linux/irq.h>\n#include <linux/ratelimit.h>\n#include <linux/interrupt.h>\n\nstatic void irq_restore_affinity_of_irq(struct irq_desc *desc, unsigned int cpu)\n{\n\tstruct irq_data *data = irq_desc_get_irq_data(desc);\n\tconst struct cpumask *affinity = irq_data_get_affinity_mask(data);\n\n\tif (!irqd_affinity_is_managed(data) || !desc->action ||\n\t    !irq_data_get_irq_chip(data) || !cpumask_test_cpu(cpu, affinity))\n\t\treturn;\n\n\tif (irqd_is_managed_and_shutdown(data)) {\n\t\tirq_startup(desc, IRQ_RESEND, IRQ_START_COND);\n\t\treturn;\n\t}\n\n\t/*\n\t * If the interrupt can only be directed to a single target\n\t * CPU then it is already assigned to a CPU in the affinity\n\t * mask. No point in trying to move it around.\n\t */\n\tif (!irqd_is_single_target(data))\n\t\tirq_set_affinity_locked(data, affinity, false);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irq",
          "args": [
            "&desc->lock"
          ],
          "line": 209
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_irq",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "158-161",
          "snippet": "void __lockfunc _raw_spin_lock_irq(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_irq(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_irq(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_irq(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "irq_to_desc",
          "args": [
            "irq"
          ],
          "line": 208
        },
        "resolved": true,
        "details": {
          "function_name": "irq_to_desc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/irqdesc.c",
          "lines": "561-564",
          "snippet": "struct irq_desc *irq_to_desc(unsigned int irq)\n{\n\treturn (irq < NR_IRQS) ? irq_desc + irq : NULL;\n}",
          "includes": [
            "#include \"internals.h\"",
            "#include <linux/sysfs.h>",
            "#include <linux/irqdomain.h>",
            "#include <linux/bitmap.h>",
            "#include <linux/radix-tree.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>",
            "#include <linux/irq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internals.h\"\n#include <linux/sysfs.h>\n#include <linux/irqdomain.h>\n#include <linux/bitmap.h>\n#include <linux/radix-tree.h>\n#include <linux/kernel_stat.h>\n#include <linux/interrupt.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n#include <linux/irq.h>\n\nstruct irq_desc *irq_to_desc(unsigned int irq)\n{\n\treturn (irq < NR_IRQS) ? irq_desc + irq : NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "irq_lock_sparse",
          "args": [],
          "line": 206
        },
        "resolved": true,
        "details": {
          "function_name": "irq_lock_sparse",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/irqdesc.c",
          "lines": "362-365",
          "snippet": "void irq_lock_sparse(void)\n{\n\tmutex_lock(&sparse_irq_lock);\n}",
          "includes": [
            "#include \"internals.h\"",
            "#include <linux/sysfs.h>",
            "#include <linux/irqdomain.h>",
            "#include <linux/bitmap.h>",
            "#include <linux/radix-tree.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>",
            "#include <linux/irq.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_MUTEX(sparse_irq_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"internals.h\"\n#include <linux/sysfs.h>\n#include <linux/irqdomain.h>\n#include <linux/bitmap.h>\n#include <linux/radix-tree.h>\n#include <linux/kernel_stat.h>\n#include <linux/interrupt.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n#include <linux/irq.h>\n\nstatic DEFINE_MUTEX(sparse_irq_lock);\n\nvoid irq_lock_sparse(void)\n{\n\tmutex_lock(&sparse_irq_lock);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"internals.h\"\n#include <linux/irq.h>\n#include <linux/ratelimit.h>\n#include <linux/interrupt.h>\n\nint irq_affinity_online_cpu(unsigned int cpu)\n{\n\tstruct irq_desc *desc;\n\tunsigned int irq;\n\n\tirq_lock_sparse();\n\tfor_each_active_irq(irq) {\n\t\tdesc = irq_to_desc(irq);\n\t\traw_spin_lock_irq(&desc->lock);\n\t\tirq_restore_affinity_of_irq(desc, cpu);\n\t\traw_spin_unlock_irq(&desc->lock);\n\t}\n\tirq_unlock_sparse();\n\n\treturn 0;\n}"
  },
  {
    "function_name": "irq_restore_affinity_of_irq",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/cpuhotplug.c",
    "lines": "174-195",
    "snippet": "static void irq_restore_affinity_of_irq(struct irq_desc *desc, unsigned int cpu)\n{\n\tstruct irq_data *data = irq_desc_get_irq_data(desc);\n\tconst struct cpumask *affinity = irq_data_get_affinity_mask(data);\n\n\tif (!irqd_affinity_is_managed(data) || !desc->action ||\n\t    !irq_data_get_irq_chip(data) || !cpumask_test_cpu(cpu, affinity))\n\t\treturn;\n\n\tif (irqd_is_managed_and_shutdown(data)) {\n\t\tirq_startup(desc, IRQ_RESEND, IRQ_START_COND);\n\t\treturn;\n\t}\n\n\t/*\n\t * If the interrupt can only be directed to a single target\n\t * CPU then it is already assigned to a CPU in the affinity\n\t * mask. No point in trying to move it around.\n\t */\n\tif (!irqd_is_single_target(data))\n\t\tirq_set_affinity_locked(data, affinity, false);\n}",
    "includes": [
      "#include \"internals.h\"",
      "#include <linux/irq.h>",
      "#include <linux/ratelimit.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "irq_set_affinity_locked",
          "args": [
            "data",
            "affinity",
            "false"
          ],
          "line": 194
        },
        "resolved": true,
        "details": {
          "function_name": "irq_set_affinity_locked",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/manage.c",
          "lines": "241-265",
          "snippet": "int irq_set_affinity_locked(struct irq_data *data, const struct cpumask *mask,\n\t\t\t    bool force)\n{\n\tstruct irq_chip *chip = irq_data_get_irq_chip(data);\n\tstruct irq_desc *desc = irq_data_to_desc(data);\n\tint ret = 0;\n\n\tif (!chip || !chip->irq_set_affinity)\n\t\treturn -EINVAL;\n\n\tif (irq_can_move_pcntxt(data) && !irqd_is_setaffinity_pending(data)) {\n\t\tret = irq_try_set_affinity(data, mask, force);\n\t} else {\n\t\tirqd_set_move_pending(data);\n\t\tirq_copy_pending(desc, mask);\n\t}\n\n\tif (desc->affinity_notify) {\n\t\tkref_get(&desc->affinity_notify->kref);\n\t\tschedule_work(&desc->affinity_notify->work);\n\t}\n\tirqd_set(data, IRQD_AFFINITY_SET);\n\n\treturn ret;\n}",
          "includes": [
            "#include \"internals.h\"",
            "#include <linux/task_work.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/slab.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/random.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>",
            "#include <linux/irq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internals.h\"\n#include <linux/task_work.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/slab.h>\n#include <linux/interrupt.h>\n#include <linux/random.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\n#include <linux/irq.h>\n\nint irq_set_affinity_locked(struct irq_data *data, const struct cpumask *mask,\n\t\t\t    bool force)\n{\n\tstruct irq_chip *chip = irq_data_get_irq_chip(data);\n\tstruct irq_desc *desc = irq_data_to_desc(data);\n\tint ret = 0;\n\n\tif (!chip || !chip->irq_set_affinity)\n\t\treturn -EINVAL;\n\n\tif (irq_can_move_pcntxt(data) && !irqd_is_setaffinity_pending(data)) {\n\t\tret = irq_try_set_affinity(data, mask, force);\n\t} else {\n\t\tirqd_set_move_pending(data);\n\t\tirq_copy_pending(desc, mask);\n\t}\n\n\tif (desc->affinity_notify) {\n\t\tkref_get(&desc->affinity_notify->kref);\n\t\tschedule_work(&desc->affinity_notify->work);\n\t}\n\tirqd_set(data, IRQD_AFFINITY_SET);\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "irqd_is_single_target",
          "args": [
            "data"
          ],
          "line": 193
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "irq_startup",
          "args": [
            "desc",
            "IRQ_RESEND",
            "IRQ_START_COND"
          ],
          "line": 184
        },
        "resolved": true,
        "details": {
          "function_name": "irq_startup",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/chip.c",
          "lines": "255-284",
          "snippet": "int irq_startup(struct irq_desc *desc, bool resend, bool force)\n{\n\tstruct irq_data *d = irq_desc_get_irq_data(desc);\n\tstruct cpumask *aff = irq_data_get_affinity_mask(d);\n\tint ret = 0;\n\n\tdesc->depth = 0;\n\n\tif (irqd_is_started(d)) {\n\t\tirq_enable(desc);\n\t} else {\n\t\tswitch (__irq_startup_managed(desc, aff, force)) {\n\t\tcase IRQ_STARTUP_NORMAL:\n\t\t\tret = __irq_startup(desc);\n\t\t\tirq_setup_affinity(desc);\n\t\t\tbreak;\n\t\tcase IRQ_STARTUP_MANAGED:\n\t\t\tirq_do_set_affinity(d, aff, false);\n\t\t\tret = __irq_startup(desc);\n\t\t\tbreak;\n\t\tcase IRQ_STARTUP_ABORT:\n\t\t\tirqd_set_managed_shutdown(d);\n\t\t\treturn 0;\n\t\t}\n\t}\n\tif (resend)\n\t\tcheck_irq_resend(desc);\n\n\treturn ret;\n}",
          "includes": [
            "#include \"internals.h\"",
            "#include <trace/events/irq.h>",
            "#include <linux/irqdomain.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/module.h>",
            "#include <linux/msi.h>",
            "#include <linux/irq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internals.h\"\n#include <trace/events/irq.h>\n#include <linux/irqdomain.h>\n#include <linux/kernel_stat.h>\n#include <linux/interrupt.h>\n#include <linux/module.h>\n#include <linux/msi.h>\n#include <linux/irq.h>\n\nint irq_startup(struct irq_desc *desc, bool resend, bool force)\n{\n\tstruct irq_data *d = irq_desc_get_irq_data(desc);\n\tstruct cpumask *aff = irq_data_get_affinity_mask(d);\n\tint ret = 0;\n\n\tdesc->depth = 0;\n\n\tif (irqd_is_started(d)) {\n\t\tirq_enable(desc);\n\t} else {\n\t\tswitch (__irq_startup_managed(desc, aff, force)) {\n\t\tcase IRQ_STARTUP_NORMAL:\n\t\t\tret = __irq_startup(desc);\n\t\t\tirq_setup_affinity(desc);\n\t\t\tbreak;\n\t\tcase IRQ_STARTUP_MANAGED:\n\t\t\tirq_do_set_affinity(d, aff, false);\n\t\t\tret = __irq_startup(desc);\n\t\t\tbreak;\n\t\tcase IRQ_STARTUP_ABORT:\n\t\t\tirqd_set_managed_shutdown(d);\n\t\t\treturn 0;\n\t\t}\n\t}\n\tif (resend)\n\t\tcheck_irq_resend(desc);\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "irqd_is_managed_and_shutdown",
          "args": [
            "data"
          ],
          "line": 183
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "affinity"
          ],
          "line": 180
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "irq_data_get_irq_chip",
          "args": [
            "data"
          ],
          "line": 180
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "irqd_affinity_is_managed",
          "args": [
            "data"
          ],
          "line": 179
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "irq_data_get_affinity_mask",
          "args": [
            "data"
          ],
          "line": 177
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "irq_desc_get_irq_data",
          "args": [
            "desc"
          ],
          "line": 176
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"internals.h\"\n#include <linux/irq.h>\n#include <linux/ratelimit.h>\n#include <linux/interrupt.h>\n\nstatic void irq_restore_affinity_of_irq(struct irq_desc *desc, unsigned int cpu)\n{\n\tstruct irq_data *data = irq_desc_get_irq_data(desc);\n\tconst struct cpumask *affinity = irq_data_get_affinity_mask(data);\n\n\tif (!irqd_affinity_is_managed(data) || !desc->action ||\n\t    !irq_data_get_irq_chip(data) || !cpumask_test_cpu(cpu, affinity))\n\t\treturn;\n\n\tif (irqd_is_managed_and_shutdown(data)) {\n\t\tirq_startup(desc, IRQ_RESEND, IRQ_START_COND);\n\t\treturn;\n\t}\n\n\t/*\n\t * If the interrupt can only be directed to a single target\n\t * CPU then it is already assigned to a CPU in the affinity\n\t * mask. No point in trying to move it around.\n\t */\n\tif (!irqd_is_single_target(data))\n\t\tirq_set_affinity_locked(data, affinity, false);\n}"
  },
  {
    "function_name": "irq_migrate_all_off_this_cpu",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/cpuhotplug.c",
    "lines": "154-172",
    "snippet": "void irq_migrate_all_off_this_cpu(void)\n{\n\tstruct irq_desc *desc;\n\tunsigned int irq;\n\n\tfor_each_active_irq(irq) {\n\t\tbool affinity_broken;\n\n\t\tdesc = irq_to_desc(irq);\n\t\traw_spin_lock(&desc->lock);\n\t\taffinity_broken = migrate_one_irq(desc);\n\t\traw_spin_unlock(&desc->lock);\n\n\t\tif (affinity_broken) {\n\t\t\tpr_warn_ratelimited(\"IRQ %u: no longer affine to CPU%u\\n\",\n\t\t\t\t\t    irq, smp_processor_id());\n\t\t}\n\t}\n}",
    "includes": [
      "#include \"internals.h\"",
      "#include <linux/irq.h>",
      "#include <linux/ratelimit.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "pr_warn_ratelimited",
          "args": [
            "\"IRQ %u: no longer affine to CPU%u\\n\"",
            "irq",
            "smp_processor_id()"
          ],
          "line": 168
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_processor_id",
          "args": [],
          "line": 169
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock",
          "args": [
            "&desc->lock"
          ],
          "line": 165
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "198-201",
          "snippet": "void __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "migrate_one_irq",
          "args": [
            "desc"
          ],
          "line": 164
        },
        "resolved": true,
        "details": {
          "function_name": "migrate_one_irq",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/cpuhotplug.c",
          "lines": "52-142",
          "snippet": "static bool migrate_one_irq(struct irq_desc *desc)\n{\n\tstruct irq_data *d = irq_desc_get_irq_data(desc);\n\tstruct irq_chip *chip = irq_data_get_irq_chip(d);\n\tbool maskchip = !irq_can_move_pcntxt(d) && !irqd_irq_masked(d);\n\tconst struct cpumask *affinity;\n\tbool brokeaff = false;\n\tint err;\n\n\t/*\n\t * IRQ chip might be already torn down, but the irq descriptor is\n\t * still in the radix tree. Also if the chip has no affinity setter,\n\t * nothing can be done here.\n\t */\n\tif (!chip || !chip->irq_set_affinity) {\n\t\tpr_debug(\"IRQ %u: Unable to migrate away\\n\", d->irq);\n\t\treturn false;\n\t}\n\n\t/*\n\t * No move required, if:\n\t * - Interrupt is per cpu\n\t * - Interrupt is not started\n\t * - Affinity mask does not include this CPU.\n\t *\n\t * Note: Do not check desc->action as this might be a chained\n\t * interrupt.\n\t */\n\tif (irqd_is_per_cpu(d) || !irqd_is_started(d) || !irq_needs_fixup(d)) {\n\t\t/*\n\t\t * If an irq move is pending, abort it if the dying CPU is\n\t\t * the sole target.\n\t\t */\n\t\tirq_fixup_move_pending(desc, false);\n\t\treturn false;\n\t}\n\n\t/*\n\t * Complete an eventually pending irq move cleanup. If this\n\t * interrupt was moved in hard irq context, then the vectors need\n\t * to be cleaned up. It can't wait until this interrupt actually\n\t * happens and this CPU was involved.\n\t */\n\tirq_force_complete_move(desc);\n\n\t/*\n\t * If there is a setaffinity pending, then try to reuse the pending\n\t * mask, so the last change of the affinity does not get lost. If\n\t * there is no move pending or the pending mask does not contain\n\t * any online CPU, use the current affinity mask.\n\t */\n\tif (irq_fixup_move_pending(desc, true))\n\t\taffinity = irq_desc_get_pending_mask(desc);\n\telse\n\t\taffinity = irq_data_get_affinity_mask(d);\n\n\t/* Mask the chip for interrupts which cannot move in process context */\n\tif (maskchip && chip->irq_mask)\n\t\tchip->irq_mask(d);\n\n\tif (cpumask_any_and(affinity, cpu_online_mask) >= nr_cpu_ids) {\n\t\t/*\n\t\t * If the interrupt is managed, then shut it down and leave\n\t\t * the affinity untouched.\n\t\t */\n\t\tif (irqd_affinity_is_managed(d)) {\n\t\t\tirqd_set_managed_shutdown(d);\n\t\t\tirq_shutdown(desc);\n\t\t\treturn false;\n\t\t}\n\t\taffinity = cpu_online_mask;\n\t\tbrokeaff = true;\n\t}\n\t/*\n\t * Do not set the force argument of irq_do_set_affinity() as this\n\t * disables the masking of offline CPUs from the supplied affinity\n\t * mask and therefore might keep/reassign the irq to the outgoing\n\t * CPU.\n\t */\n\terr = irq_do_set_affinity(d, affinity, false);\n\tif (err) {\n\t\tpr_warn_ratelimited(\"IRQ%u: set affinity failed(%d).\\n\",\n\t\t\t\t    d->irq, err);\n\t\tbrokeaff = false;\n\t}\n\n\tif (maskchip && chip->irq_unmask)\n\t\tchip->irq_unmask(d);\n\n\treturn brokeaff;\n}",
          "includes": [
            "#include \"internals.h\"",
            "#include <linux/irq.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/interrupt.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internals.h\"\n#include <linux/irq.h>\n#include <linux/ratelimit.h>\n#include <linux/interrupt.h>\n\nstatic bool migrate_one_irq(struct irq_desc *desc)\n{\n\tstruct irq_data *d = irq_desc_get_irq_data(desc);\n\tstruct irq_chip *chip = irq_data_get_irq_chip(d);\n\tbool maskchip = !irq_can_move_pcntxt(d) && !irqd_irq_masked(d);\n\tconst struct cpumask *affinity;\n\tbool brokeaff = false;\n\tint err;\n\n\t/*\n\t * IRQ chip might be already torn down, but the irq descriptor is\n\t * still in the radix tree. Also if the chip has no affinity setter,\n\t * nothing can be done here.\n\t */\n\tif (!chip || !chip->irq_set_affinity) {\n\t\tpr_debug(\"IRQ %u: Unable to migrate away\\n\", d->irq);\n\t\treturn false;\n\t}\n\n\t/*\n\t * No move required, if:\n\t * - Interrupt is per cpu\n\t * - Interrupt is not started\n\t * - Affinity mask does not include this CPU.\n\t *\n\t * Note: Do not check desc->action as this might be a chained\n\t * interrupt.\n\t */\n\tif (irqd_is_per_cpu(d) || !irqd_is_started(d) || !irq_needs_fixup(d)) {\n\t\t/*\n\t\t * If an irq move is pending, abort it if the dying CPU is\n\t\t * the sole target.\n\t\t */\n\t\tirq_fixup_move_pending(desc, false);\n\t\treturn false;\n\t}\n\n\t/*\n\t * Complete an eventually pending irq move cleanup. If this\n\t * interrupt was moved in hard irq context, then the vectors need\n\t * to be cleaned up. It can't wait until this interrupt actually\n\t * happens and this CPU was involved.\n\t */\n\tirq_force_complete_move(desc);\n\n\t/*\n\t * If there is a setaffinity pending, then try to reuse the pending\n\t * mask, so the last change of the affinity does not get lost. If\n\t * there is no move pending or the pending mask does not contain\n\t * any online CPU, use the current affinity mask.\n\t */\n\tif (irq_fixup_move_pending(desc, true))\n\t\taffinity = irq_desc_get_pending_mask(desc);\n\telse\n\t\taffinity = irq_data_get_affinity_mask(d);\n\n\t/* Mask the chip for interrupts which cannot move in process context */\n\tif (maskchip && chip->irq_mask)\n\t\tchip->irq_mask(d);\n\n\tif (cpumask_any_and(affinity, cpu_online_mask) >= nr_cpu_ids) {\n\t\t/*\n\t\t * If the interrupt is managed, then shut it down and leave\n\t\t * the affinity untouched.\n\t\t */\n\t\tif (irqd_affinity_is_managed(d)) {\n\t\t\tirqd_set_managed_shutdown(d);\n\t\t\tirq_shutdown(desc);\n\t\t\treturn false;\n\t\t}\n\t\taffinity = cpu_online_mask;\n\t\tbrokeaff = true;\n\t}\n\t/*\n\t * Do not set the force argument of irq_do_set_affinity() as this\n\t * disables the masking of offline CPUs from the supplied affinity\n\t * mask and therefore might keep/reassign the irq to the outgoing\n\t * CPU.\n\t */\n\terr = irq_do_set_affinity(d, affinity, false);\n\tif (err) {\n\t\tpr_warn_ratelimited(\"IRQ%u: set affinity failed(%d).\\n\",\n\t\t\t\t    d->irq, err);\n\t\tbrokeaff = false;\n\t}\n\n\tif (maskchip && chip->irq_unmask)\n\t\tchip->irq_unmask(d);\n\n\treturn brokeaff;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock",
          "args": [
            "&desc->lock"
          ],
          "line": 163
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "166-169",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "irq_to_desc",
          "args": [
            "irq"
          ],
          "line": 162
        },
        "resolved": true,
        "details": {
          "function_name": "irq_to_desc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/irqdesc.c",
          "lines": "561-564",
          "snippet": "struct irq_desc *irq_to_desc(unsigned int irq)\n{\n\treturn (irq < NR_IRQS) ? irq_desc + irq : NULL;\n}",
          "includes": [
            "#include \"internals.h\"",
            "#include <linux/sysfs.h>",
            "#include <linux/irqdomain.h>",
            "#include <linux/bitmap.h>",
            "#include <linux/radix-tree.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>",
            "#include <linux/irq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internals.h\"\n#include <linux/sysfs.h>\n#include <linux/irqdomain.h>\n#include <linux/bitmap.h>\n#include <linux/radix-tree.h>\n#include <linux/kernel_stat.h>\n#include <linux/interrupt.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n#include <linux/irq.h>\n\nstruct irq_desc *irq_to_desc(unsigned int irq)\n{\n\treturn (irq < NR_IRQS) ? irq_desc + irq : NULL;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"internals.h\"\n#include <linux/irq.h>\n#include <linux/ratelimit.h>\n#include <linux/interrupt.h>\n\nvoid irq_migrate_all_off_this_cpu(void)\n{\n\tstruct irq_desc *desc;\n\tunsigned int irq;\n\n\tfor_each_active_irq(irq) {\n\t\tbool affinity_broken;\n\n\t\tdesc = irq_to_desc(irq);\n\t\traw_spin_lock(&desc->lock);\n\t\taffinity_broken = migrate_one_irq(desc);\n\t\traw_spin_unlock(&desc->lock);\n\n\t\tif (affinity_broken) {\n\t\t\tpr_warn_ratelimited(\"IRQ %u: no longer affine to CPU%u\\n\",\n\t\t\t\t\t    irq, smp_processor_id());\n\t\t}\n\t}\n}"
  },
  {
    "function_name": "migrate_one_irq",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/cpuhotplug.c",
    "lines": "52-142",
    "snippet": "static bool migrate_one_irq(struct irq_desc *desc)\n{\n\tstruct irq_data *d = irq_desc_get_irq_data(desc);\n\tstruct irq_chip *chip = irq_data_get_irq_chip(d);\n\tbool maskchip = !irq_can_move_pcntxt(d) && !irqd_irq_masked(d);\n\tconst struct cpumask *affinity;\n\tbool brokeaff = false;\n\tint err;\n\n\t/*\n\t * IRQ chip might be already torn down, but the irq descriptor is\n\t * still in the radix tree. Also if the chip has no affinity setter,\n\t * nothing can be done here.\n\t */\n\tif (!chip || !chip->irq_set_affinity) {\n\t\tpr_debug(\"IRQ %u: Unable to migrate away\\n\", d->irq);\n\t\treturn false;\n\t}\n\n\t/*\n\t * No move required, if:\n\t * - Interrupt is per cpu\n\t * - Interrupt is not started\n\t * - Affinity mask does not include this CPU.\n\t *\n\t * Note: Do not check desc->action as this might be a chained\n\t * interrupt.\n\t */\n\tif (irqd_is_per_cpu(d) || !irqd_is_started(d) || !irq_needs_fixup(d)) {\n\t\t/*\n\t\t * If an irq move is pending, abort it if the dying CPU is\n\t\t * the sole target.\n\t\t */\n\t\tirq_fixup_move_pending(desc, false);\n\t\treturn false;\n\t}\n\n\t/*\n\t * Complete an eventually pending irq move cleanup. If this\n\t * interrupt was moved in hard irq context, then the vectors need\n\t * to be cleaned up. It can't wait until this interrupt actually\n\t * happens and this CPU was involved.\n\t */\n\tirq_force_complete_move(desc);\n\n\t/*\n\t * If there is a setaffinity pending, then try to reuse the pending\n\t * mask, so the last change of the affinity does not get lost. If\n\t * there is no move pending or the pending mask does not contain\n\t * any online CPU, use the current affinity mask.\n\t */\n\tif (irq_fixup_move_pending(desc, true))\n\t\taffinity = irq_desc_get_pending_mask(desc);\n\telse\n\t\taffinity = irq_data_get_affinity_mask(d);\n\n\t/* Mask the chip for interrupts which cannot move in process context */\n\tif (maskchip && chip->irq_mask)\n\t\tchip->irq_mask(d);\n\n\tif (cpumask_any_and(affinity, cpu_online_mask) >= nr_cpu_ids) {\n\t\t/*\n\t\t * If the interrupt is managed, then shut it down and leave\n\t\t * the affinity untouched.\n\t\t */\n\t\tif (irqd_affinity_is_managed(d)) {\n\t\t\tirqd_set_managed_shutdown(d);\n\t\t\tirq_shutdown(desc);\n\t\t\treturn false;\n\t\t}\n\t\taffinity = cpu_online_mask;\n\t\tbrokeaff = true;\n\t}\n\t/*\n\t * Do not set the force argument of irq_do_set_affinity() as this\n\t * disables the masking of offline CPUs from the supplied affinity\n\t * mask and therefore might keep/reassign the irq to the outgoing\n\t * CPU.\n\t */\n\terr = irq_do_set_affinity(d, affinity, false);\n\tif (err) {\n\t\tpr_warn_ratelimited(\"IRQ%u: set affinity failed(%d).\\n\",\n\t\t\t\t    d->irq, err);\n\t\tbrokeaff = false;\n\t}\n\n\tif (maskchip && chip->irq_unmask)\n\t\tchip->irq_unmask(d);\n\n\treturn brokeaff;\n}",
    "includes": [
      "#include \"internals.h\"",
      "#include <linux/irq.h>",
      "#include <linux/ratelimit.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "chip->irq_unmask",
          "args": [
            "d"
          ],
          "line": 139
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_warn_ratelimited",
          "args": [
            "\"IRQ%u: set affinity failed(%d).\\n\"",
            "d->irq",
            "err"
          ],
          "line": 133
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "irq_do_set_affinity",
          "args": [
            "d",
            "affinity",
            "false"
          ],
          "line": 131
        },
        "resolved": true,
        "details": {
          "function_name": "irq_do_set_affinity",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/manage.c",
          "lines": "184-206",
          "snippet": "int irq_do_set_affinity(struct irq_data *data, const struct cpumask *mask,\n\t\t\tbool force)\n{\n\tstruct irq_desc *desc = irq_data_to_desc(data);\n\tstruct irq_chip *chip = irq_data_get_irq_chip(data);\n\tint ret;\n\n\tif (!chip || !chip->irq_set_affinity)\n\t\treturn -EINVAL;\n\n\tret = chip->irq_set_affinity(data, mask, force);\n\tswitch (ret) {\n\tcase IRQ_SET_MASK_OK:\n\tcase IRQ_SET_MASK_OK_DONE:\n\t\tcpumask_copy(desc->irq_common_data.affinity, mask);\n\tcase IRQ_SET_MASK_OK_NOCOPY:\n\t\tirq_validate_effective_affinity(data);\n\t\tirq_set_thread_affinity(desc);\n\t\tret = 0;\n\t}\n\n\treturn ret;\n}",
          "includes": [
            "#include \"internals.h\"",
            "#include <linux/task_work.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/slab.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/random.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>",
            "#include <linux/irq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internals.h\"\n#include <linux/task_work.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/slab.h>\n#include <linux/interrupt.h>\n#include <linux/random.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\n#include <linux/irq.h>\n\nint irq_do_set_affinity(struct irq_data *data, const struct cpumask *mask,\n\t\t\tbool force)\n{\n\tstruct irq_desc *desc = irq_data_to_desc(data);\n\tstruct irq_chip *chip = irq_data_get_irq_chip(data);\n\tint ret;\n\n\tif (!chip || !chip->irq_set_affinity)\n\t\treturn -EINVAL;\n\n\tret = chip->irq_set_affinity(data, mask, force);\n\tswitch (ret) {\n\tcase IRQ_SET_MASK_OK:\n\tcase IRQ_SET_MASK_OK_DONE:\n\t\tcpumask_copy(desc->irq_common_data.affinity, mask);\n\tcase IRQ_SET_MASK_OK_NOCOPY:\n\t\tirq_validate_effective_affinity(data);\n\t\tirq_set_thread_affinity(desc);\n\t\tret = 0;\n\t}\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "irq_shutdown",
          "args": [
            "desc"
          ],
          "line": 119
        },
        "resolved": true,
        "details": {
          "function_name": "irq_shutdown",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/chip.c",
          "lines": "304-324",
          "snippet": "void irq_shutdown(struct irq_desc *desc)\n{\n\tif (irqd_is_started(&desc->irq_data)) {\n\t\tdesc->depth = 1;\n\t\tif (desc->irq_data.chip->irq_shutdown) {\n\t\t\tdesc->irq_data.chip->irq_shutdown(&desc->irq_data);\n\t\t\tirq_state_set_disabled(desc);\n\t\t\tirq_state_set_masked(desc);\n\t\t} else {\n\t\t\t__irq_disable(desc, true);\n\t\t}\n\t\tirq_state_clr_started(desc);\n\t}\n\t/*\n\t * This must be called even if the interrupt was never started up,\n\t * because the activation can happen before the interrupt is\n\t * available for request/startup. It has it's own state tracking so\n\t * it's safe to call it unconditionally.\n\t */\n\tirq_domain_deactivate_irq(&desc->irq_data);\n}",
          "includes": [
            "#include \"internals.h\"",
            "#include <trace/events/irq.h>",
            "#include <linux/irqdomain.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/module.h>",
            "#include <linux/msi.h>",
            "#include <linux/irq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internals.h\"\n#include <trace/events/irq.h>\n#include <linux/irqdomain.h>\n#include <linux/kernel_stat.h>\n#include <linux/interrupt.h>\n#include <linux/module.h>\n#include <linux/msi.h>\n#include <linux/irq.h>\n\nvoid irq_shutdown(struct irq_desc *desc)\n{\n\tif (irqd_is_started(&desc->irq_data)) {\n\t\tdesc->depth = 1;\n\t\tif (desc->irq_data.chip->irq_shutdown) {\n\t\t\tdesc->irq_data.chip->irq_shutdown(&desc->irq_data);\n\t\t\tirq_state_set_disabled(desc);\n\t\t\tirq_state_set_masked(desc);\n\t\t} else {\n\t\t\t__irq_disable(desc, true);\n\t\t}\n\t\tirq_state_clr_started(desc);\n\t}\n\t/*\n\t * This must be called even if the interrupt was never started up,\n\t * because the activation can happen before the interrupt is\n\t * available for request/startup. It has it's own state tracking so\n\t * it's safe to call it unconditionally.\n\t */\n\tirq_domain_deactivate_irq(&desc->irq_data);\n}"
        }
      },
      {
        "call_info": {
          "callee": "irqd_set_managed_shutdown",
          "args": [
            "d"
          ],
          "line": 118
        },
        "resolved": true,
        "details": {
          "function_name": "irqd_set_managed_shutdown",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/internals.h",
          "lines": "208-211",
          "snippet": "static inline void irqd_set_managed_shutdown(struct irq_data *d)\n{\n\t__irqd_to_state(d) |= IRQD_MANAGED_SHUTDOWN;\n}",
          "includes": [
            "#include <linux/debugfs.h>",
            "#include \"settings.h\"",
            "#include \"debug.h\"",
            "#include <linux/sched/clock.h>",
            "#include <linux/pm_runtime.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/irqdesc.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/debugfs.h>\n#include \"settings.h\"\n#include \"debug.h\"\n#include <linux/sched/clock.h>\n#include <linux/pm_runtime.h>\n#include <linux/kernel_stat.h>\n#include <linux/irqdesc.h>\n\nstatic inline void irqd_set_managed_shutdown(struct irq_data *d)\n{\n\t__irqd_to_state(d) |= IRQD_MANAGED_SHUTDOWN;\n}"
        }
      },
      {
        "call_info": {
          "callee": "irqd_affinity_is_managed",
          "args": [
            "d"
          ],
          "line": 117
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_any_and",
          "args": [
            "affinity",
            "cpu_online_mask"
          ],
          "line": 112
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "chip->irq_mask",
          "args": [
            "d"
          ],
          "line": 110
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "irq_data_get_affinity_mask",
          "args": [
            "d"
          ],
          "line": 106
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "irq_desc_get_pending_mask",
          "args": [
            "desc"
          ],
          "line": 104
        },
        "resolved": true,
        "details": {
          "function_name": "irq_desc_get_pending_mask",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/internals.h",
          "lines": "432-435",
          "snippet": "static inline struct cpumask *irq_desc_get_pending_mask(struct irq_desc *desc)\n{\n\treturn NULL;\n}",
          "includes": [
            "#include <linux/debugfs.h>",
            "#include \"settings.h\"",
            "#include \"debug.h\"",
            "#include <linux/sched/clock.h>",
            "#include <linux/pm_runtime.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/irqdesc.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern void __disable_irq(struct irq_desc *desc);",
            "extern void __enable_irq(struct irq_desc *desc);",
            "extern int irq_activate(struct irq_desc *desc);",
            "extern void irq_shutdown(struct irq_desc *desc);",
            "extern void irq_enable(struct irq_desc *desc);",
            "extern void irq_disable(struct irq_desc *desc);",
            "extern void mask_irq(struct irq_desc *desc);",
            "extern void unmask_irq(struct irq_desc *desc);",
            "extern void unmask_threaded_irq(struct irq_desc *desc);",
            "irqreturn_t handle_irq_event_percpu(struct irq_desc *desc);",
            "irqreturn_t handle_irq_event(struct irq_desc *desc);",
            "void check_irq_resend(struct irq_desc *desc);",
            "bool irq_wait_for_poll(struct irq_desc *desc);",
            "extern void irq_set_thread_affinity(struct irq_desc *desc);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/debugfs.h>\n#include \"settings.h\"\n#include \"debug.h\"\n#include <linux/sched/clock.h>\n#include <linux/pm_runtime.h>\n#include <linux/kernel_stat.h>\n#include <linux/irqdesc.h>\n\nextern void __disable_irq(struct irq_desc *desc);\nextern void __enable_irq(struct irq_desc *desc);\nextern int irq_activate(struct irq_desc *desc);\nextern void irq_shutdown(struct irq_desc *desc);\nextern void irq_enable(struct irq_desc *desc);\nextern void irq_disable(struct irq_desc *desc);\nextern void mask_irq(struct irq_desc *desc);\nextern void unmask_irq(struct irq_desc *desc);\nextern void unmask_threaded_irq(struct irq_desc *desc);\nirqreturn_t handle_irq_event_percpu(struct irq_desc *desc);\nirqreturn_t handle_irq_event(struct irq_desc *desc);\nvoid check_irq_resend(struct irq_desc *desc);\nbool irq_wait_for_poll(struct irq_desc *desc);\nextern void irq_set_thread_affinity(struct irq_desc *desc);\n\nstatic inline struct cpumask *irq_desc_get_pending_mask(struct irq_desc *desc)\n{\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "irq_fixup_move_pending",
          "args": [
            "desc",
            "true"
          ],
          "line": 103
        },
        "resolved": true,
        "details": {
          "function_name": "irq_fixup_move_pending",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/internals.h",
          "lines": "436-439",
          "snippet": "static inline bool irq_fixup_move_pending(struct irq_desc *desc, bool fclear)\n{\n\treturn false;\n}",
          "includes": [
            "#include <linux/debugfs.h>",
            "#include \"settings.h\"",
            "#include \"debug.h\"",
            "#include <linux/sched/clock.h>",
            "#include <linux/pm_runtime.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/irqdesc.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern void __disable_irq(struct irq_desc *desc);",
            "extern void __enable_irq(struct irq_desc *desc);",
            "extern int irq_activate(struct irq_desc *desc);",
            "extern void irq_shutdown(struct irq_desc *desc);",
            "extern void irq_enable(struct irq_desc *desc);",
            "extern void irq_disable(struct irq_desc *desc);",
            "extern void mask_irq(struct irq_desc *desc);",
            "extern void unmask_irq(struct irq_desc *desc);",
            "extern void unmask_threaded_irq(struct irq_desc *desc);",
            "irqreturn_t handle_irq_event_percpu(struct irq_desc *desc);",
            "irqreturn_t handle_irq_event(struct irq_desc *desc);",
            "void check_irq_resend(struct irq_desc *desc);",
            "bool irq_wait_for_poll(struct irq_desc *desc);",
            "extern void irq_set_thread_affinity(struct irq_desc *desc);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/debugfs.h>\n#include \"settings.h\"\n#include \"debug.h\"\n#include <linux/sched/clock.h>\n#include <linux/pm_runtime.h>\n#include <linux/kernel_stat.h>\n#include <linux/irqdesc.h>\n\nextern void __disable_irq(struct irq_desc *desc);\nextern void __enable_irq(struct irq_desc *desc);\nextern int irq_activate(struct irq_desc *desc);\nextern void irq_shutdown(struct irq_desc *desc);\nextern void irq_enable(struct irq_desc *desc);\nextern void irq_disable(struct irq_desc *desc);\nextern void mask_irq(struct irq_desc *desc);\nextern void unmask_irq(struct irq_desc *desc);\nextern void unmask_threaded_irq(struct irq_desc *desc);\nirqreturn_t handle_irq_event_percpu(struct irq_desc *desc);\nirqreturn_t handle_irq_event(struct irq_desc *desc);\nvoid check_irq_resend(struct irq_desc *desc);\nbool irq_wait_for_poll(struct irq_desc *desc);\nextern void irq_set_thread_affinity(struct irq_desc *desc);\n\nstatic inline bool irq_fixup_move_pending(struct irq_desc *desc, bool fclear)\n{\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "irq_force_complete_move",
          "args": [
            "desc"
          ],
          "line": 95
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "irq_needs_fixup",
          "args": [
            "d"
          ],
          "line": 80
        },
        "resolved": true,
        "details": {
          "function_name": "irq_needs_fixup",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/cpuhotplug.c",
          "lines": "19-50",
          "snippet": "static inline bool irq_needs_fixup(struct irq_data *d)\n{\n\tconst struct cpumask *m = irq_data_get_effective_affinity_mask(d);\n\tunsigned int cpu = smp_processor_id();\n\n#ifdef CONFIG_GENERIC_IRQ_EFFECTIVE_AFF_MASK\n\t/*\n\t * The cpumask_empty() check is a workaround for interrupt chips,\n\t * which do not implement effective affinity, but the architecture has\n\t * enabled the config switch. Use the general affinity mask instead.\n\t */\n\tif (cpumask_empty(m))\n\t\tm = irq_data_get_affinity_mask(d);\n\n\t/*\n\t * Sanity check. If the mask is not empty when excluding the outgoing\n\t * CPU then it must contain at least one online CPU. The outgoing CPU\n\t * has been removed from the online mask already.\n\t */\n\tif (cpumask_any_but(m, cpu) < nr_cpu_ids &&\n\t    cpumask_any_and(m, cpu_online_mask) >= nr_cpu_ids) {\n\t\t/*\n\t\t * If this happens then there was a missed IRQ fixup at some\n\t\t * point. Warn about it and enforce fixup.\n\t\t */\n\t\tpr_warn(\"Eff. affinity %*pbl of IRQ %u contains only offline CPUs after offlining CPU %u\\n\",\n\t\t\tcpumask_pr_args(m), d->irq, cpu);\n\t\treturn true;\n\t}\n#endif\n\treturn cpumask_test_cpu(cpu, m);\n}",
          "includes": [
            "#include \"internals.h\"",
            "#include <linux/irq.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/interrupt.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internals.h\"\n#include <linux/irq.h>\n#include <linux/ratelimit.h>\n#include <linux/interrupt.h>\n\nstatic inline bool irq_needs_fixup(struct irq_data *d)\n{\n\tconst struct cpumask *m = irq_data_get_effective_affinity_mask(d);\n\tunsigned int cpu = smp_processor_id();\n\n#ifdef CONFIG_GENERIC_IRQ_EFFECTIVE_AFF_MASK\n\t/*\n\t * The cpumask_empty() check is a workaround for interrupt chips,\n\t * which do not implement effective affinity, but the architecture has\n\t * enabled the config switch. Use the general affinity mask instead.\n\t */\n\tif (cpumask_empty(m))\n\t\tm = irq_data_get_affinity_mask(d);\n\n\t/*\n\t * Sanity check. If the mask is not empty when excluding the outgoing\n\t * CPU then it must contain at least one online CPU. The outgoing CPU\n\t * has been removed from the online mask already.\n\t */\n\tif (cpumask_any_but(m, cpu) < nr_cpu_ids &&\n\t    cpumask_any_and(m, cpu_online_mask) >= nr_cpu_ids) {\n\t\t/*\n\t\t * If this happens then there was a missed IRQ fixup at some\n\t\t * point. Warn about it and enforce fixup.\n\t\t */\n\t\tpr_warn(\"Eff. affinity %*pbl of IRQ %u contains only offline CPUs after offlining CPU %u\\n\",\n\t\t\tcpumask_pr_args(m), d->irq, cpu);\n\t\treturn true;\n\t}\n#endif\n\treturn cpumask_test_cpu(cpu, m);\n}"
        }
      },
      {
        "call_info": {
          "callee": "irqd_is_started",
          "args": [
            "d"
          ],
          "line": 80
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "irqd_is_per_cpu",
          "args": [
            "d"
          ],
          "line": 80
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_debug",
          "args": [
            "\"IRQ %u: Unable to migrate away\\n\"",
            "d->irq"
          ],
          "line": 67
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "irqd_irq_masked",
          "args": [
            "d"
          ],
          "line": 56
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "irq_can_move_pcntxt",
          "args": [
            "d"
          ],
          "line": 56
        },
        "resolved": true,
        "details": {
          "function_name": "irq_can_move_pcntxt",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/internals.h",
          "lines": "416-419",
          "snippet": "static inline bool irq_can_move_pcntxt(struct irq_data *data)\n{\n\treturn true;\n}",
          "includes": [
            "#include <linux/debugfs.h>",
            "#include \"settings.h\"",
            "#include \"debug.h\"",
            "#include <linux/sched/clock.h>",
            "#include <linux/pm_runtime.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/irqdesc.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/debugfs.h>\n#include \"settings.h\"\n#include \"debug.h\"\n#include <linux/sched/clock.h>\n#include <linux/pm_runtime.h>\n#include <linux/kernel_stat.h>\n#include <linux/irqdesc.h>\n\nstatic inline bool irq_can_move_pcntxt(struct irq_data *data)\n{\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "irq_data_get_irq_chip",
          "args": [
            "d"
          ],
          "line": 55
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "irq_desc_get_irq_data",
          "args": [
            "desc"
          ],
          "line": 54
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"internals.h\"\n#include <linux/irq.h>\n#include <linux/ratelimit.h>\n#include <linux/interrupt.h>\n\nstatic bool migrate_one_irq(struct irq_desc *desc)\n{\n\tstruct irq_data *d = irq_desc_get_irq_data(desc);\n\tstruct irq_chip *chip = irq_data_get_irq_chip(d);\n\tbool maskchip = !irq_can_move_pcntxt(d) && !irqd_irq_masked(d);\n\tconst struct cpumask *affinity;\n\tbool brokeaff = false;\n\tint err;\n\n\t/*\n\t * IRQ chip might be already torn down, but the irq descriptor is\n\t * still in the radix tree. Also if the chip has no affinity setter,\n\t * nothing can be done here.\n\t */\n\tif (!chip || !chip->irq_set_affinity) {\n\t\tpr_debug(\"IRQ %u: Unable to migrate away\\n\", d->irq);\n\t\treturn false;\n\t}\n\n\t/*\n\t * No move required, if:\n\t * - Interrupt is per cpu\n\t * - Interrupt is not started\n\t * - Affinity mask does not include this CPU.\n\t *\n\t * Note: Do not check desc->action as this might be a chained\n\t * interrupt.\n\t */\n\tif (irqd_is_per_cpu(d) || !irqd_is_started(d) || !irq_needs_fixup(d)) {\n\t\t/*\n\t\t * If an irq move is pending, abort it if the dying CPU is\n\t\t * the sole target.\n\t\t */\n\t\tirq_fixup_move_pending(desc, false);\n\t\treturn false;\n\t}\n\n\t/*\n\t * Complete an eventually pending irq move cleanup. If this\n\t * interrupt was moved in hard irq context, then the vectors need\n\t * to be cleaned up. It can't wait until this interrupt actually\n\t * happens and this CPU was involved.\n\t */\n\tirq_force_complete_move(desc);\n\n\t/*\n\t * If there is a setaffinity pending, then try to reuse the pending\n\t * mask, so the last change of the affinity does not get lost. If\n\t * there is no move pending or the pending mask does not contain\n\t * any online CPU, use the current affinity mask.\n\t */\n\tif (irq_fixup_move_pending(desc, true))\n\t\taffinity = irq_desc_get_pending_mask(desc);\n\telse\n\t\taffinity = irq_data_get_affinity_mask(d);\n\n\t/* Mask the chip for interrupts which cannot move in process context */\n\tif (maskchip && chip->irq_mask)\n\t\tchip->irq_mask(d);\n\n\tif (cpumask_any_and(affinity, cpu_online_mask) >= nr_cpu_ids) {\n\t\t/*\n\t\t * If the interrupt is managed, then shut it down and leave\n\t\t * the affinity untouched.\n\t\t */\n\t\tif (irqd_affinity_is_managed(d)) {\n\t\t\tirqd_set_managed_shutdown(d);\n\t\t\tirq_shutdown(desc);\n\t\t\treturn false;\n\t\t}\n\t\taffinity = cpu_online_mask;\n\t\tbrokeaff = true;\n\t}\n\t/*\n\t * Do not set the force argument of irq_do_set_affinity() as this\n\t * disables the masking of offline CPUs from the supplied affinity\n\t * mask and therefore might keep/reassign the irq to the outgoing\n\t * CPU.\n\t */\n\terr = irq_do_set_affinity(d, affinity, false);\n\tif (err) {\n\t\tpr_warn_ratelimited(\"IRQ%u: set affinity failed(%d).\\n\",\n\t\t\t\t    d->irq, err);\n\t\tbrokeaff = false;\n\t}\n\n\tif (maskchip && chip->irq_unmask)\n\t\tchip->irq_unmask(d);\n\n\treturn brokeaff;\n}"
  },
  {
    "function_name": "irq_needs_fixup",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq/cpuhotplug.c",
    "lines": "19-50",
    "snippet": "static inline bool irq_needs_fixup(struct irq_data *d)\n{\n\tconst struct cpumask *m = irq_data_get_effective_affinity_mask(d);\n\tunsigned int cpu = smp_processor_id();\n\n#ifdef CONFIG_GENERIC_IRQ_EFFECTIVE_AFF_MASK\n\t/*\n\t * The cpumask_empty() check is a workaround for interrupt chips,\n\t * which do not implement effective affinity, but the architecture has\n\t * enabled the config switch. Use the general affinity mask instead.\n\t */\n\tif (cpumask_empty(m))\n\t\tm = irq_data_get_affinity_mask(d);\n\n\t/*\n\t * Sanity check. If the mask is not empty when excluding the outgoing\n\t * CPU then it must contain at least one online CPU. The outgoing CPU\n\t * has been removed from the online mask already.\n\t */\n\tif (cpumask_any_but(m, cpu) < nr_cpu_ids &&\n\t    cpumask_any_and(m, cpu_online_mask) >= nr_cpu_ids) {\n\t\t/*\n\t\t * If this happens then there was a missed IRQ fixup at some\n\t\t * point. Warn about it and enforce fixup.\n\t\t */\n\t\tpr_warn(\"Eff. affinity %*pbl of IRQ %u contains only offline CPUs after offlining CPU %u\\n\",\n\t\t\tcpumask_pr_args(m), d->irq, cpu);\n\t\treturn true;\n\t}\n#endif\n\treturn cpumask_test_cpu(cpu, m);\n}",
    "includes": [
      "#include \"internals.h\"",
      "#include <linux/irq.h>",
      "#include <linux/ratelimit.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "m"
          ],
          "line": 49
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_warn",
          "args": [
            "\"Eff. affinity %*pbl of IRQ %u contains only offline CPUs after offlining CPU %u\\n\"",
            "cpumask_pr_args(m)",
            "d->irq",
            "cpu"
          ],
          "line": 44
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_pr_args",
          "args": [
            "m"
          ],
          "line": 45
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_any_and",
          "args": [
            "m",
            "cpu_online_mask"
          ],
          "line": 39
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_any_but",
          "args": [
            "m",
            "cpu"
          ],
          "line": 38
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "irq_data_get_affinity_mask",
          "args": [
            "d"
          ],
          "line": 31
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_empty",
          "args": [
            "m"
          ],
          "line": 30
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_processor_id",
          "args": [],
          "line": 22
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "irq_data_get_effective_affinity_mask",
          "args": [
            "d"
          ],
          "line": 21
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"internals.h\"\n#include <linux/irq.h>\n#include <linux/ratelimit.h>\n#include <linux/interrupt.h>\n\nstatic inline bool irq_needs_fixup(struct irq_data *d)\n{\n\tconst struct cpumask *m = irq_data_get_effective_affinity_mask(d);\n\tunsigned int cpu = smp_processor_id();\n\n#ifdef CONFIG_GENERIC_IRQ_EFFECTIVE_AFF_MASK\n\t/*\n\t * The cpumask_empty() check is a workaround for interrupt chips,\n\t * which do not implement effective affinity, but the architecture has\n\t * enabled the config switch. Use the general affinity mask instead.\n\t */\n\tif (cpumask_empty(m))\n\t\tm = irq_data_get_affinity_mask(d);\n\n\t/*\n\t * Sanity check. If the mask is not empty when excluding the outgoing\n\t * CPU then it must contain at least one online CPU. The outgoing CPU\n\t * has been removed from the online mask already.\n\t */\n\tif (cpumask_any_but(m, cpu) < nr_cpu_ids &&\n\t    cpumask_any_and(m, cpu_online_mask) >= nr_cpu_ids) {\n\t\t/*\n\t\t * If this happens then there was a missed IRQ fixup at some\n\t\t * point. Warn about it and enforce fixup.\n\t\t */\n\t\tpr_warn(\"Eff. affinity %*pbl of IRQ %u contains only offline CPUs after offlining CPU %u\\n\",\n\t\t\tcpumask_pr_args(m), d->irq, cpu);\n\t\treturn true;\n\t}\n#endif\n\treturn cpumask_test_cpu(cpu, m);\n}"
  }
]