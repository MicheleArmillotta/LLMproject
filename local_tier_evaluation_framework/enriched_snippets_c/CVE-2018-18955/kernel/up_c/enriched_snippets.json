[
  {
    "function_name": "smp_call_on_cpu",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/up.c",
    "lines": "95-109",
    "snippet": "int smp_call_on_cpu(unsigned int cpu, int (*func)(void *), void *par, bool phys)\n{\n\tint ret;\n\n\tif (cpu != 0)\n\t\treturn -ENXIO;\n\n\tif (phys)\n\t\thypervisor_pin_vcpu(0);\n\tret = func(par);\n\tif (phys)\n\t\thypervisor_pin_vcpu(-1);\n\n\treturn ret;\n}",
    "includes": [
      "#include <linux/hypervisor.h>",
      "#include <linux/smp.h>",
      "#include <linux/export.h>",
      "#include <linux/kernel.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "hypervisor_pin_vcpu",
          "args": [
            "-1"
          ],
          "line": 106
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "func",
          "args": [
            "par"
          ],
          "line": 104
        },
        "resolved": true,
        "details": {
          "function_name": "flush_smp_call_function_queue",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/smp.c",
          "lines": "209-258",
          "snippet": "static void flush_smp_call_function_queue(bool warn_cpu_offline)\n{\n\tstruct llist_head *head;\n\tstruct llist_node *entry;\n\tcall_single_data_t *csd, *csd_next;\n\tstatic bool warned;\n\n\tlockdep_assert_irqs_disabled();\n\n\thead = this_cpu_ptr(&call_single_queue);\n\tentry = llist_del_all(head);\n\tentry = llist_reverse_order(entry);\n\n\t/* There shouldn't be any pending callbacks on an offline CPU. */\n\tif (unlikely(warn_cpu_offline && !cpu_online(smp_processor_id()) &&\n\t\t     !warned && !llist_empty(head))) {\n\t\twarned = true;\n\t\tWARN(1, \"IPI on offline CPU %d\\n\", smp_processor_id());\n\n\t\t/*\n\t\t * We don't have to use the _safe() variant here\n\t\t * because we are not invoking the IPI handlers yet.\n\t\t */\n\t\tllist_for_each_entry(csd, entry, llist)\n\t\t\tpr_warn(\"IPI callback %pS sent to offline CPU\\n\",\n\t\t\t\tcsd->func);\n\t}\n\n\tllist_for_each_entry_safe(csd, csd_next, entry, llist) {\n\t\tsmp_call_func_t func = csd->func;\n\t\tvoid *info = csd->info;\n\n\t\t/* Do we wait until *after* callback? */\n\t\tif (csd->flags & CSD_FLAG_SYNCHRONOUS) {\n\t\t\tfunc(info);\n\t\t\tcsd_unlock(csd);\n\t\t} else {\n\t\t\tcsd_unlock(csd);\n\t\t\tfunc(info);\n\t\t}\n\t}\n\n\t/*\n\t * Handle irq works queued remotely by irq_work_queue_on().\n\t * Smp functions above are typically synchronous so they\n\t * better run first since some other CPUs may be busy waiting\n\t * for them.\n\t */\n\tirq_work_run();\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <linux/hypervisor.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched.h>",
            "#include <linux/cpu.h>",
            "#include <linux/smp.h>",
            "#include <linux/gfp.h>",
            "#include <linux/init.h>",
            "#include <linux/percpu.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/rculist.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/irq_work.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct llist_head, call_single_queue);",
            "static void flush_smp_call_function_queue(bool warn_cpu_offline);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <linux/hypervisor.h>\n#include <linux/sched/idle.h>\n#include <linux/sched.h>\n#include <linux/cpu.h>\n#include <linux/smp.h>\n#include <linux/gfp.h>\n#include <linux/init.h>\n#include <linux/percpu.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/rculist.h>\n#include <linux/rcupdate.h>\n#include <linux/irq_work.h>\n\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct llist_head, call_single_queue);\nstatic void flush_smp_call_function_queue(bool warn_cpu_offline);\n\nstatic void flush_smp_call_function_queue(bool warn_cpu_offline)\n{\n\tstruct llist_head *head;\n\tstruct llist_node *entry;\n\tcall_single_data_t *csd, *csd_next;\n\tstatic bool warned;\n\n\tlockdep_assert_irqs_disabled();\n\n\thead = this_cpu_ptr(&call_single_queue);\n\tentry = llist_del_all(head);\n\tentry = llist_reverse_order(entry);\n\n\t/* There shouldn't be any pending callbacks on an offline CPU. */\n\tif (unlikely(warn_cpu_offline && !cpu_online(smp_processor_id()) &&\n\t\t     !warned && !llist_empty(head))) {\n\t\twarned = true;\n\t\tWARN(1, \"IPI on offline CPU %d\\n\", smp_processor_id());\n\n\t\t/*\n\t\t * We don't have to use the _safe() variant here\n\t\t * because we are not invoking the IPI handlers yet.\n\t\t */\n\t\tllist_for_each_entry(csd, entry, llist)\n\t\t\tpr_warn(\"IPI callback %pS sent to offline CPU\\n\",\n\t\t\t\tcsd->func);\n\t}\n\n\tllist_for_each_entry_safe(csd, csd_next, entry, llist) {\n\t\tsmp_call_func_t func = csd->func;\n\t\tvoid *info = csd->info;\n\n\t\t/* Do we wait until *after* callback? */\n\t\tif (csd->flags & CSD_FLAG_SYNCHRONOUS) {\n\t\t\tfunc(info);\n\t\t\tcsd_unlock(csd);\n\t\t} else {\n\t\t\tcsd_unlock(csd);\n\t\t\tfunc(info);\n\t\t}\n\t}\n\n\t/*\n\t * Handle irq works queued remotely by irq_work_queue_on().\n\t * Smp functions above are typically synchronous so they\n\t * better run first since some other CPUs may be busy waiting\n\t * for them.\n\t */\n\tirq_work_run();\n}"
        }
      },
      {
        "call_info": {
          "callee": "hypervisor_pin_vcpu",
          "args": [
            "0"
          ],
          "line": 103
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/hypervisor.h>\n#include <linux/smp.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nint smp_call_on_cpu(unsigned int cpu, int (*func)(void *), void *par, bool phys)\n{\n\tint ret;\n\n\tif (cpu != 0)\n\t\treturn -ENXIO;\n\n\tif (phys)\n\t\thypervisor_pin_vcpu(0);\n\tret = func(par);\n\tif (phys)\n\t\thypervisor_pin_vcpu(-1);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "on_each_cpu_cond",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/up.c",
    "lines": "87-92",
    "snippet": "void on_each_cpu_cond(bool (*cond_func)(int cpu, void *info),\n\t\t      smp_call_func_t func, void *info, bool wait,\n\t\t      gfp_t gfp_flags)\n{\n\ton_each_cpu_cond_mask(cond_func, func, info, wait, gfp_flags, NULL);\n}",
    "includes": [
      "#include <linux/hypervisor.h>",
      "#include <linux/smp.h>",
      "#include <linux/export.h>",
      "#include <linux/kernel.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "on_each_cpu_cond_mask",
          "args": [
            "cond_func",
            "func",
            "info",
            "wait",
            "gfp_flags",
            "NULL"
          ],
          "line": 91
        },
        "resolved": true,
        "details": {
          "function_name": "on_each_cpu_cond_mask",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/up.c",
          "lines": "71-84",
          "snippet": "void on_each_cpu_cond_mask(bool (*cond_func)(int cpu, void *info),\n\t\t\t   smp_call_func_t func, void *info, bool wait,\n\t\t\t   gfp_t gfp_flags, const struct cpumask *mask)\n{\n\tunsigned long flags;\n\n\tpreempt_disable();\n\tif (cond_func(0, info)) {\n\t\tlocal_irq_save(flags);\n\t\tfunc(info);\n\t\tlocal_irq_restore(flags);\n\t}\n\tpreempt_enable();\n}",
          "includes": [
            "#include <linux/hypervisor.h>",
            "#include <linux/smp.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/hypervisor.h>\n#include <linux/smp.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nvoid on_each_cpu_cond_mask(bool (*cond_func)(int cpu, void *info),\n\t\t\t   smp_call_func_t func, void *info, bool wait,\n\t\t\t   gfp_t gfp_flags, const struct cpumask *mask)\n{\n\tunsigned long flags;\n\n\tpreempt_disable();\n\tif (cond_func(0, info)) {\n\t\tlocal_irq_save(flags);\n\t\tfunc(info);\n\t\tlocal_irq_restore(flags);\n\t}\n\tpreempt_enable();\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/hypervisor.h>\n#include <linux/smp.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nvoid on_each_cpu_cond(bool (*cond_func)(int cpu, void *info),\n\t\t      smp_call_func_t func, void *info, bool wait,\n\t\t      gfp_t gfp_flags)\n{\n\ton_each_cpu_cond_mask(cond_func, func, info, wait, gfp_flags, NULL);\n}"
  },
  {
    "function_name": "on_each_cpu_cond_mask",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/up.c",
    "lines": "71-84",
    "snippet": "void on_each_cpu_cond_mask(bool (*cond_func)(int cpu, void *info),\n\t\t\t   smp_call_func_t func, void *info, bool wait,\n\t\t\t   gfp_t gfp_flags, const struct cpumask *mask)\n{\n\tunsigned long flags;\n\n\tpreempt_disable();\n\tif (cond_func(0, info)) {\n\t\tlocal_irq_save(flags);\n\t\tfunc(info);\n\t\tlocal_irq_restore(flags);\n\t}\n\tpreempt_enable();\n}",
    "includes": [
      "#include <linux/hypervisor.h>",
      "#include <linux/smp.h>",
      "#include <linux/export.h>",
      "#include <linux/kernel.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "preempt_enable",
          "args": [],
          "line": 83
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_irq_restore",
          "args": [
            "flags"
          ],
          "line": 81
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "func",
          "args": [
            "info"
          ],
          "line": 80
        },
        "resolved": true,
        "details": {
          "function_name": "flush_smp_call_function_queue",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/smp.c",
          "lines": "209-258",
          "snippet": "static void flush_smp_call_function_queue(bool warn_cpu_offline)\n{\n\tstruct llist_head *head;\n\tstruct llist_node *entry;\n\tcall_single_data_t *csd, *csd_next;\n\tstatic bool warned;\n\n\tlockdep_assert_irqs_disabled();\n\n\thead = this_cpu_ptr(&call_single_queue);\n\tentry = llist_del_all(head);\n\tentry = llist_reverse_order(entry);\n\n\t/* There shouldn't be any pending callbacks on an offline CPU. */\n\tif (unlikely(warn_cpu_offline && !cpu_online(smp_processor_id()) &&\n\t\t     !warned && !llist_empty(head))) {\n\t\twarned = true;\n\t\tWARN(1, \"IPI on offline CPU %d\\n\", smp_processor_id());\n\n\t\t/*\n\t\t * We don't have to use the _safe() variant here\n\t\t * because we are not invoking the IPI handlers yet.\n\t\t */\n\t\tllist_for_each_entry(csd, entry, llist)\n\t\t\tpr_warn(\"IPI callback %pS sent to offline CPU\\n\",\n\t\t\t\tcsd->func);\n\t}\n\n\tllist_for_each_entry_safe(csd, csd_next, entry, llist) {\n\t\tsmp_call_func_t func = csd->func;\n\t\tvoid *info = csd->info;\n\n\t\t/* Do we wait until *after* callback? */\n\t\tif (csd->flags & CSD_FLAG_SYNCHRONOUS) {\n\t\t\tfunc(info);\n\t\t\tcsd_unlock(csd);\n\t\t} else {\n\t\t\tcsd_unlock(csd);\n\t\t\tfunc(info);\n\t\t}\n\t}\n\n\t/*\n\t * Handle irq works queued remotely by irq_work_queue_on().\n\t * Smp functions above are typically synchronous so they\n\t * better run first since some other CPUs may be busy waiting\n\t * for them.\n\t */\n\tirq_work_run();\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <linux/hypervisor.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched.h>",
            "#include <linux/cpu.h>",
            "#include <linux/smp.h>",
            "#include <linux/gfp.h>",
            "#include <linux/init.h>",
            "#include <linux/percpu.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/rculist.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/irq_work.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct llist_head, call_single_queue);",
            "static void flush_smp_call_function_queue(bool warn_cpu_offline);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <linux/hypervisor.h>\n#include <linux/sched/idle.h>\n#include <linux/sched.h>\n#include <linux/cpu.h>\n#include <linux/smp.h>\n#include <linux/gfp.h>\n#include <linux/init.h>\n#include <linux/percpu.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/rculist.h>\n#include <linux/rcupdate.h>\n#include <linux/irq_work.h>\n\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct llist_head, call_single_queue);\nstatic void flush_smp_call_function_queue(bool warn_cpu_offline);\n\nstatic void flush_smp_call_function_queue(bool warn_cpu_offline)\n{\n\tstruct llist_head *head;\n\tstruct llist_node *entry;\n\tcall_single_data_t *csd, *csd_next;\n\tstatic bool warned;\n\n\tlockdep_assert_irqs_disabled();\n\n\thead = this_cpu_ptr(&call_single_queue);\n\tentry = llist_del_all(head);\n\tentry = llist_reverse_order(entry);\n\n\t/* There shouldn't be any pending callbacks on an offline CPU. */\n\tif (unlikely(warn_cpu_offline && !cpu_online(smp_processor_id()) &&\n\t\t     !warned && !llist_empty(head))) {\n\t\twarned = true;\n\t\tWARN(1, \"IPI on offline CPU %d\\n\", smp_processor_id());\n\n\t\t/*\n\t\t * We don't have to use the _safe() variant here\n\t\t * because we are not invoking the IPI handlers yet.\n\t\t */\n\t\tllist_for_each_entry(csd, entry, llist)\n\t\t\tpr_warn(\"IPI callback %pS sent to offline CPU\\n\",\n\t\t\t\tcsd->func);\n\t}\n\n\tllist_for_each_entry_safe(csd, csd_next, entry, llist) {\n\t\tsmp_call_func_t func = csd->func;\n\t\tvoid *info = csd->info;\n\n\t\t/* Do we wait until *after* callback? */\n\t\tif (csd->flags & CSD_FLAG_SYNCHRONOUS) {\n\t\t\tfunc(info);\n\t\t\tcsd_unlock(csd);\n\t\t} else {\n\t\t\tcsd_unlock(csd);\n\t\t\tfunc(info);\n\t\t}\n\t}\n\n\t/*\n\t * Handle irq works queued remotely by irq_work_queue_on().\n\t * Smp functions above are typically synchronous so they\n\t * better run first since some other CPUs may be busy waiting\n\t * for them.\n\t */\n\tirq_work_run();\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_irq_save",
          "args": [
            "flags"
          ],
          "line": 79
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cond_func",
          "args": [
            "0",
            "info"
          ],
          "line": 78
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "preempt_disable",
          "args": [],
          "line": 77
        },
        "resolved": true,
        "details": {
          "function_name": "schedule_preempt_disabled",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/core.c",
          "lines": "3571-3576",
          "snippet": "void __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}",
          "includes": [
            "#include \"features.h\"",
            "#include <trace/events/sched.h>",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/kcov.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include <trace/events/sched.h>\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/kcov.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n\nstatic void __sched;\nstatic void __sched;\n\nvoid __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/hypervisor.h>\n#include <linux/smp.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nvoid on_each_cpu_cond_mask(bool (*cond_func)(int cpu, void *info),\n\t\t\t   smp_call_func_t func, void *info, bool wait,\n\t\t\t   gfp_t gfp_flags, const struct cpumask *mask)\n{\n\tunsigned long flags;\n\n\tpreempt_disable();\n\tif (cond_func(0, info)) {\n\t\tlocal_irq_save(flags);\n\t\tfunc(info);\n\t\tlocal_irq_restore(flags);\n\t}\n\tpreempt_enable();\n}"
  },
  {
    "function_name": "on_each_cpu_mask",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/up.c",
    "lines": "54-64",
    "snippet": "void on_each_cpu_mask(const struct cpumask *mask,\n\t\t      smp_call_func_t func, void *info, bool wait)\n{\n\tunsigned long flags;\n\n\tif (cpumask_test_cpu(0, mask)) {\n\t\tlocal_irq_save(flags);\n\t\tfunc(info);\n\t\tlocal_irq_restore(flags);\n\t}\n}",
    "includes": [
      "#include <linux/hypervisor.h>",
      "#include <linux/smp.h>",
      "#include <linux/export.h>",
      "#include <linux/kernel.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_irq_restore",
          "args": [
            "flags"
          ],
          "line": 62
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "func",
          "args": [
            "info"
          ],
          "line": 61
        },
        "resolved": true,
        "details": {
          "function_name": "flush_smp_call_function_queue",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/smp.c",
          "lines": "209-258",
          "snippet": "static void flush_smp_call_function_queue(bool warn_cpu_offline)\n{\n\tstruct llist_head *head;\n\tstruct llist_node *entry;\n\tcall_single_data_t *csd, *csd_next;\n\tstatic bool warned;\n\n\tlockdep_assert_irqs_disabled();\n\n\thead = this_cpu_ptr(&call_single_queue);\n\tentry = llist_del_all(head);\n\tentry = llist_reverse_order(entry);\n\n\t/* There shouldn't be any pending callbacks on an offline CPU. */\n\tif (unlikely(warn_cpu_offline && !cpu_online(smp_processor_id()) &&\n\t\t     !warned && !llist_empty(head))) {\n\t\twarned = true;\n\t\tWARN(1, \"IPI on offline CPU %d\\n\", smp_processor_id());\n\n\t\t/*\n\t\t * We don't have to use the _safe() variant here\n\t\t * because we are not invoking the IPI handlers yet.\n\t\t */\n\t\tllist_for_each_entry(csd, entry, llist)\n\t\t\tpr_warn(\"IPI callback %pS sent to offline CPU\\n\",\n\t\t\t\tcsd->func);\n\t}\n\n\tllist_for_each_entry_safe(csd, csd_next, entry, llist) {\n\t\tsmp_call_func_t func = csd->func;\n\t\tvoid *info = csd->info;\n\n\t\t/* Do we wait until *after* callback? */\n\t\tif (csd->flags & CSD_FLAG_SYNCHRONOUS) {\n\t\t\tfunc(info);\n\t\t\tcsd_unlock(csd);\n\t\t} else {\n\t\t\tcsd_unlock(csd);\n\t\t\tfunc(info);\n\t\t}\n\t}\n\n\t/*\n\t * Handle irq works queued remotely by irq_work_queue_on().\n\t * Smp functions above are typically synchronous so they\n\t * better run first since some other CPUs may be busy waiting\n\t * for them.\n\t */\n\tirq_work_run();\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <linux/hypervisor.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched.h>",
            "#include <linux/cpu.h>",
            "#include <linux/smp.h>",
            "#include <linux/gfp.h>",
            "#include <linux/init.h>",
            "#include <linux/percpu.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/rculist.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/irq_work.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct llist_head, call_single_queue);",
            "static void flush_smp_call_function_queue(bool warn_cpu_offline);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <linux/hypervisor.h>\n#include <linux/sched/idle.h>\n#include <linux/sched.h>\n#include <linux/cpu.h>\n#include <linux/smp.h>\n#include <linux/gfp.h>\n#include <linux/init.h>\n#include <linux/percpu.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/rculist.h>\n#include <linux/rcupdate.h>\n#include <linux/irq_work.h>\n\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct llist_head, call_single_queue);\nstatic void flush_smp_call_function_queue(bool warn_cpu_offline);\n\nstatic void flush_smp_call_function_queue(bool warn_cpu_offline)\n{\n\tstruct llist_head *head;\n\tstruct llist_node *entry;\n\tcall_single_data_t *csd, *csd_next;\n\tstatic bool warned;\n\n\tlockdep_assert_irqs_disabled();\n\n\thead = this_cpu_ptr(&call_single_queue);\n\tentry = llist_del_all(head);\n\tentry = llist_reverse_order(entry);\n\n\t/* There shouldn't be any pending callbacks on an offline CPU. */\n\tif (unlikely(warn_cpu_offline && !cpu_online(smp_processor_id()) &&\n\t\t     !warned && !llist_empty(head))) {\n\t\twarned = true;\n\t\tWARN(1, \"IPI on offline CPU %d\\n\", smp_processor_id());\n\n\t\t/*\n\t\t * We don't have to use the _safe() variant here\n\t\t * because we are not invoking the IPI handlers yet.\n\t\t */\n\t\tllist_for_each_entry(csd, entry, llist)\n\t\t\tpr_warn(\"IPI callback %pS sent to offline CPU\\n\",\n\t\t\t\tcsd->func);\n\t}\n\n\tllist_for_each_entry_safe(csd, csd_next, entry, llist) {\n\t\tsmp_call_func_t func = csd->func;\n\t\tvoid *info = csd->info;\n\n\t\t/* Do we wait until *after* callback? */\n\t\tif (csd->flags & CSD_FLAG_SYNCHRONOUS) {\n\t\t\tfunc(info);\n\t\t\tcsd_unlock(csd);\n\t\t} else {\n\t\t\tcsd_unlock(csd);\n\t\t\tfunc(info);\n\t\t}\n\t}\n\n\t/*\n\t * Handle irq works queued remotely by irq_work_queue_on().\n\t * Smp functions above are typically synchronous so they\n\t * better run first since some other CPUs may be busy waiting\n\t * for them.\n\t */\n\tirq_work_run();\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_irq_save",
          "args": [
            "flags"
          ],
          "line": 60
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "0",
            "mask"
          ],
          "line": 59
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/hypervisor.h>\n#include <linux/smp.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nvoid on_each_cpu_mask(const struct cpumask *mask,\n\t\t      smp_call_func_t func, void *info, bool wait)\n{\n\tunsigned long flags;\n\n\tif (cpumask_test_cpu(0, mask)) {\n\t\tlocal_irq_save(flags);\n\t\tfunc(info);\n\t\tlocal_irq_restore(flags);\n\t}\n}"
  },
  {
    "function_name": "on_each_cpu",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/up.c",
    "lines": "37-45",
    "snippet": "int on_each_cpu(smp_call_func_t func, void *info, int wait)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tfunc(info);\n\tlocal_irq_restore(flags);\n\treturn 0;\n}",
    "includes": [
      "#include <linux/hypervisor.h>",
      "#include <linux/smp.h>",
      "#include <linux/export.h>",
      "#include <linux/kernel.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_irq_restore",
          "args": [
            "flags"
          ],
          "line": 43
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "func",
          "args": [
            "info"
          ],
          "line": 42
        },
        "resolved": true,
        "details": {
          "function_name": "flush_smp_call_function_queue",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/smp.c",
          "lines": "209-258",
          "snippet": "static void flush_smp_call_function_queue(bool warn_cpu_offline)\n{\n\tstruct llist_head *head;\n\tstruct llist_node *entry;\n\tcall_single_data_t *csd, *csd_next;\n\tstatic bool warned;\n\n\tlockdep_assert_irqs_disabled();\n\n\thead = this_cpu_ptr(&call_single_queue);\n\tentry = llist_del_all(head);\n\tentry = llist_reverse_order(entry);\n\n\t/* There shouldn't be any pending callbacks on an offline CPU. */\n\tif (unlikely(warn_cpu_offline && !cpu_online(smp_processor_id()) &&\n\t\t     !warned && !llist_empty(head))) {\n\t\twarned = true;\n\t\tWARN(1, \"IPI on offline CPU %d\\n\", smp_processor_id());\n\n\t\t/*\n\t\t * We don't have to use the _safe() variant here\n\t\t * because we are not invoking the IPI handlers yet.\n\t\t */\n\t\tllist_for_each_entry(csd, entry, llist)\n\t\t\tpr_warn(\"IPI callback %pS sent to offline CPU\\n\",\n\t\t\t\tcsd->func);\n\t}\n\n\tllist_for_each_entry_safe(csd, csd_next, entry, llist) {\n\t\tsmp_call_func_t func = csd->func;\n\t\tvoid *info = csd->info;\n\n\t\t/* Do we wait until *after* callback? */\n\t\tif (csd->flags & CSD_FLAG_SYNCHRONOUS) {\n\t\t\tfunc(info);\n\t\t\tcsd_unlock(csd);\n\t\t} else {\n\t\t\tcsd_unlock(csd);\n\t\t\tfunc(info);\n\t\t}\n\t}\n\n\t/*\n\t * Handle irq works queued remotely by irq_work_queue_on().\n\t * Smp functions above are typically synchronous so they\n\t * better run first since some other CPUs may be busy waiting\n\t * for them.\n\t */\n\tirq_work_run();\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <linux/hypervisor.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched.h>",
            "#include <linux/cpu.h>",
            "#include <linux/smp.h>",
            "#include <linux/gfp.h>",
            "#include <linux/init.h>",
            "#include <linux/percpu.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/rculist.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/irq_work.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct llist_head, call_single_queue);",
            "static void flush_smp_call_function_queue(bool warn_cpu_offline);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <linux/hypervisor.h>\n#include <linux/sched/idle.h>\n#include <linux/sched.h>\n#include <linux/cpu.h>\n#include <linux/smp.h>\n#include <linux/gfp.h>\n#include <linux/init.h>\n#include <linux/percpu.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/rculist.h>\n#include <linux/rcupdate.h>\n#include <linux/irq_work.h>\n\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct llist_head, call_single_queue);\nstatic void flush_smp_call_function_queue(bool warn_cpu_offline);\n\nstatic void flush_smp_call_function_queue(bool warn_cpu_offline)\n{\n\tstruct llist_head *head;\n\tstruct llist_node *entry;\n\tcall_single_data_t *csd, *csd_next;\n\tstatic bool warned;\n\n\tlockdep_assert_irqs_disabled();\n\n\thead = this_cpu_ptr(&call_single_queue);\n\tentry = llist_del_all(head);\n\tentry = llist_reverse_order(entry);\n\n\t/* There shouldn't be any pending callbacks on an offline CPU. */\n\tif (unlikely(warn_cpu_offline && !cpu_online(smp_processor_id()) &&\n\t\t     !warned && !llist_empty(head))) {\n\t\twarned = true;\n\t\tWARN(1, \"IPI on offline CPU %d\\n\", smp_processor_id());\n\n\t\t/*\n\t\t * We don't have to use the _safe() variant here\n\t\t * because we are not invoking the IPI handlers yet.\n\t\t */\n\t\tllist_for_each_entry(csd, entry, llist)\n\t\t\tpr_warn(\"IPI callback %pS sent to offline CPU\\n\",\n\t\t\t\tcsd->func);\n\t}\n\n\tllist_for_each_entry_safe(csd, csd_next, entry, llist) {\n\t\tsmp_call_func_t func = csd->func;\n\t\tvoid *info = csd->info;\n\n\t\t/* Do we wait until *after* callback? */\n\t\tif (csd->flags & CSD_FLAG_SYNCHRONOUS) {\n\t\t\tfunc(info);\n\t\t\tcsd_unlock(csd);\n\t\t} else {\n\t\t\tcsd_unlock(csd);\n\t\t\tfunc(info);\n\t\t}\n\t}\n\n\t/*\n\t * Handle irq works queued remotely by irq_work_queue_on().\n\t * Smp functions above are typically synchronous so they\n\t * better run first since some other CPUs may be busy waiting\n\t * for them.\n\t */\n\tirq_work_run();\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_irq_save",
          "args": [
            "flags"
          ],
          "line": 41
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/hypervisor.h>\n#include <linux/smp.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nint on_each_cpu(smp_call_func_t func, void *info, int wait)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tfunc(info);\n\tlocal_irq_restore(flags);\n\treturn 0;\n}"
  },
  {
    "function_name": "smp_call_function_single_async",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/up.c",
    "lines": "26-34",
    "snippet": "int smp_call_function_single_async(int cpu, call_single_data_t *csd)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tcsd->func(csd->info);\n\tlocal_irq_restore(flags);\n\treturn 0;\n}",
    "includes": [
      "#include <linux/hypervisor.h>",
      "#include <linux/smp.h>",
      "#include <linux/export.h>",
      "#include <linux/kernel.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_irq_restore",
          "args": [
            "flags"
          ],
          "line": 32
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "csd->func",
          "args": [
            "csd->info"
          ],
          "line": 31
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_irq_save",
          "args": [
            "flags"
          ],
          "line": 30
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/hypervisor.h>\n#include <linux/smp.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nint smp_call_function_single_async(int cpu, call_single_data_t *csd)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tcsd->func(csd->info);\n\tlocal_irq_restore(flags);\n\treturn 0;\n}"
  },
  {
    "function_name": "smp_call_function_single",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/up.c",
    "lines": "11-23",
    "snippet": "int smp_call_function_single(int cpu, void (*func) (void *info), void *info,\n\t\t\t\tint wait)\n{\n\tunsigned long flags;\n\n\tWARN_ON(cpu != 0);\n\n\tlocal_irq_save(flags);\n\tfunc(info);\n\tlocal_irq_restore(flags);\n\n\treturn 0;\n}",
    "includes": [
      "#include <linux/hypervisor.h>",
      "#include <linux/smp.h>",
      "#include <linux/export.h>",
      "#include <linux/kernel.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_irq_restore",
          "args": [
            "flags"
          ],
          "line": 20
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "func",
          "args": [
            "info"
          ],
          "line": 19
        },
        "resolved": true,
        "details": {
          "function_name": "flush_smp_call_function_queue",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/smp.c",
          "lines": "209-258",
          "snippet": "static void flush_smp_call_function_queue(bool warn_cpu_offline)\n{\n\tstruct llist_head *head;\n\tstruct llist_node *entry;\n\tcall_single_data_t *csd, *csd_next;\n\tstatic bool warned;\n\n\tlockdep_assert_irqs_disabled();\n\n\thead = this_cpu_ptr(&call_single_queue);\n\tentry = llist_del_all(head);\n\tentry = llist_reverse_order(entry);\n\n\t/* There shouldn't be any pending callbacks on an offline CPU. */\n\tif (unlikely(warn_cpu_offline && !cpu_online(smp_processor_id()) &&\n\t\t     !warned && !llist_empty(head))) {\n\t\twarned = true;\n\t\tWARN(1, \"IPI on offline CPU %d\\n\", smp_processor_id());\n\n\t\t/*\n\t\t * We don't have to use the _safe() variant here\n\t\t * because we are not invoking the IPI handlers yet.\n\t\t */\n\t\tllist_for_each_entry(csd, entry, llist)\n\t\t\tpr_warn(\"IPI callback %pS sent to offline CPU\\n\",\n\t\t\t\tcsd->func);\n\t}\n\n\tllist_for_each_entry_safe(csd, csd_next, entry, llist) {\n\t\tsmp_call_func_t func = csd->func;\n\t\tvoid *info = csd->info;\n\n\t\t/* Do we wait until *after* callback? */\n\t\tif (csd->flags & CSD_FLAG_SYNCHRONOUS) {\n\t\t\tfunc(info);\n\t\t\tcsd_unlock(csd);\n\t\t} else {\n\t\t\tcsd_unlock(csd);\n\t\t\tfunc(info);\n\t\t}\n\t}\n\n\t/*\n\t * Handle irq works queued remotely by irq_work_queue_on().\n\t * Smp functions above are typically synchronous so they\n\t * better run first since some other CPUs may be busy waiting\n\t * for them.\n\t */\n\tirq_work_run();\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <linux/hypervisor.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched.h>",
            "#include <linux/cpu.h>",
            "#include <linux/smp.h>",
            "#include <linux/gfp.h>",
            "#include <linux/init.h>",
            "#include <linux/percpu.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/rculist.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/irq_work.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct llist_head, call_single_queue);",
            "static void flush_smp_call_function_queue(bool warn_cpu_offline);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <linux/hypervisor.h>\n#include <linux/sched/idle.h>\n#include <linux/sched.h>\n#include <linux/cpu.h>\n#include <linux/smp.h>\n#include <linux/gfp.h>\n#include <linux/init.h>\n#include <linux/percpu.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/rculist.h>\n#include <linux/rcupdate.h>\n#include <linux/irq_work.h>\n\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct llist_head, call_single_queue);\nstatic void flush_smp_call_function_queue(bool warn_cpu_offline);\n\nstatic void flush_smp_call_function_queue(bool warn_cpu_offline)\n{\n\tstruct llist_head *head;\n\tstruct llist_node *entry;\n\tcall_single_data_t *csd, *csd_next;\n\tstatic bool warned;\n\n\tlockdep_assert_irqs_disabled();\n\n\thead = this_cpu_ptr(&call_single_queue);\n\tentry = llist_del_all(head);\n\tentry = llist_reverse_order(entry);\n\n\t/* There shouldn't be any pending callbacks on an offline CPU. */\n\tif (unlikely(warn_cpu_offline && !cpu_online(smp_processor_id()) &&\n\t\t     !warned && !llist_empty(head))) {\n\t\twarned = true;\n\t\tWARN(1, \"IPI on offline CPU %d\\n\", smp_processor_id());\n\n\t\t/*\n\t\t * We don't have to use the _safe() variant here\n\t\t * because we are not invoking the IPI handlers yet.\n\t\t */\n\t\tllist_for_each_entry(csd, entry, llist)\n\t\t\tpr_warn(\"IPI callback %pS sent to offline CPU\\n\",\n\t\t\t\tcsd->func);\n\t}\n\n\tllist_for_each_entry_safe(csd, csd_next, entry, llist) {\n\t\tsmp_call_func_t func = csd->func;\n\t\tvoid *info = csd->info;\n\n\t\t/* Do we wait until *after* callback? */\n\t\tif (csd->flags & CSD_FLAG_SYNCHRONOUS) {\n\t\t\tfunc(info);\n\t\t\tcsd_unlock(csd);\n\t\t} else {\n\t\t\tcsd_unlock(csd);\n\t\t\tfunc(info);\n\t\t}\n\t}\n\n\t/*\n\t * Handle irq works queued remotely by irq_work_queue_on().\n\t * Smp functions above are typically synchronous so they\n\t * better run first since some other CPUs may be busy waiting\n\t * for them.\n\t */\n\tirq_work_run();\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_irq_save",
          "args": [
            "flags"
          ],
          "line": 18
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "cpu != 0"
          ],
          "line": 16
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/hypervisor.h>\n#include <linux/smp.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nint smp_call_function_single(int cpu, void (*func) (void *info), void *info,\n\t\t\t\tint wait)\n{\n\tunsigned long flags;\n\n\tWARN_ON(cpu != 0);\n\n\tlocal_irq_save(flags);\n\tfunc(info);\n\tlocal_irq_restore(flags);\n\n\treturn 0;\n}"
  }
]