[
  {
    "function_name": "test_ringbuffer",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "5018-5172",
    "snippet": "static __init int test_ringbuffer(void)\n{\n\tstruct task_struct *rb_hammer;\n\tstruct ring_buffer *buffer;\n\tint cpu;\n\tint ret = 0;\n\n\tpr_info(\"Running ring buffer tests...\\n\");\n\n\tbuffer = ring_buffer_alloc(RB_TEST_BUFFER_SIZE, RB_FL_OVERWRITE);\n\tif (WARN_ON(!buffer))\n\t\treturn 0;\n\n\t/* Disable buffer so that threads can't write to it yet */\n\tring_buffer_record_off(buffer);\n\n\tfor_each_online_cpu(cpu) {\n\t\trb_data[cpu].buffer = buffer;\n\t\trb_data[cpu].cpu = cpu;\n\t\trb_data[cpu].cnt = cpu;\n\t\trb_threads[cpu] = kthread_create(rb_test, &rb_data[cpu],\n\t\t\t\t\t\t \"rbtester/%d\", cpu);\n\t\tif (WARN_ON(IS_ERR(rb_threads[cpu]))) {\n\t\t\tpr_cont(\"FAILED\\n\");\n\t\t\tret = PTR_ERR(rb_threads[cpu]);\n\t\t\tgoto out_free;\n\t\t}\n\n\t\tkthread_bind(rb_threads[cpu], cpu);\n \t\twake_up_process(rb_threads[cpu]);\n\t}\n\n\t/* Now create the rb hammer! */\n\trb_hammer = kthread_run(rb_hammer_test, NULL, \"rbhammer\");\n\tif (WARN_ON(IS_ERR(rb_hammer))) {\n\t\tpr_cont(\"FAILED\\n\");\n\t\tret = PTR_ERR(rb_hammer);\n\t\tgoto out_free;\n\t}\n\n\tring_buffer_record_on(buffer);\n\t/*\n\t * Show buffer is enabled before setting rb_test_started.\n\t * Yes there's a small race window where events could be\n\t * dropped and the thread wont catch it. But when a ring\n\t * buffer gets enabled, there will always be some kind of\n\t * delay before other CPUs see it. Thus, we don't care about\n\t * those dropped events. We care about events dropped after\n\t * the threads see that the buffer is active.\n\t */\n\tsmp_wmb();\n\trb_test_started = true;\n\n\tset_current_state(TASK_INTERRUPTIBLE);\n\t/* Just run for 10 seconds */;\n\tschedule_timeout(10 * HZ);\n\n\tkthread_stop(rb_hammer);\n\n out_free:\n\tfor_each_online_cpu(cpu) {\n\t\tif (!rb_threads[cpu])\n\t\t\tbreak;\n\t\tkthread_stop(rb_threads[cpu]);\n\t}\n\tif (ret) {\n\t\tring_buffer_free(buffer);\n\t\treturn ret;\n\t}\n\n\t/* Report! */\n\tpr_info(\"finished\\n\");\n\tfor_each_online_cpu(cpu) {\n\t\tstruct ring_buffer_event *event;\n\t\tstruct rb_test_data *data = &rb_data[cpu];\n\t\tstruct rb_item *item;\n\t\tunsigned long total_events;\n\t\tunsigned long total_dropped;\n\t\tunsigned long total_written;\n\t\tunsigned long total_alloc;\n\t\tunsigned long total_read = 0;\n\t\tunsigned long total_size = 0;\n\t\tunsigned long total_len = 0;\n\t\tunsigned long total_lost = 0;\n\t\tunsigned long lost;\n\t\tint big_event_size;\n\t\tint small_event_size;\n\n\t\tret = -1;\n\n\t\ttotal_events = data->events + data->events_nested;\n\t\ttotal_written = data->bytes_written + data->bytes_written_nested;\n\t\ttotal_alloc = data->bytes_alloc + data->bytes_alloc_nested;\n\t\ttotal_dropped = data->bytes_dropped + data->bytes_dropped_nested;\n\n\t\tbig_event_size = data->max_size + data->max_size_nested;\n\t\tsmall_event_size = data->min_size + data->min_size_nested;\n\n\t\tpr_info(\"CPU %d:\\n\", cpu);\n\t\tpr_info(\"              events:    %ld\\n\", total_events);\n\t\tpr_info(\"       dropped bytes:    %ld\\n\", total_dropped);\n\t\tpr_info(\"       alloced bytes:    %ld\\n\", total_alloc);\n\t\tpr_info(\"       written bytes:    %ld\\n\", total_written);\n\t\tpr_info(\"       biggest event:    %d\\n\", big_event_size);\n\t\tpr_info(\"      smallest event:    %d\\n\", small_event_size);\n\n\t\tif (RB_WARN_ON(buffer, total_dropped))\n\t\t\tbreak;\n\n\t\tret = 0;\n\n\t\twhile ((event = ring_buffer_consume(buffer, cpu, NULL, &lost))) {\n\t\t\ttotal_lost += lost;\n\t\t\titem = ring_buffer_event_data(event);\n\t\t\ttotal_len += ring_buffer_event_length(event);\n\t\t\ttotal_size += item->size + sizeof(struct rb_item);\n\t\t\tif (memcmp(&item->str[0], rb_string, item->size) != 0) {\n\t\t\t\tpr_info(\"FAILED!\\n\");\n\t\t\t\tpr_info(\"buffer had: %.*s\\n\", item->size, item->str);\n\t\t\t\tpr_info(\"expected:   %.*s\\n\", item->size, rb_string);\n\t\t\t\tRB_WARN_ON(buffer, 1);\n\t\t\t\tret = -1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\ttotal_read++;\n\t\t}\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\tret = -1;\n\n\t\tpr_info(\"         read events:   %ld\\n\", total_read);\n\t\tpr_info(\"         lost events:   %ld\\n\", total_lost);\n\t\tpr_info(\"        total events:   %ld\\n\", total_lost + total_read);\n\t\tpr_info(\"  recorded len bytes:   %ld\\n\", total_len);\n\t\tpr_info(\" recorded size bytes:   %ld\\n\", total_size);\n\t\tif (total_lost)\n\t\t\tpr_info(\" With dropped events, record len and size may not match\\n\"\n\t\t\t\t\" alloced and written from above\\n\");\n\t\tif (!total_lost) {\n\t\t\tif (RB_WARN_ON(buffer, total_len != total_alloc ||\n\t\t\t\t       total_size != total_written))\n\t\t\t\tbreak;\n\t\t}\n\t\tif (RB_WARN_ON(buffer, total_lost + total_read != total_events))\n\t\t\tbreak;\n\n\t\tret = 0;\n\t}\n\tif (!ret)\n\t\tpr_info(\"Ring buffer PASSED!\\n\");\n\n\tring_buffer_free(buffer);\n\treturn 0;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_TEST_BUFFER_SIZE\t1048576"
    ],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "ring_buffer_free",
          "args": [
            "buffer"
          ],
          "line": 5170
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_free",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1424-1438",
          "snippet": "void\nring_buffer_free(struct ring_buffer *buffer)\n{\n\tint cpu;\n\n\tcpuhp_state_remove_instance(CPUHP_TRACE_RB_PREPARE, &buffer->node);\n\n\tfor_each_buffer_cpu(buffer, cpu)\n\t\trb_free_cpu_buffer(buffer->buffers[cpu]);\n\n\tkfree(buffer->buffers);\n\tfree_cpumask_var(buffer->cpumask);\n\n\tkfree(buffer);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid\nring_buffer_free(struct ring_buffer *buffer)\n{\n\tint cpu;\n\n\tcpuhp_state_remove_instance(CPUHP_TRACE_RB_PREPARE, &buffer->node);\n\n\tfor_each_buffer_cpu(buffer, cpu)\n\t\trb_free_cpu_buffer(buffer->buffers[cpu]);\n\n\tkfree(buffer->buffers);\n\tfree_cpumask_var(buffer->cpumask);\n\n\tkfree(buffer);\n}"
        }
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"Ring buffer PASSED!\\n\""
          ],
          "line": 5168
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "buffer",
            "total_lost + total_read != total_events"
          ],
          "line": 5162
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "buffer",
            "total_len != total_alloc ||\n\t\t\t\t       total_size != total_written"
          ],
          "line": 5158
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\" With dropped events, record len and size may not match\\n\"\n\t\t\t\t\" alloced and written from above\\n\""
          ],
          "line": 5155
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\" recorded size bytes:   %ld\\n\"",
            "total_size"
          ],
          "line": 5153
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"  recorded len bytes:   %ld\\n\"",
            "total_len"
          ],
          "line": 5152
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"        total events:   %ld\\n\"",
            "total_lost + total_read"
          ],
          "line": 5151
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"         lost events:   %ld\\n\"",
            "total_lost"
          ],
          "line": 5150
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"         read events:   %ld\\n\"",
            "total_read"
          ],
          "line": 5149
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "buffer",
            "1"
          ],
          "line": 5138
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"expected:   %.*s\\n\"",
            "item->size",
            "rb_string"
          ],
          "line": 5137
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"buffer had: %.*s\\n\"",
            "item->size",
            "item->str"
          ],
          "line": 5136
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"FAILED!\\n\""
          ],
          "line": 5135
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "memcmp",
          "args": [
            "&item->str[0]",
            "rb_string",
            "item->size"
          ],
          "line": 5134
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ring_buffer_event_length",
          "args": [
            "event"
          ],
          "line": 5132
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_event_length",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "237-251",
          "snippet": "unsigned ring_buffer_event_length(struct ring_buffer_event *event)\n{\n\tunsigned length;\n\n\tif (extended_time(event))\n\t\tevent = skip_time_extend(event);\n\n\tlength = rb_event_length(event);\n\tif (event->type_len > RINGBUF_TYPE_DATA_TYPE_LEN_MAX)\n\t\treturn length;\n\tlength -= RB_EVNT_HDR_SIZE;\n\tif (length > RB_MAX_SMALL_DATA + sizeof(event->array[0]))\n                length -= sizeof(event->array[0]);\n\treturn length;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_MAX_SMALL_DATA\t(RB_ALIGNMENT * RINGBUF_TYPE_DATA_TYPE_LEN_MAX)",
            "#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_MAX_SMALL_DATA\t(RB_ALIGNMENT * RINGBUF_TYPE_DATA_TYPE_LEN_MAX)\n#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nunsigned ring_buffer_event_length(struct ring_buffer_event *event)\n{\n\tunsigned length;\n\n\tif (extended_time(event))\n\t\tevent = skip_time_extend(event);\n\n\tlength = rb_event_length(event);\n\tif (event->type_len > RINGBUF_TYPE_DATA_TYPE_LEN_MAX)\n\t\treturn length;\n\tlength -= RB_EVNT_HDR_SIZE;\n\tif (length > RB_MAX_SMALL_DATA + sizeof(event->array[0]))\n                length -= sizeof(event->array[0]);\n\treturn length;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ring_buffer_event_data",
          "args": [
            "event"
          ],
          "line": 5131
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_event_data",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "272-275",
          "snippet": "void *ring_buffer_event_data(struct ring_buffer_event *event)\n{\n\treturn rb_event_data(event);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nvoid *ring_buffer_event_data(struct ring_buffer_event *event)\n{\n\treturn rb_event_data(event);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ring_buffer_consume",
          "args": [
            "buffer",
            "cpu",
            "NULL",
            "&lost"
          ],
          "line": 5129
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_consume",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "4101-4137",
          "snippet": "struct ring_buffer_event *\nring_buffer_consume(struct ring_buffer *buffer, int cpu, u64 *ts,\n\t\t    unsigned long *lost_events)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct ring_buffer_event *event = NULL;\n\tunsigned long flags;\n\tbool dolock;\n\n again:\n\t/* might be called in atomic */\n\tpreempt_disable();\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\tgoto out;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tlocal_irq_save(flags);\n\tdolock = rb_reader_lock(cpu_buffer);\n\n\tevent = rb_buffer_peek(cpu_buffer, ts, lost_events);\n\tif (event) {\n\t\tcpu_buffer->lost_events = 0;\n\t\trb_advance_reader(cpu_buffer);\n\t}\n\n\trb_reader_unlock(cpu_buffer, dolock);\n\tlocal_irq_restore(flags);\n\n out:\n\tpreempt_enable();\n\n\tif (event && event->type_len == RINGBUF_TYPE_PADDING)\n\t\tgoto again;\n\n\treturn event;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstruct ring_buffer_event *\nring_buffer_consume(struct ring_buffer *buffer, int cpu, u64 *ts,\n\t\t    unsigned long *lost_events)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct ring_buffer_event *event = NULL;\n\tunsigned long flags;\n\tbool dolock;\n\n again:\n\t/* might be called in atomic */\n\tpreempt_disable();\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\tgoto out;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tlocal_irq_save(flags);\n\tdolock = rb_reader_lock(cpu_buffer);\n\n\tevent = rb_buffer_peek(cpu_buffer, ts, lost_events);\n\tif (event) {\n\t\tcpu_buffer->lost_events = 0;\n\t\trb_advance_reader(cpu_buffer);\n\t}\n\n\trb_reader_unlock(cpu_buffer, dolock);\n\tlocal_irq_restore(flags);\n\n out:\n\tpreempt_enable();\n\n\tif (event && event->type_len == RINGBUF_TYPE_PADDING)\n\t\tgoto again;\n\n\treturn event;\n}"
        }
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "buffer",
            "total_dropped"
          ],
          "line": 5124
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"      smallest event:    %d\\n\"",
            "small_event_size"
          ],
          "line": 5122
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"       biggest event:    %d\\n\"",
            "big_event_size"
          ],
          "line": 5121
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"       written bytes:    %ld\\n\"",
            "total_written"
          ],
          "line": 5120
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"       alloced bytes:    %ld\\n\"",
            "total_alloc"
          ],
          "line": 5119
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"       dropped bytes:    %ld\\n\"",
            "total_dropped"
          ],
          "line": 5118
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"              events:    %ld\\n\"",
            "total_events"
          ],
          "line": 5117
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"CPU %d:\\n\"",
            "cpu"
          ],
          "line": 5116
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"finished\\n\""
          ],
          "line": 5089
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kthread_stop",
          "args": [
            "rb_threads[cpu]"
          ],
          "line": 5081
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_stop",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/kthread.c",
          "lines": "538-556",
          "snippet": "int kthread_stop(struct task_struct *k)\n{\n\tstruct kthread *kthread;\n\tint ret;\n\n\ttrace_sched_kthread_stop(k);\n\n\tget_task_struct(k);\n\tkthread = to_kthread(k);\n\tset_bit(KTHREAD_SHOULD_STOP, &kthread->flags);\n\tkthread_unpark(k);\n\twake_up_process(k);\n\twait_for_completion(&kthread->exited);\n\tret = k->exit_code;\n\tput_task_struct(k);\n\n\ttrace_sched_kthread_stop_ret(ret);\n\treturn ret;\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <uapi/linux/sched/types.h>\n\nint kthread_stop(struct task_struct *k)\n{\n\tstruct kthread *kthread;\n\tint ret;\n\n\ttrace_sched_kthread_stop(k);\n\n\tget_task_struct(k);\n\tkthread = to_kthread(k);\n\tset_bit(KTHREAD_SHOULD_STOP, &kthread->flags);\n\tkthread_unpark(k);\n\twake_up_process(k);\n\twait_for_completion(&kthread->exited);\n\tret = k->exit_code;\n\tput_task_struct(k);\n\n\ttrace_sched_kthread_stop_ret(ret);\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "schedule_timeout",
          "args": [
            "10 * HZ"
          ],
          "line": 5073
        },
        "resolved": true,
        "details": {
          "function_name": "io_schedule_timeout",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/core.c",
          "lines": "5119-5129",
          "snippet": "long __sched io_schedule_timeout(long timeout)\n{\n\tint token;\n\tlong ret;\n\n\ttoken = io_schedule_prepare();\n\tret = schedule_timeout(timeout);\n\tio_schedule_finish(token);\n\n\treturn ret;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include <trace/events/sched.h>",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/kcov.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include <trace/events/sched.h>\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/kcov.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n\nstatic void __sched;\nstatic void __sched;\n\nlong __sched io_schedule_timeout(long timeout)\n{\n\tint token;\n\tlong ret;\n\n\ttoken = io_schedule_prepare();\n\tret = schedule_timeout(timeout);\n\tio_schedule_finish(token);\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "set_current_state",
          "args": [
            "TASK_INTERRUPTIBLE"
          ],
          "line": 5071
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_wmb",
          "args": [],
          "line": 5068
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ring_buffer_record_on",
          "args": [
            "buffer"
          ],
          "line": 5058
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_record_on",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3209-3218",
          "snippet": "void ring_buffer_record_on(struct ring_buffer *buffer)\n{\n\tunsigned int rd;\n\tunsigned int new_rd;\n\n\tdo {\n\t\trd = atomic_read(&buffer->record_disabled);\n\t\tnew_rd = rd & ~RB_BUFFER_OFF;\n\t} while (atomic_cmpxchg(&buffer->record_disabled, rd, new_rd) != rd);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_BUFFER_OFF\t\t(1 << 20)"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_BUFFER_OFF\t\t(1 << 20)\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid ring_buffer_record_on(struct ring_buffer *buffer)\n{\n\tunsigned int rd;\n\tunsigned int new_rd;\n\n\tdo {\n\t\trd = atomic_read(&buffer->record_disabled);\n\t\tnew_rd = rd & ~RB_BUFFER_OFF;\n\t} while (atomic_cmpxchg(&buffer->record_disabled, rd, new_rd) != rd);\n}"
        }
      },
      {
        "call_info": {
          "callee": "PTR_ERR",
          "args": [
            "rb_hammer"
          ],
          "line": 5054
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_cont",
          "args": [
            "\"FAILED\\n\""
          ],
          "line": 5053
        },
        "resolved": true,
        "details": {
          "function_name": "pr_cont_pool_info",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/workqueue.c",
          "lines": "4431-4437",
          "snippet": "static void pr_cont_pool_info(struct worker_pool *pool)\n{\n\tpr_cont(\" cpus=%*pbl\", nr_cpumask_bits, pool->attrs->cpumask);\n\tif (pool->node != NUMA_NO_NODE)\n\t\tpr_cont(\" node=%d\", pool->node);\n\tpr_cont(\" flags=0x%x nice=%d\", pool->flags, pool->attrs->nice);\n}",
          "includes": [
            "#include <trace/events/workqueue.h>",
            "#include \"workqueue_internal.h\"",
            "#include <linux/nmi.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/nodemask.h>",
            "#include <linux/rculist.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/jhash.h>",
            "#include <linux/idr.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/freezer.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/kthread.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/slab.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/completion.h>",
            "#include <linux/signal.h>",
            "#include <linux/init.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct worker_pool [NR_STD_WORKER_POOLS], cpu_worker_pools);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/workqueue.h>\n#include \"workqueue_internal.h\"\n#include <linux/nmi.h>\n#include <linux/sched/isolation.h>\n#include <linux/uaccess.h>\n#include <linux/moduleparam.h>\n#include <linux/nodemask.h>\n#include <linux/rculist.h>\n#include <linux/hashtable.h>\n#include <linux/jhash.h>\n#include <linux/idr.h>\n#include <linux/lockdep.h>\n#include <linux/debug_locks.h>\n#include <linux/freezer.h>\n#include <linux/mempolicy.h>\n#include <linux/hardirq.h>\n#include <linux/kthread.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/workqueue.h>\n#include <linux/completion.h>\n#include <linux/signal.h>\n#include <linux/init.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/export.h>\n\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct worker_pool [NR_STD_WORKER_POOLS], cpu_worker_pools);\n\nstatic void pr_cont_pool_info(struct worker_pool *pool)\n{\n\tpr_cont(\" cpus=%*pbl\", nr_cpumask_bits, pool->attrs->cpumask);\n\tif (pool->node != NUMA_NO_NODE)\n\t\tpr_cont(\" node=%d\", pool->node);\n\tpr_cont(\" flags=0x%x nice=%d\", pool->flags, pool->attrs->nice);\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "IS_ERR(rb_hammer)"
          ],
          "line": 5052
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ERR",
          "args": [
            "rb_hammer"
          ],
          "line": 5052
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kthread_run",
          "args": [
            "rb_hammer_test",
            "NULL",
            "\"rbhammer\""
          ],
          "line": 5051
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "wake_up_process",
          "args": [
            "rb_threads[cpu]"
          ],
          "line": 5047
        },
        "resolved": true,
        "details": {
          "function_name": "wake_up_process",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/core.c",
          "lines": "2127-2130",
          "snippet": "int wake_up_process(struct task_struct *p)\n{\n\treturn try_to_wake_up(p, TASK_NORMAL, 0);\n}",
          "includes": [
            "#include \"features.h\"",
            "#include <trace/events/sched.h>",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/kcov.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include <trace/events/sched.h>\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/kcov.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n\nstatic __always_inline struct;\n\nint wake_up_process(struct task_struct *p)\n{\n\treturn try_to_wake_up(p, TASK_NORMAL, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kthread_bind",
          "args": [
            "rb_threads[cpu]",
            "cpu"
          ],
          "line": 5046
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_bind",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/kthread.c",
          "lines": "421-424",
          "snippet": "void kthread_bind(struct task_struct *p, unsigned int cpu)\n{\n\t__kthread_bind(p, cpu, TASK_UNINTERRUPTIBLE);\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <uapi/linux/sched/types.h>\n\nvoid kthread_bind(struct task_struct *p, unsigned int cpu)\n{\n\t__kthread_bind(p, cpu, TASK_UNINTERRUPTIBLE);\n}"
        }
      },
      {
        "call_info": {
          "callee": "PTR_ERR",
          "args": [
            "rb_threads[cpu]"
          ],
          "line": 5042
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "IS_ERR(rb_threads[cpu])"
          ],
          "line": 5040
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ERR",
          "args": [
            "rb_threads[cpu]"
          ],
          "line": 5040
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kthread_create",
          "args": [
            "rb_test",
            "&rb_data[cpu]",
            "\"rbtester/%d\"",
            "cpu"
          ],
          "line": 5038
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_create_worker",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/kthread.c",
          "lines": "716-727",
          "snippet": "struct kthread_worker *\nkthread_create_worker(unsigned int flags, const char namefmt[], ...)\n{\n\tstruct kthread_worker *worker;\n\tva_list args;\n\n\tva_start(args, namefmt);\n\tworker = __kthread_create_worker(-1, flags, namefmt, args);\n\tva_end(args);\n\n\treturn worker;\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __printf(4, 0)\nstruct task_struct *__kthread_create_on_node(int (*threadfn)(void *data),\n\t\t\t\t\t\t    void *data, int node,\n\t\t\t\t\t\t    const char namefmt[],\n\t\t\t\t\t\t    va_list args)\n{\n\tDECLARE_COMPLETION_ONSTACK(done);\n\tstruct task_struct *task;",
            "static __printf(3, 0) struct kthread_worker *\n__kthread_create_worker(int cpu, unsigned int flags,\n\t\t\tconst char namefmt[], va_list args)\n{\n\tstruct kthread_worker *worker;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <uapi/linux/sched/types.h>\n\nstatic __printf(4, 0)\nstruct task_struct *__kthread_create_on_node(int (*threadfn)(void *data),\n\t\t\t\t\t\t    void *data, int node,\n\t\t\t\t\t\t    const char namefmt[],\n\t\t\t\t\t\t    va_list args)\n{\n\tDECLARE_COMPLETION_ONSTACK(done);\n\tstruct task_struct *task;\nstatic __printf(3, 0) struct kthread_worker *\n__kthread_create_worker(int cpu, unsigned int flags,\n\t\t\tconst char namefmt[], va_list args)\n{\n\tstruct kthread_worker *worker;\n\nstruct kthread_worker *\nkthread_create_worker(unsigned int flags, const char namefmt[], ...)\n{\n\tstruct kthread_worker *worker;\n\tva_list args;\n\n\tva_start(args, namefmt);\n\tworker = __kthread_create_worker(-1, flags, namefmt, args);\n\tva_end(args);\n\n\treturn worker;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ring_buffer_record_off",
          "args": [
            "buffer"
          ],
          "line": 5032
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_record_off",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3186-3195",
          "snippet": "void ring_buffer_record_off(struct ring_buffer *buffer)\n{\n\tunsigned int rd;\n\tunsigned int new_rd;\n\n\tdo {\n\t\trd = atomic_read(&buffer->record_disabled);\n\t\tnew_rd = rd | RB_BUFFER_OFF;\n\t} while (atomic_cmpxchg(&buffer->record_disabled, rd, new_rd) != rd);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_BUFFER_OFF\t\t(1 << 20)"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_BUFFER_OFF\t\t(1 << 20)\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid ring_buffer_record_off(struct ring_buffer *buffer)\n{\n\tunsigned int rd;\n\tunsigned int new_rd;\n\n\tdo {\n\t\trd = atomic_read(&buffer->record_disabled);\n\t\tnew_rd = rd | RB_BUFFER_OFF;\n\t} while (atomic_cmpxchg(&buffer->record_disabled, rd, new_rd) != rd);\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "!buffer"
          ],
          "line": 5028
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ring_buffer_alloc",
          "args": [
            "RB_TEST_BUFFER_SIZE",
            "RB_FL_OVERWRITE"
          ],
          "line": 5027
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_alloc_read_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "4546-4582",
          "snippet": "void *ring_buffer_alloc_read_page(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct buffer_data_page *bpage = NULL;\n\tunsigned long flags;\n\tstruct page *page;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn ERR_PTR(-ENODEV);\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tlocal_irq_save(flags);\n\tarch_spin_lock(&cpu_buffer->lock);\n\n\tif (cpu_buffer->free_page) {\n\t\tbpage = cpu_buffer->free_page;\n\t\tcpu_buffer->free_page = NULL;\n\t}\n\n\tarch_spin_unlock(&cpu_buffer->lock);\n\tlocal_irq_restore(flags);\n\n\tif (bpage)\n\t\tgoto out;\n\n\tpage = alloc_pages_node(cpu_to_node(cpu),\n\t\t\t\tGFP_KERNEL | __GFP_NORETRY, 0);\n\tif (!page)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tbpage = page_address(page);\n\n out:\n\trb_init_page(bpage);\n\n\treturn bpage;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid *ring_buffer_alloc_read_page(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct buffer_data_page *bpage = NULL;\n\tunsigned long flags;\n\tstruct page *page;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn ERR_PTR(-ENODEV);\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tlocal_irq_save(flags);\n\tarch_spin_lock(&cpu_buffer->lock);\n\n\tif (cpu_buffer->free_page) {\n\t\tbpage = cpu_buffer->free_page;\n\t\tcpu_buffer->free_page = NULL;\n\t}\n\n\tarch_spin_unlock(&cpu_buffer->lock);\n\tlocal_irq_restore(flags);\n\n\tif (bpage)\n\t\tgoto out;\n\n\tpage = alloc_pages_node(cpu_to_node(cpu),\n\t\t\t\tGFP_KERNEL | __GFP_NORETRY, 0);\n\tif (!page)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tbpage = page_address(page);\n\n out:\n\trb_init_page(bpage);\n\n\treturn bpage;\n}"
        }
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"Running ring buffer tests...\\n\""
          ],
          "line": 5025
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_TEST_BUFFER_SIZE\t1048576\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic __init int test_ringbuffer(void)\n{\n\tstruct task_struct *rb_hammer;\n\tstruct ring_buffer *buffer;\n\tint cpu;\n\tint ret = 0;\n\n\tpr_info(\"Running ring buffer tests...\\n\");\n\n\tbuffer = ring_buffer_alloc(RB_TEST_BUFFER_SIZE, RB_FL_OVERWRITE);\n\tif (WARN_ON(!buffer))\n\t\treturn 0;\n\n\t/* Disable buffer so that threads can't write to it yet */\n\tring_buffer_record_off(buffer);\n\n\tfor_each_online_cpu(cpu) {\n\t\trb_data[cpu].buffer = buffer;\n\t\trb_data[cpu].cpu = cpu;\n\t\trb_data[cpu].cnt = cpu;\n\t\trb_threads[cpu] = kthread_create(rb_test, &rb_data[cpu],\n\t\t\t\t\t\t \"rbtester/%d\", cpu);\n\t\tif (WARN_ON(IS_ERR(rb_threads[cpu]))) {\n\t\t\tpr_cont(\"FAILED\\n\");\n\t\t\tret = PTR_ERR(rb_threads[cpu]);\n\t\t\tgoto out_free;\n\t\t}\n\n\t\tkthread_bind(rb_threads[cpu], cpu);\n \t\twake_up_process(rb_threads[cpu]);\n\t}\n\n\t/* Now create the rb hammer! */\n\trb_hammer = kthread_run(rb_hammer_test, NULL, \"rbhammer\");\n\tif (WARN_ON(IS_ERR(rb_hammer))) {\n\t\tpr_cont(\"FAILED\\n\");\n\t\tret = PTR_ERR(rb_hammer);\n\t\tgoto out_free;\n\t}\n\n\tring_buffer_record_on(buffer);\n\t/*\n\t * Show buffer is enabled before setting rb_test_started.\n\t * Yes there's a small race window where events could be\n\t * dropped and the thread wont catch it. But when a ring\n\t * buffer gets enabled, there will always be some kind of\n\t * delay before other CPUs see it. Thus, we don't care about\n\t * those dropped events. We care about events dropped after\n\t * the threads see that the buffer is active.\n\t */\n\tsmp_wmb();\n\trb_test_started = true;\n\n\tset_current_state(TASK_INTERRUPTIBLE);\n\t/* Just run for 10 seconds */;\n\tschedule_timeout(10 * HZ);\n\n\tkthread_stop(rb_hammer);\n\n out_free:\n\tfor_each_online_cpu(cpu) {\n\t\tif (!rb_threads[cpu])\n\t\t\tbreak;\n\t\tkthread_stop(rb_threads[cpu]);\n\t}\n\tif (ret) {\n\t\tring_buffer_free(buffer);\n\t\treturn ret;\n\t}\n\n\t/* Report! */\n\tpr_info(\"finished\\n\");\n\tfor_each_online_cpu(cpu) {\n\t\tstruct ring_buffer_event *event;\n\t\tstruct rb_test_data *data = &rb_data[cpu];\n\t\tstruct rb_item *item;\n\t\tunsigned long total_events;\n\t\tunsigned long total_dropped;\n\t\tunsigned long total_written;\n\t\tunsigned long total_alloc;\n\t\tunsigned long total_read = 0;\n\t\tunsigned long total_size = 0;\n\t\tunsigned long total_len = 0;\n\t\tunsigned long total_lost = 0;\n\t\tunsigned long lost;\n\t\tint big_event_size;\n\t\tint small_event_size;\n\n\t\tret = -1;\n\n\t\ttotal_events = data->events + data->events_nested;\n\t\ttotal_written = data->bytes_written + data->bytes_written_nested;\n\t\ttotal_alloc = data->bytes_alloc + data->bytes_alloc_nested;\n\t\ttotal_dropped = data->bytes_dropped + data->bytes_dropped_nested;\n\n\t\tbig_event_size = data->max_size + data->max_size_nested;\n\t\tsmall_event_size = data->min_size + data->min_size_nested;\n\n\t\tpr_info(\"CPU %d:\\n\", cpu);\n\t\tpr_info(\"              events:    %ld\\n\", total_events);\n\t\tpr_info(\"       dropped bytes:    %ld\\n\", total_dropped);\n\t\tpr_info(\"       alloced bytes:    %ld\\n\", total_alloc);\n\t\tpr_info(\"       written bytes:    %ld\\n\", total_written);\n\t\tpr_info(\"       biggest event:    %d\\n\", big_event_size);\n\t\tpr_info(\"      smallest event:    %d\\n\", small_event_size);\n\n\t\tif (RB_WARN_ON(buffer, total_dropped))\n\t\t\tbreak;\n\n\t\tret = 0;\n\n\t\twhile ((event = ring_buffer_consume(buffer, cpu, NULL, &lost))) {\n\t\t\ttotal_lost += lost;\n\t\t\titem = ring_buffer_event_data(event);\n\t\t\ttotal_len += ring_buffer_event_length(event);\n\t\t\ttotal_size += item->size + sizeof(struct rb_item);\n\t\t\tif (memcmp(&item->str[0], rb_string, item->size) != 0) {\n\t\t\t\tpr_info(\"FAILED!\\n\");\n\t\t\t\tpr_info(\"buffer had: %.*s\\n\", item->size, item->str);\n\t\t\t\tpr_info(\"expected:   %.*s\\n\", item->size, rb_string);\n\t\t\t\tRB_WARN_ON(buffer, 1);\n\t\t\t\tret = -1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\ttotal_read++;\n\t\t}\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\tret = -1;\n\n\t\tpr_info(\"         read events:   %ld\\n\", total_read);\n\t\tpr_info(\"         lost events:   %ld\\n\", total_lost);\n\t\tpr_info(\"        total events:   %ld\\n\", total_lost + total_read);\n\t\tpr_info(\"  recorded len bytes:   %ld\\n\", total_len);\n\t\tpr_info(\" recorded size bytes:   %ld\\n\", total_size);\n\t\tif (total_lost)\n\t\t\tpr_info(\" With dropped events, record len and size may not match\\n\"\n\t\t\t\t\" alloced and written from above\\n\");\n\t\tif (!total_lost) {\n\t\t\tif (RB_WARN_ON(buffer, total_len != total_alloc ||\n\t\t\t\t       total_size != total_written))\n\t\t\t\tbreak;\n\t\t}\n\t\tif (RB_WARN_ON(buffer, total_lost + total_read != total_events))\n\t\t\tbreak;\n\n\t\tret = 0;\n\t}\n\tif (!ret)\n\t\tpr_info(\"Ring buffer PASSED!\\n\");\n\n\tring_buffer_free(buffer);\n\treturn 0;\n}"
  },
  {
    "function_name": "rb_hammer_test",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "5005-5016",
    "snippet": "static __init int rb_hammer_test(void *arg)\n{\n\twhile (!kthread_should_stop()) {\n\n\t\t/* Send an IPI to all cpus to write data! */\n\t\tsmp_call_function(rb_ipi, NULL, 1);\n\t\t/* No sleep, but for non preempt, let others run */\n\t\tschedule();\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "schedule",
          "args": [],
          "line": 5012
        },
        "resolved": true,
        "details": {
          "function_name": "audit_schedule_prune",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/audit_tree.c",
          "lines": "919-922",
          "snippet": "static void audit_schedule_prune(void)\n{\n\twake_up_process(prune_thread);\n}",
          "includes": [
            "#include <linux/slab.h>",
            "#include <linux/refcount.h>",
            "#include <linux/kthread.h>",
            "#include <linux/mount.h>",
            "#include <linux/namei.h>",
            "#include <linux/fsnotify_backend.h>",
            "#include \"audit.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static struct task_struct *prune_thread;",
            "static void audit_schedule_prune(void);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/slab.h>\n#include <linux/refcount.h>\n#include <linux/kthread.h>\n#include <linux/mount.h>\n#include <linux/namei.h>\n#include <linux/fsnotify_backend.h>\n#include \"audit.h\"\n\nstatic struct task_struct *prune_thread;\nstatic void audit_schedule_prune(void);\n\nstatic void audit_schedule_prune(void)\n{\n\twake_up_process(prune_thread);\n}"
        }
      },
      {
        "call_info": {
          "callee": "smp_call_function",
          "args": [
            "rb_ipi",
            "NULL",
            "1"
          ],
          "line": 5010
        },
        "resolved": true,
        "details": {
          "function_name": "smp_call_function",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/smp.c",
          "lines": "489-496",
          "snippet": "int smp_call_function(smp_call_func_t func, void *info, int wait)\n{\n\tpreempt_disable();\n\tsmp_call_function_many(cpu_online_mask, func, info, wait);\n\tpreempt_enable();\n\n\treturn 0;\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <linux/hypervisor.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched.h>",
            "#include <linux/cpu.h>",
            "#include <linux/smp.h>",
            "#include <linux/gfp.h>",
            "#include <linux/init.h>",
            "#include <linux/percpu.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/rculist.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/irq_work.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <linux/hypervisor.h>\n#include <linux/sched/idle.h>\n#include <linux/sched.h>\n#include <linux/cpu.h>\n#include <linux/smp.h>\n#include <linux/gfp.h>\n#include <linux/init.h>\n#include <linux/percpu.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/rculist.h>\n#include <linux/rcupdate.h>\n#include <linux/irq_work.h>\n\nint smp_call_function(smp_call_func_t func, void *info, int wait)\n{\n\tpreempt_disable();\n\tsmp_call_function_many(cpu_online_mask, func, info, wait);\n\tpreempt_enable();\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kthread_should_stop",
          "args": [],
          "line": 5007
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_should_stop",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/kthread.c",
          "lines": "98-101",
          "snippet": "bool kthread_should_stop(void)\n{\n\treturn test_bit(KTHREAD_SHOULD_STOP, &to_kthread(current)->flags);\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <uapi/linux/sched/types.h>\n\nbool kthread_should_stop(void)\n{\n\treturn test_bit(KTHREAD_SHOULD_STOP, &to_kthread(current)->flags);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __init int rb_hammer_test(void *arg)\n{\n\twhile (!kthread_should_stop()) {\n\n\t\t/* Send an IPI to all cpus to write data! */\n\t\tsmp_call_function(rb_ipi, NULL, 1);\n\t\t/* No sleep, but for non preempt, let others run */\n\t\tschedule();\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "rb_ipi",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "4996-5003",
    "snippet": "static __init void rb_ipi(void *ignore)\n{\n\tstruct rb_test_data *data;\n\tint cpu = smp_processor_id();\n\n\tdata = &rb_data[cpu];\n\trb_write_something(data, true);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_write_something",
          "args": [
            "data",
            "true"
          ],
          "line": 5002
        },
        "resolved": true,
        "details": {
          "function_name": "rb_write_something",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "4913-4978",
          "snippet": "static __init int rb_write_something(struct rb_test_data *data, bool nested)\n{\n\tstruct ring_buffer_event *event;\n\tstruct rb_item *item;\n\tbool started;\n\tint event_len;\n\tint size;\n\tint len;\n\tint cnt;\n\n\t/* Have nested writes different that what is written */\n\tcnt = data->cnt + (nested ? 27 : 0);\n\n\t/* Multiply cnt by ~e, to make some unique increment */\n\tsize = (data->cnt * 68 / 25) % (sizeof(rb_string) - 1);\n\n\tlen = size + sizeof(struct rb_item);\n\n\tstarted = rb_test_started;\n\t/* read rb_test_started before checking buffer enabled */\n\tsmp_rmb();\n\n\tevent = ring_buffer_lock_reserve(data->buffer, len);\n\tif (!event) {\n\t\t/* Ignore dropped events before test starts. */\n\t\tif (started) {\n\t\t\tif (nested)\n\t\t\t\tdata->bytes_dropped += len;\n\t\t\telse\n\t\t\t\tdata->bytes_dropped_nested += len;\n\t\t}\n\t\treturn len;\n\t}\n\n\tevent_len = ring_buffer_event_length(event);\n\n\tif (RB_WARN_ON(data->buffer, event_len < len))\n\t\tgoto out;\n\n\titem = ring_buffer_event_data(event);\n\titem->size = size;\n\tmemcpy(item->str, rb_string, size);\n\n\tif (nested) {\n\t\tdata->bytes_alloc_nested += event_len;\n\t\tdata->bytes_written_nested += len;\n\t\tdata->events_nested++;\n\t\tif (!data->min_size_nested || len < data->min_size_nested)\n\t\t\tdata->min_size_nested = len;\n\t\tif (len > data->max_size_nested)\n\t\t\tdata->max_size_nested = len;\n\t} else {\n\t\tdata->bytes_alloc += event_len;\n\t\tdata->bytes_written += len;\n\t\tdata->events++;\n\t\tif (!data->min_size || len < data->min_size)\n\t\t\tdata->max_size = len;\n\t\tif (len > data->max_size)\n\t\t\tdata->max_size = len;\n\t}\n\n out:\n\tring_buffer_unlock_commit(data->buffer, event);\n\n\treturn 0;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic __init int rb_write_something(struct rb_test_data *data, bool nested)\n{\n\tstruct ring_buffer_event *event;\n\tstruct rb_item *item;\n\tbool started;\n\tint event_len;\n\tint size;\n\tint len;\n\tint cnt;\n\n\t/* Have nested writes different that what is written */\n\tcnt = data->cnt + (nested ? 27 : 0);\n\n\t/* Multiply cnt by ~e, to make some unique increment */\n\tsize = (data->cnt * 68 / 25) % (sizeof(rb_string) - 1);\n\n\tlen = size + sizeof(struct rb_item);\n\n\tstarted = rb_test_started;\n\t/* read rb_test_started before checking buffer enabled */\n\tsmp_rmb();\n\n\tevent = ring_buffer_lock_reserve(data->buffer, len);\n\tif (!event) {\n\t\t/* Ignore dropped events before test starts. */\n\t\tif (started) {\n\t\t\tif (nested)\n\t\t\t\tdata->bytes_dropped += len;\n\t\t\telse\n\t\t\t\tdata->bytes_dropped_nested += len;\n\t\t}\n\t\treturn len;\n\t}\n\n\tevent_len = ring_buffer_event_length(event);\n\n\tif (RB_WARN_ON(data->buffer, event_len < len))\n\t\tgoto out;\n\n\titem = ring_buffer_event_data(event);\n\titem->size = size;\n\tmemcpy(item->str, rb_string, size);\n\n\tif (nested) {\n\t\tdata->bytes_alloc_nested += event_len;\n\t\tdata->bytes_written_nested += len;\n\t\tdata->events_nested++;\n\t\tif (!data->min_size_nested || len < data->min_size_nested)\n\t\t\tdata->min_size_nested = len;\n\t\tif (len > data->max_size_nested)\n\t\t\tdata->max_size_nested = len;\n\t} else {\n\t\tdata->bytes_alloc += event_len;\n\t\tdata->bytes_written += len;\n\t\tdata->events++;\n\t\tif (!data->min_size || len < data->min_size)\n\t\t\tdata->max_size = len;\n\t\tif (len > data->max_size)\n\t\t\tdata->max_size = len;\n\t}\n\n out:\n\tring_buffer_unlock_commit(data->buffer, event);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "smp_processor_id",
          "args": [],
          "line": 4999
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __init void rb_ipi(void *ignore)\n{\n\tstruct rb_test_data *data;\n\tint cpu = smp_processor_id();\n\n\tdata = &rb_data[cpu];\n\trb_write_something(data, true);\n}"
  },
  {
    "function_name": "rb_test",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "4980-4994",
    "snippet": "static __init int rb_test(void *arg)\n{\n\tstruct rb_test_data *data = arg;\n\n\twhile (!kthread_should_stop()) {\n\t\trb_write_something(data, false);\n\t\tdata->cnt++;\n\n\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\t/* Now sleep between a min of 100-300us and a max of 1ms */\n\t\tusleep_range(((data->cnt % 3) + 1) * 100, 1000);\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "usleep_range",
          "args": [
            "((data->cnt % 3) + 1) * 100",
            "1000"
          ],
          "line": 4990
        },
        "resolved": true,
        "details": {
          "function_name": "usleep_range",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/time/timer.c",
          "lines": "1987-1998",
          "snippet": "void __sched usleep_range(unsigned long min, unsigned long max)\n{\n\tktime_t exp = ktime_add_us(ktime_get(), min);\n\tu64 delta = (u64)(max - min) * NSEC_PER_USEC;\n\n\tfor (;;) {\n\t\t__set_current_state(TASK_UNINTERRUPTIBLE);\n\t\t/* Do not return before the requested sleep time has elapsed */\n\t\tif (!schedule_hrtimeout_range(&exp, delta, HRTIMER_MODE_ABS))\n\t\t\tbreak;\n\t}\n}",
          "includes": [
            "#include <trace/events/timer.h>",
            "#include \"tick-internal.h\"",
            "#include <asm/io.h>",
            "#include <asm/timex.h>",
            "#include <asm/div64.h>",
            "#include <asm/unistd.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/compat.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/tick.h>",
            "#include <linux/delay.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/cpu.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/time.h>",
            "#include <linux/thread_info.h>",
            "#include <linux/notifier.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/swap.h>",
            "#include <linux/mm.h>",
            "#include <linux/init.h>",
            "#include <linux/percpu.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel_stat.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "__visible u64"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/timer.h>\n#include \"tick-internal.h\"\n#include <asm/io.h>\n#include <asm/timex.h>\n#include <asm/div64.h>\n#include <asm/unistd.h>\n#include <linux/uaccess.h>\n#include <linux/compat.h>\n#include <linux/slab.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/signal.h>\n#include <linux/irq_work.h>\n#include <linux/kallsyms.h>\n#include <linux/tick.h>\n#include <linux/delay.h>\n#include <linux/syscalls.h>\n#include <linux/cpu.h>\n#include <linux/posix-timers.h>\n#include <linux/jiffies.h>\n#include <linux/time.h>\n#include <linux/thread_info.h>\n#include <linux/notifier.h>\n#include <linux/pid_namespace.h>\n#include <linux/swap.h>\n#include <linux/mm.h>\n#include <linux/init.h>\n#include <linux/percpu.h>\n#include <linux/interrupt.h>\n#include <linux/export.h>\n#include <linux/kernel_stat.h>\n\n__visible u64;\n\nvoid __sched usleep_range(unsigned long min, unsigned long max)\n{\n\tktime_t exp = ktime_add_us(ktime_get(), min);\n\tu64 delta = (u64)(max - min) * NSEC_PER_USEC;\n\n\tfor (;;) {\n\t\t__set_current_state(TASK_UNINTERRUPTIBLE);\n\t\t/* Do not return before the requested sleep time has elapsed */\n\t\tif (!schedule_hrtimeout_range(&exp, delta, HRTIMER_MODE_ABS))\n\t\t\tbreak;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "set_current_state",
          "args": [
            "TASK_INTERRUPTIBLE"
          ],
          "line": 4988
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_write_something",
          "args": [
            "data",
            "false"
          ],
          "line": 4985
        },
        "resolved": true,
        "details": {
          "function_name": "rb_write_something",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "4913-4978",
          "snippet": "static __init int rb_write_something(struct rb_test_data *data, bool nested)\n{\n\tstruct ring_buffer_event *event;\n\tstruct rb_item *item;\n\tbool started;\n\tint event_len;\n\tint size;\n\tint len;\n\tint cnt;\n\n\t/* Have nested writes different that what is written */\n\tcnt = data->cnt + (nested ? 27 : 0);\n\n\t/* Multiply cnt by ~e, to make some unique increment */\n\tsize = (data->cnt * 68 / 25) % (sizeof(rb_string) - 1);\n\n\tlen = size + sizeof(struct rb_item);\n\n\tstarted = rb_test_started;\n\t/* read rb_test_started before checking buffer enabled */\n\tsmp_rmb();\n\n\tevent = ring_buffer_lock_reserve(data->buffer, len);\n\tif (!event) {\n\t\t/* Ignore dropped events before test starts. */\n\t\tif (started) {\n\t\t\tif (nested)\n\t\t\t\tdata->bytes_dropped += len;\n\t\t\telse\n\t\t\t\tdata->bytes_dropped_nested += len;\n\t\t}\n\t\treturn len;\n\t}\n\n\tevent_len = ring_buffer_event_length(event);\n\n\tif (RB_WARN_ON(data->buffer, event_len < len))\n\t\tgoto out;\n\n\titem = ring_buffer_event_data(event);\n\titem->size = size;\n\tmemcpy(item->str, rb_string, size);\n\n\tif (nested) {\n\t\tdata->bytes_alloc_nested += event_len;\n\t\tdata->bytes_written_nested += len;\n\t\tdata->events_nested++;\n\t\tif (!data->min_size_nested || len < data->min_size_nested)\n\t\t\tdata->min_size_nested = len;\n\t\tif (len > data->max_size_nested)\n\t\t\tdata->max_size_nested = len;\n\t} else {\n\t\tdata->bytes_alloc += event_len;\n\t\tdata->bytes_written += len;\n\t\tdata->events++;\n\t\tif (!data->min_size || len < data->min_size)\n\t\t\tdata->max_size = len;\n\t\tif (len > data->max_size)\n\t\t\tdata->max_size = len;\n\t}\n\n out:\n\tring_buffer_unlock_commit(data->buffer, event);\n\n\treturn 0;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic __init int rb_write_something(struct rb_test_data *data, bool nested)\n{\n\tstruct ring_buffer_event *event;\n\tstruct rb_item *item;\n\tbool started;\n\tint event_len;\n\tint size;\n\tint len;\n\tint cnt;\n\n\t/* Have nested writes different that what is written */\n\tcnt = data->cnt + (nested ? 27 : 0);\n\n\t/* Multiply cnt by ~e, to make some unique increment */\n\tsize = (data->cnt * 68 / 25) % (sizeof(rb_string) - 1);\n\n\tlen = size + sizeof(struct rb_item);\n\n\tstarted = rb_test_started;\n\t/* read rb_test_started before checking buffer enabled */\n\tsmp_rmb();\n\n\tevent = ring_buffer_lock_reserve(data->buffer, len);\n\tif (!event) {\n\t\t/* Ignore dropped events before test starts. */\n\t\tif (started) {\n\t\t\tif (nested)\n\t\t\t\tdata->bytes_dropped += len;\n\t\t\telse\n\t\t\t\tdata->bytes_dropped_nested += len;\n\t\t}\n\t\treturn len;\n\t}\n\n\tevent_len = ring_buffer_event_length(event);\n\n\tif (RB_WARN_ON(data->buffer, event_len < len))\n\t\tgoto out;\n\n\titem = ring_buffer_event_data(event);\n\titem->size = size;\n\tmemcpy(item->str, rb_string, size);\n\n\tif (nested) {\n\t\tdata->bytes_alloc_nested += event_len;\n\t\tdata->bytes_written_nested += len;\n\t\tdata->events_nested++;\n\t\tif (!data->min_size_nested || len < data->min_size_nested)\n\t\t\tdata->min_size_nested = len;\n\t\tif (len > data->max_size_nested)\n\t\t\tdata->max_size_nested = len;\n\t} else {\n\t\tdata->bytes_alloc += event_len;\n\t\tdata->bytes_written += len;\n\t\tdata->events++;\n\t\tif (!data->min_size || len < data->min_size)\n\t\t\tdata->max_size = len;\n\t\tif (len > data->max_size)\n\t\t\tdata->max_size = len;\n\t}\n\n out:\n\tring_buffer_unlock_commit(data->buffer, event);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kthread_should_stop",
          "args": [],
          "line": 4984
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_should_stop",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/kthread.c",
          "lines": "98-101",
          "snippet": "bool kthread_should_stop(void)\n{\n\treturn test_bit(KTHREAD_SHOULD_STOP, &to_kthread(current)->flags);\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <uapi/linux/sched/types.h>\n\nbool kthread_should_stop(void)\n{\n\treturn test_bit(KTHREAD_SHOULD_STOP, &to_kthread(current)->flags);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __init int rb_test(void *arg)\n{\n\tstruct rb_test_data *data = arg;\n\n\twhile (!kthread_should_stop()) {\n\t\trb_write_something(data, false);\n\t\tdata->cnt++;\n\n\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\t/* Now sleep between a min of 100-300us and a max of 1ms */\n\t\tusleep_range(((data->cnt % 3) + 1) * 100, 1000);\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "rb_write_something",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "4913-4978",
    "snippet": "static __init int rb_write_something(struct rb_test_data *data, bool nested)\n{\n\tstruct ring_buffer_event *event;\n\tstruct rb_item *item;\n\tbool started;\n\tint event_len;\n\tint size;\n\tint len;\n\tint cnt;\n\n\t/* Have nested writes different that what is written */\n\tcnt = data->cnt + (nested ? 27 : 0);\n\n\t/* Multiply cnt by ~e, to make some unique increment */\n\tsize = (data->cnt * 68 / 25) % (sizeof(rb_string) - 1);\n\n\tlen = size + sizeof(struct rb_item);\n\n\tstarted = rb_test_started;\n\t/* read rb_test_started before checking buffer enabled */\n\tsmp_rmb();\n\n\tevent = ring_buffer_lock_reserve(data->buffer, len);\n\tif (!event) {\n\t\t/* Ignore dropped events before test starts. */\n\t\tif (started) {\n\t\t\tif (nested)\n\t\t\t\tdata->bytes_dropped += len;\n\t\t\telse\n\t\t\t\tdata->bytes_dropped_nested += len;\n\t\t}\n\t\treturn len;\n\t}\n\n\tevent_len = ring_buffer_event_length(event);\n\n\tif (RB_WARN_ON(data->buffer, event_len < len))\n\t\tgoto out;\n\n\titem = ring_buffer_event_data(event);\n\titem->size = size;\n\tmemcpy(item->str, rb_string, size);\n\n\tif (nested) {\n\t\tdata->bytes_alloc_nested += event_len;\n\t\tdata->bytes_written_nested += len;\n\t\tdata->events_nested++;\n\t\tif (!data->min_size_nested || len < data->min_size_nested)\n\t\t\tdata->min_size_nested = len;\n\t\tif (len > data->max_size_nested)\n\t\t\tdata->max_size_nested = len;\n\t} else {\n\t\tdata->bytes_alloc += event_len;\n\t\tdata->bytes_written += len;\n\t\tdata->events++;\n\t\tif (!data->min_size || len < data->min_size)\n\t\t\tdata->max_size = len;\n\t\tif (len > data->max_size)\n\t\t\tdata->max_size = len;\n\t}\n\n out:\n\tring_buffer_unlock_commit(data->buffer, event);\n\n\treturn 0;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "ring_buffer_unlock_commit",
          "args": [
            "data->buffer",
            "event"
          ],
          "line": 4975
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_unlock_commit",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2738-2755",
          "snippet": "int ring_buffer_unlock_commit(struct ring_buffer *buffer,\n\t\t\t      struct ring_buffer_event *event)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tint cpu = raw_smp_processor_id();\n\n\tcpu_buffer = buffer->buffers[cpu];\n\n\trb_commit(cpu_buffer, event);\n\n\trb_wakeups(buffer, cpu_buffer);\n\n\ttrace_recursive_unlock(cpu_buffer);\n\n\tpreempt_enable_notrace();\n\n\treturn 0;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nint ring_buffer_unlock_commit(struct ring_buffer *buffer,\n\t\t\t      struct ring_buffer_event *event)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tint cpu = raw_smp_processor_id();\n\n\tcpu_buffer = buffer->buffers[cpu];\n\n\trb_commit(cpu_buffer, event);\n\n\trb_wakeups(buffer, cpu_buffer);\n\n\ttrace_recursive_unlock(cpu_buffer);\n\n\tpreempt_enable_notrace();\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "memcpy",
          "args": [
            "item->str",
            "rb_string",
            "size"
          ],
          "line": 4954
        },
        "resolved": true,
        "details": {
          "function_name": "memcpy_skip",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/events/internal.h",
          "lines": "178-182",
          "snippet": "static inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}",
          "includes": [
            "#include <linux/uaccess.h>",
            "#include <linux/hardirq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/uaccess.h>\n#include <linux/hardirq.h>\n\nstatic inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ring_buffer_event_data",
          "args": [
            "event"
          ],
          "line": 4952
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_event_data",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "272-275",
          "snippet": "void *ring_buffer_event_data(struct ring_buffer_event *event)\n{\n\treturn rb_event_data(event);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nvoid *ring_buffer_event_data(struct ring_buffer_event *event)\n{\n\treturn rb_event_data(event);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "data->buffer",
            "event_len < len"
          ],
          "line": 4949
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ring_buffer_event_length",
          "args": [
            "event"
          ],
          "line": 4947
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_event_length",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "237-251",
          "snippet": "unsigned ring_buffer_event_length(struct ring_buffer_event *event)\n{\n\tunsigned length;\n\n\tif (extended_time(event))\n\t\tevent = skip_time_extend(event);\n\n\tlength = rb_event_length(event);\n\tif (event->type_len > RINGBUF_TYPE_DATA_TYPE_LEN_MAX)\n\t\treturn length;\n\tlength -= RB_EVNT_HDR_SIZE;\n\tif (length > RB_MAX_SMALL_DATA + sizeof(event->array[0]))\n                length -= sizeof(event->array[0]);\n\treturn length;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_MAX_SMALL_DATA\t(RB_ALIGNMENT * RINGBUF_TYPE_DATA_TYPE_LEN_MAX)",
            "#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_MAX_SMALL_DATA\t(RB_ALIGNMENT * RINGBUF_TYPE_DATA_TYPE_LEN_MAX)\n#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nunsigned ring_buffer_event_length(struct ring_buffer_event *event)\n{\n\tunsigned length;\n\n\tif (extended_time(event))\n\t\tevent = skip_time_extend(event);\n\n\tlength = rb_event_length(event);\n\tif (event->type_len > RINGBUF_TYPE_DATA_TYPE_LEN_MAX)\n\t\treturn length;\n\tlength -= RB_EVNT_HDR_SIZE;\n\tif (length > RB_MAX_SMALL_DATA + sizeof(event->array[0]))\n                length -= sizeof(event->array[0]);\n\treturn length;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ring_buffer_lock_reserve",
          "args": [
            "data->buffer",
            "len"
          ],
          "line": 4935
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_lock_reserve",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2923-2963",
          "snippet": "struct ring_buffer_event *\nring_buffer_lock_reserve(struct ring_buffer *buffer, unsigned long length)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct ring_buffer_event *event;\n\tint cpu;\n\n\t/* If we are tracing schedule, we don't want to recurse */\n\tpreempt_disable_notrace();\n\n\tif (unlikely(atomic_read(&buffer->record_disabled)))\n\t\tgoto out;\n\n\tcpu = raw_smp_processor_id();\n\n\tif (unlikely(!cpumask_test_cpu(cpu, buffer->cpumask)))\n\t\tgoto out;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\n\tif (unlikely(atomic_read(&cpu_buffer->record_disabled)))\n\t\tgoto out;\n\n\tif (unlikely(length > BUF_MAX_DATA_SIZE))\n\t\tgoto out;\n\n\tif (unlikely(trace_recursive_lock(cpu_buffer)))\n\t\tgoto out;\n\n\tevent = rb_reserve_next_event(buffer, cpu_buffer, length);\n\tif (!event)\n\t\tgoto out_unlock;\n\n\treturn event;\n\n out_unlock:\n\ttrace_recursive_unlock(cpu_buffer);\n out:\n\tpreempt_enable_notrace();\n\treturn NULL;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define BUF_MAX_DATA_SIZE (BUF_PAGE_SIZE - (sizeof(u32) * 2))"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define BUF_MAX_DATA_SIZE (BUF_PAGE_SIZE - (sizeof(u32) * 2))\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstruct ring_buffer_event *\nring_buffer_lock_reserve(struct ring_buffer *buffer, unsigned long length)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct ring_buffer_event *event;\n\tint cpu;\n\n\t/* If we are tracing schedule, we don't want to recurse */\n\tpreempt_disable_notrace();\n\n\tif (unlikely(atomic_read(&buffer->record_disabled)))\n\t\tgoto out;\n\n\tcpu = raw_smp_processor_id();\n\n\tif (unlikely(!cpumask_test_cpu(cpu, buffer->cpumask)))\n\t\tgoto out;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\n\tif (unlikely(atomic_read(&cpu_buffer->record_disabled)))\n\t\tgoto out;\n\n\tif (unlikely(length > BUF_MAX_DATA_SIZE))\n\t\tgoto out;\n\n\tif (unlikely(trace_recursive_lock(cpu_buffer)))\n\t\tgoto out;\n\n\tevent = rb_reserve_next_event(buffer, cpu_buffer, length);\n\tif (!event)\n\t\tgoto out_unlock;\n\n\treturn event;\n\n out_unlock:\n\ttrace_recursive_unlock(cpu_buffer);\n out:\n\tpreempt_enable_notrace();\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "smp_rmb",
          "args": [],
          "line": 4933
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic __init int rb_write_something(struct rb_test_data *data, bool nested)\n{\n\tstruct ring_buffer_event *event;\n\tstruct rb_item *item;\n\tbool started;\n\tint event_len;\n\tint size;\n\tint len;\n\tint cnt;\n\n\t/* Have nested writes different that what is written */\n\tcnt = data->cnt + (nested ? 27 : 0);\n\n\t/* Multiply cnt by ~e, to make some unique increment */\n\tsize = (data->cnt * 68 / 25) % (sizeof(rb_string) - 1);\n\n\tlen = size + sizeof(struct rb_item);\n\n\tstarted = rb_test_started;\n\t/* read rb_test_started before checking buffer enabled */\n\tsmp_rmb();\n\n\tevent = ring_buffer_lock_reserve(data->buffer, len);\n\tif (!event) {\n\t\t/* Ignore dropped events before test starts. */\n\t\tif (started) {\n\t\t\tif (nested)\n\t\t\t\tdata->bytes_dropped += len;\n\t\t\telse\n\t\t\t\tdata->bytes_dropped_nested += len;\n\t\t}\n\t\treturn len;\n\t}\n\n\tevent_len = ring_buffer_event_length(event);\n\n\tif (RB_WARN_ON(data->buffer, event_len < len))\n\t\tgoto out;\n\n\titem = ring_buffer_event_data(event);\n\titem->size = size;\n\tmemcpy(item->str, rb_string, size);\n\n\tif (nested) {\n\t\tdata->bytes_alloc_nested += event_len;\n\t\tdata->bytes_written_nested += len;\n\t\tdata->events_nested++;\n\t\tif (!data->min_size_nested || len < data->min_size_nested)\n\t\t\tdata->min_size_nested = len;\n\t\tif (len > data->max_size_nested)\n\t\t\tdata->max_size_nested = len;\n\t} else {\n\t\tdata->bytes_alloc += event_len;\n\t\tdata->bytes_written += len;\n\t\tdata->events++;\n\t\tif (!data->min_size || len < data->min_size)\n\t\t\tdata->max_size = len;\n\t\tif (len > data->max_size)\n\t\t\tdata->max_size = len;\n\t}\n\n out:\n\tring_buffer_unlock_commit(data->buffer, event);\n\n\treturn 0;\n}"
  },
  {
    "function_name": "trace_rb_cpu_prepare",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "4822-4858",
    "snippet": "int trace_rb_cpu_prepare(unsigned int cpu, struct hlist_node *node)\n{\n\tstruct ring_buffer *buffer;\n\tlong nr_pages_same;\n\tint cpu_i;\n\tunsigned long nr_pages;\n\n\tbuffer = container_of(node, struct ring_buffer, node);\n\tif (cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn 0;\n\n\tnr_pages = 0;\n\tnr_pages_same = 1;\n\t/* check if all cpu sizes are same */\n\tfor_each_buffer_cpu(buffer, cpu_i) {\n\t\t/* fill in the size from first enabled cpu */\n\t\tif (nr_pages == 0)\n\t\t\tnr_pages = buffer->buffers[cpu_i]->nr_pages;\n\t\tif (nr_pages != buffer->buffers[cpu_i]->nr_pages) {\n\t\t\tnr_pages_same = 0;\n\t\t\tbreak;\n\t\t}\n\t}\n\t/* allocate minimum pages, user can later expand it */\n\tif (!nr_pages_same)\n\t\tnr_pages = 2;\n\tbuffer->buffers[cpu] =\n\t\trb_allocate_cpu_buffer(buffer, nr_pages, cpu);\n\tif (!buffer->buffers[cpu]) {\n\t\tWARN(1, \"failed to allocate ring buffer on CPU %u\\n\",\n\t\t     cpu);\n\t\treturn -ENOMEM;\n\t}\n\tsmp_wmb();\n\tcpumask_set_cpu(cpu, buffer->cpumask);\n\treturn 0;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpumask_set_cpu",
          "args": [
            "cpu",
            "buffer->cpumask"
          ],
          "line": 4856
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_wmb",
          "args": [],
          "line": 4855
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN",
          "args": [
            "1",
            "\"failed to allocate ring buffer on CPU %u\\n\"",
            "cpu"
          ],
          "line": 4851
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_allocate_cpu_buffer",
          "args": [
            "buffer",
            "nr_pages",
            "cpu"
          ],
          "line": 4849
        },
        "resolved": true,
        "details": {
          "function_name": "rb_allocate_cpu_buffer",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1260-1319",
          "snippet": "static struct ring_buffer_per_cpu *\nrb_allocate_cpu_buffer(struct ring_buffer *buffer, long nr_pages, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct buffer_page *bpage;\n\tstruct page *page;\n\tint ret;\n\n\tcpu_buffer = kzalloc_node(ALIGN(sizeof(*cpu_buffer), cache_line_size()),\n\t\t\t\t  GFP_KERNEL, cpu_to_node(cpu));\n\tif (!cpu_buffer)\n\t\treturn NULL;\n\n\tcpu_buffer->cpu = cpu;\n\tcpu_buffer->buffer = buffer;\n\traw_spin_lock_init(&cpu_buffer->reader_lock);\n\tlockdep_set_class(&cpu_buffer->reader_lock, buffer->reader_lock_key);\n\tcpu_buffer->lock = (arch_spinlock_t)__ARCH_SPIN_LOCK_UNLOCKED;\n\tINIT_WORK(&cpu_buffer->update_pages_work, update_pages_handler);\n\tinit_completion(&cpu_buffer->update_done);\n\tinit_irq_work(&cpu_buffer->irq_work.work, rb_wake_up_waiters);\n\tinit_waitqueue_head(&cpu_buffer->irq_work.waiters);\n\tinit_waitqueue_head(&cpu_buffer->irq_work.full_waiters);\n\n\tbpage = kzalloc_node(ALIGN(sizeof(*bpage), cache_line_size()),\n\t\t\t    GFP_KERNEL, cpu_to_node(cpu));\n\tif (!bpage)\n\t\tgoto fail_free_buffer;\n\n\trb_check_bpage(cpu_buffer, bpage);\n\n\tcpu_buffer->reader_page = bpage;\n\tpage = alloc_pages_node(cpu_to_node(cpu), GFP_KERNEL, 0);\n\tif (!page)\n\t\tgoto fail_free_reader;\n\tbpage->page = page_address(page);\n\trb_init_page(bpage->page);\n\n\tINIT_LIST_HEAD(&cpu_buffer->reader_page->list);\n\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\n\tret = rb_allocate_pages(cpu_buffer, nr_pages);\n\tif (ret < 0)\n\t\tgoto fail_free_reader;\n\n\tcpu_buffer->head_page\n\t\t= list_entry(cpu_buffer->pages, struct buffer_page, list);\n\tcpu_buffer->tail_page = cpu_buffer->commit_page = cpu_buffer->head_page;\n\n\trb_head_page_activate(cpu_buffer);\n\n\treturn cpu_buffer;\n\n fail_free_reader:\n\tfree_buffer_page(cpu_buffer->reader_page);\n\n fail_free_buffer:\n\tkfree(cpu_buffer);\n\treturn NULL;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void update_pages_handler(struct work_struct *work);",
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void update_pages_handler(struct work_struct *work);\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic struct ring_buffer_per_cpu *\nrb_allocate_cpu_buffer(struct ring_buffer *buffer, long nr_pages, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct buffer_page *bpage;\n\tstruct page *page;\n\tint ret;\n\n\tcpu_buffer = kzalloc_node(ALIGN(sizeof(*cpu_buffer), cache_line_size()),\n\t\t\t\t  GFP_KERNEL, cpu_to_node(cpu));\n\tif (!cpu_buffer)\n\t\treturn NULL;\n\n\tcpu_buffer->cpu = cpu;\n\tcpu_buffer->buffer = buffer;\n\traw_spin_lock_init(&cpu_buffer->reader_lock);\n\tlockdep_set_class(&cpu_buffer->reader_lock, buffer->reader_lock_key);\n\tcpu_buffer->lock = (arch_spinlock_t)__ARCH_SPIN_LOCK_UNLOCKED;\n\tINIT_WORK(&cpu_buffer->update_pages_work, update_pages_handler);\n\tinit_completion(&cpu_buffer->update_done);\n\tinit_irq_work(&cpu_buffer->irq_work.work, rb_wake_up_waiters);\n\tinit_waitqueue_head(&cpu_buffer->irq_work.waiters);\n\tinit_waitqueue_head(&cpu_buffer->irq_work.full_waiters);\n\n\tbpage = kzalloc_node(ALIGN(sizeof(*bpage), cache_line_size()),\n\t\t\t    GFP_KERNEL, cpu_to_node(cpu));\n\tif (!bpage)\n\t\tgoto fail_free_buffer;\n\n\trb_check_bpage(cpu_buffer, bpage);\n\n\tcpu_buffer->reader_page = bpage;\n\tpage = alloc_pages_node(cpu_to_node(cpu), GFP_KERNEL, 0);\n\tif (!page)\n\t\tgoto fail_free_reader;\n\tbpage->page = page_address(page);\n\trb_init_page(bpage->page);\n\n\tINIT_LIST_HEAD(&cpu_buffer->reader_page->list);\n\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\n\tret = rb_allocate_pages(cpu_buffer, nr_pages);\n\tif (ret < 0)\n\t\tgoto fail_free_reader;\n\n\tcpu_buffer->head_page\n\t\t= list_entry(cpu_buffer->pages, struct buffer_page, list);\n\tcpu_buffer->tail_page = cpu_buffer->commit_page = cpu_buffer->head_page;\n\n\trb_head_page_activate(cpu_buffer);\n\n\treturn cpu_buffer;\n\n fail_free_reader:\n\tfree_buffer_page(cpu_buffer->reader_page);\n\n fail_free_buffer:\n\tkfree(cpu_buffer);\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "for_each_buffer_cpu",
          "args": [
            "buffer",
            "cpu_i"
          ],
          "line": 4836
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "buffer->cpumask"
          ],
          "line": 4830
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "node",
            "structring_buffer",
            "node"
          ],
          "line": 4829
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nint trace_rb_cpu_prepare(unsigned int cpu, struct hlist_node *node)\n{\n\tstruct ring_buffer *buffer;\n\tlong nr_pages_same;\n\tint cpu_i;\n\tunsigned long nr_pages;\n\n\tbuffer = container_of(node, struct ring_buffer, node);\n\tif (cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn 0;\n\n\tnr_pages = 0;\n\tnr_pages_same = 1;\n\t/* check if all cpu sizes are same */\n\tfor_each_buffer_cpu(buffer, cpu_i) {\n\t\t/* fill in the size from first enabled cpu */\n\t\tif (nr_pages == 0)\n\t\t\tnr_pages = buffer->buffers[cpu_i]->nr_pages;\n\t\tif (nr_pages != buffer->buffers[cpu_i]->nr_pages) {\n\t\t\tnr_pages_same = 0;\n\t\t\tbreak;\n\t\t}\n\t}\n\t/* allocate minimum pages, user can later expand it */\n\tif (!nr_pages_same)\n\t\tnr_pages = 2;\n\tbuffer->buffers[cpu] =\n\t\trb_allocate_cpu_buffer(buffer, nr_pages, cpu);\n\tif (!buffer->buffers[cpu]) {\n\t\tWARN(1, \"failed to allocate ring buffer on CPU %u\\n\",\n\t\t     cpu);\n\t\treturn -ENOMEM;\n\t}\n\tsmp_wmb();\n\tcpumask_set_cpu(cpu, buffer->cpumask);\n\treturn 0;\n}"
  },
  {
    "function_name": "ring_buffer_read_page",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "4653-4814",
    "snippet": "int ring_buffer_read_page(struct ring_buffer *buffer,\n\t\t\t  void **data_page, size_t len, int cpu, int full)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = buffer->buffers[cpu];\n\tstruct ring_buffer_event *event;\n\tstruct buffer_data_page *bpage;\n\tstruct buffer_page *reader;\n\tunsigned long missed_events;\n\tunsigned long flags;\n\tunsigned int commit;\n\tunsigned int read;\n\tu64 save_timestamp;\n\tint ret = -1;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\tgoto out;\n\n\t/*\n\t * If len is not big enough to hold the page header, then\n\t * we can not copy anything.\n\t */\n\tif (len <= BUF_PAGE_HDR_SIZE)\n\t\tgoto out;\n\n\tlen -= BUF_PAGE_HDR_SIZE;\n\n\tif (!data_page)\n\t\tgoto out;\n\n\tbpage = *data_page;\n\tif (!bpage)\n\t\tgoto out;\n\n\traw_spin_lock_irqsave(&cpu_buffer->reader_lock, flags);\n\n\treader = rb_get_reader_page(cpu_buffer);\n\tif (!reader)\n\t\tgoto out_unlock;\n\n\tevent = rb_reader_event(cpu_buffer);\n\n\tread = reader->read;\n\tcommit = rb_page_commit(reader);\n\n\t/* Check if any events were dropped */\n\tmissed_events = cpu_buffer->lost_events;\n\n\t/*\n\t * If this page has been partially read or\n\t * if len is not big enough to read the rest of the page or\n\t * a writer is still on the page, then\n\t * we must copy the data from the page to the buffer.\n\t * Otherwise, we can simply swap the page with the one passed in.\n\t */\n\tif (read || (len < (commit - read)) ||\n\t    cpu_buffer->reader_page == cpu_buffer->commit_page) {\n\t\tstruct buffer_data_page *rpage = cpu_buffer->reader_page->page;\n\t\tunsigned int rpos = read;\n\t\tunsigned int pos = 0;\n\t\tunsigned int size;\n\n\t\tif (full)\n\t\t\tgoto out_unlock;\n\n\t\tif (len > (commit - read))\n\t\t\tlen = (commit - read);\n\n\t\t/* Always keep the time extend and data together */\n\t\tsize = rb_event_ts_length(event);\n\n\t\tif (len < size)\n\t\t\tgoto out_unlock;\n\n\t\t/* save the current timestamp, since the user will need it */\n\t\tsave_timestamp = cpu_buffer->read_stamp;\n\n\t\t/* Need to copy one event at a time */\n\t\tdo {\n\t\t\t/* We need the size of one event, because\n\t\t\t * rb_advance_reader only advances by one event,\n\t\t\t * whereas rb_event_ts_length may include the size of\n\t\t\t * one or two events.\n\t\t\t * We have already ensured there's enough space if this\n\t\t\t * is a time extend. */\n\t\t\tsize = rb_event_length(event);\n\t\t\tmemcpy(bpage->data + pos, rpage->data + rpos, size);\n\n\t\t\tlen -= size;\n\n\t\t\trb_advance_reader(cpu_buffer);\n\t\t\trpos = reader->read;\n\t\t\tpos += size;\n\n\t\t\tif (rpos >= commit)\n\t\t\t\tbreak;\n\n\t\t\tevent = rb_reader_event(cpu_buffer);\n\t\t\t/* Always keep the time extend and data together */\n\t\t\tsize = rb_event_ts_length(event);\n\t\t} while (len >= size);\n\n\t\t/* update bpage */\n\t\tlocal_set(&bpage->commit, pos);\n\t\tbpage->time_stamp = save_timestamp;\n\n\t\t/* we copied everything to the beginning */\n\t\tread = 0;\n\t} else {\n\t\t/* update the entry counter */\n\t\tcpu_buffer->read += rb_page_entries(reader);\n\t\tcpu_buffer->read_bytes += BUF_PAGE_SIZE;\n\n\t\t/* swap the pages */\n\t\trb_init_page(bpage);\n\t\tbpage = reader->page;\n\t\treader->page = *data_page;\n\t\tlocal_set(&reader->write, 0);\n\t\tlocal_set(&reader->entries, 0);\n\t\treader->read = 0;\n\t\t*data_page = bpage;\n\n\t\t/*\n\t\t * Use the real_end for the data size,\n\t\t * This gives us a chance to store the lost events\n\t\t * on the page.\n\t\t */\n\t\tif (reader->real_end)\n\t\t\tlocal_set(&bpage->commit, reader->real_end);\n\t}\n\tret = read;\n\n\tcpu_buffer->lost_events = 0;\n\n\tcommit = local_read(&bpage->commit);\n\t/*\n\t * Set a flag in the commit field if we lost events\n\t */\n\tif (missed_events) {\n\t\t/* If there is room at the end of the page to save the\n\t\t * missed events, then record it there.\n\t\t */\n\t\tif (BUF_PAGE_SIZE - commit >= sizeof(missed_events)) {\n\t\t\tmemcpy(&bpage->data[commit], &missed_events,\n\t\t\t       sizeof(missed_events));\n\t\t\tlocal_add(RB_MISSED_STORED, &bpage->commit);\n\t\t\tcommit += sizeof(missed_events);\n\t\t}\n\t\tlocal_add(RB_MISSED_EVENTS, &bpage->commit);\n\t}\n\n\t/*\n\t * This page may be off to user land. Zero it out here.\n\t */\n\tif (commit < BUF_PAGE_SIZE)\n\t\tmemset(&bpage->data[commit], 0, BUF_PAGE_SIZE - commit);\n\n out_unlock:\n\traw_spin_unlock_irqrestore(&cpu_buffer->reader_lock, flags);\n\n out:\n\treturn ret;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)",
      "#define RB_MISSED_STORED\t(1 << 30)",
      "#define RB_MISSED_EVENTS\t(1 << 31)",
      "#define BUF_PAGE_HDR_SIZE offsetof(struct buffer_data_page, data)"
    ],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore",
          "args": [
            "&cpu_buffer->reader_lock",
            "flags"
          ],
          "line": 4810
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_irqrestore",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "182-185",
          "snippet": "void __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "memset",
          "args": [
            "&bpage->data[commit]",
            "0",
            "BUF_PAGE_SIZE - commit"
          ],
          "line": 4807
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_add",
          "args": [
            "RB_MISSED_EVENTS",
            "&bpage->commit"
          ],
          "line": 4800
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_add",
          "args": [
            "RB_MISSED_STORED",
            "&bpage->commit"
          ],
          "line": 4797
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "memcpy",
          "args": [
            "&bpage->data[commit]",
            "&missed_events",
            "sizeof(missed_events)"
          ],
          "line": 4795
        },
        "resolved": true,
        "details": {
          "function_name": "memcpy_skip",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/events/internal.h",
          "lines": "178-182",
          "snippet": "static inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}",
          "includes": [
            "#include <linux/uaccess.h>",
            "#include <linux/hardirq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/uaccess.h>\n#include <linux/hardirq.h>\n\nstatic inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_read",
          "args": [
            "&bpage->commit"
          ],
          "line": 4786
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_set",
          "args": [
            "&bpage->commit",
            "reader->real_end"
          ],
          "line": 4780
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_set",
          "args": [
            "&reader->entries",
            "0"
          ],
          "line": 4770
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_set",
          "args": [
            "&reader->write",
            "0"
          ],
          "line": 4769
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_init_page",
          "args": [
            "bpage"
          ],
          "line": 4766
        },
        "resolved": true,
        "details": {
          "function_name": "rb_init_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "351-354",
          "snippet": "static void rb_init_page(struct buffer_data_page *bpage)\n{\n\tlocal_set(&bpage->commit, 0);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_init_page(struct buffer_data_page *bpage)\n{\n\tlocal_set(&bpage->commit, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_page_entries",
          "args": [
            "reader"
          ],
          "line": 4762
        },
        "resolved": true,
        "details": {
          "function_name": "rb_page_entries",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1459-1462",
          "snippet": "static inline unsigned long rb_page_entries(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->entries) & RB_WRITE_MASK;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_WRITE_MASK\t\t0xfffff"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_WRITE_MASK\t\t0xfffff\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline unsigned long rb_page_entries(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->entries) & RB_WRITE_MASK;\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_set",
          "args": [
            "&bpage->commit",
            "pos"
          ],
          "line": 4755
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_event_ts_length",
          "args": [
            "event"
          ],
          "line": 4751
        },
        "resolved": true,
        "details": {
          "function_name": "rb_event_ts_length",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "214-225",
          "snippet": "static inline unsigned\nrb_event_ts_length(struct ring_buffer_event *event)\n{\n\tunsigned len = 0;\n\n\tif (extended_time(event)) {\n\t\t/* time extends include the data event after it */\n\t\tlen = RB_LEN_TIME_EXTEND;\n\t\tevent = skip_time_extend(event);\n\t}\n\treturn len + rb_event_length(event);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic inline unsigned\nrb_event_ts_length(struct ring_buffer_event *event)\n{\n\tunsigned len = 0;\n\n\tif (extended_time(event)) {\n\t\t/* time extends include the data event after it */\n\t\tlen = RB_LEN_TIME_EXTEND;\n\t\tevent = skip_time_extend(event);\n\t}\n\treturn len + rb_event_length(event);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_reader_event",
          "args": [
            "cpu_buffer"
          ],
          "line": 4749
        },
        "resolved": true,
        "details": {
          "function_name": "rb_reader_event",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1885-1890",
          "snippet": "ring_buffer_event *\nrb_reader_event(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn __rb_page_index(cpu_buffer->reader_page,\n\t\t\t       cpu_buffer->reader_page->read);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nring_buffer_event *\nrb_reader_event(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn __rb_page_index(cpu_buffer->reader_page,\n\t\t\t       cpu_buffer->reader_page->read);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_advance_reader",
          "args": [
            "cpu_buffer"
          ],
          "line": 4742
        },
        "resolved": true,
        "details": {
          "function_name": "rb_advance_reader",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3764-3785",
          "snippet": "static void rb_advance_reader(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct ring_buffer_event *event;\n\tstruct buffer_page *reader;\n\tunsigned length;\n\n\treader = rb_get_reader_page(cpu_buffer);\n\n\t/* This function should not be called when buffer is empty */\n\tif (RB_WARN_ON(cpu_buffer, !reader))\n\t\treturn;\n\n\tevent = rb_reader_event(cpu_buffer);\n\n\tif (event->type_len <= RINGBUF_TYPE_DATA_TYPE_LEN_MAX)\n\t\tcpu_buffer->read++;\n\n\trb_update_read_stamp(cpu_buffer, event);\n\n\tlength = rb_event_length(event);\n\tcpu_buffer->reader_page->read += length;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic void rb_advance_reader(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct ring_buffer_event *event;\n\tstruct buffer_page *reader;\n\tunsigned length;\n\n\treader = rb_get_reader_page(cpu_buffer);\n\n\t/* This function should not be called when buffer is empty */\n\tif (RB_WARN_ON(cpu_buffer, !reader))\n\t\treturn;\n\n\tevent = rb_reader_event(cpu_buffer);\n\n\tif (event->type_len <= RINGBUF_TYPE_DATA_TYPE_LEN_MAX)\n\t\tcpu_buffer->read++;\n\n\trb_update_read_stamp(cpu_buffer, event);\n\n\tlength = rb_event_length(event);\n\tcpu_buffer->reader_page->read += length;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_event_length",
          "args": [
            "event"
          ],
          "line": 4737
        },
        "resolved": true,
        "details": {
          "function_name": "rb_event_length",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "185-208",
          "snippet": "static inline unsigned\nrb_event_length(struct ring_buffer_event *event)\n{\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event))\n\t\t\t/* undefined */\n\t\t\treturn -1;\n\t\treturn  event->array[0] + RB_EVNT_HDR_SIZE;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\treturn RB_LEN_TIME_EXTEND;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\treturn RB_LEN_TIME_STAMP;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\treturn rb_event_data_length(event);\n\tdefault:\n\t\tBUG();\n\t}\n\t/* not hit */\n\treturn 0;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX",
            "#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX\n#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic inline unsigned\nrb_event_length(struct ring_buffer_event *event)\n{\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event))\n\t\t\t/* undefined */\n\t\t\treturn -1;\n\t\treturn  event->array[0] + RB_EVNT_HDR_SIZE;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\treturn RB_LEN_TIME_EXTEND;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\treturn RB_LEN_TIME_STAMP;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\treturn rb_event_data_length(event);\n\tdefault:\n\t\tBUG();\n\t}\n\t/* not hit */\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_page_commit",
          "args": [
            "reader"
          ],
          "line": 4695
        },
        "resolved": true,
        "details": {
          "function_name": "rb_page_commit",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1898-1901",
          "snippet": "static __always_inline unsigned rb_page_commit(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->page->commit);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline unsigned rb_page_commit(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->page->commit);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_get_reader_page",
          "args": [
            "cpu_buffer"
          ],
          "line": 4688
        },
        "resolved": true,
        "details": {
          "function_name": "rb_get_reader_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3631-3762",
          "snippet": "static struct buffer_page *\nrb_get_reader_page(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *reader = NULL;\n\tunsigned long overwrite;\n\tunsigned long flags;\n\tint nr_loops = 0;\n\tint ret;\n\n\tlocal_irq_save(flags);\n\tarch_spin_lock(&cpu_buffer->lock);\n\n again:\n\t/*\n\t * This should normally only loop twice. But because the\n\t * start of the reader inserts an empty page, it causes\n\t * a case where we will loop three times. There should be no\n\t * reason to loop four times (that I know of).\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 3)) {\n\t\treader = NULL;\n\t\tgoto out;\n\t}\n\n\treader = cpu_buffer->reader_page;\n\n\t/* If there's more to read, return this page */\n\tif (cpu_buffer->reader_page->read < rb_page_size(reader))\n\t\tgoto out;\n\n\t/* Never should we have an index greater than the size */\n\tif (RB_WARN_ON(cpu_buffer,\n\t\t       cpu_buffer->reader_page->read > rb_page_size(reader)))\n\t\tgoto out;\n\n\t/* check if we caught up to the tail */\n\treader = NULL;\n\tif (cpu_buffer->commit_page == cpu_buffer->reader_page)\n\t\tgoto out;\n\n\t/* Don't bother swapping if the ring buffer is empty */\n\tif (rb_num_of_entries(cpu_buffer) == 0)\n\t\tgoto out;\n\n\t/*\n\t * Reset the reader page to size zero.\n\t */\n\tlocal_set(&cpu_buffer->reader_page->write, 0);\n\tlocal_set(&cpu_buffer->reader_page->entries, 0);\n\tlocal_set(&cpu_buffer->reader_page->page->commit, 0);\n\tcpu_buffer->reader_page->real_end = 0;\n\n spin:\n\t/*\n\t * Splice the empty reader page into the list around the head.\n\t */\n\treader = rb_set_head_page(cpu_buffer);\n\tif (!reader)\n\t\tgoto out;\n\tcpu_buffer->reader_page->list.next = rb_list_head(reader->list.next);\n\tcpu_buffer->reader_page->list.prev = reader->list.prev;\n\n\t/*\n\t * cpu_buffer->pages just needs to point to the buffer, it\n\t *  has no specific buffer page to point to. Lets move it out\n\t *  of our way so we don't accidentally swap it.\n\t */\n\tcpu_buffer->pages = reader->list.prev;\n\n\t/* The reader page will be pointing to the new head */\n\trb_set_list_to_head(cpu_buffer, &cpu_buffer->reader_page->list);\n\n\t/*\n\t * We want to make sure we read the overruns after we set up our\n\t * pointers to the next object. The writer side does a\n\t * cmpxchg to cross pages which acts as the mb on the writer\n\t * side. Note, the reader will constantly fail the swap\n\t * while the writer is updating the pointers, so this\n\t * guarantees that the overwrite recorded here is the one we\n\t * want to compare with the last_overrun.\n\t */\n\tsmp_mb();\n\toverwrite = local_read(&(cpu_buffer->overrun));\n\n\t/*\n\t * Here's the tricky part.\n\t *\n\t * We need to move the pointer past the header page.\n\t * But we can only do that if a writer is not currently\n\t * moving it. The page before the header page has the\n\t * flag bit '1' set if it is pointing to the page we want.\n\t * but if the writer is in the process of moving it\n\t * than it will be '2' or already moved '0'.\n\t */\n\n\tret = rb_head_page_replace(reader, cpu_buffer->reader_page);\n\n\t/*\n\t * If we did not convert it, then we must try again.\n\t */\n\tif (!ret)\n\t\tgoto spin;\n\n\t/*\n\t * Yeah! We succeeded in replacing the page.\n\t *\n\t * Now make the new head point back to the reader page.\n\t */\n\trb_list_head(reader->list.next)->prev = &cpu_buffer->reader_page->list;\n\trb_inc_page(cpu_buffer, &cpu_buffer->head_page);\n\n\t/* Finally update the reader page to the new head */\n\tcpu_buffer->reader_page = reader;\n\tcpu_buffer->reader_page->read = 0;\n\n\tif (overwrite != cpu_buffer->last_overrun) {\n\t\tcpu_buffer->lost_events = overwrite - cpu_buffer->last_overrun;\n\t\tcpu_buffer->last_overrun = overwrite;\n\t}\n\n\tgoto again;\n\n out:\n\t/* Update the read_stamp on the first event */\n\tif (reader && reader->read == 0)\n\t\tcpu_buffer->read_stamp = reader->page->time_stamp;\n\n\tarch_spin_unlock(&cpu_buffer->lock);\n\tlocal_irq_restore(flags);\n\n\treturn reader;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic struct buffer_page *\nrb_get_reader_page(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *reader = NULL;\n\tunsigned long overwrite;\n\tunsigned long flags;\n\tint nr_loops = 0;\n\tint ret;\n\n\tlocal_irq_save(flags);\n\tarch_spin_lock(&cpu_buffer->lock);\n\n again:\n\t/*\n\t * This should normally only loop twice. But because the\n\t * start of the reader inserts an empty page, it causes\n\t * a case where we will loop three times. There should be no\n\t * reason to loop four times (that I know of).\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 3)) {\n\t\treader = NULL;\n\t\tgoto out;\n\t}\n\n\treader = cpu_buffer->reader_page;\n\n\t/* If there's more to read, return this page */\n\tif (cpu_buffer->reader_page->read < rb_page_size(reader))\n\t\tgoto out;\n\n\t/* Never should we have an index greater than the size */\n\tif (RB_WARN_ON(cpu_buffer,\n\t\t       cpu_buffer->reader_page->read > rb_page_size(reader)))\n\t\tgoto out;\n\n\t/* check if we caught up to the tail */\n\treader = NULL;\n\tif (cpu_buffer->commit_page == cpu_buffer->reader_page)\n\t\tgoto out;\n\n\t/* Don't bother swapping if the ring buffer is empty */\n\tif (rb_num_of_entries(cpu_buffer) == 0)\n\t\tgoto out;\n\n\t/*\n\t * Reset the reader page to size zero.\n\t */\n\tlocal_set(&cpu_buffer->reader_page->write, 0);\n\tlocal_set(&cpu_buffer->reader_page->entries, 0);\n\tlocal_set(&cpu_buffer->reader_page->page->commit, 0);\n\tcpu_buffer->reader_page->real_end = 0;\n\n spin:\n\t/*\n\t * Splice the empty reader page into the list around the head.\n\t */\n\treader = rb_set_head_page(cpu_buffer);\n\tif (!reader)\n\t\tgoto out;\n\tcpu_buffer->reader_page->list.next = rb_list_head(reader->list.next);\n\tcpu_buffer->reader_page->list.prev = reader->list.prev;\n\n\t/*\n\t * cpu_buffer->pages just needs to point to the buffer, it\n\t *  has no specific buffer page to point to. Lets move it out\n\t *  of our way so we don't accidentally swap it.\n\t */\n\tcpu_buffer->pages = reader->list.prev;\n\n\t/* The reader page will be pointing to the new head */\n\trb_set_list_to_head(cpu_buffer, &cpu_buffer->reader_page->list);\n\n\t/*\n\t * We want to make sure we read the overruns after we set up our\n\t * pointers to the next object. The writer side does a\n\t * cmpxchg to cross pages which acts as the mb on the writer\n\t * side. Note, the reader will constantly fail the swap\n\t * while the writer is updating the pointers, so this\n\t * guarantees that the overwrite recorded here is the one we\n\t * want to compare with the last_overrun.\n\t */\n\tsmp_mb();\n\toverwrite = local_read(&(cpu_buffer->overrun));\n\n\t/*\n\t * Here's the tricky part.\n\t *\n\t * We need to move the pointer past the header page.\n\t * But we can only do that if a writer is not currently\n\t * moving it. The page before the header page has the\n\t * flag bit '1' set if it is pointing to the page we want.\n\t * but if the writer is in the process of moving it\n\t * than it will be '2' or already moved '0'.\n\t */\n\n\tret = rb_head_page_replace(reader, cpu_buffer->reader_page);\n\n\t/*\n\t * If we did not convert it, then we must try again.\n\t */\n\tif (!ret)\n\t\tgoto spin;\n\n\t/*\n\t * Yeah! We succeeded in replacing the page.\n\t *\n\t * Now make the new head point back to the reader page.\n\t */\n\trb_list_head(reader->list.next)->prev = &cpu_buffer->reader_page->list;\n\trb_inc_page(cpu_buffer, &cpu_buffer->head_page);\n\n\t/* Finally update the reader page to the new head */\n\tcpu_buffer->reader_page = reader;\n\tcpu_buffer->reader_page->read = 0;\n\n\tif (overwrite != cpu_buffer->last_overrun) {\n\t\tcpu_buffer->lost_events = overwrite - cpu_buffer->last_overrun;\n\t\tcpu_buffer->last_overrun = overwrite;\n\t}\n\n\tgoto again;\n\n out:\n\t/* Update the read_stamp on the first event */\n\tif (reader && reader->read == 0)\n\t\tcpu_buffer->read_stamp = reader->page->time_stamp;\n\n\tarch_spin_unlock(&cpu_buffer->lock);\n\tlocal_irq_restore(flags);\n\n\treturn reader;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irqsave",
          "args": [
            "&cpu_buffer->reader_lock",
            "flags"
          ],
          "line": 4686
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_irqsave_nested",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "359-370",
          "snippet": "unsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED_FLAGS(lock, do_raw_spin_trylock, do_raw_spin_lock,\n\t\t\t\tdo_raw_spin_lock_flags, &flags);\n\treturn flags;\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nunsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED_FLAGS(lock, do_raw_spin_trylock, do_raw_spin_lock,\n\t\t\t\tdo_raw_spin_lock_flags, &flags);\n\treturn flags;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "buffer->cpumask"
          ],
          "line": 4667
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)\n#define RB_MISSED_STORED\t(1 << 30)\n#define RB_MISSED_EVENTS\t(1 << 31)\n#define BUF_PAGE_HDR_SIZE offsetof(struct buffer_data_page, data)\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nint ring_buffer_read_page(struct ring_buffer *buffer,\n\t\t\t  void **data_page, size_t len, int cpu, int full)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = buffer->buffers[cpu];\n\tstruct ring_buffer_event *event;\n\tstruct buffer_data_page *bpage;\n\tstruct buffer_page *reader;\n\tunsigned long missed_events;\n\tunsigned long flags;\n\tunsigned int commit;\n\tunsigned int read;\n\tu64 save_timestamp;\n\tint ret = -1;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\tgoto out;\n\n\t/*\n\t * If len is not big enough to hold the page header, then\n\t * we can not copy anything.\n\t */\n\tif (len <= BUF_PAGE_HDR_SIZE)\n\t\tgoto out;\n\n\tlen -= BUF_PAGE_HDR_SIZE;\n\n\tif (!data_page)\n\t\tgoto out;\n\n\tbpage = *data_page;\n\tif (!bpage)\n\t\tgoto out;\n\n\traw_spin_lock_irqsave(&cpu_buffer->reader_lock, flags);\n\n\treader = rb_get_reader_page(cpu_buffer);\n\tif (!reader)\n\t\tgoto out_unlock;\n\n\tevent = rb_reader_event(cpu_buffer);\n\n\tread = reader->read;\n\tcommit = rb_page_commit(reader);\n\n\t/* Check if any events were dropped */\n\tmissed_events = cpu_buffer->lost_events;\n\n\t/*\n\t * If this page has been partially read or\n\t * if len is not big enough to read the rest of the page or\n\t * a writer is still on the page, then\n\t * we must copy the data from the page to the buffer.\n\t * Otherwise, we can simply swap the page with the one passed in.\n\t */\n\tif (read || (len < (commit - read)) ||\n\t    cpu_buffer->reader_page == cpu_buffer->commit_page) {\n\t\tstruct buffer_data_page *rpage = cpu_buffer->reader_page->page;\n\t\tunsigned int rpos = read;\n\t\tunsigned int pos = 0;\n\t\tunsigned int size;\n\n\t\tif (full)\n\t\t\tgoto out_unlock;\n\n\t\tif (len > (commit - read))\n\t\t\tlen = (commit - read);\n\n\t\t/* Always keep the time extend and data together */\n\t\tsize = rb_event_ts_length(event);\n\n\t\tif (len < size)\n\t\t\tgoto out_unlock;\n\n\t\t/* save the current timestamp, since the user will need it */\n\t\tsave_timestamp = cpu_buffer->read_stamp;\n\n\t\t/* Need to copy one event at a time */\n\t\tdo {\n\t\t\t/* We need the size of one event, because\n\t\t\t * rb_advance_reader only advances by one event,\n\t\t\t * whereas rb_event_ts_length may include the size of\n\t\t\t * one or two events.\n\t\t\t * We have already ensured there's enough space if this\n\t\t\t * is a time extend. */\n\t\t\tsize = rb_event_length(event);\n\t\t\tmemcpy(bpage->data + pos, rpage->data + rpos, size);\n\n\t\t\tlen -= size;\n\n\t\t\trb_advance_reader(cpu_buffer);\n\t\t\trpos = reader->read;\n\t\t\tpos += size;\n\n\t\t\tif (rpos >= commit)\n\t\t\t\tbreak;\n\n\t\t\tevent = rb_reader_event(cpu_buffer);\n\t\t\t/* Always keep the time extend and data together */\n\t\t\tsize = rb_event_ts_length(event);\n\t\t} while (len >= size);\n\n\t\t/* update bpage */\n\t\tlocal_set(&bpage->commit, pos);\n\t\tbpage->time_stamp = save_timestamp;\n\n\t\t/* we copied everything to the beginning */\n\t\tread = 0;\n\t} else {\n\t\t/* update the entry counter */\n\t\tcpu_buffer->read += rb_page_entries(reader);\n\t\tcpu_buffer->read_bytes += BUF_PAGE_SIZE;\n\n\t\t/* swap the pages */\n\t\trb_init_page(bpage);\n\t\tbpage = reader->page;\n\t\treader->page = *data_page;\n\t\tlocal_set(&reader->write, 0);\n\t\tlocal_set(&reader->entries, 0);\n\t\treader->read = 0;\n\t\t*data_page = bpage;\n\n\t\t/*\n\t\t * Use the real_end for the data size,\n\t\t * This gives us a chance to store the lost events\n\t\t * on the page.\n\t\t */\n\t\tif (reader->real_end)\n\t\t\tlocal_set(&bpage->commit, reader->real_end);\n\t}\n\tret = read;\n\n\tcpu_buffer->lost_events = 0;\n\n\tcommit = local_read(&bpage->commit);\n\t/*\n\t * Set a flag in the commit field if we lost events\n\t */\n\tif (missed_events) {\n\t\t/* If there is room at the end of the page to save the\n\t\t * missed events, then record it there.\n\t\t */\n\t\tif (BUF_PAGE_SIZE - commit >= sizeof(missed_events)) {\n\t\t\tmemcpy(&bpage->data[commit], &missed_events,\n\t\t\t       sizeof(missed_events));\n\t\t\tlocal_add(RB_MISSED_STORED, &bpage->commit);\n\t\t\tcommit += sizeof(missed_events);\n\t\t}\n\t\tlocal_add(RB_MISSED_EVENTS, &bpage->commit);\n\t}\n\n\t/*\n\t * This page may be off to user land. Zero it out here.\n\t */\n\tif (commit < BUF_PAGE_SIZE)\n\t\tmemset(&bpage->data[commit], 0, BUF_PAGE_SIZE - commit);\n\n out_unlock:\n\traw_spin_unlock_irqrestore(&cpu_buffer->reader_lock, flags);\n\n out:\n\treturn ret;\n}"
  },
  {
    "function_name": "ring_buffer_free_read_page",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "4593-4617",
    "snippet": "void ring_buffer_free_read_page(struct ring_buffer *buffer, int cpu, void *data)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = buffer->buffers[cpu];\n\tstruct buffer_data_page *bpage = data;\n\tstruct page *page = virt_to_page(bpage);\n\tunsigned long flags;\n\n\t/* If the page is still in use someplace else, we can't reuse it */\n\tif (page_ref_count(page) > 1)\n\t\tgoto out;\n\n\tlocal_irq_save(flags);\n\tarch_spin_lock(&cpu_buffer->lock);\n\n\tif (!cpu_buffer->free_page) {\n\t\tcpu_buffer->free_page = bpage;\n\t\tbpage = NULL;\n\t}\n\n\tarch_spin_unlock(&cpu_buffer->lock);\n\tlocal_irq_restore(flags);\n\n out:\n\tfree_page((unsigned long)bpage);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "free_page",
          "args": [
            "(unsigned long)bpage"
          ],
          "line": 4616
        },
        "resolved": true,
        "details": {
          "function_name": "perf_mmap_free_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/events/ring_buffer.c",
          "lines": "770-776",
          "snippet": "static void perf_mmap_free_page(unsigned long addr)\n{\n\tstruct page *page = virt_to_page((void *)addr);\n\n\tpage->mapping = NULL;\n\t__free_page(page);\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <linux/nospec.h>",
            "#include <linux/poll.h>",
            "#include <linux/circ_buf.h>",
            "#include <linux/slab.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/perf_event.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <linux/nospec.h>\n#include <linux/poll.h>\n#include <linux/circ_buf.h>\n#include <linux/slab.h>\n#include <linux/vmalloc.h>\n#include <linux/perf_event.h>\n\nstatic void perf_mmap_free_page(unsigned long addr)\n{\n\tstruct page *page = virt_to_page((void *)addr);\n\n\tpage->mapping = NULL;\n\t__free_page(page);\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_irq_restore",
          "args": [
            "flags"
          ],
          "line": 4613
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "arch_spin_unlock",
          "args": [
            "&cpu_buffer->lock"
          ],
          "line": 4612
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "arch_spin_lock",
          "args": [
            "&cpu_buffer->lock"
          ],
          "line": 4605
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_irq_save",
          "args": [
            "flags"
          ],
          "line": 4604
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "page_ref_count",
          "args": [
            "page"
          ],
          "line": 4601
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "virt_to_page",
          "args": [
            "bpage"
          ],
          "line": 4597
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid ring_buffer_free_read_page(struct ring_buffer *buffer, int cpu, void *data)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = buffer->buffers[cpu];\n\tstruct buffer_data_page *bpage = data;\n\tstruct page *page = virt_to_page(bpage);\n\tunsigned long flags;\n\n\t/* If the page is still in use someplace else, we can't reuse it */\n\tif (page_ref_count(page) > 1)\n\t\tgoto out;\n\n\tlocal_irq_save(flags);\n\tarch_spin_lock(&cpu_buffer->lock);\n\n\tif (!cpu_buffer->free_page) {\n\t\tcpu_buffer->free_page = bpage;\n\t\tbpage = NULL;\n\t}\n\n\tarch_spin_unlock(&cpu_buffer->lock);\n\tlocal_irq_restore(flags);\n\n out:\n\tfree_page((unsigned long)bpage);\n}"
  },
  {
    "function_name": "ring_buffer_alloc_read_page",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "4546-4582",
    "snippet": "void *ring_buffer_alloc_read_page(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct buffer_data_page *bpage = NULL;\n\tunsigned long flags;\n\tstruct page *page;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn ERR_PTR(-ENODEV);\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tlocal_irq_save(flags);\n\tarch_spin_lock(&cpu_buffer->lock);\n\n\tif (cpu_buffer->free_page) {\n\t\tbpage = cpu_buffer->free_page;\n\t\tcpu_buffer->free_page = NULL;\n\t}\n\n\tarch_spin_unlock(&cpu_buffer->lock);\n\tlocal_irq_restore(flags);\n\n\tif (bpage)\n\t\tgoto out;\n\n\tpage = alloc_pages_node(cpu_to_node(cpu),\n\t\t\t\tGFP_KERNEL | __GFP_NORETRY, 0);\n\tif (!page)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tbpage = page_address(page);\n\n out:\n\trb_init_page(bpage);\n\n\treturn bpage;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_init_page",
          "args": [
            "bpage"
          ],
          "line": 4579
        },
        "resolved": true,
        "details": {
          "function_name": "rb_init_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "351-354",
          "snippet": "static void rb_init_page(struct buffer_data_page *bpage)\n{\n\tlocal_set(&bpage->commit, 0);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_init_page(struct buffer_data_page *bpage)\n{\n\tlocal_set(&bpage->commit, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "page_address",
          "args": [
            "page"
          ],
          "line": 4576
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-ENOMEM"
          ],
          "line": 4574
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "alloc_pages_node",
          "args": [
            "cpu_to_node(cpu)",
            "GFP_KERNEL | __GFP_NORETRY",
            "0"
          ],
          "line": 4571
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_to_node",
          "args": [
            "cpu"
          ],
          "line": 4571
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_irq_restore",
          "args": [
            "flags"
          ],
          "line": 4566
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "arch_spin_unlock",
          "args": [
            "&cpu_buffer->lock"
          ],
          "line": 4565
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "arch_spin_lock",
          "args": [
            "&cpu_buffer->lock"
          ],
          "line": 4558
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_irq_save",
          "args": [
            "flags"
          ],
          "line": 4557
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-ENODEV"
          ],
          "line": 4554
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "buffer->cpumask"
          ],
          "line": 4553
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid *ring_buffer_alloc_read_page(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct buffer_data_page *bpage = NULL;\n\tunsigned long flags;\n\tstruct page *page;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn ERR_PTR(-ENODEV);\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tlocal_irq_save(flags);\n\tarch_spin_lock(&cpu_buffer->lock);\n\n\tif (cpu_buffer->free_page) {\n\t\tbpage = cpu_buffer->free_page;\n\t\tcpu_buffer->free_page = NULL;\n\t}\n\n\tarch_spin_unlock(&cpu_buffer->lock);\n\tlocal_irq_restore(flags);\n\n\tif (bpage)\n\t\tgoto out;\n\n\tpage = alloc_pages_node(cpu_to_node(cpu),\n\t\t\t\tGFP_KERNEL | __GFP_NORETRY, 0);\n\tif (!page)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tbpage = page_address(page);\n\n out:\n\trb_init_page(bpage);\n\n\treturn bpage;\n}"
  },
  {
    "function_name": "ring_buffer_swap_cpu",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "4466-4526",
    "snippet": "int ring_buffer_swap_cpu(struct ring_buffer *buffer_a,\n\t\t\t struct ring_buffer *buffer_b, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer_a;\n\tstruct ring_buffer_per_cpu *cpu_buffer_b;\n\tint ret = -EINVAL;\n\n\tif (!cpumask_test_cpu(cpu, buffer_a->cpumask) ||\n\t    !cpumask_test_cpu(cpu, buffer_b->cpumask))\n\t\tgoto out;\n\n\tcpu_buffer_a = buffer_a->buffers[cpu];\n\tcpu_buffer_b = buffer_b->buffers[cpu];\n\n\t/* At least make sure the two buffers are somewhat the same */\n\tif (cpu_buffer_a->nr_pages != cpu_buffer_b->nr_pages)\n\t\tgoto out;\n\n\tret = -EAGAIN;\n\n\tif (atomic_read(&buffer_a->record_disabled))\n\t\tgoto out;\n\n\tif (atomic_read(&buffer_b->record_disabled))\n\t\tgoto out;\n\n\tif (atomic_read(&cpu_buffer_a->record_disabled))\n\t\tgoto out;\n\n\tif (atomic_read(&cpu_buffer_b->record_disabled))\n\t\tgoto out;\n\n\t/*\n\t * We can't do a synchronize_sched here because this\n\t * function can be called in atomic context.\n\t * Normally this will be called from the same CPU as cpu.\n\t * If not it's up to the caller to protect this.\n\t */\n\tatomic_inc(&cpu_buffer_a->record_disabled);\n\tatomic_inc(&cpu_buffer_b->record_disabled);\n\n\tret = -EBUSY;\n\tif (local_read(&cpu_buffer_a->committing))\n\t\tgoto out_dec;\n\tif (local_read(&cpu_buffer_b->committing))\n\t\tgoto out_dec;\n\n\tbuffer_a->buffers[cpu] = cpu_buffer_b;\n\tbuffer_b->buffers[cpu] = cpu_buffer_a;\n\n\tcpu_buffer_b->buffer = buffer_a;\n\tcpu_buffer_a->buffer = buffer_b;\n\n\tret = 0;\n\nout_dec:\n\tatomic_dec(&cpu_buffer_a->record_disabled);\n\tatomic_dec(&cpu_buffer_b->record_disabled);\nout:\n\treturn ret;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_dec",
          "args": [
            "&cpu_buffer_b->record_disabled"
          ],
          "line": 4523
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_dec",
          "args": [
            "&cpu_buffer_a->record_disabled"
          ],
          "line": 4522
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_read",
          "args": [
            "&cpu_buffer_b->committing"
          ],
          "line": 4510
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_read",
          "args": [
            "&cpu_buffer_a->committing"
          ],
          "line": 4508
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_inc",
          "args": [
            "&cpu_buffer_b->record_disabled"
          ],
          "line": 4505
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_inc",
          "args": [
            "&cpu_buffer_a->record_disabled"
          ],
          "line": 4504
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&cpu_buffer_b->record_disabled"
          ],
          "line": 4495
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&cpu_buffer_a->record_disabled"
          ],
          "line": 4492
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&buffer_b->record_disabled"
          ],
          "line": 4489
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&buffer_a->record_disabled"
          ],
          "line": 4486
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "buffer_b->cpumask"
          ],
          "line": 4474
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "buffer_a->cpumask"
          ],
          "line": 4473
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nint ring_buffer_swap_cpu(struct ring_buffer *buffer_a,\n\t\t\t struct ring_buffer *buffer_b, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer_a;\n\tstruct ring_buffer_per_cpu *cpu_buffer_b;\n\tint ret = -EINVAL;\n\n\tif (!cpumask_test_cpu(cpu, buffer_a->cpumask) ||\n\t    !cpumask_test_cpu(cpu, buffer_b->cpumask))\n\t\tgoto out;\n\n\tcpu_buffer_a = buffer_a->buffers[cpu];\n\tcpu_buffer_b = buffer_b->buffers[cpu];\n\n\t/* At least make sure the two buffers are somewhat the same */\n\tif (cpu_buffer_a->nr_pages != cpu_buffer_b->nr_pages)\n\t\tgoto out;\n\n\tret = -EAGAIN;\n\n\tif (atomic_read(&buffer_a->record_disabled))\n\t\tgoto out;\n\n\tif (atomic_read(&buffer_b->record_disabled))\n\t\tgoto out;\n\n\tif (atomic_read(&cpu_buffer_a->record_disabled))\n\t\tgoto out;\n\n\tif (atomic_read(&cpu_buffer_b->record_disabled))\n\t\tgoto out;\n\n\t/*\n\t * We can't do a synchronize_sched here because this\n\t * function can be called in atomic context.\n\t * Normally this will be called from the same CPU as cpu.\n\t * If not it's up to the caller to protect this.\n\t */\n\tatomic_inc(&cpu_buffer_a->record_disabled);\n\tatomic_inc(&cpu_buffer_b->record_disabled);\n\n\tret = -EBUSY;\n\tif (local_read(&cpu_buffer_a->committing))\n\t\tgoto out_dec;\n\tif (local_read(&cpu_buffer_b->committing))\n\t\tgoto out_dec;\n\n\tbuffer_a->buffers[cpu] = cpu_buffer_b;\n\tbuffer_b->buffers[cpu] = cpu_buffer_a;\n\n\tcpu_buffer_b->buffer = buffer_a;\n\tcpu_buffer_a->buffer = buffer_b;\n\n\tret = 0;\n\nout_dec:\n\tatomic_dec(&cpu_buffer_a->record_disabled);\n\tatomic_dec(&cpu_buffer_b->record_disabled);\nout:\n\treturn ret;\n}"
  },
  {
    "function_name": "ring_buffer_empty_cpu",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "4434-4452",
    "snippet": "bool ring_buffer_empty_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long flags;\n\tbool dolock;\n\tint ret;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn true;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tlocal_irq_save(flags);\n\tdolock = rb_reader_lock(cpu_buffer);\n\tret = rb_per_cpu_empty(cpu_buffer);\n\trb_reader_unlock(cpu_buffer, dolock);\n\tlocal_irq_restore(flags);\n\n\treturn ret;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_irq_restore",
          "args": [
            "flags"
          ],
          "line": 4449
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_reader_unlock",
          "args": [
            "cpu_buffer",
            "dolock"
          ],
          "line": 4448
        },
        "resolved": true,
        "details": {
          "function_name": "rb_reader_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "4019-4025",
          "snippet": "static inline void\nrb_reader_unlock(struct ring_buffer_per_cpu *cpu_buffer, bool locked)\n{\n\tif (likely(locked))\n\t\traw_spin_unlock(&cpu_buffer->reader_lock);\n\treturn;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline void\nrb_reader_unlock(struct ring_buffer_per_cpu *cpu_buffer, bool locked)\n{\n\tif (likely(locked))\n\t\traw_spin_unlock(&cpu_buffer->reader_lock);\n\treturn;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_per_cpu_empty",
          "args": [
            "cpu_buffer"
          ],
          "line": 4447
        },
        "resolved": true,
        "details": {
          "function_name": "rb_per_cpu_empty",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3131-3145",
          "snippet": "static bool rb_per_cpu_empty(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *reader = cpu_buffer->reader_page;\n\tstruct buffer_page *head = rb_set_head_page(cpu_buffer);\n\tstruct buffer_page *commit = cpu_buffer->commit_page;\n\n\t/* In case of error, head will be NULL */\n\tif (unlikely(!head))\n\t\treturn true;\n\n\treturn reader->read == rb_page_commit(reader) &&\n\t\t(commit == reader ||\n\t\t (commit == head &&\n\t\t  head->read == rb_page_commit(commit)));\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic bool rb_per_cpu_empty(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *reader = cpu_buffer->reader_page;\n\tstruct buffer_page *head = rb_set_head_page(cpu_buffer);\n\tstruct buffer_page *commit = cpu_buffer->commit_page;\n\n\t/* In case of error, head will be NULL */\n\tif (unlikely(!head))\n\t\treturn true;\n\n\treturn reader->read == rb_page_commit(reader) &&\n\t\t(commit == reader ||\n\t\t (commit == head &&\n\t\t  head->read == rb_page_commit(commit)));\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_reader_lock",
          "args": [
            "cpu_buffer"
          ],
          "line": 4446
        },
        "resolved": true,
        "details": {
          "function_name": "rb_reader_lock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3995-4017",
          "snippet": "static inline bool rb_reader_lock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tif (likely(!in_nmi())) {\n\t\traw_spin_lock(&cpu_buffer->reader_lock);\n\t\treturn true;\n\t}\n\n\t/*\n\t * If an NMI die dumps out the content of the ring buffer\n\t * trylock must be used to prevent a deadlock if the NMI\n\t * preempted a task that holds the ring buffer locks. If\n\t * we get the lock then all is fine, if not, then continue\n\t * to do the read, but this can corrupt the ring buffer,\n\t * so it must be permanently disabled from future writes.\n\t * Reading from NMI is a oneshot deal.\n\t */\n\tif (raw_spin_trylock(&cpu_buffer->reader_lock))\n\t\treturn true;\n\n\t/* Continue without locking, but disable the ring buffer */\n\tatomic_inc(&cpu_buffer->record_disabled);\n\treturn false;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline bool rb_reader_lock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tif (likely(!in_nmi())) {\n\t\traw_spin_lock(&cpu_buffer->reader_lock);\n\t\treturn true;\n\t}\n\n\t/*\n\t * If an NMI die dumps out the content of the ring buffer\n\t * trylock must be used to prevent a deadlock if the NMI\n\t * preempted a task that holds the ring buffer locks. If\n\t * we get the lock then all is fine, if not, then continue\n\t * to do the read, but this can corrupt the ring buffer,\n\t * so it must be permanently disabled from future writes.\n\t * Reading from NMI is a oneshot deal.\n\t */\n\tif (raw_spin_trylock(&cpu_buffer->reader_lock))\n\t\treturn true;\n\n\t/* Continue without locking, but disable the ring buffer */\n\tatomic_inc(&cpu_buffer->record_disabled);\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_irq_save",
          "args": [
            "flags"
          ],
          "line": 4445
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "buffer->cpumask"
          ],
          "line": 4441
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nbool ring_buffer_empty_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long flags;\n\tbool dolock;\n\tint ret;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn true;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tlocal_irq_save(flags);\n\tdolock = rb_reader_lock(cpu_buffer);\n\tret = rb_per_cpu_empty(cpu_buffer);\n\trb_reader_unlock(cpu_buffer, dolock);\n\tlocal_irq_restore(flags);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "ring_buffer_empty",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "4404-4426",
    "snippet": "bool ring_buffer_empty(struct ring_buffer *buffer)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long flags;\n\tbool dolock;\n\tint cpu;\n\tint ret;\n\n\t/* yes this is racy, but if you don't like the race, lock the buffer */\n\tfor_each_buffer_cpu(buffer, cpu) {\n\t\tcpu_buffer = buffer->buffers[cpu];\n\t\tlocal_irq_save(flags);\n\t\tdolock = rb_reader_lock(cpu_buffer);\n\t\tret = rb_per_cpu_empty(cpu_buffer);\n\t\trb_reader_unlock(cpu_buffer, dolock);\n\t\tlocal_irq_restore(flags);\n\n\t\tif (!ret)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_irq_restore",
          "args": [
            "flags"
          ],
          "line": 4419
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_reader_unlock",
          "args": [
            "cpu_buffer",
            "dolock"
          ],
          "line": 4418
        },
        "resolved": true,
        "details": {
          "function_name": "rb_reader_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "4019-4025",
          "snippet": "static inline void\nrb_reader_unlock(struct ring_buffer_per_cpu *cpu_buffer, bool locked)\n{\n\tif (likely(locked))\n\t\traw_spin_unlock(&cpu_buffer->reader_lock);\n\treturn;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline void\nrb_reader_unlock(struct ring_buffer_per_cpu *cpu_buffer, bool locked)\n{\n\tif (likely(locked))\n\t\traw_spin_unlock(&cpu_buffer->reader_lock);\n\treturn;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_per_cpu_empty",
          "args": [
            "cpu_buffer"
          ],
          "line": 4417
        },
        "resolved": true,
        "details": {
          "function_name": "rb_per_cpu_empty",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3131-3145",
          "snippet": "static bool rb_per_cpu_empty(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *reader = cpu_buffer->reader_page;\n\tstruct buffer_page *head = rb_set_head_page(cpu_buffer);\n\tstruct buffer_page *commit = cpu_buffer->commit_page;\n\n\t/* In case of error, head will be NULL */\n\tif (unlikely(!head))\n\t\treturn true;\n\n\treturn reader->read == rb_page_commit(reader) &&\n\t\t(commit == reader ||\n\t\t (commit == head &&\n\t\t  head->read == rb_page_commit(commit)));\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic bool rb_per_cpu_empty(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *reader = cpu_buffer->reader_page;\n\tstruct buffer_page *head = rb_set_head_page(cpu_buffer);\n\tstruct buffer_page *commit = cpu_buffer->commit_page;\n\n\t/* In case of error, head will be NULL */\n\tif (unlikely(!head))\n\t\treturn true;\n\n\treturn reader->read == rb_page_commit(reader) &&\n\t\t(commit == reader ||\n\t\t (commit == head &&\n\t\t  head->read == rb_page_commit(commit)));\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_reader_lock",
          "args": [
            "cpu_buffer"
          ],
          "line": 4416
        },
        "resolved": true,
        "details": {
          "function_name": "rb_reader_lock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3995-4017",
          "snippet": "static inline bool rb_reader_lock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tif (likely(!in_nmi())) {\n\t\traw_spin_lock(&cpu_buffer->reader_lock);\n\t\treturn true;\n\t}\n\n\t/*\n\t * If an NMI die dumps out the content of the ring buffer\n\t * trylock must be used to prevent a deadlock if the NMI\n\t * preempted a task that holds the ring buffer locks. If\n\t * we get the lock then all is fine, if not, then continue\n\t * to do the read, but this can corrupt the ring buffer,\n\t * so it must be permanently disabled from future writes.\n\t * Reading from NMI is a oneshot deal.\n\t */\n\tif (raw_spin_trylock(&cpu_buffer->reader_lock))\n\t\treturn true;\n\n\t/* Continue without locking, but disable the ring buffer */\n\tatomic_inc(&cpu_buffer->record_disabled);\n\treturn false;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline bool rb_reader_lock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tif (likely(!in_nmi())) {\n\t\traw_spin_lock(&cpu_buffer->reader_lock);\n\t\treturn true;\n\t}\n\n\t/*\n\t * If an NMI die dumps out the content of the ring buffer\n\t * trylock must be used to prevent a deadlock if the NMI\n\t * preempted a task that holds the ring buffer locks. If\n\t * we get the lock then all is fine, if not, then continue\n\t * to do the read, but this can corrupt the ring buffer,\n\t * so it must be permanently disabled from future writes.\n\t * Reading from NMI is a oneshot deal.\n\t */\n\tif (raw_spin_trylock(&cpu_buffer->reader_lock))\n\t\treturn true;\n\n\t/* Continue without locking, but disable the ring buffer */\n\tatomic_inc(&cpu_buffer->record_disabled);\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_irq_save",
          "args": [
            "flags"
          ],
          "line": 4415
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "for_each_buffer_cpu",
          "args": [
            "buffer",
            "cpu"
          ],
          "line": 4413
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nbool ring_buffer_empty(struct ring_buffer *buffer)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long flags;\n\tbool dolock;\n\tint cpu;\n\tint ret;\n\n\t/* yes this is racy, but if you don't like the race, lock the buffer */\n\tfor_each_buffer_cpu(buffer, cpu) {\n\t\tcpu_buffer = buffer->buffers[cpu];\n\t\tlocal_irq_save(flags);\n\t\tdolock = rb_reader_lock(cpu_buffer);\n\t\tret = rb_per_cpu_empty(cpu_buffer);\n\t\trb_reader_unlock(cpu_buffer, dolock);\n\t\tlocal_irq_restore(flags);\n\n\t\tif (!ret)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}"
  },
  {
    "function_name": "ring_buffer_reset",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "4391-4397",
    "snippet": "void ring_buffer_reset(struct ring_buffer *buffer)\n{\n\tint cpu;\n\n\tfor_each_buffer_cpu(buffer, cpu)\n\t\tring_buffer_reset_cpu(buffer, cpu);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "ring_buffer_reset_cpu",
          "args": [
            "buffer",
            "cpu"
          ],
          "line": 4396
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_reset_cpu",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "4354-4384",
          "snippet": "void ring_buffer_reset_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = buffer->buffers[cpu];\n\tunsigned long flags;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn;\n\n\tatomic_inc(&buffer->resize_disabled);\n\tatomic_inc(&cpu_buffer->record_disabled);\n\n\t/* Make sure all commits have finished */\n\tsynchronize_sched();\n\n\traw_spin_lock_irqsave(&cpu_buffer->reader_lock, flags);\n\n\tif (RB_WARN_ON(cpu_buffer, local_read(&cpu_buffer->committing)))\n\t\tgoto out;\n\n\tarch_spin_lock(&cpu_buffer->lock);\n\n\trb_reset_cpu(cpu_buffer);\n\n\tarch_spin_unlock(&cpu_buffer->lock);\n\n out:\n\traw_spin_unlock_irqrestore(&cpu_buffer->reader_lock, flags);\n\n\tatomic_dec(&cpu_buffer->record_disabled);\n\tatomic_dec(&buffer->resize_disabled);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid ring_buffer_reset_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = buffer->buffers[cpu];\n\tunsigned long flags;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn;\n\n\tatomic_inc(&buffer->resize_disabled);\n\tatomic_inc(&cpu_buffer->record_disabled);\n\n\t/* Make sure all commits have finished */\n\tsynchronize_sched();\n\n\traw_spin_lock_irqsave(&cpu_buffer->reader_lock, flags);\n\n\tif (RB_WARN_ON(cpu_buffer, local_read(&cpu_buffer->committing)))\n\t\tgoto out;\n\n\tarch_spin_lock(&cpu_buffer->lock);\n\n\trb_reset_cpu(cpu_buffer);\n\n\tarch_spin_unlock(&cpu_buffer->lock);\n\n out:\n\traw_spin_unlock_irqrestore(&cpu_buffer->reader_lock, flags);\n\n\tatomic_dec(&cpu_buffer->record_disabled);\n\tatomic_dec(&buffer->resize_disabled);\n}"
        }
      },
      {
        "call_info": {
          "callee": "for_each_buffer_cpu",
          "args": [
            "buffer",
            "cpu"
          ],
          "line": 4395
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid ring_buffer_reset(struct ring_buffer *buffer)\n{\n\tint cpu;\n\n\tfor_each_buffer_cpu(buffer, cpu)\n\t\tring_buffer_reset_cpu(buffer, cpu);\n}"
  },
  {
    "function_name": "ring_buffer_reset_cpu",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "4354-4384",
    "snippet": "void ring_buffer_reset_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = buffer->buffers[cpu];\n\tunsigned long flags;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn;\n\n\tatomic_inc(&buffer->resize_disabled);\n\tatomic_inc(&cpu_buffer->record_disabled);\n\n\t/* Make sure all commits have finished */\n\tsynchronize_sched();\n\n\traw_spin_lock_irqsave(&cpu_buffer->reader_lock, flags);\n\n\tif (RB_WARN_ON(cpu_buffer, local_read(&cpu_buffer->committing)))\n\t\tgoto out;\n\n\tarch_spin_lock(&cpu_buffer->lock);\n\n\trb_reset_cpu(cpu_buffer);\n\n\tarch_spin_unlock(&cpu_buffer->lock);\n\n out:\n\traw_spin_unlock_irqrestore(&cpu_buffer->reader_lock, flags);\n\n\tatomic_dec(&cpu_buffer->record_disabled);\n\tatomic_dec(&buffer->resize_disabled);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_dec",
          "args": [
            "&buffer->resize_disabled"
          ],
          "line": 4383
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_dec",
          "args": [
            "&cpu_buffer->record_disabled"
          ],
          "line": 4382
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore",
          "args": [
            "&cpu_buffer->reader_lock",
            "flags"
          ],
          "line": 4380
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_irqrestore",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "182-185",
          "snippet": "void __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "arch_spin_unlock",
          "args": [
            "&cpu_buffer->lock"
          ],
          "line": 4377
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_reset_cpu",
          "args": [
            "cpu_buffer"
          ],
          "line": 4375
        },
        "resolved": true,
        "details": {
          "function_name": "rb_reset_cpu",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "4307-4347",
          "snippet": "static void\nrb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\trb_head_page_deactivate(cpu_buffer);\n\n\tcpu_buffer->head_page\n\t\t= list_entry(cpu_buffer->pages, struct buffer_page, list);\n\tlocal_set(&cpu_buffer->head_page->write, 0);\n\tlocal_set(&cpu_buffer->head_page->entries, 0);\n\tlocal_set(&cpu_buffer->head_page->page->commit, 0);\n\n\tcpu_buffer->head_page->read = 0;\n\n\tcpu_buffer->tail_page = cpu_buffer->head_page;\n\tcpu_buffer->commit_page = cpu_buffer->head_page;\n\n\tINIT_LIST_HEAD(&cpu_buffer->reader_page->list);\n\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\tlocal_set(&cpu_buffer->reader_page->write, 0);\n\tlocal_set(&cpu_buffer->reader_page->entries, 0);\n\tlocal_set(&cpu_buffer->reader_page->page->commit, 0);\n\tcpu_buffer->reader_page->read = 0;\n\n\tlocal_set(&cpu_buffer->entries_bytes, 0);\n\tlocal_set(&cpu_buffer->overrun, 0);\n\tlocal_set(&cpu_buffer->commit_overrun, 0);\n\tlocal_set(&cpu_buffer->dropped_events, 0);\n\tlocal_set(&cpu_buffer->entries, 0);\n\tlocal_set(&cpu_buffer->committing, 0);\n\tlocal_set(&cpu_buffer->commits, 0);\n\tcpu_buffer->read = 0;\n\tcpu_buffer->read_bytes = 0;\n\n\tcpu_buffer->write_stamp = 0;\n\tcpu_buffer->read_stamp = 0;\n\n\tcpu_buffer->lost_events = 0;\n\tcpu_buffer->last_overrun = 0;\n\n\trb_head_page_activate(cpu_buffer);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void\nrb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\trb_head_page_deactivate(cpu_buffer);\n\n\tcpu_buffer->head_page\n\t\t= list_entry(cpu_buffer->pages, struct buffer_page, list);\n\tlocal_set(&cpu_buffer->head_page->write, 0);\n\tlocal_set(&cpu_buffer->head_page->entries, 0);\n\tlocal_set(&cpu_buffer->head_page->page->commit, 0);\n\n\tcpu_buffer->head_page->read = 0;\n\n\tcpu_buffer->tail_page = cpu_buffer->head_page;\n\tcpu_buffer->commit_page = cpu_buffer->head_page;\n\n\tINIT_LIST_HEAD(&cpu_buffer->reader_page->list);\n\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\tlocal_set(&cpu_buffer->reader_page->write, 0);\n\tlocal_set(&cpu_buffer->reader_page->entries, 0);\n\tlocal_set(&cpu_buffer->reader_page->page->commit, 0);\n\tcpu_buffer->reader_page->read = 0;\n\n\tlocal_set(&cpu_buffer->entries_bytes, 0);\n\tlocal_set(&cpu_buffer->overrun, 0);\n\tlocal_set(&cpu_buffer->commit_overrun, 0);\n\tlocal_set(&cpu_buffer->dropped_events, 0);\n\tlocal_set(&cpu_buffer->entries, 0);\n\tlocal_set(&cpu_buffer->committing, 0);\n\tlocal_set(&cpu_buffer->commits, 0);\n\tcpu_buffer->read = 0;\n\tcpu_buffer->read_bytes = 0;\n\n\tcpu_buffer->write_stamp = 0;\n\tcpu_buffer->read_stamp = 0;\n\n\tcpu_buffer->lost_events = 0;\n\tcpu_buffer->last_overrun = 0;\n\n\trb_head_page_activate(cpu_buffer);\n}"
        }
      },
      {
        "call_info": {
          "callee": "arch_spin_lock",
          "args": [
            "&cpu_buffer->lock"
          ],
          "line": 4373
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "local_read(&cpu_buffer->committing)"
          ],
          "line": 4370
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_read",
          "args": [
            "&cpu_buffer->committing"
          ],
          "line": 4370
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irqsave",
          "args": [
            "&cpu_buffer->reader_lock",
            "flags"
          ],
          "line": 4368
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_irqsave_nested",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "359-370",
          "snippet": "unsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED_FLAGS(lock, do_raw_spin_trylock, do_raw_spin_lock,\n\t\t\t\tdo_raw_spin_lock_flags, &flags);\n\treturn flags;\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nunsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED_FLAGS(lock, do_raw_spin_trylock, do_raw_spin_lock,\n\t\t\t\tdo_raw_spin_lock_flags, &flags);\n\treturn flags;\n}"
        }
      },
      {
        "call_info": {
          "callee": "synchronize_sched",
          "args": [],
          "line": 4366
        },
        "resolved": true,
        "details": {
          "function_name": "synchronize_sched_expedited_wait",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/tree_exp.h",
          "lines": "468-540",
          "snippet": "static void synchronize_sched_expedited_wait(void)\n{\n\tint cpu;\n\tunsigned long jiffies_stall;\n\tunsigned long jiffies_start;\n\tunsigned long mask;\n\tint ndetected;\n\tstruct rcu_node *rnp;\n\tstruct rcu_node *rnp_root = rcu_get_root();\n\tint ret;\n\n\ttrace_rcu_exp_grace_period(rcu_state.name, rcu_exp_gp_seq_endval(), TPS(\"startwait\"));\n\tjiffies_stall = rcu_jiffies_till_stall_check();\n\tjiffies_start = jiffies;\n\n\tfor (;;) {\n\t\tret = swait_event_timeout_exclusive(\n\t\t\t\trcu_state.expedited_wq,\n\t\t\t\tsync_rcu_preempt_exp_done_unlocked(rnp_root),\n\t\t\t\tjiffies_stall);\n\t\tif (ret > 0 || sync_rcu_preempt_exp_done_unlocked(rnp_root))\n\t\t\treturn;\n\t\tWARN_ON(ret < 0);  /* workqueues should not be signaled. */\n\t\tif (rcu_cpu_stall_suppress)\n\t\t\tcontinue;\n\t\tpanic_on_rcu_stall();\n\t\tpr_err(\"INFO: %s detected expedited stalls on CPUs/tasks: {\",\n\t\t       rcu_state.name);\n\t\tndetected = 0;\n\t\trcu_for_each_leaf_node(rnp) {\n\t\t\tndetected += rcu_print_task_exp_stall(rnp);\n\t\t\tfor_each_leaf_node_possible_cpu(rnp, cpu) {\n\t\t\t\tstruct rcu_data *rdp;\n\n\t\t\t\tmask = leaf_node_cpu_bit(rnp, cpu);\n\t\t\t\tif (!(rnp->expmask & mask))\n\t\t\t\t\tcontinue;\n\t\t\t\tndetected++;\n\t\t\t\trdp = per_cpu_ptr(&rcu_data, cpu);\n\t\t\t\tpr_cont(\" %d-%c%c%c\", cpu,\n\t\t\t\t\t\"O.\"[!!cpu_online(cpu)],\n\t\t\t\t\t\"o.\"[!!(rdp->grpmask & rnp->expmaskinit)],\n\t\t\t\t\t\"N.\"[!!(rdp->grpmask & rnp->expmaskinitnext)]);\n\t\t\t}\n\t\t}\n\t\tpr_cont(\" } %lu jiffies s: %lu root: %#lx/%c\\n\",\n\t\t\tjiffies - jiffies_start, rcu_state.expedited_sequence,\n\t\t\trnp_root->expmask, \".T\"[!!rnp_root->exp_tasks]);\n\t\tif (ndetected) {\n\t\t\tpr_err(\"blocking rcu_node structures:\");\n\t\t\trcu_for_each_node_breadth_first(rnp) {\n\t\t\t\tif (rnp == rnp_root)\n\t\t\t\t\tcontinue; /* printed unconditionally */\n\t\t\t\tif (sync_rcu_preempt_exp_done_unlocked(rnp))\n\t\t\t\t\tcontinue;\n\t\t\t\tpr_cont(\" l=%u:%d-%d:%#lx/%c\",\n\t\t\t\t\trnp->level, rnp->grplo, rnp->grphi,\n\t\t\t\t\trnp->expmask,\n\t\t\t\t\t\".T\"[!!rnp->exp_tasks]);\n\t\t\t}\n\t\t\tpr_cont(\"\\n\");\n\t\t}\n\t\trcu_for_each_leaf_node(rnp) {\n\t\t\tfor_each_leaf_node_possible_cpu(rnp, cpu) {\n\t\t\t\tmask = leaf_node_cpu_bit(rnp, cpu);\n\t\t\t\tif (!(rnp->expmask & mask))\n\t\t\t\t\tcontinue;\n\t\t\t\tdump_cpu_task(cpu);\n\t\t\t}\n\t\t}\n\t\tjiffies_stall = 3 * rcu_jiffies_till_stall_check() + 3;\n\t}\n}",
          "includes": [
            "#include <linux/lockdep.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/lockdep.h>\n\nstatic void synchronize_sched_expedited_wait(void)\n{\n\tint cpu;\n\tunsigned long jiffies_stall;\n\tunsigned long jiffies_start;\n\tunsigned long mask;\n\tint ndetected;\n\tstruct rcu_node *rnp;\n\tstruct rcu_node *rnp_root = rcu_get_root();\n\tint ret;\n\n\ttrace_rcu_exp_grace_period(rcu_state.name, rcu_exp_gp_seq_endval(), TPS(\"startwait\"));\n\tjiffies_stall = rcu_jiffies_till_stall_check();\n\tjiffies_start = jiffies;\n\n\tfor (;;) {\n\t\tret = swait_event_timeout_exclusive(\n\t\t\t\trcu_state.expedited_wq,\n\t\t\t\tsync_rcu_preempt_exp_done_unlocked(rnp_root),\n\t\t\t\tjiffies_stall);\n\t\tif (ret > 0 || sync_rcu_preempt_exp_done_unlocked(rnp_root))\n\t\t\treturn;\n\t\tWARN_ON(ret < 0);  /* workqueues should not be signaled. */\n\t\tif (rcu_cpu_stall_suppress)\n\t\t\tcontinue;\n\t\tpanic_on_rcu_stall();\n\t\tpr_err(\"INFO: %s detected expedited stalls on CPUs/tasks: {\",\n\t\t       rcu_state.name);\n\t\tndetected = 0;\n\t\trcu_for_each_leaf_node(rnp) {\n\t\t\tndetected += rcu_print_task_exp_stall(rnp);\n\t\t\tfor_each_leaf_node_possible_cpu(rnp, cpu) {\n\t\t\t\tstruct rcu_data *rdp;\n\n\t\t\t\tmask = leaf_node_cpu_bit(rnp, cpu);\n\t\t\t\tif (!(rnp->expmask & mask))\n\t\t\t\t\tcontinue;\n\t\t\t\tndetected++;\n\t\t\t\trdp = per_cpu_ptr(&rcu_data, cpu);\n\t\t\t\tpr_cont(\" %d-%c%c%c\", cpu,\n\t\t\t\t\t\"O.\"[!!cpu_online(cpu)],\n\t\t\t\t\t\"o.\"[!!(rdp->grpmask & rnp->expmaskinit)],\n\t\t\t\t\t\"N.\"[!!(rdp->grpmask & rnp->expmaskinitnext)]);\n\t\t\t}\n\t\t}\n\t\tpr_cont(\" } %lu jiffies s: %lu root: %#lx/%c\\n\",\n\t\t\tjiffies - jiffies_start, rcu_state.expedited_sequence,\n\t\t\trnp_root->expmask, \".T\"[!!rnp_root->exp_tasks]);\n\t\tif (ndetected) {\n\t\t\tpr_err(\"blocking rcu_node structures:\");\n\t\t\trcu_for_each_node_breadth_first(rnp) {\n\t\t\t\tif (rnp == rnp_root)\n\t\t\t\t\tcontinue; /* printed unconditionally */\n\t\t\t\tif (sync_rcu_preempt_exp_done_unlocked(rnp))\n\t\t\t\t\tcontinue;\n\t\t\t\tpr_cont(\" l=%u:%d-%d:%#lx/%c\",\n\t\t\t\t\trnp->level, rnp->grplo, rnp->grphi,\n\t\t\t\t\trnp->expmask,\n\t\t\t\t\t\".T\"[!!rnp->exp_tasks]);\n\t\t\t}\n\t\t\tpr_cont(\"\\n\");\n\t\t}\n\t\trcu_for_each_leaf_node(rnp) {\n\t\t\tfor_each_leaf_node_possible_cpu(rnp, cpu) {\n\t\t\t\tmask = leaf_node_cpu_bit(rnp, cpu);\n\t\t\t\tif (!(rnp->expmask & mask))\n\t\t\t\t\tcontinue;\n\t\t\t\tdump_cpu_task(cpu);\n\t\t\t}\n\t\t}\n\t\tjiffies_stall = 3 * rcu_jiffies_till_stall_check() + 3;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_inc",
          "args": [
            "&cpu_buffer->record_disabled"
          ],
          "line": 4363
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_inc",
          "args": [
            "&buffer->resize_disabled"
          ],
          "line": 4362
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "buffer->cpumask"
          ],
          "line": 4359
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid ring_buffer_reset_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = buffer->buffers[cpu];\n\tunsigned long flags;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn;\n\n\tatomic_inc(&buffer->resize_disabled);\n\tatomic_inc(&cpu_buffer->record_disabled);\n\n\t/* Make sure all commits have finished */\n\tsynchronize_sched();\n\n\traw_spin_lock_irqsave(&cpu_buffer->reader_lock, flags);\n\n\tif (RB_WARN_ON(cpu_buffer, local_read(&cpu_buffer->committing)))\n\t\tgoto out;\n\n\tarch_spin_lock(&cpu_buffer->lock);\n\n\trb_reset_cpu(cpu_buffer);\n\n\tarch_spin_unlock(&cpu_buffer->lock);\n\n out:\n\traw_spin_unlock_irqrestore(&cpu_buffer->reader_lock, flags);\n\n\tatomic_dec(&cpu_buffer->record_disabled);\n\tatomic_dec(&buffer->resize_disabled);\n}"
  },
  {
    "function_name": "rb_reset_cpu",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "4307-4347",
    "snippet": "static void\nrb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\trb_head_page_deactivate(cpu_buffer);\n\n\tcpu_buffer->head_page\n\t\t= list_entry(cpu_buffer->pages, struct buffer_page, list);\n\tlocal_set(&cpu_buffer->head_page->write, 0);\n\tlocal_set(&cpu_buffer->head_page->entries, 0);\n\tlocal_set(&cpu_buffer->head_page->page->commit, 0);\n\n\tcpu_buffer->head_page->read = 0;\n\n\tcpu_buffer->tail_page = cpu_buffer->head_page;\n\tcpu_buffer->commit_page = cpu_buffer->head_page;\n\n\tINIT_LIST_HEAD(&cpu_buffer->reader_page->list);\n\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\tlocal_set(&cpu_buffer->reader_page->write, 0);\n\tlocal_set(&cpu_buffer->reader_page->entries, 0);\n\tlocal_set(&cpu_buffer->reader_page->page->commit, 0);\n\tcpu_buffer->reader_page->read = 0;\n\n\tlocal_set(&cpu_buffer->entries_bytes, 0);\n\tlocal_set(&cpu_buffer->overrun, 0);\n\tlocal_set(&cpu_buffer->commit_overrun, 0);\n\tlocal_set(&cpu_buffer->dropped_events, 0);\n\tlocal_set(&cpu_buffer->entries, 0);\n\tlocal_set(&cpu_buffer->committing, 0);\n\tlocal_set(&cpu_buffer->commits, 0);\n\tcpu_buffer->read = 0;\n\tcpu_buffer->read_bytes = 0;\n\n\tcpu_buffer->write_stamp = 0;\n\tcpu_buffer->read_stamp = 0;\n\n\tcpu_buffer->lost_events = 0;\n\tcpu_buffer->last_overrun = 0;\n\n\trb_head_page_activate(cpu_buffer);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_head_page_activate",
          "args": [
            "cpu_buffer"
          ],
          "line": 4346
        },
        "resolved": true,
        "details": {
          "function_name": "rb_head_page_activate",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "888-900",
          "snippet": "static void rb_head_page_activate(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *head;\n\n\thead = cpu_buffer->head_page;\n\tif (!head)\n\t\treturn;\n\n\t/*\n\t * Set the previous list pointer to have the HEAD flag.\n\t */\n\trb_set_list_to_head(cpu_buffer, head->list.prev);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_head_page_activate(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *head;\n\n\thead = cpu_buffer->head_page;\n\tif (!head)\n\t\treturn;\n\n\t/*\n\t * Set the previous list pointer to have the HEAD flag.\n\t */\n\trb_set_list_to_head(cpu_buffer, head->list.prev);\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_set",
          "args": [
            "&cpu_buffer->commits",
            "0"
          ],
          "line": 4336
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_set",
          "args": [
            "&cpu_buffer->committing",
            "0"
          ],
          "line": 4335
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_set",
          "args": [
            "&cpu_buffer->entries",
            "0"
          ],
          "line": 4334
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_set",
          "args": [
            "&cpu_buffer->dropped_events",
            "0"
          ],
          "line": 4333
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_set",
          "args": [
            "&cpu_buffer->commit_overrun",
            "0"
          ],
          "line": 4332
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_set",
          "args": [
            "&cpu_buffer->overrun",
            "0"
          ],
          "line": 4331
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_set",
          "args": [
            "&cpu_buffer->entries_bytes",
            "0"
          ],
          "line": 4330
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_set",
          "args": [
            "&cpu_buffer->reader_page->page->commit",
            "0"
          ],
          "line": 4327
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_set",
          "args": [
            "&cpu_buffer->reader_page->entries",
            "0"
          ],
          "line": 4326
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_set",
          "args": [
            "&cpu_buffer->reader_page->write",
            "0"
          ],
          "line": 4325
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "INIT_LIST_HEAD",
          "args": [
            "&cpu_buffer->new_pages"
          ],
          "line": 4324
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "INIT_LIST_HEAD",
          "args": [
            "&cpu_buffer->reader_page->list"
          ],
          "line": 4323
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_set",
          "args": [
            "&cpu_buffer->head_page->page->commit",
            "0"
          ],
          "line": 4316
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_set",
          "args": [
            "&cpu_buffer->head_page->entries",
            "0"
          ],
          "line": 4315
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_set",
          "args": [
            "&cpu_buffer->head_page->write",
            "0"
          ],
          "line": 4314
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_entry",
          "args": [
            "cpu_buffer->pages",
            "structbuffer_page",
            "list"
          ],
          "line": 4313
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_head_page_deactivate",
          "args": [
            "cpu_buffer"
          ],
          "line": 4310
        },
        "resolved": true,
        "details": {
          "function_name": "rb_head_page_deactivate",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "912-922",
          "snippet": "static void\nrb_head_page_deactivate(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *hd;\n\n\t/* Go through the whole list and clear any pointers found. */\n\trb_list_head_clear(cpu_buffer->pages);\n\n\tlist_for_each(hd, cpu_buffer->pages)\n\t\trb_list_head_clear(hd);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void\nrb_head_page_deactivate(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *hd;\n\n\t/* Go through the whole list and clear any pointers found. */\n\trb_list_head_clear(cpu_buffer->pages);\n\n\tlist_for_each(hd, cpu_buffer->pages)\n\t\trb_list_head_clear(hd);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void\nrb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\trb_head_page_deactivate(cpu_buffer);\n\n\tcpu_buffer->head_page\n\t\t= list_entry(cpu_buffer->pages, struct buffer_page, list);\n\tlocal_set(&cpu_buffer->head_page->write, 0);\n\tlocal_set(&cpu_buffer->head_page->entries, 0);\n\tlocal_set(&cpu_buffer->head_page->page->commit, 0);\n\n\tcpu_buffer->head_page->read = 0;\n\n\tcpu_buffer->tail_page = cpu_buffer->head_page;\n\tcpu_buffer->commit_page = cpu_buffer->head_page;\n\n\tINIT_LIST_HEAD(&cpu_buffer->reader_page->list);\n\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\tlocal_set(&cpu_buffer->reader_page->write, 0);\n\tlocal_set(&cpu_buffer->reader_page->entries, 0);\n\tlocal_set(&cpu_buffer->reader_page->page->commit, 0);\n\tcpu_buffer->reader_page->read = 0;\n\n\tlocal_set(&cpu_buffer->entries_bytes, 0);\n\tlocal_set(&cpu_buffer->overrun, 0);\n\tlocal_set(&cpu_buffer->commit_overrun, 0);\n\tlocal_set(&cpu_buffer->dropped_events, 0);\n\tlocal_set(&cpu_buffer->entries, 0);\n\tlocal_set(&cpu_buffer->committing, 0);\n\tlocal_set(&cpu_buffer->commits, 0);\n\tcpu_buffer->read = 0;\n\tcpu_buffer->read_bytes = 0;\n\n\tcpu_buffer->write_stamp = 0;\n\tcpu_buffer->read_stamp = 0;\n\n\tcpu_buffer->lost_events = 0;\n\tcpu_buffer->last_overrun = 0;\n\n\trb_head_page_activate(cpu_buffer);\n}"
  },
  {
    "function_name": "ring_buffer_size",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "4292-4304",
    "snippet": "unsigned long ring_buffer_size(struct ring_buffer *buffer, int cpu)\n{\n\t/*\n\t * Earlier, this method returned\n\t *\tBUF_PAGE_SIZE * buffer->nr_pages\n\t * Since the nr_pages field is now removed, we have converted this to\n\t * return the per cpu buffer value.\n\t */\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn 0;\n\n\treturn BUF_PAGE_SIZE * buffer->buffers[cpu]->nr_pages;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)"
    ],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "buffer->cpumask"
          ],
          "line": 4300
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nunsigned long ring_buffer_size(struct ring_buffer *buffer, int cpu)\n{\n\t/*\n\t * Earlier, this method returned\n\t *\tBUF_PAGE_SIZE * buffer->nr_pages\n\t * Since the nr_pages field is now removed, we have converted this to\n\t * return the per cpu buffer value.\n\t */\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn 0;\n\n\treturn BUF_PAGE_SIZE * buffer->buffers[cpu]->nr_pages;\n}"
  },
  {
    "function_name": "ring_buffer_read",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "4264-4285",
    "snippet": "struct ring_buffer_event *\nring_buffer_read(struct ring_buffer_iter *iter, u64 *ts)\n{\n\tstruct ring_buffer_event *event;\n\tstruct ring_buffer_per_cpu *cpu_buffer = iter->cpu_buffer;\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&cpu_buffer->reader_lock, flags);\n again:\n\tevent = rb_iter_peek(iter, ts);\n\tif (!event)\n\t\tgoto out;\n\n\tif (event->type_len == RINGBUF_TYPE_PADDING)\n\t\tgoto again;\n\n\trb_advance_iter(iter);\n out:\n\traw_spin_unlock_irqrestore(&cpu_buffer->reader_lock, flags);\n\n\treturn event;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore",
          "args": [
            "&cpu_buffer->reader_lock",
            "flags"
          ],
          "line": 4282
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_irqrestore",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "182-185",
          "snippet": "void __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_advance_iter",
          "args": [
            "iter"
          ],
          "line": 4280
        },
        "resolved": true,
        "details": {
          "function_name": "rb_advance_iter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3787-3827",
          "snippet": "static void rb_advance_iter(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct ring_buffer_event *event;\n\tunsigned length;\n\n\tcpu_buffer = iter->cpu_buffer;\n\n\t/*\n\t * Check if we are at the end of the buffer.\n\t */\n\tif (iter->head >= rb_page_size(iter->head_page)) {\n\t\t/* discarded commits can make the page empty */\n\t\tif (iter->head_page == cpu_buffer->commit_page)\n\t\t\treturn;\n\t\trb_inc_iter(iter);\n\t\treturn;\n\t}\n\n\tevent = rb_iter_head_event(iter);\n\n\tlength = rb_event_length(event);\n\n\t/*\n\t * This should not be called to advance the header if we are\n\t * at the tail of the buffer.\n\t */\n\tif (RB_WARN_ON(cpu_buffer,\n\t\t       (iter->head_page == cpu_buffer->commit_page) &&\n\t\t       (iter->head + length > rb_commit_index(cpu_buffer))))\n\t\treturn;\n\n\trb_update_iter_read_stamp(iter, event);\n\n\titer->head += length;\n\n\t/* check for end of page padding */\n\tif ((iter->head >= rb_page_size(iter->head_page)) &&\n\t    (iter->head_page != cpu_buffer->commit_page))\n\t\trb_inc_iter(iter);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic void rb_advance_iter(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct ring_buffer_event *event;\n\tunsigned length;\n\n\tcpu_buffer = iter->cpu_buffer;\n\n\t/*\n\t * Check if we are at the end of the buffer.\n\t */\n\tif (iter->head >= rb_page_size(iter->head_page)) {\n\t\t/* discarded commits can make the page empty */\n\t\tif (iter->head_page == cpu_buffer->commit_page)\n\t\t\treturn;\n\t\trb_inc_iter(iter);\n\t\treturn;\n\t}\n\n\tevent = rb_iter_head_event(iter);\n\n\tlength = rb_event_length(event);\n\n\t/*\n\t * This should not be called to advance the header if we are\n\t * at the tail of the buffer.\n\t */\n\tif (RB_WARN_ON(cpu_buffer,\n\t\t       (iter->head_page == cpu_buffer->commit_page) &&\n\t\t       (iter->head + length > rb_commit_index(cpu_buffer))))\n\t\treturn;\n\n\trb_update_iter_read_stamp(iter, event);\n\n\titer->head += length;\n\n\t/* check for end of page padding */\n\tif ((iter->head >= rb_page_size(iter->head_page)) &&\n\t    (iter->head_page != cpu_buffer->commit_page))\n\t\trb_inc_iter(iter);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_iter_peek",
          "args": [
            "iter",
            "ts"
          ],
          "line": 4273
        },
        "resolved": true,
        "details": {
          "function_name": "rb_iter_peek",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3907-3992",
          "snippet": "static struct ring_buffer_event *\nrb_iter_peek(struct ring_buffer_iter *iter, u64 *ts)\n{\n\tstruct ring_buffer *buffer;\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct ring_buffer_event *event;\n\tint nr_loops = 0;\n\n\tif (ts)\n\t\t*ts = 0;\n\n\tcpu_buffer = iter->cpu_buffer;\n\tbuffer = cpu_buffer->buffer;\n\n\t/*\n\t * Check if someone performed a consuming read to\n\t * the buffer. A consuming read invalidates the iterator\n\t * and we need to reset the iterator in this case.\n\t */\n\tif (unlikely(iter->cache_read != cpu_buffer->read ||\n\t\t     iter->cache_reader_page != cpu_buffer->reader_page))\n\t\trb_iter_reset(iter);\n\n again:\n\tif (ring_buffer_iter_empty(iter))\n\t\treturn NULL;\n\n\t/*\n\t * We repeat when a time extend is encountered or we hit\n\t * the end of the page. Since the time extend is always attached\n\t * to a data event, we should never loop more than three times.\n\t * Once for going to next page, once on time extend, and\n\t * finally once to get the event.\n\t * (We never hit the following condition more than thrice).\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 3))\n\t\treturn NULL;\n\n\tif (rb_per_cpu_empty(cpu_buffer))\n\t\treturn NULL;\n\n\tif (iter->head >= rb_page_size(iter->head_page)) {\n\t\trb_inc_iter(iter);\n\t\tgoto again;\n\t}\n\n\tevent = rb_iter_head_event(iter);\n\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event)) {\n\t\t\trb_inc_iter(iter);\n\t\t\tgoto again;\n\t\t}\n\t\trb_advance_iter(iter);\n\t\treturn event;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\t/* Internal data, OK to advance */\n\t\trb_advance_iter(iter);\n\t\tgoto again;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\tif (ts) {\n\t\t\t*ts = ring_buffer_event_time_stamp(event);\n\t\t\tring_buffer_normalize_time_stamp(cpu_buffer->buffer,\n\t\t\t\t\t\t\t cpu_buffer->cpu, ts);\n\t\t}\n\t\t/* Internal data, OK to advance */\n\t\trb_advance_iter(iter);\n\t\tgoto again;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\tif (ts && !(*ts)) {\n\t\t\t*ts = iter->read_stamp + event->time_delta;\n\t\t\tring_buffer_normalize_time_stamp(buffer,\n\t\t\t\t\t\t\t cpu_buffer->cpu, ts);\n\t\t}\n\t\treturn event;\n\n\tdefault:\n\t\tBUG();\n\t}\n\n\treturn NULL;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic struct ring_buffer_event *\nrb_iter_peek(struct ring_buffer_iter *iter, u64 *ts)\n{\n\tstruct ring_buffer *buffer;\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct ring_buffer_event *event;\n\tint nr_loops = 0;\n\n\tif (ts)\n\t\t*ts = 0;\n\n\tcpu_buffer = iter->cpu_buffer;\n\tbuffer = cpu_buffer->buffer;\n\n\t/*\n\t * Check if someone performed a consuming read to\n\t * the buffer. A consuming read invalidates the iterator\n\t * and we need to reset the iterator in this case.\n\t */\n\tif (unlikely(iter->cache_read != cpu_buffer->read ||\n\t\t     iter->cache_reader_page != cpu_buffer->reader_page))\n\t\trb_iter_reset(iter);\n\n again:\n\tif (ring_buffer_iter_empty(iter))\n\t\treturn NULL;\n\n\t/*\n\t * We repeat when a time extend is encountered or we hit\n\t * the end of the page. Since the time extend is always attached\n\t * to a data event, we should never loop more than three times.\n\t * Once for going to next page, once on time extend, and\n\t * finally once to get the event.\n\t * (We never hit the following condition more than thrice).\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 3))\n\t\treturn NULL;\n\n\tif (rb_per_cpu_empty(cpu_buffer))\n\t\treturn NULL;\n\n\tif (iter->head >= rb_page_size(iter->head_page)) {\n\t\trb_inc_iter(iter);\n\t\tgoto again;\n\t}\n\n\tevent = rb_iter_head_event(iter);\n\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event)) {\n\t\t\trb_inc_iter(iter);\n\t\t\tgoto again;\n\t\t}\n\t\trb_advance_iter(iter);\n\t\treturn event;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\t/* Internal data, OK to advance */\n\t\trb_advance_iter(iter);\n\t\tgoto again;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\tif (ts) {\n\t\t\t*ts = ring_buffer_event_time_stamp(event);\n\t\t\tring_buffer_normalize_time_stamp(cpu_buffer->buffer,\n\t\t\t\t\t\t\t cpu_buffer->cpu, ts);\n\t\t}\n\t\t/* Internal data, OK to advance */\n\t\trb_advance_iter(iter);\n\t\tgoto again;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\tif (ts && !(*ts)) {\n\t\t\t*ts = iter->read_stamp + event->time_delta;\n\t\t\tring_buffer_normalize_time_stamp(buffer,\n\t\t\t\t\t\t\t cpu_buffer->cpu, ts);\n\t\t}\n\t\treturn event;\n\n\tdefault:\n\t\tBUG();\n\t}\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irqsave",
          "args": [
            "&cpu_buffer->reader_lock",
            "flags"
          ],
          "line": 4271
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_irqsave_nested",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "359-370",
          "snippet": "unsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED_FLAGS(lock, do_raw_spin_trylock, do_raw_spin_lock,\n\t\t\t\tdo_raw_spin_lock_flags, &flags);\n\treturn flags;\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nunsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED_FLAGS(lock, do_raw_spin_trylock, do_raw_spin_lock,\n\t\t\t\tdo_raw_spin_lock_flags, &flags);\n\treturn flags;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstruct ring_buffer_event *\nring_buffer_read(struct ring_buffer_iter *iter, u64 *ts)\n{\n\tstruct ring_buffer_event *event;\n\tstruct ring_buffer_per_cpu *cpu_buffer = iter->cpu_buffer;\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&cpu_buffer->reader_lock, flags);\n again:\n\tevent = rb_iter_peek(iter, ts);\n\tif (!event)\n\t\tgoto out;\n\n\tif (event->type_len == RINGBUF_TYPE_PADDING)\n\t\tgoto again;\n\n\trb_advance_iter(iter);\n out:\n\traw_spin_unlock_irqrestore(&cpu_buffer->reader_lock, flags);\n\n\treturn event;\n}"
  },
  {
    "function_name": "ring_buffer_read_finish",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "4235-4254",
    "snippet": "void\nring_buffer_read_finish(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = iter->cpu_buffer;\n\tunsigned long flags;\n\n\t/*\n\t * Ring buffer is disabled from recording, here's a good place\n\t * to check the integrity of the ring buffer.\n\t * Must prevent readers from trying to read, as the check\n\t * clears the HEAD page and readers require it.\n\t */\n\traw_spin_lock_irqsave(&cpu_buffer->reader_lock, flags);\n\trb_check_pages(cpu_buffer);\n\traw_spin_unlock_irqrestore(&cpu_buffer->reader_lock, flags);\n\n\tatomic_dec(&cpu_buffer->record_disabled);\n\tatomic_dec(&cpu_buffer->buffer->resize_disabled);\n\tkfree(iter);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "iter"
          ],
          "line": 4253
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/params.c",
          "lines": "73-86",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_dec",
          "args": [
            "&cpu_buffer->buffer->resize_disabled"
          ],
          "line": 4252
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_dec",
          "args": [
            "&cpu_buffer->record_disabled"
          ],
          "line": 4251
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore",
          "args": [
            "&cpu_buffer->reader_lock",
            "flags"
          ],
          "line": 4249
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_irqrestore",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "182-185",
          "snippet": "void __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_check_pages",
          "args": [
            "cpu_buffer"
          ],
          "line": 4248
        },
        "resolved": true,
        "details": {
          "function_name": "rb_check_pages",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1129-1162",
          "snippet": "static int rb_check_pages(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *head = cpu_buffer->pages;\n\tstruct buffer_page *bpage, *tmp;\n\n\t/* Reset the head page if it exists */\n\tif (cpu_buffer->head_page)\n\t\trb_set_head_page(cpu_buffer);\n\n\trb_head_page_deactivate(cpu_buffer);\n\n\tif (RB_WARN_ON(cpu_buffer, head->next->prev != head))\n\t\treturn -1;\n\tif (RB_WARN_ON(cpu_buffer, head->prev->next != head))\n\t\treturn -1;\n\n\tif (rb_check_list(cpu_buffer, head))\n\t\treturn -1;\n\n\tlist_for_each_entry_safe(bpage, tmp, head, list) {\n\t\tif (RB_WARN_ON(cpu_buffer,\n\t\t\t       bpage->list.next->prev != &bpage->list))\n\t\t\treturn -1;\n\t\tif (RB_WARN_ON(cpu_buffer,\n\t\t\t       bpage->list.prev->next != &bpage->list))\n\t\t\treturn -1;\n\t\tif (rb_check_list(cpu_buffer, &bpage->list))\n\t\t\treturn -1;\n\t}\n\n\trb_head_page_activate(cpu_buffer);\n\n\treturn 0;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int rb_check_pages(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *head = cpu_buffer->pages;\n\tstruct buffer_page *bpage, *tmp;\n\n\t/* Reset the head page if it exists */\n\tif (cpu_buffer->head_page)\n\t\trb_set_head_page(cpu_buffer);\n\n\trb_head_page_deactivate(cpu_buffer);\n\n\tif (RB_WARN_ON(cpu_buffer, head->next->prev != head))\n\t\treturn -1;\n\tif (RB_WARN_ON(cpu_buffer, head->prev->next != head))\n\t\treturn -1;\n\n\tif (rb_check_list(cpu_buffer, head))\n\t\treturn -1;\n\n\tlist_for_each_entry_safe(bpage, tmp, head, list) {\n\t\tif (RB_WARN_ON(cpu_buffer,\n\t\t\t       bpage->list.next->prev != &bpage->list))\n\t\t\treturn -1;\n\t\tif (RB_WARN_ON(cpu_buffer,\n\t\t\t       bpage->list.prev->next != &bpage->list))\n\t\t\treturn -1;\n\t\tif (rb_check_list(cpu_buffer, &bpage->list))\n\t\t\treturn -1;\n\t}\n\n\trb_head_page_activate(cpu_buffer);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irqsave",
          "args": [
            "&cpu_buffer->reader_lock",
            "flags"
          ],
          "line": 4247
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_irqsave_nested",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "359-370",
          "snippet": "unsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED_FLAGS(lock, do_raw_spin_trylock, do_raw_spin_lock,\n\t\t\t\tdo_raw_spin_lock_flags, &flags);\n\treturn flags;\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nunsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED_FLAGS(lock, do_raw_spin_trylock, do_raw_spin_lock,\n\t\t\t\tdo_raw_spin_lock_flags, &flags);\n\treturn flags;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid\nring_buffer_read_finish(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = iter->cpu_buffer;\n\tunsigned long flags;\n\n\t/*\n\t * Ring buffer is disabled from recording, here's a good place\n\t * to check the integrity of the ring buffer.\n\t * Must prevent readers from trying to read, as the check\n\t * clears the HEAD page and readers require it.\n\t */\n\traw_spin_lock_irqsave(&cpu_buffer->reader_lock, flags);\n\trb_check_pages(cpu_buffer);\n\traw_spin_unlock_irqrestore(&cpu_buffer->reader_lock, flags);\n\n\tatomic_dec(&cpu_buffer->record_disabled);\n\tatomic_dec(&cpu_buffer->buffer->resize_disabled);\n\tkfree(iter);\n}"
  },
  {
    "function_name": "ring_buffer_read_start",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "4209-4225",
    "snippet": "void\nring_buffer_read_start(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long flags;\n\n\tif (!iter)\n\t\treturn;\n\n\tcpu_buffer = iter->cpu_buffer;\n\n\traw_spin_lock_irqsave(&cpu_buffer->reader_lock, flags);\n\tarch_spin_lock(&cpu_buffer->lock);\n\trb_iter_reset(iter);\n\tarch_spin_unlock(&cpu_buffer->lock);\n\traw_spin_unlock_irqrestore(&cpu_buffer->reader_lock, flags);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore",
          "args": [
            "&cpu_buffer->reader_lock",
            "flags"
          ],
          "line": 4224
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_irqrestore",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "182-185",
          "snippet": "void __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "arch_spin_unlock",
          "args": [
            "&cpu_buffer->lock"
          ],
          "line": 4223
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_iter_reset",
          "args": [
            "iter"
          ],
          "line": 4222
        },
        "resolved": true,
        "details": {
          "function_name": "rb_iter_reset",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3504-3519",
          "snippet": "static void rb_iter_reset(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = iter->cpu_buffer;\n\n\t/* Iterator usage is expected to have record disabled */\n\titer->head_page = cpu_buffer->reader_page;\n\titer->head = cpu_buffer->reader_page->read;\n\n\titer->cache_reader_page = iter->head_page;\n\titer->cache_read = cpu_buffer->read;\n\n\tif (iter->head)\n\t\titer->read_stamp = cpu_buffer->read_stamp;\n\telse\n\t\titer->read_stamp = iter->head_page->page->time_stamp;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_iter_reset(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = iter->cpu_buffer;\n\n\t/* Iterator usage is expected to have record disabled */\n\titer->head_page = cpu_buffer->reader_page;\n\titer->head = cpu_buffer->reader_page->read;\n\n\titer->cache_reader_page = iter->head_page;\n\titer->cache_read = cpu_buffer->read;\n\n\tif (iter->head)\n\t\titer->read_stamp = cpu_buffer->read_stamp;\n\telse\n\t\titer->read_stamp = iter->head_page->page->time_stamp;\n}"
        }
      },
      {
        "call_info": {
          "callee": "arch_spin_lock",
          "args": [
            "&cpu_buffer->lock"
          ],
          "line": 4221
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irqsave",
          "args": [
            "&cpu_buffer->reader_lock",
            "flags"
          ],
          "line": 4220
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_irqsave_nested",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "359-370",
          "snippet": "unsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED_FLAGS(lock, do_raw_spin_trylock, do_raw_spin_lock,\n\t\t\t\tdo_raw_spin_lock_flags, &flags);\n\treturn flags;\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nunsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED_FLAGS(lock, do_raw_spin_trylock, do_raw_spin_lock,\n\t\t\t\tdo_raw_spin_lock_flags, &flags);\n\treturn flags;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid\nring_buffer_read_start(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long flags;\n\n\tif (!iter)\n\t\treturn;\n\n\tcpu_buffer = iter->cpu_buffer;\n\n\traw_spin_lock_irqsave(&cpu_buffer->reader_lock, flags);\n\tarch_spin_lock(&cpu_buffer->lock);\n\trb_iter_reset(iter);\n\tarch_spin_unlock(&cpu_buffer->lock);\n\traw_spin_unlock_irqrestore(&cpu_buffer->reader_lock, flags);\n}"
  },
  {
    "function_name": "ring_buffer_read_prepare_sync",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "4191-4195",
    "snippet": "void\nring_buffer_read_prepare_sync(void)\n{\n\tsynchronize_sched();\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "synchronize_sched",
          "args": [],
          "line": 4194
        },
        "resolved": true,
        "details": {
          "function_name": "synchronize_sched_expedited_wait",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/tree_exp.h",
          "lines": "468-540",
          "snippet": "static void synchronize_sched_expedited_wait(void)\n{\n\tint cpu;\n\tunsigned long jiffies_stall;\n\tunsigned long jiffies_start;\n\tunsigned long mask;\n\tint ndetected;\n\tstruct rcu_node *rnp;\n\tstruct rcu_node *rnp_root = rcu_get_root();\n\tint ret;\n\n\ttrace_rcu_exp_grace_period(rcu_state.name, rcu_exp_gp_seq_endval(), TPS(\"startwait\"));\n\tjiffies_stall = rcu_jiffies_till_stall_check();\n\tjiffies_start = jiffies;\n\n\tfor (;;) {\n\t\tret = swait_event_timeout_exclusive(\n\t\t\t\trcu_state.expedited_wq,\n\t\t\t\tsync_rcu_preempt_exp_done_unlocked(rnp_root),\n\t\t\t\tjiffies_stall);\n\t\tif (ret > 0 || sync_rcu_preempt_exp_done_unlocked(rnp_root))\n\t\t\treturn;\n\t\tWARN_ON(ret < 0);  /* workqueues should not be signaled. */\n\t\tif (rcu_cpu_stall_suppress)\n\t\t\tcontinue;\n\t\tpanic_on_rcu_stall();\n\t\tpr_err(\"INFO: %s detected expedited stalls on CPUs/tasks: {\",\n\t\t       rcu_state.name);\n\t\tndetected = 0;\n\t\trcu_for_each_leaf_node(rnp) {\n\t\t\tndetected += rcu_print_task_exp_stall(rnp);\n\t\t\tfor_each_leaf_node_possible_cpu(rnp, cpu) {\n\t\t\t\tstruct rcu_data *rdp;\n\n\t\t\t\tmask = leaf_node_cpu_bit(rnp, cpu);\n\t\t\t\tif (!(rnp->expmask & mask))\n\t\t\t\t\tcontinue;\n\t\t\t\tndetected++;\n\t\t\t\trdp = per_cpu_ptr(&rcu_data, cpu);\n\t\t\t\tpr_cont(\" %d-%c%c%c\", cpu,\n\t\t\t\t\t\"O.\"[!!cpu_online(cpu)],\n\t\t\t\t\t\"o.\"[!!(rdp->grpmask & rnp->expmaskinit)],\n\t\t\t\t\t\"N.\"[!!(rdp->grpmask & rnp->expmaskinitnext)]);\n\t\t\t}\n\t\t}\n\t\tpr_cont(\" } %lu jiffies s: %lu root: %#lx/%c\\n\",\n\t\t\tjiffies - jiffies_start, rcu_state.expedited_sequence,\n\t\t\trnp_root->expmask, \".T\"[!!rnp_root->exp_tasks]);\n\t\tif (ndetected) {\n\t\t\tpr_err(\"blocking rcu_node structures:\");\n\t\t\trcu_for_each_node_breadth_first(rnp) {\n\t\t\t\tif (rnp == rnp_root)\n\t\t\t\t\tcontinue; /* printed unconditionally */\n\t\t\t\tif (sync_rcu_preempt_exp_done_unlocked(rnp))\n\t\t\t\t\tcontinue;\n\t\t\t\tpr_cont(\" l=%u:%d-%d:%#lx/%c\",\n\t\t\t\t\trnp->level, rnp->grplo, rnp->grphi,\n\t\t\t\t\trnp->expmask,\n\t\t\t\t\t\".T\"[!!rnp->exp_tasks]);\n\t\t\t}\n\t\t\tpr_cont(\"\\n\");\n\t\t}\n\t\trcu_for_each_leaf_node(rnp) {\n\t\t\tfor_each_leaf_node_possible_cpu(rnp, cpu) {\n\t\t\t\tmask = leaf_node_cpu_bit(rnp, cpu);\n\t\t\t\tif (!(rnp->expmask & mask))\n\t\t\t\t\tcontinue;\n\t\t\t\tdump_cpu_task(cpu);\n\t\t\t}\n\t\t}\n\t\tjiffies_stall = 3 * rcu_jiffies_till_stall_check() + 3;\n\t}\n}",
          "includes": [
            "#include <linux/lockdep.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/lockdep.h>\n\nstatic void synchronize_sched_expedited_wait(void)\n{\n\tint cpu;\n\tunsigned long jiffies_stall;\n\tunsigned long jiffies_start;\n\tunsigned long mask;\n\tint ndetected;\n\tstruct rcu_node *rnp;\n\tstruct rcu_node *rnp_root = rcu_get_root();\n\tint ret;\n\n\ttrace_rcu_exp_grace_period(rcu_state.name, rcu_exp_gp_seq_endval(), TPS(\"startwait\"));\n\tjiffies_stall = rcu_jiffies_till_stall_check();\n\tjiffies_start = jiffies;\n\n\tfor (;;) {\n\t\tret = swait_event_timeout_exclusive(\n\t\t\t\trcu_state.expedited_wq,\n\t\t\t\tsync_rcu_preempt_exp_done_unlocked(rnp_root),\n\t\t\t\tjiffies_stall);\n\t\tif (ret > 0 || sync_rcu_preempt_exp_done_unlocked(rnp_root))\n\t\t\treturn;\n\t\tWARN_ON(ret < 0);  /* workqueues should not be signaled. */\n\t\tif (rcu_cpu_stall_suppress)\n\t\t\tcontinue;\n\t\tpanic_on_rcu_stall();\n\t\tpr_err(\"INFO: %s detected expedited stalls on CPUs/tasks: {\",\n\t\t       rcu_state.name);\n\t\tndetected = 0;\n\t\trcu_for_each_leaf_node(rnp) {\n\t\t\tndetected += rcu_print_task_exp_stall(rnp);\n\t\t\tfor_each_leaf_node_possible_cpu(rnp, cpu) {\n\t\t\t\tstruct rcu_data *rdp;\n\n\t\t\t\tmask = leaf_node_cpu_bit(rnp, cpu);\n\t\t\t\tif (!(rnp->expmask & mask))\n\t\t\t\t\tcontinue;\n\t\t\t\tndetected++;\n\t\t\t\trdp = per_cpu_ptr(&rcu_data, cpu);\n\t\t\t\tpr_cont(\" %d-%c%c%c\", cpu,\n\t\t\t\t\t\"O.\"[!!cpu_online(cpu)],\n\t\t\t\t\t\"o.\"[!!(rdp->grpmask & rnp->expmaskinit)],\n\t\t\t\t\t\"N.\"[!!(rdp->grpmask & rnp->expmaskinitnext)]);\n\t\t\t}\n\t\t}\n\t\tpr_cont(\" } %lu jiffies s: %lu root: %#lx/%c\\n\",\n\t\t\tjiffies - jiffies_start, rcu_state.expedited_sequence,\n\t\t\trnp_root->expmask, \".T\"[!!rnp_root->exp_tasks]);\n\t\tif (ndetected) {\n\t\t\tpr_err(\"blocking rcu_node structures:\");\n\t\t\trcu_for_each_node_breadth_first(rnp) {\n\t\t\t\tif (rnp == rnp_root)\n\t\t\t\t\tcontinue; /* printed unconditionally */\n\t\t\t\tif (sync_rcu_preempt_exp_done_unlocked(rnp))\n\t\t\t\t\tcontinue;\n\t\t\t\tpr_cont(\" l=%u:%d-%d:%#lx/%c\",\n\t\t\t\t\trnp->level, rnp->grplo, rnp->grphi,\n\t\t\t\t\trnp->expmask,\n\t\t\t\t\t\".T\"[!!rnp->exp_tasks]);\n\t\t\t}\n\t\t\tpr_cont(\"\\n\");\n\t\t}\n\t\trcu_for_each_leaf_node(rnp) {\n\t\t\tfor_each_leaf_node_possible_cpu(rnp, cpu) {\n\t\t\t\tmask = leaf_node_cpu_bit(rnp, cpu);\n\t\t\t\tif (!(rnp->expmask & mask))\n\t\t\t\t\tcontinue;\n\t\t\t\tdump_cpu_task(cpu);\n\t\t\t}\n\t\t}\n\t\tjiffies_stall = 3 * rcu_jiffies_till_stall_check() + 3;\n\t}\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nvoid\nring_buffer_read_prepare_sync(void)\n{\n\tsynchronize_sched();\n}"
  },
  {
    "function_name": "ring_buffer_read_prepare",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "4160-4181",
    "snippet": "struct ring_buffer_iter *\nring_buffer_read_prepare(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct ring_buffer_iter *iter;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn NULL;\n\n\titer = kmalloc(sizeof(*iter), GFP_KERNEL);\n\tif (!iter)\n\t\treturn NULL;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\n\titer->cpu_buffer = cpu_buffer;\n\n\tatomic_inc(&buffer->resize_disabled);\n\tatomic_inc(&cpu_buffer->record_disabled);\n\n\treturn iter;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_inc",
          "args": [
            "&cpu_buffer->record_disabled"
          ],
          "line": 4178
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_inc",
          "args": [
            "&buffer->resize_disabled"
          ],
          "line": 4177
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kmalloc",
          "args": [
            "sizeof(*iter)",
            "GFP_KERNEL"
          ],
          "line": 4169
        },
        "resolved": true,
        "details": {
          "function_name": "debug_kmalloc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/debug/kdb/kdb_support.c",
          "lines": "745-801",
          "snippet": "void *debug_kmalloc(size_t size, gfp_t flags)\n{\n\tunsigned int rem, h_offset;\n\tstruct debug_alloc_header *best, *bestprev, *prev, *h;\n\tvoid *p = NULL;\n\tif (!get_dap_lock()) {\n\t\t__release(dap_lock);\t/* we never actually got it */\n\t\treturn NULL;\n\t}\n\th = (struct debug_alloc_header *)(debug_alloc_pool + dah_first);\n\tif (dah_first_call) {\n\t\th->size = sizeof(debug_alloc_pool_aligned) - dah_overhead;\n\t\tdah_first_call = 0;\n\t}\n\tsize = ALIGN(size, dah_align);\n\tprev = best = bestprev = NULL;\n\twhile (1) {\n\t\tif (h->size >= size && (!best || h->size < best->size)) {\n\t\t\tbest = h;\n\t\t\tbestprev = prev;\n\t\t\tif (h->size == size)\n\t\t\t\tbreak;\n\t\t}\n\t\tif (!h->next)\n\t\t\tbreak;\n\t\tprev = h;\n\t\th = (struct debug_alloc_header *)(debug_alloc_pool + h->next);\n\t}\n\tif (!best)\n\t\tgoto out;\n\trem = best->size - size;\n\t/* The pool must always contain at least one header */\n\tif (best->next == 0 && bestprev == NULL && rem < dah_overhead)\n\t\tgoto out;\n\tif (rem >= dah_overhead) {\n\t\tbest->size = size;\n\t\th_offset = ((char *)best - debug_alloc_pool) +\n\t\t\t   dah_overhead + best->size;\n\t\th = (struct debug_alloc_header *)(debug_alloc_pool + h_offset);\n\t\th->size = rem - dah_overhead;\n\t\th->next = best->next;\n\t} else\n\t\th_offset = best->next;\n\tbest->caller = __builtin_return_address(0);\n\tdah_used += best->size;\n\tdah_used_max = max(dah_used, dah_used_max);\n\tif (bestprev)\n\t\tbestprev->next = h_offset;\n\telse\n\t\tdah_first = h_offset;\n\tp = (char *)best + dah_overhead;\n\tmemset(p, POISON_INUSE, best->size - 1);\n\t*((char *)p + best->size - 1) = POISON_END;\nout:\n\tspin_unlock(&dap_lock);\n\treturn p;\n}",
          "includes": [
            "#include \"kdb_private.h\"",
            "#include <linux/slab.h>",
            "#include <linux/kdb.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/highmem.h>",
            "#include <linux/module.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/stddef.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/mm.h>",
            "#include <linux/sched.h>",
            "#include <linux/types.h>",
            "#include <stdarg.h>"
          ],
          "macros_used": [
            "#define dah_overhead ALIGN(sizeof(struct debug_alloc_header), dah_align)",
            "#define dah_align 8"
          ],
          "globals_used": [
            "static u64 debug_alloc_pool_aligned[256*1024/dah_align];",
            "static char *debug_alloc_pool = (char *)debug_alloc_pool_aligned;",
            "static u32 dah_first, dah_first_call = 1, dah_used, dah_used_max;",
            "static DEFINE_SPINLOCK(dap_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"kdb_private.h\"\n#include <linux/slab.h>\n#include <linux/kdb.h>\n#include <linux/uaccess.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/highmem.h>\n#include <linux/module.h>\n#include <linux/ptrace.h>\n#include <linux/vmalloc.h>\n#include <linux/stddef.h>\n#include <linux/kallsyms.h>\n#include <linux/mm.h>\n#include <linux/sched.h>\n#include <linux/types.h>\n#include <stdarg.h>\n\n#define dah_overhead ALIGN(sizeof(struct debug_alloc_header), dah_align)\n#define dah_align 8\n\nstatic u64 debug_alloc_pool_aligned[256*1024/dah_align];\nstatic char *debug_alloc_pool = (char *)debug_alloc_pool_aligned;\nstatic u32 dah_first, dah_first_call = 1, dah_used, dah_used_max;\nstatic DEFINE_SPINLOCK(dap_lock);\n\nvoid *debug_kmalloc(size_t size, gfp_t flags)\n{\n\tunsigned int rem, h_offset;\n\tstruct debug_alloc_header *best, *bestprev, *prev, *h;\n\tvoid *p = NULL;\n\tif (!get_dap_lock()) {\n\t\t__release(dap_lock);\t/* we never actually got it */\n\t\treturn NULL;\n\t}\n\th = (struct debug_alloc_header *)(debug_alloc_pool + dah_first);\n\tif (dah_first_call) {\n\t\th->size = sizeof(debug_alloc_pool_aligned) - dah_overhead;\n\t\tdah_first_call = 0;\n\t}\n\tsize = ALIGN(size, dah_align);\n\tprev = best = bestprev = NULL;\n\twhile (1) {\n\t\tif (h->size >= size && (!best || h->size < best->size)) {\n\t\t\tbest = h;\n\t\t\tbestprev = prev;\n\t\t\tif (h->size == size)\n\t\t\t\tbreak;\n\t\t}\n\t\tif (!h->next)\n\t\t\tbreak;\n\t\tprev = h;\n\t\th = (struct debug_alloc_header *)(debug_alloc_pool + h->next);\n\t}\n\tif (!best)\n\t\tgoto out;\n\trem = best->size - size;\n\t/* The pool must always contain at least one header */\n\tif (best->next == 0 && bestprev == NULL && rem < dah_overhead)\n\t\tgoto out;\n\tif (rem >= dah_overhead) {\n\t\tbest->size = size;\n\t\th_offset = ((char *)best - debug_alloc_pool) +\n\t\t\t   dah_overhead + best->size;\n\t\th = (struct debug_alloc_header *)(debug_alloc_pool + h_offset);\n\t\th->size = rem - dah_overhead;\n\t\th->next = best->next;\n\t} else\n\t\th_offset = best->next;\n\tbest->caller = __builtin_return_address(0);\n\tdah_used += best->size;\n\tdah_used_max = max(dah_used, dah_used_max);\n\tif (bestprev)\n\t\tbestprev->next = h_offset;\n\telse\n\t\tdah_first = h_offset;\n\tp = (char *)best + dah_overhead;\n\tmemset(p, POISON_INUSE, best->size - 1);\n\t*((char *)p + best->size - 1) = POISON_END;\nout:\n\tspin_unlock(&dap_lock);\n\treturn p;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "buffer->cpumask"
          ],
          "line": 4166
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstruct ring_buffer_iter *\nring_buffer_read_prepare(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct ring_buffer_iter *iter;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn NULL;\n\n\titer = kmalloc(sizeof(*iter), GFP_KERNEL);\n\tif (!iter)\n\t\treturn NULL;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\n\titer->cpu_buffer = cpu_buffer;\n\n\tatomic_inc(&buffer->resize_disabled);\n\tatomic_inc(&cpu_buffer->record_disabled);\n\n\treturn iter;\n}"
  },
  {
    "function_name": "ring_buffer_consume",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "4101-4137",
    "snippet": "struct ring_buffer_event *\nring_buffer_consume(struct ring_buffer *buffer, int cpu, u64 *ts,\n\t\t    unsigned long *lost_events)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct ring_buffer_event *event = NULL;\n\tunsigned long flags;\n\tbool dolock;\n\n again:\n\t/* might be called in atomic */\n\tpreempt_disable();\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\tgoto out;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tlocal_irq_save(flags);\n\tdolock = rb_reader_lock(cpu_buffer);\n\n\tevent = rb_buffer_peek(cpu_buffer, ts, lost_events);\n\tif (event) {\n\t\tcpu_buffer->lost_events = 0;\n\t\trb_advance_reader(cpu_buffer);\n\t}\n\n\trb_reader_unlock(cpu_buffer, dolock);\n\tlocal_irq_restore(flags);\n\n out:\n\tpreempt_enable();\n\n\tif (event && event->type_len == RINGBUF_TYPE_PADDING)\n\t\tgoto again;\n\n\treturn event;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "preempt_enable",
          "args": [],
          "line": 4131
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_irq_restore",
          "args": [
            "flags"
          ],
          "line": 4128
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_reader_unlock",
          "args": [
            "cpu_buffer",
            "dolock"
          ],
          "line": 4127
        },
        "resolved": true,
        "details": {
          "function_name": "rb_reader_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "4019-4025",
          "snippet": "static inline void\nrb_reader_unlock(struct ring_buffer_per_cpu *cpu_buffer, bool locked)\n{\n\tif (likely(locked))\n\t\traw_spin_unlock(&cpu_buffer->reader_lock);\n\treturn;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline void\nrb_reader_unlock(struct ring_buffer_per_cpu *cpu_buffer, bool locked)\n{\n\tif (likely(locked))\n\t\traw_spin_unlock(&cpu_buffer->reader_lock);\n\treturn;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_advance_reader",
          "args": [
            "cpu_buffer"
          ],
          "line": 4124
        },
        "resolved": true,
        "details": {
          "function_name": "rb_advance_reader",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3764-3785",
          "snippet": "static void rb_advance_reader(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct ring_buffer_event *event;\n\tstruct buffer_page *reader;\n\tunsigned length;\n\n\treader = rb_get_reader_page(cpu_buffer);\n\n\t/* This function should not be called when buffer is empty */\n\tif (RB_WARN_ON(cpu_buffer, !reader))\n\t\treturn;\n\n\tevent = rb_reader_event(cpu_buffer);\n\n\tif (event->type_len <= RINGBUF_TYPE_DATA_TYPE_LEN_MAX)\n\t\tcpu_buffer->read++;\n\n\trb_update_read_stamp(cpu_buffer, event);\n\n\tlength = rb_event_length(event);\n\tcpu_buffer->reader_page->read += length;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic void rb_advance_reader(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct ring_buffer_event *event;\n\tstruct buffer_page *reader;\n\tunsigned length;\n\n\treader = rb_get_reader_page(cpu_buffer);\n\n\t/* This function should not be called when buffer is empty */\n\tif (RB_WARN_ON(cpu_buffer, !reader))\n\t\treturn;\n\n\tevent = rb_reader_event(cpu_buffer);\n\n\tif (event->type_len <= RINGBUF_TYPE_DATA_TYPE_LEN_MAX)\n\t\tcpu_buffer->read++;\n\n\trb_update_read_stamp(cpu_buffer, event);\n\n\tlength = rb_event_length(event);\n\tcpu_buffer->reader_page->read += length;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_buffer_peek",
          "args": [
            "cpu_buffer",
            "ts",
            "lost_events"
          ],
          "line": 4121
        },
        "resolved": true,
        "details": {
          "function_name": "rb_buffer_peek",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3834-3904",
          "snippet": "static struct ring_buffer_event *\nrb_buffer_peek(struct ring_buffer_per_cpu *cpu_buffer, u64 *ts,\n\t       unsigned long *lost_events)\n{\n\tstruct ring_buffer_event *event;\n\tstruct buffer_page *reader;\n\tint nr_loops = 0;\n\n\tif (ts)\n\t\t*ts = 0;\n again:\n\t/*\n\t * We repeat when a time extend is encountered.\n\t * Since the time extend is always attached to a data event,\n\t * we should never loop more than once.\n\t * (We never hit the following condition more than twice).\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 2))\n\t\treturn NULL;\n\n\treader = rb_get_reader_page(cpu_buffer);\n\tif (!reader)\n\t\treturn NULL;\n\n\tevent = rb_reader_event(cpu_buffer);\n\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event))\n\t\t\tRB_WARN_ON(cpu_buffer, 1);\n\t\t/*\n\t\t * Because the writer could be discarding every\n\t\t * event it creates (which would probably be bad)\n\t\t * if we were to go back to \"again\" then we may never\n\t\t * catch up, and will trigger the warn on, or lock\n\t\t * the box. Return the padding, and we will release\n\t\t * the current locks, and try again.\n\t\t */\n\t\treturn event;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\t/* Internal data, OK to advance */\n\t\trb_advance_reader(cpu_buffer);\n\t\tgoto again;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\tif (ts) {\n\t\t\t*ts = ring_buffer_event_time_stamp(event);\n\t\t\tring_buffer_normalize_time_stamp(cpu_buffer->buffer,\n\t\t\t\t\t\t\t cpu_buffer->cpu, ts);\n\t\t}\n\t\t/* Internal data, OK to advance */\n\t\trb_advance_reader(cpu_buffer);\n\t\tgoto again;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\tif (ts && !(*ts)) {\n\t\t\t*ts = cpu_buffer->read_stamp + event->time_delta;\n\t\t\tring_buffer_normalize_time_stamp(cpu_buffer->buffer,\n\t\t\t\t\t\t\t cpu_buffer->cpu, ts);\n\t\t}\n\t\tif (lost_events)\n\t\t\t*lost_events = rb_lost_events(cpu_buffer);\n\t\treturn event;\n\n\tdefault:\n\t\tBUG();\n\t}\n\n\treturn NULL;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic struct ring_buffer_event *\nrb_buffer_peek(struct ring_buffer_per_cpu *cpu_buffer, u64 *ts,\n\t       unsigned long *lost_events)\n{\n\tstruct ring_buffer_event *event;\n\tstruct buffer_page *reader;\n\tint nr_loops = 0;\n\n\tif (ts)\n\t\t*ts = 0;\n again:\n\t/*\n\t * We repeat when a time extend is encountered.\n\t * Since the time extend is always attached to a data event,\n\t * we should never loop more than once.\n\t * (We never hit the following condition more than twice).\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 2))\n\t\treturn NULL;\n\n\treader = rb_get_reader_page(cpu_buffer);\n\tif (!reader)\n\t\treturn NULL;\n\n\tevent = rb_reader_event(cpu_buffer);\n\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event))\n\t\t\tRB_WARN_ON(cpu_buffer, 1);\n\t\t/*\n\t\t * Because the writer could be discarding every\n\t\t * event it creates (which would probably be bad)\n\t\t * if we were to go back to \"again\" then we may never\n\t\t * catch up, and will trigger the warn on, or lock\n\t\t * the box. Return the padding, and we will release\n\t\t * the current locks, and try again.\n\t\t */\n\t\treturn event;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\t/* Internal data, OK to advance */\n\t\trb_advance_reader(cpu_buffer);\n\t\tgoto again;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\tif (ts) {\n\t\t\t*ts = ring_buffer_event_time_stamp(event);\n\t\t\tring_buffer_normalize_time_stamp(cpu_buffer->buffer,\n\t\t\t\t\t\t\t cpu_buffer->cpu, ts);\n\t\t}\n\t\t/* Internal data, OK to advance */\n\t\trb_advance_reader(cpu_buffer);\n\t\tgoto again;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\tif (ts && !(*ts)) {\n\t\t\t*ts = cpu_buffer->read_stamp + event->time_delta;\n\t\t\tring_buffer_normalize_time_stamp(cpu_buffer->buffer,\n\t\t\t\t\t\t\t cpu_buffer->cpu, ts);\n\t\t}\n\t\tif (lost_events)\n\t\t\t*lost_events = rb_lost_events(cpu_buffer);\n\t\treturn event;\n\n\tdefault:\n\t\tBUG();\n\t}\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_reader_lock",
          "args": [
            "cpu_buffer"
          ],
          "line": 4119
        },
        "resolved": true,
        "details": {
          "function_name": "rb_reader_lock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3995-4017",
          "snippet": "static inline bool rb_reader_lock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tif (likely(!in_nmi())) {\n\t\traw_spin_lock(&cpu_buffer->reader_lock);\n\t\treturn true;\n\t}\n\n\t/*\n\t * If an NMI die dumps out the content of the ring buffer\n\t * trylock must be used to prevent a deadlock if the NMI\n\t * preempted a task that holds the ring buffer locks. If\n\t * we get the lock then all is fine, if not, then continue\n\t * to do the read, but this can corrupt the ring buffer,\n\t * so it must be permanently disabled from future writes.\n\t * Reading from NMI is a oneshot deal.\n\t */\n\tif (raw_spin_trylock(&cpu_buffer->reader_lock))\n\t\treturn true;\n\n\t/* Continue without locking, but disable the ring buffer */\n\tatomic_inc(&cpu_buffer->record_disabled);\n\treturn false;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline bool rb_reader_lock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tif (likely(!in_nmi())) {\n\t\traw_spin_lock(&cpu_buffer->reader_lock);\n\t\treturn true;\n\t}\n\n\t/*\n\t * If an NMI die dumps out the content of the ring buffer\n\t * trylock must be used to prevent a deadlock if the NMI\n\t * preempted a task that holds the ring buffer locks. If\n\t * we get the lock then all is fine, if not, then continue\n\t * to do the read, but this can corrupt the ring buffer,\n\t * so it must be permanently disabled from future writes.\n\t * Reading from NMI is a oneshot deal.\n\t */\n\tif (raw_spin_trylock(&cpu_buffer->reader_lock))\n\t\treturn true;\n\n\t/* Continue without locking, but disable the ring buffer */\n\tatomic_inc(&cpu_buffer->record_disabled);\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_irq_save",
          "args": [
            "flags"
          ],
          "line": 4118
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "buffer->cpumask"
          ],
          "line": 4114
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "preempt_disable",
          "args": [],
          "line": 4112
        },
        "resolved": true,
        "details": {
          "function_name": "schedule_preempt_disabled",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/core.c",
          "lines": "3571-3576",
          "snippet": "void __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}",
          "includes": [
            "#include \"features.h\"",
            "#include <trace/events/sched.h>",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/kcov.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include <trace/events/sched.h>\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/kcov.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n\nstatic void __sched;\nstatic void __sched;\n\nvoid __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstruct ring_buffer_event *\nring_buffer_consume(struct ring_buffer *buffer, int cpu, u64 *ts,\n\t\t    unsigned long *lost_events)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct ring_buffer_event *event = NULL;\n\tunsigned long flags;\n\tbool dolock;\n\n again:\n\t/* might be called in atomic */\n\tpreempt_disable();\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\tgoto out;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tlocal_irq_save(flags);\n\tdolock = rb_reader_lock(cpu_buffer);\n\n\tevent = rb_buffer_peek(cpu_buffer, ts, lost_events);\n\tif (event) {\n\t\tcpu_buffer->lost_events = 0;\n\t\trb_advance_reader(cpu_buffer);\n\t}\n\n\trb_reader_unlock(cpu_buffer, dolock);\n\tlocal_irq_restore(flags);\n\n out:\n\tpreempt_enable();\n\n\tif (event && event->type_len == RINGBUF_TYPE_PADDING)\n\t\tgoto again;\n\n\treturn event;\n}"
  },
  {
    "function_name": "ring_buffer_iter_peek",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "4072-4088",
    "snippet": "struct ring_buffer_event *\nring_buffer_iter_peek(struct ring_buffer_iter *iter, u64 *ts)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = iter->cpu_buffer;\n\tstruct ring_buffer_event *event;\n\tunsigned long flags;\n\n again:\n\traw_spin_lock_irqsave(&cpu_buffer->reader_lock, flags);\n\tevent = rb_iter_peek(iter, ts);\n\traw_spin_unlock_irqrestore(&cpu_buffer->reader_lock, flags);\n\n\tif (event && event->type_len == RINGBUF_TYPE_PADDING)\n\t\tgoto again;\n\n\treturn event;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore",
          "args": [
            "&cpu_buffer->reader_lock",
            "flags"
          ],
          "line": 4082
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_irqrestore",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "182-185",
          "snippet": "void __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_iter_peek",
          "args": [
            "iter",
            "ts"
          ],
          "line": 4081
        },
        "resolved": true,
        "details": {
          "function_name": "rb_iter_peek",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3907-3992",
          "snippet": "static struct ring_buffer_event *\nrb_iter_peek(struct ring_buffer_iter *iter, u64 *ts)\n{\n\tstruct ring_buffer *buffer;\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct ring_buffer_event *event;\n\tint nr_loops = 0;\n\n\tif (ts)\n\t\t*ts = 0;\n\n\tcpu_buffer = iter->cpu_buffer;\n\tbuffer = cpu_buffer->buffer;\n\n\t/*\n\t * Check if someone performed a consuming read to\n\t * the buffer. A consuming read invalidates the iterator\n\t * and we need to reset the iterator in this case.\n\t */\n\tif (unlikely(iter->cache_read != cpu_buffer->read ||\n\t\t     iter->cache_reader_page != cpu_buffer->reader_page))\n\t\trb_iter_reset(iter);\n\n again:\n\tif (ring_buffer_iter_empty(iter))\n\t\treturn NULL;\n\n\t/*\n\t * We repeat when a time extend is encountered or we hit\n\t * the end of the page. Since the time extend is always attached\n\t * to a data event, we should never loop more than three times.\n\t * Once for going to next page, once on time extend, and\n\t * finally once to get the event.\n\t * (We never hit the following condition more than thrice).\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 3))\n\t\treturn NULL;\n\n\tif (rb_per_cpu_empty(cpu_buffer))\n\t\treturn NULL;\n\n\tif (iter->head >= rb_page_size(iter->head_page)) {\n\t\trb_inc_iter(iter);\n\t\tgoto again;\n\t}\n\n\tevent = rb_iter_head_event(iter);\n\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event)) {\n\t\t\trb_inc_iter(iter);\n\t\t\tgoto again;\n\t\t}\n\t\trb_advance_iter(iter);\n\t\treturn event;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\t/* Internal data, OK to advance */\n\t\trb_advance_iter(iter);\n\t\tgoto again;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\tif (ts) {\n\t\t\t*ts = ring_buffer_event_time_stamp(event);\n\t\t\tring_buffer_normalize_time_stamp(cpu_buffer->buffer,\n\t\t\t\t\t\t\t cpu_buffer->cpu, ts);\n\t\t}\n\t\t/* Internal data, OK to advance */\n\t\trb_advance_iter(iter);\n\t\tgoto again;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\tif (ts && !(*ts)) {\n\t\t\t*ts = iter->read_stamp + event->time_delta;\n\t\t\tring_buffer_normalize_time_stamp(buffer,\n\t\t\t\t\t\t\t cpu_buffer->cpu, ts);\n\t\t}\n\t\treturn event;\n\n\tdefault:\n\t\tBUG();\n\t}\n\n\treturn NULL;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic struct ring_buffer_event *\nrb_iter_peek(struct ring_buffer_iter *iter, u64 *ts)\n{\n\tstruct ring_buffer *buffer;\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct ring_buffer_event *event;\n\tint nr_loops = 0;\n\n\tif (ts)\n\t\t*ts = 0;\n\n\tcpu_buffer = iter->cpu_buffer;\n\tbuffer = cpu_buffer->buffer;\n\n\t/*\n\t * Check if someone performed a consuming read to\n\t * the buffer. A consuming read invalidates the iterator\n\t * and we need to reset the iterator in this case.\n\t */\n\tif (unlikely(iter->cache_read != cpu_buffer->read ||\n\t\t     iter->cache_reader_page != cpu_buffer->reader_page))\n\t\trb_iter_reset(iter);\n\n again:\n\tif (ring_buffer_iter_empty(iter))\n\t\treturn NULL;\n\n\t/*\n\t * We repeat when a time extend is encountered or we hit\n\t * the end of the page. Since the time extend is always attached\n\t * to a data event, we should never loop more than three times.\n\t * Once for going to next page, once on time extend, and\n\t * finally once to get the event.\n\t * (We never hit the following condition more than thrice).\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 3))\n\t\treturn NULL;\n\n\tif (rb_per_cpu_empty(cpu_buffer))\n\t\treturn NULL;\n\n\tif (iter->head >= rb_page_size(iter->head_page)) {\n\t\trb_inc_iter(iter);\n\t\tgoto again;\n\t}\n\n\tevent = rb_iter_head_event(iter);\n\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event)) {\n\t\t\trb_inc_iter(iter);\n\t\t\tgoto again;\n\t\t}\n\t\trb_advance_iter(iter);\n\t\treturn event;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\t/* Internal data, OK to advance */\n\t\trb_advance_iter(iter);\n\t\tgoto again;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\tif (ts) {\n\t\t\t*ts = ring_buffer_event_time_stamp(event);\n\t\t\tring_buffer_normalize_time_stamp(cpu_buffer->buffer,\n\t\t\t\t\t\t\t cpu_buffer->cpu, ts);\n\t\t}\n\t\t/* Internal data, OK to advance */\n\t\trb_advance_iter(iter);\n\t\tgoto again;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\tif (ts && !(*ts)) {\n\t\t\t*ts = iter->read_stamp + event->time_delta;\n\t\t\tring_buffer_normalize_time_stamp(buffer,\n\t\t\t\t\t\t\t cpu_buffer->cpu, ts);\n\t\t}\n\t\treturn event;\n\n\tdefault:\n\t\tBUG();\n\t}\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irqsave",
          "args": [
            "&cpu_buffer->reader_lock",
            "flags"
          ],
          "line": 4080
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_irqsave_nested",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "359-370",
          "snippet": "unsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED_FLAGS(lock, do_raw_spin_trylock, do_raw_spin_lock,\n\t\t\t\tdo_raw_spin_lock_flags, &flags);\n\treturn flags;\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nunsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED_FLAGS(lock, do_raw_spin_trylock, do_raw_spin_lock,\n\t\t\t\tdo_raw_spin_lock_flags, &flags);\n\treturn flags;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstruct ring_buffer_event *\nring_buffer_iter_peek(struct ring_buffer_iter *iter, u64 *ts)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = iter->cpu_buffer;\n\tstruct ring_buffer_event *event;\n\tunsigned long flags;\n\n again:\n\traw_spin_lock_irqsave(&cpu_buffer->reader_lock, flags);\n\tevent = rb_iter_peek(iter, ts);\n\traw_spin_unlock_irqrestore(&cpu_buffer->reader_lock, flags);\n\n\tif (event && event->type_len == RINGBUF_TYPE_PADDING)\n\t\tgoto again;\n\n\treturn event;\n}"
  },
  {
    "function_name": "ring_buffer_peek",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "4037-4062",
    "snippet": "struct ring_buffer_event *\nring_buffer_peek(struct ring_buffer *buffer, int cpu, u64 *ts,\n\t\t unsigned long *lost_events)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = buffer->buffers[cpu];\n\tstruct ring_buffer_event *event;\n\tunsigned long flags;\n\tbool dolock;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn NULL;\n\n again:\n\tlocal_irq_save(flags);\n\tdolock = rb_reader_lock(cpu_buffer);\n\tevent = rb_buffer_peek(cpu_buffer, ts, lost_events);\n\tif (event && event->type_len == RINGBUF_TYPE_PADDING)\n\t\trb_advance_reader(cpu_buffer);\n\trb_reader_unlock(cpu_buffer, dolock);\n\tlocal_irq_restore(flags);\n\n\tif (event && event->type_len == RINGBUF_TYPE_PADDING)\n\t\tgoto again;\n\n\treturn event;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_irq_restore",
          "args": [
            "flags"
          ],
          "line": 4056
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_reader_unlock",
          "args": [
            "cpu_buffer",
            "dolock"
          ],
          "line": 4055
        },
        "resolved": true,
        "details": {
          "function_name": "rb_reader_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "4019-4025",
          "snippet": "static inline void\nrb_reader_unlock(struct ring_buffer_per_cpu *cpu_buffer, bool locked)\n{\n\tif (likely(locked))\n\t\traw_spin_unlock(&cpu_buffer->reader_lock);\n\treturn;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline void\nrb_reader_unlock(struct ring_buffer_per_cpu *cpu_buffer, bool locked)\n{\n\tif (likely(locked))\n\t\traw_spin_unlock(&cpu_buffer->reader_lock);\n\treturn;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_advance_reader",
          "args": [
            "cpu_buffer"
          ],
          "line": 4054
        },
        "resolved": true,
        "details": {
          "function_name": "rb_advance_reader",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3764-3785",
          "snippet": "static void rb_advance_reader(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct ring_buffer_event *event;\n\tstruct buffer_page *reader;\n\tunsigned length;\n\n\treader = rb_get_reader_page(cpu_buffer);\n\n\t/* This function should not be called when buffer is empty */\n\tif (RB_WARN_ON(cpu_buffer, !reader))\n\t\treturn;\n\n\tevent = rb_reader_event(cpu_buffer);\n\n\tif (event->type_len <= RINGBUF_TYPE_DATA_TYPE_LEN_MAX)\n\t\tcpu_buffer->read++;\n\n\trb_update_read_stamp(cpu_buffer, event);\n\n\tlength = rb_event_length(event);\n\tcpu_buffer->reader_page->read += length;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic void rb_advance_reader(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct ring_buffer_event *event;\n\tstruct buffer_page *reader;\n\tunsigned length;\n\n\treader = rb_get_reader_page(cpu_buffer);\n\n\t/* This function should not be called when buffer is empty */\n\tif (RB_WARN_ON(cpu_buffer, !reader))\n\t\treturn;\n\n\tevent = rb_reader_event(cpu_buffer);\n\n\tif (event->type_len <= RINGBUF_TYPE_DATA_TYPE_LEN_MAX)\n\t\tcpu_buffer->read++;\n\n\trb_update_read_stamp(cpu_buffer, event);\n\n\tlength = rb_event_length(event);\n\tcpu_buffer->reader_page->read += length;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_buffer_peek",
          "args": [
            "cpu_buffer",
            "ts",
            "lost_events"
          ],
          "line": 4052
        },
        "resolved": true,
        "details": {
          "function_name": "rb_buffer_peek",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3834-3904",
          "snippet": "static struct ring_buffer_event *\nrb_buffer_peek(struct ring_buffer_per_cpu *cpu_buffer, u64 *ts,\n\t       unsigned long *lost_events)\n{\n\tstruct ring_buffer_event *event;\n\tstruct buffer_page *reader;\n\tint nr_loops = 0;\n\n\tif (ts)\n\t\t*ts = 0;\n again:\n\t/*\n\t * We repeat when a time extend is encountered.\n\t * Since the time extend is always attached to a data event,\n\t * we should never loop more than once.\n\t * (We never hit the following condition more than twice).\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 2))\n\t\treturn NULL;\n\n\treader = rb_get_reader_page(cpu_buffer);\n\tif (!reader)\n\t\treturn NULL;\n\n\tevent = rb_reader_event(cpu_buffer);\n\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event))\n\t\t\tRB_WARN_ON(cpu_buffer, 1);\n\t\t/*\n\t\t * Because the writer could be discarding every\n\t\t * event it creates (which would probably be bad)\n\t\t * if we were to go back to \"again\" then we may never\n\t\t * catch up, and will trigger the warn on, or lock\n\t\t * the box. Return the padding, and we will release\n\t\t * the current locks, and try again.\n\t\t */\n\t\treturn event;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\t/* Internal data, OK to advance */\n\t\trb_advance_reader(cpu_buffer);\n\t\tgoto again;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\tif (ts) {\n\t\t\t*ts = ring_buffer_event_time_stamp(event);\n\t\t\tring_buffer_normalize_time_stamp(cpu_buffer->buffer,\n\t\t\t\t\t\t\t cpu_buffer->cpu, ts);\n\t\t}\n\t\t/* Internal data, OK to advance */\n\t\trb_advance_reader(cpu_buffer);\n\t\tgoto again;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\tif (ts && !(*ts)) {\n\t\t\t*ts = cpu_buffer->read_stamp + event->time_delta;\n\t\t\tring_buffer_normalize_time_stamp(cpu_buffer->buffer,\n\t\t\t\t\t\t\t cpu_buffer->cpu, ts);\n\t\t}\n\t\tif (lost_events)\n\t\t\t*lost_events = rb_lost_events(cpu_buffer);\n\t\treturn event;\n\n\tdefault:\n\t\tBUG();\n\t}\n\n\treturn NULL;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic struct ring_buffer_event *\nrb_buffer_peek(struct ring_buffer_per_cpu *cpu_buffer, u64 *ts,\n\t       unsigned long *lost_events)\n{\n\tstruct ring_buffer_event *event;\n\tstruct buffer_page *reader;\n\tint nr_loops = 0;\n\n\tif (ts)\n\t\t*ts = 0;\n again:\n\t/*\n\t * We repeat when a time extend is encountered.\n\t * Since the time extend is always attached to a data event,\n\t * we should never loop more than once.\n\t * (We never hit the following condition more than twice).\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 2))\n\t\treturn NULL;\n\n\treader = rb_get_reader_page(cpu_buffer);\n\tif (!reader)\n\t\treturn NULL;\n\n\tevent = rb_reader_event(cpu_buffer);\n\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event))\n\t\t\tRB_WARN_ON(cpu_buffer, 1);\n\t\t/*\n\t\t * Because the writer could be discarding every\n\t\t * event it creates (which would probably be bad)\n\t\t * if we were to go back to \"again\" then we may never\n\t\t * catch up, and will trigger the warn on, or lock\n\t\t * the box. Return the padding, and we will release\n\t\t * the current locks, and try again.\n\t\t */\n\t\treturn event;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\t/* Internal data, OK to advance */\n\t\trb_advance_reader(cpu_buffer);\n\t\tgoto again;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\tif (ts) {\n\t\t\t*ts = ring_buffer_event_time_stamp(event);\n\t\t\tring_buffer_normalize_time_stamp(cpu_buffer->buffer,\n\t\t\t\t\t\t\t cpu_buffer->cpu, ts);\n\t\t}\n\t\t/* Internal data, OK to advance */\n\t\trb_advance_reader(cpu_buffer);\n\t\tgoto again;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\tif (ts && !(*ts)) {\n\t\t\t*ts = cpu_buffer->read_stamp + event->time_delta;\n\t\t\tring_buffer_normalize_time_stamp(cpu_buffer->buffer,\n\t\t\t\t\t\t\t cpu_buffer->cpu, ts);\n\t\t}\n\t\tif (lost_events)\n\t\t\t*lost_events = rb_lost_events(cpu_buffer);\n\t\treturn event;\n\n\tdefault:\n\t\tBUG();\n\t}\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_reader_lock",
          "args": [
            "cpu_buffer"
          ],
          "line": 4051
        },
        "resolved": true,
        "details": {
          "function_name": "rb_reader_lock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3995-4017",
          "snippet": "static inline bool rb_reader_lock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tif (likely(!in_nmi())) {\n\t\traw_spin_lock(&cpu_buffer->reader_lock);\n\t\treturn true;\n\t}\n\n\t/*\n\t * If an NMI die dumps out the content of the ring buffer\n\t * trylock must be used to prevent a deadlock if the NMI\n\t * preempted a task that holds the ring buffer locks. If\n\t * we get the lock then all is fine, if not, then continue\n\t * to do the read, but this can corrupt the ring buffer,\n\t * so it must be permanently disabled from future writes.\n\t * Reading from NMI is a oneshot deal.\n\t */\n\tif (raw_spin_trylock(&cpu_buffer->reader_lock))\n\t\treturn true;\n\n\t/* Continue without locking, but disable the ring buffer */\n\tatomic_inc(&cpu_buffer->record_disabled);\n\treturn false;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline bool rb_reader_lock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tif (likely(!in_nmi())) {\n\t\traw_spin_lock(&cpu_buffer->reader_lock);\n\t\treturn true;\n\t}\n\n\t/*\n\t * If an NMI die dumps out the content of the ring buffer\n\t * trylock must be used to prevent a deadlock if the NMI\n\t * preempted a task that holds the ring buffer locks. If\n\t * we get the lock then all is fine, if not, then continue\n\t * to do the read, but this can corrupt the ring buffer,\n\t * so it must be permanently disabled from future writes.\n\t * Reading from NMI is a oneshot deal.\n\t */\n\tif (raw_spin_trylock(&cpu_buffer->reader_lock))\n\t\treturn true;\n\n\t/* Continue without locking, but disable the ring buffer */\n\tatomic_inc(&cpu_buffer->record_disabled);\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_irq_save",
          "args": [
            "flags"
          ],
          "line": 4050
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "buffer->cpumask"
          ],
          "line": 4046
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstruct ring_buffer_event *\nring_buffer_peek(struct ring_buffer *buffer, int cpu, u64 *ts,\n\t\t unsigned long *lost_events)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = buffer->buffers[cpu];\n\tstruct ring_buffer_event *event;\n\tunsigned long flags;\n\tbool dolock;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn NULL;\n\n again:\n\tlocal_irq_save(flags);\n\tdolock = rb_reader_lock(cpu_buffer);\n\tevent = rb_buffer_peek(cpu_buffer, ts, lost_events);\n\tif (event && event->type_len == RINGBUF_TYPE_PADDING)\n\t\trb_advance_reader(cpu_buffer);\n\trb_reader_unlock(cpu_buffer, dolock);\n\tlocal_irq_restore(flags);\n\n\tif (event && event->type_len == RINGBUF_TYPE_PADDING)\n\t\tgoto again;\n\n\treturn event;\n}"
  },
  {
    "function_name": "rb_reader_unlock",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "4019-4025",
    "snippet": "static inline void\nrb_reader_unlock(struct ring_buffer_per_cpu *cpu_buffer, bool locked)\n{\n\tif (likely(locked))\n\t\traw_spin_unlock(&cpu_buffer->reader_lock);\n\treturn;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_spin_unlock",
          "args": [
            "&cpu_buffer->reader_lock"
          ],
          "line": 4023
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "198-201",
          "snippet": "void __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "locked"
          ],
          "line": 4022
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline void\nrb_reader_unlock(struct ring_buffer_per_cpu *cpu_buffer, bool locked)\n{\n\tif (likely(locked))\n\t\traw_spin_unlock(&cpu_buffer->reader_lock);\n\treturn;\n}"
  },
  {
    "function_name": "rb_reader_lock",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3995-4017",
    "snippet": "static inline bool rb_reader_lock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tif (likely(!in_nmi())) {\n\t\traw_spin_lock(&cpu_buffer->reader_lock);\n\t\treturn true;\n\t}\n\n\t/*\n\t * If an NMI die dumps out the content of the ring buffer\n\t * trylock must be used to prevent a deadlock if the NMI\n\t * preempted a task that holds the ring buffer locks. If\n\t * we get the lock then all is fine, if not, then continue\n\t * to do the read, but this can corrupt the ring buffer,\n\t * so it must be permanently disabled from future writes.\n\t * Reading from NMI is a oneshot deal.\n\t */\n\tif (raw_spin_trylock(&cpu_buffer->reader_lock))\n\t\treturn true;\n\n\t/* Continue without locking, but disable the ring buffer */\n\tatomic_inc(&cpu_buffer->record_disabled);\n\treturn false;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_inc",
          "args": [
            "&cpu_buffer->record_disabled"
          ],
          "line": 4015
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_trylock",
          "args": [
            "&cpu_buffer->reader_lock"
          ],
          "line": 4011
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_trylock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "134-137",
          "snippet": "int __lockfunc _raw_spin_trylock_bh(raw_spinlock_t *lock)\n{\n\treturn __raw_spin_trylock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nint __lockfunc _raw_spin_trylock_bh(raw_spinlock_t *lock)\n{\n\treturn __raw_spin_trylock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock",
          "args": [
            "&cpu_buffer->reader_lock"
          ],
          "line": 3998
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "166-169",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "!in_nmi()"
          ],
          "line": 3997
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "in_nmi",
          "args": [],
          "line": 3997
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline bool rb_reader_lock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tif (likely(!in_nmi())) {\n\t\traw_spin_lock(&cpu_buffer->reader_lock);\n\t\treturn true;\n\t}\n\n\t/*\n\t * If an NMI die dumps out the content of the ring buffer\n\t * trylock must be used to prevent a deadlock if the NMI\n\t * preempted a task that holds the ring buffer locks. If\n\t * we get the lock then all is fine, if not, then continue\n\t * to do the read, but this can corrupt the ring buffer,\n\t * so it must be permanently disabled from future writes.\n\t * Reading from NMI is a oneshot deal.\n\t */\n\tif (raw_spin_trylock(&cpu_buffer->reader_lock))\n\t\treturn true;\n\n\t/* Continue without locking, but disable the ring buffer */\n\tatomic_inc(&cpu_buffer->record_disabled);\n\treturn false;\n}"
  },
  {
    "function_name": "rb_iter_peek",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3907-3992",
    "snippet": "static struct ring_buffer_event *\nrb_iter_peek(struct ring_buffer_iter *iter, u64 *ts)\n{\n\tstruct ring_buffer *buffer;\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct ring_buffer_event *event;\n\tint nr_loops = 0;\n\n\tif (ts)\n\t\t*ts = 0;\n\n\tcpu_buffer = iter->cpu_buffer;\n\tbuffer = cpu_buffer->buffer;\n\n\t/*\n\t * Check if someone performed a consuming read to\n\t * the buffer. A consuming read invalidates the iterator\n\t * and we need to reset the iterator in this case.\n\t */\n\tif (unlikely(iter->cache_read != cpu_buffer->read ||\n\t\t     iter->cache_reader_page != cpu_buffer->reader_page))\n\t\trb_iter_reset(iter);\n\n again:\n\tif (ring_buffer_iter_empty(iter))\n\t\treturn NULL;\n\n\t/*\n\t * We repeat when a time extend is encountered or we hit\n\t * the end of the page. Since the time extend is always attached\n\t * to a data event, we should never loop more than three times.\n\t * Once for going to next page, once on time extend, and\n\t * finally once to get the event.\n\t * (We never hit the following condition more than thrice).\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 3))\n\t\treturn NULL;\n\n\tif (rb_per_cpu_empty(cpu_buffer))\n\t\treturn NULL;\n\n\tif (iter->head >= rb_page_size(iter->head_page)) {\n\t\trb_inc_iter(iter);\n\t\tgoto again;\n\t}\n\n\tevent = rb_iter_head_event(iter);\n\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event)) {\n\t\t\trb_inc_iter(iter);\n\t\t\tgoto again;\n\t\t}\n\t\trb_advance_iter(iter);\n\t\treturn event;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\t/* Internal data, OK to advance */\n\t\trb_advance_iter(iter);\n\t\tgoto again;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\tif (ts) {\n\t\t\t*ts = ring_buffer_event_time_stamp(event);\n\t\t\tring_buffer_normalize_time_stamp(cpu_buffer->buffer,\n\t\t\t\t\t\t\t cpu_buffer->cpu, ts);\n\t\t}\n\t\t/* Internal data, OK to advance */\n\t\trb_advance_iter(iter);\n\t\tgoto again;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\tif (ts && !(*ts)) {\n\t\t\t*ts = iter->read_stamp + event->time_delta;\n\t\t\tring_buffer_normalize_time_stamp(buffer,\n\t\t\t\t\t\t\t cpu_buffer->cpu, ts);\n\t\t}\n\t\treturn event;\n\n\tdefault:\n\t\tBUG();\n\t}\n\n\treturn NULL;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX"
    ],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "BUG",
          "args": [],
          "line": 3988
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ring_buffer_normalize_time_stamp",
          "args": [
            "buffer",
            "cpu_buffer->cpu",
            "ts"
          ],
          "line": 3982
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_normalize_time_stamp",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "739-744",
          "snippet": "void ring_buffer_normalize_time_stamp(struct ring_buffer *buffer,\n\t\t\t\t      int cpu, u64 *ts)\n{\n\t/* Just stupid testing the normalize function and deltas */\n\t*ts >>= DEBUG_SHIFT;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define DEBUG_SHIFT 0"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define DEBUG_SHIFT 0\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid ring_buffer_normalize_time_stamp(struct ring_buffer *buffer,\n\t\t\t\t      int cpu, u64 *ts)\n{\n\t/* Just stupid testing the normalize function and deltas */\n\t*ts >>= DEBUG_SHIFT;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_advance_iter",
          "args": [
            "iter"
          ],
          "line": 3976
        },
        "resolved": true,
        "details": {
          "function_name": "rb_advance_iter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3787-3827",
          "snippet": "static void rb_advance_iter(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct ring_buffer_event *event;\n\tunsigned length;\n\n\tcpu_buffer = iter->cpu_buffer;\n\n\t/*\n\t * Check if we are at the end of the buffer.\n\t */\n\tif (iter->head >= rb_page_size(iter->head_page)) {\n\t\t/* discarded commits can make the page empty */\n\t\tif (iter->head_page == cpu_buffer->commit_page)\n\t\t\treturn;\n\t\trb_inc_iter(iter);\n\t\treturn;\n\t}\n\n\tevent = rb_iter_head_event(iter);\n\n\tlength = rb_event_length(event);\n\n\t/*\n\t * This should not be called to advance the header if we are\n\t * at the tail of the buffer.\n\t */\n\tif (RB_WARN_ON(cpu_buffer,\n\t\t       (iter->head_page == cpu_buffer->commit_page) &&\n\t\t       (iter->head + length > rb_commit_index(cpu_buffer))))\n\t\treturn;\n\n\trb_update_iter_read_stamp(iter, event);\n\n\titer->head += length;\n\n\t/* check for end of page padding */\n\tif ((iter->head >= rb_page_size(iter->head_page)) &&\n\t    (iter->head_page != cpu_buffer->commit_page))\n\t\trb_inc_iter(iter);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic void rb_advance_iter(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct ring_buffer_event *event;\n\tunsigned length;\n\n\tcpu_buffer = iter->cpu_buffer;\n\n\t/*\n\t * Check if we are at the end of the buffer.\n\t */\n\tif (iter->head >= rb_page_size(iter->head_page)) {\n\t\t/* discarded commits can make the page empty */\n\t\tif (iter->head_page == cpu_buffer->commit_page)\n\t\t\treturn;\n\t\trb_inc_iter(iter);\n\t\treturn;\n\t}\n\n\tevent = rb_iter_head_event(iter);\n\n\tlength = rb_event_length(event);\n\n\t/*\n\t * This should not be called to advance the header if we are\n\t * at the tail of the buffer.\n\t */\n\tif (RB_WARN_ON(cpu_buffer,\n\t\t       (iter->head_page == cpu_buffer->commit_page) &&\n\t\t       (iter->head + length > rb_commit_index(cpu_buffer))))\n\t\treturn;\n\n\trb_update_iter_read_stamp(iter, event);\n\n\titer->head += length;\n\n\t/* check for end of page padding */\n\tif ((iter->head >= rb_page_size(iter->head_page)) &&\n\t    (iter->head_page != cpu_buffer->commit_page))\n\t\trb_inc_iter(iter);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ring_buffer_event_time_stamp",
          "args": [
            "event"
          ],
          "line": 3971
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_event_time_stamp",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "295-304",
          "snippet": "u64 ring_buffer_event_time_stamp(struct ring_buffer_event *event)\n{\n\tu64 ts;\n\n\tts = event->array[0];\n\tts <<= TS_SHIFT;\n\tts += event->time_delta;\n\n\treturn ts;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define TS_SHIFT\t27"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define TS_SHIFT\t27\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nu64 ring_buffer_event_time_stamp(struct ring_buffer_event *event)\n{\n\tu64 ts;\n\n\tts = event->array[0];\n\tts <<= TS_SHIFT;\n\tts += event->time_delta;\n\n\treturn ts;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_inc_iter",
          "args": [
            "iter"
          ],
          "line": 3958
        },
        "resolved": true,
        "details": {
          "function_name": "rb_inc_iter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1923-1940",
          "snippet": "static void rb_inc_iter(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = iter->cpu_buffer;\n\n\t/*\n\t * The iterator could be on the reader page (it starts there).\n\t * But the head could have moved, since the reader was\n\t * found. Check for this case and assign the iterator\n\t * to the head page instead of next.\n\t */\n\tif (iter->head_page == cpu_buffer->reader_page)\n\t\titer->head_page = rb_set_head_page(cpu_buffer);\n\telse\n\t\trb_inc_page(cpu_buffer, &iter->head_page);\n\n\titer->read_stamp = iter->head_page->page->time_stamp;\n\titer->head = 0;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_inc_iter(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = iter->cpu_buffer;\n\n\t/*\n\t * The iterator could be on the reader page (it starts there).\n\t * But the head could have moved, since the reader was\n\t * found. Check for this case and assign the iterator\n\t * to the head page instead of next.\n\t */\n\tif (iter->head_page == cpu_buffer->reader_page)\n\t\titer->head_page = rb_set_head_page(cpu_buffer);\n\telse\n\t\trb_inc_page(cpu_buffer, &iter->head_page);\n\n\titer->read_stamp = iter->head_page->page->time_stamp;\n\titer->head = 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_null_event",
          "args": [
            "event"
          ],
          "line": 3957
        },
        "resolved": true,
        "details": {
          "function_name": "rb_null_event",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "156-159",
          "snippet": "static inline int rb_null_event(struct ring_buffer_event *event)\n{\n\treturn event->type_len == RINGBUF_TYPE_PADDING && !event->time_delta;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic inline int rb_null_event(struct ring_buffer_event *event)\n{\n\treturn event->type_len == RINGBUF_TYPE_PADDING && !event->time_delta;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_iter_head_event",
          "args": [
            "iter"
          ],
          "line": 3953
        },
        "resolved": true,
        "details": {
          "function_name": "rb_iter_head_event",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1892-1896",
          "snippet": "ring_buffer_event *\nrb_iter_head_event(struct ring_buffer_iter *iter)\n{\n\treturn __rb_page_index(iter->head_page, iter->head);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nring_buffer_event *\nrb_iter_head_event(struct ring_buffer_iter *iter)\n{\n\treturn __rb_page_index(iter->head_page, iter->head);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_page_size",
          "args": [
            "iter->head_page"
          ],
          "line": 3948
        },
        "resolved": true,
        "details": {
          "function_name": "rb_page_size",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1904-1907",
          "snippet": "static __always_inline unsigned rb_page_size(struct buffer_page *bpage)\n{\n\treturn rb_page_commit(bpage);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline unsigned rb_page_size(struct buffer_page *bpage)\n{\n\treturn rb_page_commit(bpage);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_per_cpu_empty",
          "args": [
            "cpu_buffer"
          ],
          "line": 3945
        },
        "resolved": true,
        "details": {
          "function_name": "rb_per_cpu_empty",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3131-3145",
          "snippet": "static bool rb_per_cpu_empty(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *reader = cpu_buffer->reader_page;\n\tstruct buffer_page *head = rb_set_head_page(cpu_buffer);\n\tstruct buffer_page *commit = cpu_buffer->commit_page;\n\n\t/* In case of error, head will be NULL */\n\tif (unlikely(!head))\n\t\treturn true;\n\n\treturn reader->read == rb_page_commit(reader) &&\n\t\t(commit == reader ||\n\t\t (commit == head &&\n\t\t  head->read == rb_page_commit(commit)));\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic bool rb_per_cpu_empty(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *reader = cpu_buffer->reader_page;\n\tstruct buffer_page *head = rb_set_head_page(cpu_buffer);\n\tstruct buffer_page *commit = cpu_buffer->commit_page;\n\n\t/* In case of error, head will be NULL */\n\tif (unlikely(!head))\n\t\treturn true;\n\n\treturn reader->read == rb_page_commit(reader) &&\n\t\t(commit == reader ||\n\t\t (commit == head &&\n\t\t  head->read == rb_page_commit(commit)));\n}"
        }
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "++nr_loops > 3"
          ],
          "line": 3942
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ring_buffer_iter_empty",
          "args": [
            "iter"
          ],
          "line": 3931
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_iter_empty",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3548-3568",
          "snippet": "int ring_buffer_iter_empty(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct buffer_page *reader;\n\tstruct buffer_page *head_page;\n\tstruct buffer_page *commit_page;\n\tunsigned commit;\n\n\tcpu_buffer = iter->cpu_buffer;\n\n\t/* Remember, trace recording is off when iterator is in use */\n\treader = cpu_buffer->reader_page;\n\thead_page = cpu_buffer->head_page;\n\tcommit_page = cpu_buffer->commit_page;\n\tcommit = rb_page_commit(commit_page);\n\n\treturn ((iter->head_page == commit_page && iter->head == commit) ||\n\t\t(iter->head_page == reader && commit_page == head_page &&\n\t\t head_page->read == commit &&\n\t\t iter->head == rb_page_commit(cpu_buffer->reader_page)));\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nint ring_buffer_iter_empty(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct buffer_page *reader;\n\tstruct buffer_page *head_page;\n\tstruct buffer_page *commit_page;\n\tunsigned commit;\n\n\tcpu_buffer = iter->cpu_buffer;\n\n\t/* Remember, trace recording is off when iterator is in use */\n\treader = cpu_buffer->reader_page;\n\thead_page = cpu_buffer->head_page;\n\tcommit_page = cpu_buffer->commit_page;\n\tcommit = rb_page_commit(commit_page);\n\n\treturn ((iter->head_page == commit_page && iter->head == commit) ||\n\t\t(iter->head_page == reader && commit_page == head_page &&\n\t\t head_page->read == commit &&\n\t\t iter->head == rb_page_commit(cpu_buffer->reader_page)));\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_iter_reset",
          "args": [
            "iter"
          ],
          "line": 3928
        },
        "resolved": true,
        "details": {
          "function_name": "rb_iter_reset",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3504-3519",
          "snippet": "static void rb_iter_reset(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = iter->cpu_buffer;\n\n\t/* Iterator usage is expected to have record disabled */\n\titer->head_page = cpu_buffer->reader_page;\n\titer->head = cpu_buffer->reader_page->read;\n\n\titer->cache_reader_page = iter->head_page;\n\titer->cache_read = cpu_buffer->read;\n\n\tif (iter->head)\n\t\titer->read_stamp = cpu_buffer->read_stamp;\n\telse\n\t\titer->read_stamp = iter->head_page->page->time_stamp;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_iter_reset(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = iter->cpu_buffer;\n\n\t/* Iterator usage is expected to have record disabled */\n\titer->head_page = cpu_buffer->reader_page;\n\titer->head = cpu_buffer->reader_page->read;\n\n\titer->cache_reader_page = iter->head_page;\n\titer->cache_read = cpu_buffer->read;\n\n\tif (iter->head)\n\t\titer->read_stamp = cpu_buffer->read_stamp;\n\telse\n\t\titer->read_stamp = iter->head_page->page->time_stamp;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "iter->cache_read != cpu_buffer->read ||\n\t\t     iter->cache_reader_page != cpu_buffer->reader_page"
          ],
          "line": 3926
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic struct ring_buffer_event *\nrb_iter_peek(struct ring_buffer_iter *iter, u64 *ts)\n{\n\tstruct ring_buffer *buffer;\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct ring_buffer_event *event;\n\tint nr_loops = 0;\n\n\tif (ts)\n\t\t*ts = 0;\n\n\tcpu_buffer = iter->cpu_buffer;\n\tbuffer = cpu_buffer->buffer;\n\n\t/*\n\t * Check if someone performed a consuming read to\n\t * the buffer. A consuming read invalidates the iterator\n\t * and we need to reset the iterator in this case.\n\t */\n\tif (unlikely(iter->cache_read != cpu_buffer->read ||\n\t\t     iter->cache_reader_page != cpu_buffer->reader_page))\n\t\trb_iter_reset(iter);\n\n again:\n\tif (ring_buffer_iter_empty(iter))\n\t\treturn NULL;\n\n\t/*\n\t * We repeat when a time extend is encountered or we hit\n\t * the end of the page. Since the time extend is always attached\n\t * to a data event, we should never loop more than three times.\n\t * Once for going to next page, once on time extend, and\n\t * finally once to get the event.\n\t * (We never hit the following condition more than thrice).\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 3))\n\t\treturn NULL;\n\n\tif (rb_per_cpu_empty(cpu_buffer))\n\t\treturn NULL;\n\n\tif (iter->head >= rb_page_size(iter->head_page)) {\n\t\trb_inc_iter(iter);\n\t\tgoto again;\n\t}\n\n\tevent = rb_iter_head_event(iter);\n\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event)) {\n\t\t\trb_inc_iter(iter);\n\t\t\tgoto again;\n\t\t}\n\t\trb_advance_iter(iter);\n\t\treturn event;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\t/* Internal data, OK to advance */\n\t\trb_advance_iter(iter);\n\t\tgoto again;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\tif (ts) {\n\t\t\t*ts = ring_buffer_event_time_stamp(event);\n\t\t\tring_buffer_normalize_time_stamp(cpu_buffer->buffer,\n\t\t\t\t\t\t\t cpu_buffer->cpu, ts);\n\t\t}\n\t\t/* Internal data, OK to advance */\n\t\trb_advance_iter(iter);\n\t\tgoto again;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\tif (ts && !(*ts)) {\n\t\t\t*ts = iter->read_stamp + event->time_delta;\n\t\t\tring_buffer_normalize_time_stamp(buffer,\n\t\t\t\t\t\t\t cpu_buffer->cpu, ts);\n\t\t}\n\t\treturn event;\n\n\tdefault:\n\t\tBUG();\n\t}\n\n\treturn NULL;\n}"
  },
  {
    "function_name": "rb_buffer_peek",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3834-3904",
    "snippet": "static struct ring_buffer_event *\nrb_buffer_peek(struct ring_buffer_per_cpu *cpu_buffer, u64 *ts,\n\t       unsigned long *lost_events)\n{\n\tstruct ring_buffer_event *event;\n\tstruct buffer_page *reader;\n\tint nr_loops = 0;\n\n\tif (ts)\n\t\t*ts = 0;\n again:\n\t/*\n\t * We repeat when a time extend is encountered.\n\t * Since the time extend is always attached to a data event,\n\t * we should never loop more than once.\n\t * (We never hit the following condition more than twice).\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 2))\n\t\treturn NULL;\n\n\treader = rb_get_reader_page(cpu_buffer);\n\tif (!reader)\n\t\treturn NULL;\n\n\tevent = rb_reader_event(cpu_buffer);\n\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event))\n\t\t\tRB_WARN_ON(cpu_buffer, 1);\n\t\t/*\n\t\t * Because the writer could be discarding every\n\t\t * event it creates (which would probably be bad)\n\t\t * if we were to go back to \"again\" then we may never\n\t\t * catch up, and will trigger the warn on, or lock\n\t\t * the box. Return the padding, and we will release\n\t\t * the current locks, and try again.\n\t\t */\n\t\treturn event;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\t/* Internal data, OK to advance */\n\t\trb_advance_reader(cpu_buffer);\n\t\tgoto again;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\tif (ts) {\n\t\t\t*ts = ring_buffer_event_time_stamp(event);\n\t\t\tring_buffer_normalize_time_stamp(cpu_buffer->buffer,\n\t\t\t\t\t\t\t cpu_buffer->cpu, ts);\n\t\t}\n\t\t/* Internal data, OK to advance */\n\t\trb_advance_reader(cpu_buffer);\n\t\tgoto again;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\tif (ts && !(*ts)) {\n\t\t\t*ts = cpu_buffer->read_stamp + event->time_delta;\n\t\t\tring_buffer_normalize_time_stamp(cpu_buffer->buffer,\n\t\t\t\t\t\t\t cpu_buffer->cpu, ts);\n\t\t}\n\t\tif (lost_events)\n\t\t\t*lost_events = rb_lost_events(cpu_buffer);\n\t\treturn event;\n\n\tdefault:\n\t\tBUG();\n\t}\n\n\treturn NULL;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX"
    ],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "BUG",
          "args": [],
          "line": 3900
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_lost_events",
          "args": [
            "cpu_buffer"
          ],
          "line": 3896
        },
        "resolved": true,
        "details": {
          "function_name": "rb_lost_events",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3829-3832",
          "snippet": "static int rb_lost_events(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn cpu_buffer->lost_events;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int rb_lost_events(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn cpu_buffer->lost_events;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ring_buffer_normalize_time_stamp",
          "args": [
            "cpu_buffer->buffer",
            "cpu_buffer->cpu",
            "ts"
          ],
          "line": 3892
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_normalize_time_stamp",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "739-744",
          "snippet": "void ring_buffer_normalize_time_stamp(struct ring_buffer *buffer,\n\t\t\t\t      int cpu, u64 *ts)\n{\n\t/* Just stupid testing the normalize function and deltas */\n\t*ts >>= DEBUG_SHIFT;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define DEBUG_SHIFT 0"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define DEBUG_SHIFT 0\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid ring_buffer_normalize_time_stamp(struct ring_buffer *buffer,\n\t\t\t\t      int cpu, u64 *ts)\n{\n\t/* Just stupid testing the normalize function and deltas */\n\t*ts >>= DEBUG_SHIFT;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_advance_reader",
          "args": [
            "cpu_buffer"
          ],
          "line": 3886
        },
        "resolved": true,
        "details": {
          "function_name": "rb_advance_reader",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3764-3785",
          "snippet": "static void rb_advance_reader(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct ring_buffer_event *event;\n\tstruct buffer_page *reader;\n\tunsigned length;\n\n\treader = rb_get_reader_page(cpu_buffer);\n\n\t/* This function should not be called when buffer is empty */\n\tif (RB_WARN_ON(cpu_buffer, !reader))\n\t\treturn;\n\n\tevent = rb_reader_event(cpu_buffer);\n\n\tif (event->type_len <= RINGBUF_TYPE_DATA_TYPE_LEN_MAX)\n\t\tcpu_buffer->read++;\n\n\trb_update_read_stamp(cpu_buffer, event);\n\n\tlength = rb_event_length(event);\n\tcpu_buffer->reader_page->read += length;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic void rb_advance_reader(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct ring_buffer_event *event;\n\tstruct buffer_page *reader;\n\tunsigned length;\n\n\treader = rb_get_reader_page(cpu_buffer);\n\n\t/* This function should not be called when buffer is empty */\n\tif (RB_WARN_ON(cpu_buffer, !reader))\n\t\treturn;\n\n\tevent = rb_reader_event(cpu_buffer);\n\n\tif (event->type_len <= RINGBUF_TYPE_DATA_TYPE_LEN_MAX)\n\t\tcpu_buffer->read++;\n\n\trb_update_read_stamp(cpu_buffer, event);\n\n\tlength = rb_event_length(event);\n\tcpu_buffer->reader_page->read += length;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ring_buffer_event_time_stamp",
          "args": [
            "event"
          ],
          "line": 3881
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_event_time_stamp",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "295-304",
          "snippet": "u64 ring_buffer_event_time_stamp(struct ring_buffer_event *event)\n{\n\tu64 ts;\n\n\tts = event->array[0];\n\tts <<= TS_SHIFT;\n\tts += event->time_delta;\n\n\treturn ts;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define TS_SHIFT\t27"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define TS_SHIFT\t27\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nu64 ring_buffer_event_time_stamp(struct ring_buffer_event *event)\n{\n\tu64 ts;\n\n\tts = event->array[0];\n\tts <<= TS_SHIFT;\n\tts += event->time_delta;\n\n\treturn ts;\n}"
        }
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "1"
          ],
          "line": 3863
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_null_event",
          "args": [
            "event"
          ],
          "line": 3862
        },
        "resolved": true,
        "details": {
          "function_name": "rb_null_event",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "156-159",
          "snippet": "static inline int rb_null_event(struct ring_buffer_event *event)\n{\n\treturn event->type_len == RINGBUF_TYPE_PADDING && !event->time_delta;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic inline int rb_null_event(struct ring_buffer_event *event)\n{\n\treturn event->type_len == RINGBUF_TYPE_PADDING && !event->time_delta;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_reader_event",
          "args": [
            "cpu_buffer"
          ],
          "line": 3858
        },
        "resolved": true,
        "details": {
          "function_name": "rb_reader_event",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1885-1890",
          "snippet": "ring_buffer_event *\nrb_reader_event(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn __rb_page_index(cpu_buffer->reader_page,\n\t\t\t       cpu_buffer->reader_page->read);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nring_buffer_event *\nrb_reader_event(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn __rb_page_index(cpu_buffer->reader_page,\n\t\t\t       cpu_buffer->reader_page->read);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_get_reader_page",
          "args": [
            "cpu_buffer"
          ],
          "line": 3854
        },
        "resolved": true,
        "details": {
          "function_name": "rb_get_reader_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3631-3762",
          "snippet": "static struct buffer_page *\nrb_get_reader_page(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *reader = NULL;\n\tunsigned long overwrite;\n\tunsigned long flags;\n\tint nr_loops = 0;\n\tint ret;\n\n\tlocal_irq_save(flags);\n\tarch_spin_lock(&cpu_buffer->lock);\n\n again:\n\t/*\n\t * This should normally only loop twice. But because the\n\t * start of the reader inserts an empty page, it causes\n\t * a case where we will loop three times. There should be no\n\t * reason to loop four times (that I know of).\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 3)) {\n\t\treader = NULL;\n\t\tgoto out;\n\t}\n\n\treader = cpu_buffer->reader_page;\n\n\t/* If there's more to read, return this page */\n\tif (cpu_buffer->reader_page->read < rb_page_size(reader))\n\t\tgoto out;\n\n\t/* Never should we have an index greater than the size */\n\tif (RB_WARN_ON(cpu_buffer,\n\t\t       cpu_buffer->reader_page->read > rb_page_size(reader)))\n\t\tgoto out;\n\n\t/* check if we caught up to the tail */\n\treader = NULL;\n\tif (cpu_buffer->commit_page == cpu_buffer->reader_page)\n\t\tgoto out;\n\n\t/* Don't bother swapping if the ring buffer is empty */\n\tif (rb_num_of_entries(cpu_buffer) == 0)\n\t\tgoto out;\n\n\t/*\n\t * Reset the reader page to size zero.\n\t */\n\tlocal_set(&cpu_buffer->reader_page->write, 0);\n\tlocal_set(&cpu_buffer->reader_page->entries, 0);\n\tlocal_set(&cpu_buffer->reader_page->page->commit, 0);\n\tcpu_buffer->reader_page->real_end = 0;\n\n spin:\n\t/*\n\t * Splice the empty reader page into the list around the head.\n\t */\n\treader = rb_set_head_page(cpu_buffer);\n\tif (!reader)\n\t\tgoto out;\n\tcpu_buffer->reader_page->list.next = rb_list_head(reader->list.next);\n\tcpu_buffer->reader_page->list.prev = reader->list.prev;\n\n\t/*\n\t * cpu_buffer->pages just needs to point to the buffer, it\n\t *  has no specific buffer page to point to. Lets move it out\n\t *  of our way so we don't accidentally swap it.\n\t */\n\tcpu_buffer->pages = reader->list.prev;\n\n\t/* The reader page will be pointing to the new head */\n\trb_set_list_to_head(cpu_buffer, &cpu_buffer->reader_page->list);\n\n\t/*\n\t * We want to make sure we read the overruns after we set up our\n\t * pointers to the next object. The writer side does a\n\t * cmpxchg to cross pages which acts as the mb on the writer\n\t * side. Note, the reader will constantly fail the swap\n\t * while the writer is updating the pointers, so this\n\t * guarantees that the overwrite recorded here is the one we\n\t * want to compare with the last_overrun.\n\t */\n\tsmp_mb();\n\toverwrite = local_read(&(cpu_buffer->overrun));\n\n\t/*\n\t * Here's the tricky part.\n\t *\n\t * We need to move the pointer past the header page.\n\t * But we can only do that if a writer is not currently\n\t * moving it. The page before the header page has the\n\t * flag bit '1' set if it is pointing to the page we want.\n\t * but if the writer is in the process of moving it\n\t * than it will be '2' or already moved '0'.\n\t */\n\n\tret = rb_head_page_replace(reader, cpu_buffer->reader_page);\n\n\t/*\n\t * If we did not convert it, then we must try again.\n\t */\n\tif (!ret)\n\t\tgoto spin;\n\n\t/*\n\t * Yeah! We succeeded in replacing the page.\n\t *\n\t * Now make the new head point back to the reader page.\n\t */\n\trb_list_head(reader->list.next)->prev = &cpu_buffer->reader_page->list;\n\trb_inc_page(cpu_buffer, &cpu_buffer->head_page);\n\n\t/* Finally update the reader page to the new head */\n\tcpu_buffer->reader_page = reader;\n\tcpu_buffer->reader_page->read = 0;\n\n\tif (overwrite != cpu_buffer->last_overrun) {\n\t\tcpu_buffer->lost_events = overwrite - cpu_buffer->last_overrun;\n\t\tcpu_buffer->last_overrun = overwrite;\n\t}\n\n\tgoto again;\n\n out:\n\t/* Update the read_stamp on the first event */\n\tif (reader && reader->read == 0)\n\t\tcpu_buffer->read_stamp = reader->page->time_stamp;\n\n\tarch_spin_unlock(&cpu_buffer->lock);\n\tlocal_irq_restore(flags);\n\n\treturn reader;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic struct buffer_page *\nrb_get_reader_page(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *reader = NULL;\n\tunsigned long overwrite;\n\tunsigned long flags;\n\tint nr_loops = 0;\n\tint ret;\n\n\tlocal_irq_save(flags);\n\tarch_spin_lock(&cpu_buffer->lock);\n\n again:\n\t/*\n\t * This should normally only loop twice. But because the\n\t * start of the reader inserts an empty page, it causes\n\t * a case where we will loop three times. There should be no\n\t * reason to loop four times (that I know of).\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 3)) {\n\t\treader = NULL;\n\t\tgoto out;\n\t}\n\n\treader = cpu_buffer->reader_page;\n\n\t/* If there's more to read, return this page */\n\tif (cpu_buffer->reader_page->read < rb_page_size(reader))\n\t\tgoto out;\n\n\t/* Never should we have an index greater than the size */\n\tif (RB_WARN_ON(cpu_buffer,\n\t\t       cpu_buffer->reader_page->read > rb_page_size(reader)))\n\t\tgoto out;\n\n\t/* check if we caught up to the tail */\n\treader = NULL;\n\tif (cpu_buffer->commit_page == cpu_buffer->reader_page)\n\t\tgoto out;\n\n\t/* Don't bother swapping if the ring buffer is empty */\n\tif (rb_num_of_entries(cpu_buffer) == 0)\n\t\tgoto out;\n\n\t/*\n\t * Reset the reader page to size zero.\n\t */\n\tlocal_set(&cpu_buffer->reader_page->write, 0);\n\tlocal_set(&cpu_buffer->reader_page->entries, 0);\n\tlocal_set(&cpu_buffer->reader_page->page->commit, 0);\n\tcpu_buffer->reader_page->real_end = 0;\n\n spin:\n\t/*\n\t * Splice the empty reader page into the list around the head.\n\t */\n\treader = rb_set_head_page(cpu_buffer);\n\tif (!reader)\n\t\tgoto out;\n\tcpu_buffer->reader_page->list.next = rb_list_head(reader->list.next);\n\tcpu_buffer->reader_page->list.prev = reader->list.prev;\n\n\t/*\n\t * cpu_buffer->pages just needs to point to the buffer, it\n\t *  has no specific buffer page to point to. Lets move it out\n\t *  of our way so we don't accidentally swap it.\n\t */\n\tcpu_buffer->pages = reader->list.prev;\n\n\t/* The reader page will be pointing to the new head */\n\trb_set_list_to_head(cpu_buffer, &cpu_buffer->reader_page->list);\n\n\t/*\n\t * We want to make sure we read the overruns after we set up our\n\t * pointers to the next object. The writer side does a\n\t * cmpxchg to cross pages which acts as the mb on the writer\n\t * side. Note, the reader will constantly fail the swap\n\t * while the writer is updating the pointers, so this\n\t * guarantees that the overwrite recorded here is the one we\n\t * want to compare with the last_overrun.\n\t */\n\tsmp_mb();\n\toverwrite = local_read(&(cpu_buffer->overrun));\n\n\t/*\n\t * Here's the tricky part.\n\t *\n\t * We need to move the pointer past the header page.\n\t * But we can only do that if a writer is not currently\n\t * moving it. The page before the header page has the\n\t * flag bit '1' set if it is pointing to the page we want.\n\t * but if the writer is in the process of moving it\n\t * than it will be '2' or already moved '0'.\n\t */\n\n\tret = rb_head_page_replace(reader, cpu_buffer->reader_page);\n\n\t/*\n\t * If we did not convert it, then we must try again.\n\t */\n\tif (!ret)\n\t\tgoto spin;\n\n\t/*\n\t * Yeah! We succeeded in replacing the page.\n\t *\n\t * Now make the new head point back to the reader page.\n\t */\n\trb_list_head(reader->list.next)->prev = &cpu_buffer->reader_page->list;\n\trb_inc_page(cpu_buffer, &cpu_buffer->head_page);\n\n\t/* Finally update the reader page to the new head */\n\tcpu_buffer->reader_page = reader;\n\tcpu_buffer->reader_page->read = 0;\n\n\tif (overwrite != cpu_buffer->last_overrun) {\n\t\tcpu_buffer->lost_events = overwrite - cpu_buffer->last_overrun;\n\t\tcpu_buffer->last_overrun = overwrite;\n\t}\n\n\tgoto again;\n\n out:\n\t/* Update the read_stamp on the first event */\n\tif (reader && reader->read == 0)\n\t\tcpu_buffer->read_stamp = reader->page->time_stamp;\n\n\tarch_spin_unlock(&cpu_buffer->lock);\n\tlocal_irq_restore(flags);\n\n\treturn reader;\n}"
        }
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "++nr_loops > 2"
          ],
          "line": 3851
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic struct ring_buffer_event *\nrb_buffer_peek(struct ring_buffer_per_cpu *cpu_buffer, u64 *ts,\n\t       unsigned long *lost_events)\n{\n\tstruct ring_buffer_event *event;\n\tstruct buffer_page *reader;\n\tint nr_loops = 0;\n\n\tif (ts)\n\t\t*ts = 0;\n again:\n\t/*\n\t * We repeat when a time extend is encountered.\n\t * Since the time extend is always attached to a data event,\n\t * we should never loop more than once.\n\t * (We never hit the following condition more than twice).\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 2))\n\t\treturn NULL;\n\n\treader = rb_get_reader_page(cpu_buffer);\n\tif (!reader)\n\t\treturn NULL;\n\n\tevent = rb_reader_event(cpu_buffer);\n\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event))\n\t\t\tRB_WARN_ON(cpu_buffer, 1);\n\t\t/*\n\t\t * Because the writer could be discarding every\n\t\t * event it creates (which would probably be bad)\n\t\t * if we were to go back to \"again\" then we may never\n\t\t * catch up, and will trigger the warn on, or lock\n\t\t * the box. Return the padding, and we will release\n\t\t * the current locks, and try again.\n\t\t */\n\t\treturn event;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\t/* Internal data, OK to advance */\n\t\trb_advance_reader(cpu_buffer);\n\t\tgoto again;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\tif (ts) {\n\t\t\t*ts = ring_buffer_event_time_stamp(event);\n\t\t\tring_buffer_normalize_time_stamp(cpu_buffer->buffer,\n\t\t\t\t\t\t\t cpu_buffer->cpu, ts);\n\t\t}\n\t\t/* Internal data, OK to advance */\n\t\trb_advance_reader(cpu_buffer);\n\t\tgoto again;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\tif (ts && !(*ts)) {\n\t\t\t*ts = cpu_buffer->read_stamp + event->time_delta;\n\t\t\tring_buffer_normalize_time_stamp(cpu_buffer->buffer,\n\t\t\t\t\t\t\t cpu_buffer->cpu, ts);\n\t\t}\n\t\tif (lost_events)\n\t\t\t*lost_events = rb_lost_events(cpu_buffer);\n\t\treturn event;\n\n\tdefault:\n\t\tBUG();\n\t}\n\n\treturn NULL;\n}"
  },
  {
    "function_name": "rb_lost_events",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3829-3832",
    "snippet": "static int rb_lost_events(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn cpu_buffer->lost_events;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int rb_lost_events(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn cpu_buffer->lost_events;\n}"
  },
  {
    "function_name": "rb_advance_iter",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3787-3827",
    "snippet": "static void rb_advance_iter(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct ring_buffer_event *event;\n\tunsigned length;\n\n\tcpu_buffer = iter->cpu_buffer;\n\n\t/*\n\t * Check if we are at the end of the buffer.\n\t */\n\tif (iter->head >= rb_page_size(iter->head_page)) {\n\t\t/* discarded commits can make the page empty */\n\t\tif (iter->head_page == cpu_buffer->commit_page)\n\t\t\treturn;\n\t\trb_inc_iter(iter);\n\t\treturn;\n\t}\n\n\tevent = rb_iter_head_event(iter);\n\n\tlength = rb_event_length(event);\n\n\t/*\n\t * This should not be called to advance the header if we are\n\t * at the tail of the buffer.\n\t */\n\tif (RB_WARN_ON(cpu_buffer,\n\t\t       (iter->head_page == cpu_buffer->commit_page) &&\n\t\t       (iter->head + length > rb_commit_index(cpu_buffer))))\n\t\treturn;\n\n\trb_update_iter_read_stamp(iter, event);\n\n\titer->head += length;\n\n\t/* check for end of page padding */\n\tif ((iter->head >= rb_page_size(iter->head_page)) &&\n\t    (iter->head_page != cpu_buffer->commit_page))\n\t\trb_inc_iter(iter);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_inc_iter",
          "args": [
            "iter"
          ],
          "line": 3826
        },
        "resolved": true,
        "details": {
          "function_name": "rb_inc_iter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1923-1940",
          "snippet": "static void rb_inc_iter(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = iter->cpu_buffer;\n\n\t/*\n\t * The iterator could be on the reader page (it starts there).\n\t * But the head could have moved, since the reader was\n\t * found. Check for this case and assign the iterator\n\t * to the head page instead of next.\n\t */\n\tif (iter->head_page == cpu_buffer->reader_page)\n\t\titer->head_page = rb_set_head_page(cpu_buffer);\n\telse\n\t\trb_inc_page(cpu_buffer, &iter->head_page);\n\n\titer->read_stamp = iter->head_page->page->time_stamp;\n\titer->head = 0;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_inc_iter(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = iter->cpu_buffer;\n\n\t/*\n\t * The iterator could be on the reader page (it starts there).\n\t * But the head could have moved, since the reader was\n\t * found. Check for this case and assign the iterator\n\t * to the head page instead of next.\n\t */\n\tif (iter->head_page == cpu_buffer->reader_page)\n\t\titer->head_page = rb_set_head_page(cpu_buffer);\n\telse\n\t\trb_inc_page(cpu_buffer, &iter->head_page);\n\n\titer->read_stamp = iter->head_page->page->time_stamp;\n\titer->head = 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_page_size",
          "args": [
            "iter->head_page"
          ],
          "line": 3824
        },
        "resolved": true,
        "details": {
          "function_name": "rb_page_size",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1904-1907",
          "snippet": "static __always_inline unsigned rb_page_size(struct buffer_page *bpage)\n{\n\treturn rb_page_commit(bpage);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline unsigned rb_page_size(struct buffer_page *bpage)\n{\n\treturn rb_page_commit(bpage);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_update_iter_read_stamp",
          "args": [
            "iter",
            "event"
          ],
          "line": 3819
        },
        "resolved": true,
        "details": {
          "function_name": "rb_update_iter_read_stamp",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3601-3629",
          "snippet": "static void\nrb_update_iter_read_stamp(struct ring_buffer_iter *iter,\n\t\t\t  struct ring_buffer_event *event)\n{\n\tu64 delta;\n\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\treturn;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\titer->read_stamp += delta;\n\t\treturn;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\titer->read_stamp = delta;\n\t\treturn;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\titer->read_stamp += event->time_delta;\n\t\treturn;\n\n\tdefault:\n\t\tBUG();\n\t}\n\treturn;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic void\nrb_update_iter_read_stamp(struct ring_buffer_iter *iter,\n\t\t\t  struct ring_buffer_event *event)\n{\n\tu64 delta;\n\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\treturn;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\titer->read_stamp += delta;\n\t\treturn;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\titer->read_stamp = delta;\n\t\treturn;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\titer->read_stamp += event->time_delta;\n\t\treturn;\n\n\tdefault:\n\t\tBUG();\n\t}\n\treturn;\n}"
        }
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "(iter->head_page == cpu_buffer->commit_page) &&\n\t\t       (iter->head + length > rb_commit_index(cpu_buffer))"
          ],
          "line": 3814
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_commit_index",
          "args": [
            "cpu_buffer"
          ],
          "line": 3816
        },
        "resolved": true,
        "details": {
          "function_name": "rb_commit_index",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1909-1913",
          "snippet": "static __always_inline unsigned\nrb_commit_index(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn rb_page_commit(cpu_buffer->commit_page);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline unsigned\nrb_commit_index(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn rb_page_commit(cpu_buffer->commit_page);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_event_length",
          "args": [
            "event"
          ],
          "line": 3808
        },
        "resolved": true,
        "details": {
          "function_name": "rb_event_length",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "185-208",
          "snippet": "static inline unsigned\nrb_event_length(struct ring_buffer_event *event)\n{\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event))\n\t\t\t/* undefined */\n\t\t\treturn -1;\n\t\treturn  event->array[0] + RB_EVNT_HDR_SIZE;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\treturn RB_LEN_TIME_EXTEND;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\treturn RB_LEN_TIME_STAMP;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\treturn rb_event_data_length(event);\n\tdefault:\n\t\tBUG();\n\t}\n\t/* not hit */\n\treturn 0;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX",
            "#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX\n#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic inline unsigned\nrb_event_length(struct ring_buffer_event *event)\n{\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event))\n\t\t\t/* undefined */\n\t\t\treturn -1;\n\t\treturn  event->array[0] + RB_EVNT_HDR_SIZE;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\treturn RB_LEN_TIME_EXTEND;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\treturn RB_LEN_TIME_STAMP;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\treturn rb_event_data_length(event);\n\tdefault:\n\t\tBUG();\n\t}\n\t/* not hit */\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_iter_head_event",
          "args": [
            "iter"
          ],
          "line": 3806
        },
        "resolved": true,
        "details": {
          "function_name": "rb_iter_head_event",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1892-1896",
          "snippet": "ring_buffer_event *\nrb_iter_head_event(struct ring_buffer_iter *iter)\n{\n\treturn __rb_page_index(iter->head_page, iter->head);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nring_buffer_event *\nrb_iter_head_event(struct ring_buffer_iter *iter)\n{\n\treturn __rb_page_index(iter->head_page, iter->head);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic void rb_advance_iter(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct ring_buffer_event *event;\n\tunsigned length;\n\n\tcpu_buffer = iter->cpu_buffer;\n\n\t/*\n\t * Check if we are at the end of the buffer.\n\t */\n\tif (iter->head >= rb_page_size(iter->head_page)) {\n\t\t/* discarded commits can make the page empty */\n\t\tif (iter->head_page == cpu_buffer->commit_page)\n\t\t\treturn;\n\t\trb_inc_iter(iter);\n\t\treturn;\n\t}\n\n\tevent = rb_iter_head_event(iter);\n\n\tlength = rb_event_length(event);\n\n\t/*\n\t * This should not be called to advance the header if we are\n\t * at the tail of the buffer.\n\t */\n\tif (RB_WARN_ON(cpu_buffer,\n\t\t       (iter->head_page == cpu_buffer->commit_page) &&\n\t\t       (iter->head + length > rb_commit_index(cpu_buffer))))\n\t\treturn;\n\n\trb_update_iter_read_stamp(iter, event);\n\n\titer->head += length;\n\n\t/* check for end of page padding */\n\tif ((iter->head >= rb_page_size(iter->head_page)) &&\n\t    (iter->head_page != cpu_buffer->commit_page))\n\t\trb_inc_iter(iter);\n}"
  },
  {
    "function_name": "rb_advance_reader",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3764-3785",
    "snippet": "static void rb_advance_reader(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct ring_buffer_event *event;\n\tstruct buffer_page *reader;\n\tunsigned length;\n\n\treader = rb_get_reader_page(cpu_buffer);\n\n\t/* This function should not be called when buffer is empty */\n\tif (RB_WARN_ON(cpu_buffer, !reader))\n\t\treturn;\n\n\tevent = rb_reader_event(cpu_buffer);\n\n\tif (event->type_len <= RINGBUF_TYPE_DATA_TYPE_LEN_MAX)\n\t\tcpu_buffer->read++;\n\n\trb_update_read_stamp(cpu_buffer, event);\n\n\tlength = rb_event_length(event);\n\tcpu_buffer->reader_page->read += length;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_event_length",
          "args": [
            "event"
          ],
          "line": 3783
        },
        "resolved": true,
        "details": {
          "function_name": "rb_event_length",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "185-208",
          "snippet": "static inline unsigned\nrb_event_length(struct ring_buffer_event *event)\n{\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event))\n\t\t\t/* undefined */\n\t\t\treturn -1;\n\t\treturn  event->array[0] + RB_EVNT_HDR_SIZE;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\treturn RB_LEN_TIME_EXTEND;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\treturn RB_LEN_TIME_STAMP;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\treturn rb_event_data_length(event);\n\tdefault:\n\t\tBUG();\n\t}\n\t/* not hit */\n\treturn 0;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX",
            "#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX\n#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic inline unsigned\nrb_event_length(struct ring_buffer_event *event)\n{\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event))\n\t\t\t/* undefined */\n\t\t\treturn -1;\n\t\treturn  event->array[0] + RB_EVNT_HDR_SIZE;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\treturn RB_LEN_TIME_EXTEND;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\treturn RB_LEN_TIME_STAMP;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\treturn rb_event_data_length(event);\n\tdefault:\n\t\tBUG();\n\t}\n\t/* not hit */\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_update_read_stamp",
          "args": [
            "cpu_buffer",
            "event"
          ],
          "line": 3781
        },
        "resolved": true,
        "details": {
          "function_name": "rb_update_read_stamp",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3571-3599",
          "snippet": "static void\nrb_update_read_stamp(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t     struct ring_buffer_event *event)\n{\n\tu64 delta;\n\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\treturn;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\tcpu_buffer->read_stamp += delta;\n\t\treturn;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\tcpu_buffer->read_stamp = delta;\n\t\treturn;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\tcpu_buffer->read_stamp += event->time_delta;\n\t\treturn;\n\n\tdefault:\n\t\tBUG();\n\t}\n\treturn;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic void\nrb_update_read_stamp(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t     struct ring_buffer_event *event)\n{\n\tu64 delta;\n\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\treturn;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\tcpu_buffer->read_stamp += delta;\n\t\treturn;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\tcpu_buffer->read_stamp = delta;\n\t\treturn;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\tcpu_buffer->read_stamp += event->time_delta;\n\t\treturn;\n\n\tdefault:\n\t\tBUG();\n\t}\n\treturn;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_reader_event",
          "args": [
            "cpu_buffer"
          ],
          "line": 3776
        },
        "resolved": true,
        "details": {
          "function_name": "rb_reader_event",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1885-1890",
          "snippet": "ring_buffer_event *\nrb_reader_event(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn __rb_page_index(cpu_buffer->reader_page,\n\t\t\t       cpu_buffer->reader_page->read);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nring_buffer_event *\nrb_reader_event(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn __rb_page_index(cpu_buffer->reader_page,\n\t\t\t       cpu_buffer->reader_page->read);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "!reader"
          ],
          "line": 3773
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_get_reader_page",
          "args": [
            "cpu_buffer"
          ],
          "line": 3770
        },
        "resolved": true,
        "details": {
          "function_name": "rb_get_reader_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3631-3762",
          "snippet": "static struct buffer_page *\nrb_get_reader_page(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *reader = NULL;\n\tunsigned long overwrite;\n\tunsigned long flags;\n\tint nr_loops = 0;\n\tint ret;\n\n\tlocal_irq_save(flags);\n\tarch_spin_lock(&cpu_buffer->lock);\n\n again:\n\t/*\n\t * This should normally only loop twice. But because the\n\t * start of the reader inserts an empty page, it causes\n\t * a case where we will loop three times. There should be no\n\t * reason to loop four times (that I know of).\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 3)) {\n\t\treader = NULL;\n\t\tgoto out;\n\t}\n\n\treader = cpu_buffer->reader_page;\n\n\t/* If there's more to read, return this page */\n\tif (cpu_buffer->reader_page->read < rb_page_size(reader))\n\t\tgoto out;\n\n\t/* Never should we have an index greater than the size */\n\tif (RB_WARN_ON(cpu_buffer,\n\t\t       cpu_buffer->reader_page->read > rb_page_size(reader)))\n\t\tgoto out;\n\n\t/* check if we caught up to the tail */\n\treader = NULL;\n\tif (cpu_buffer->commit_page == cpu_buffer->reader_page)\n\t\tgoto out;\n\n\t/* Don't bother swapping if the ring buffer is empty */\n\tif (rb_num_of_entries(cpu_buffer) == 0)\n\t\tgoto out;\n\n\t/*\n\t * Reset the reader page to size zero.\n\t */\n\tlocal_set(&cpu_buffer->reader_page->write, 0);\n\tlocal_set(&cpu_buffer->reader_page->entries, 0);\n\tlocal_set(&cpu_buffer->reader_page->page->commit, 0);\n\tcpu_buffer->reader_page->real_end = 0;\n\n spin:\n\t/*\n\t * Splice the empty reader page into the list around the head.\n\t */\n\treader = rb_set_head_page(cpu_buffer);\n\tif (!reader)\n\t\tgoto out;\n\tcpu_buffer->reader_page->list.next = rb_list_head(reader->list.next);\n\tcpu_buffer->reader_page->list.prev = reader->list.prev;\n\n\t/*\n\t * cpu_buffer->pages just needs to point to the buffer, it\n\t *  has no specific buffer page to point to. Lets move it out\n\t *  of our way so we don't accidentally swap it.\n\t */\n\tcpu_buffer->pages = reader->list.prev;\n\n\t/* The reader page will be pointing to the new head */\n\trb_set_list_to_head(cpu_buffer, &cpu_buffer->reader_page->list);\n\n\t/*\n\t * We want to make sure we read the overruns after we set up our\n\t * pointers to the next object. The writer side does a\n\t * cmpxchg to cross pages which acts as the mb on the writer\n\t * side. Note, the reader will constantly fail the swap\n\t * while the writer is updating the pointers, so this\n\t * guarantees that the overwrite recorded here is the one we\n\t * want to compare with the last_overrun.\n\t */\n\tsmp_mb();\n\toverwrite = local_read(&(cpu_buffer->overrun));\n\n\t/*\n\t * Here's the tricky part.\n\t *\n\t * We need to move the pointer past the header page.\n\t * But we can only do that if a writer is not currently\n\t * moving it. The page before the header page has the\n\t * flag bit '1' set if it is pointing to the page we want.\n\t * but if the writer is in the process of moving it\n\t * than it will be '2' or already moved '0'.\n\t */\n\n\tret = rb_head_page_replace(reader, cpu_buffer->reader_page);\n\n\t/*\n\t * If we did not convert it, then we must try again.\n\t */\n\tif (!ret)\n\t\tgoto spin;\n\n\t/*\n\t * Yeah! We succeeded in replacing the page.\n\t *\n\t * Now make the new head point back to the reader page.\n\t */\n\trb_list_head(reader->list.next)->prev = &cpu_buffer->reader_page->list;\n\trb_inc_page(cpu_buffer, &cpu_buffer->head_page);\n\n\t/* Finally update the reader page to the new head */\n\tcpu_buffer->reader_page = reader;\n\tcpu_buffer->reader_page->read = 0;\n\n\tif (overwrite != cpu_buffer->last_overrun) {\n\t\tcpu_buffer->lost_events = overwrite - cpu_buffer->last_overrun;\n\t\tcpu_buffer->last_overrun = overwrite;\n\t}\n\n\tgoto again;\n\n out:\n\t/* Update the read_stamp on the first event */\n\tif (reader && reader->read == 0)\n\t\tcpu_buffer->read_stamp = reader->page->time_stamp;\n\n\tarch_spin_unlock(&cpu_buffer->lock);\n\tlocal_irq_restore(flags);\n\n\treturn reader;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic struct buffer_page *\nrb_get_reader_page(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *reader = NULL;\n\tunsigned long overwrite;\n\tunsigned long flags;\n\tint nr_loops = 0;\n\tint ret;\n\n\tlocal_irq_save(flags);\n\tarch_spin_lock(&cpu_buffer->lock);\n\n again:\n\t/*\n\t * This should normally only loop twice. But because the\n\t * start of the reader inserts an empty page, it causes\n\t * a case where we will loop three times. There should be no\n\t * reason to loop four times (that I know of).\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 3)) {\n\t\treader = NULL;\n\t\tgoto out;\n\t}\n\n\treader = cpu_buffer->reader_page;\n\n\t/* If there's more to read, return this page */\n\tif (cpu_buffer->reader_page->read < rb_page_size(reader))\n\t\tgoto out;\n\n\t/* Never should we have an index greater than the size */\n\tif (RB_WARN_ON(cpu_buffer,\n\t\t       cpu_buffer->reader_page->read > rb_page_size(reader)))\n\t\tgoto out;\n\n\t/* check if we caught up to the tail */\n\treader = NULL;\n\tif (cpu_buffer->commit_page == cpu_buffer->reader_page)\n\t\tgoto out;\n\n\t/* Don't bother swapping if the ring buffer is empty */\n\tif (rb_num_of_entries(cpu_buffer) == 0)\n\t\tgoto out;\n\n\t/*\n\t * Reset the reader page to size zero.\n\t */\n\tlocal_set(&cpu_buffer->reader_page->write, 0);\n\tlocal_set(&cpu_buffer->reader_page->entries, 0);\n\tlocal_set(&cpu_buffer->reader_page->page->commit, 0);\n\tcpu_buffer->reader_page->real_end = 0;\n\n spin:\n\t/*\n\t * Splice the empty reader page into the list around the head.\n\t */\n\treader = rb_set_head_page(cpu_buffer);\n\tif (!reader)\n\t\tgoto out;\n\tcpu_buffer->reader_page->list.next = rb_list_head(reader->list.next);\n\tcpu_buffer->reader_page->list.prev = reader->list.prev;\n\n\t/*\n\t * cpu_buffer->pages just needs to point to the buffer, it\n\t *  has no specific buffer page to point to. Lets move it out\n\t *  of our way so we don't accidentally swap it.\n\t */\n\tcpu_buffer->pages = reader->list.prev;\n\n\t/* The reader page will be pointing to the new head */\n\trb_set_list_to_head(cpu_buffer, &cpu_buffer->reader_page->list);\n\n\t/*\n\t * We want to make sure we read the overruns after we set up our\n\t * pointers to the next object. The writer side does a\n\t * cmpxchg to cross pages which acts as the mb on the writer\n\t * side. Note, the reader will constantly fail the swap\n\t * while the writer is updating the pointers, so this\n\t * guarantees that the overwrite recorded here is the one we\n\t * want to compare with the last_overrun.\n\t */\n\tsmp_mb();\n\toverwrite = local_read(&(cpu_buffer->overrun));\n\n\t/*\n\t * Here's the tricky part.\n\t *\n\t * We need to move the pointer past the header page.\n\t * But we can only do that if a writer is not currently\n\t * moving it. The page before the header page has the\n\t * flag bit '1' set if it is pointing to the page we want.\n\t * but if the writer is in the process of moving it\n\t * than it will be '2' or already moved '0'.\n\t */\n\n\tret = rb_head_page_replace(reader, cpu_buffer->reader_page);\n\n\t/*\n\t * If we did not convert it, then we must try again.\n\t */\n\tif (!ret)\n\t\tgoto spin;\n\n\t/*\n\t * Yeah! We succeeded in replacing the page.\n\t *\n\t * Now make the new head point back to the reader page.\n\t */\n\trb_list_head(reader->list.next)->prev = &cpu_buffer->reader_page->list;\n\trb_inc_page(cpu_buffer, &cpu_buffer->head_page);\n\n\t/* Finally update the reader page to the new head */\n\tcpu_buffer->reader_page = reader;\n\tcpu_buffer->reader_page->read = 0;\n\n\tif (overwrite != cpu_buffer->last_overrun) {\n\t\tcpu_buffer->lost_events = overwrite - cpu_buffer->last_overrun;\n\t\tcpu_buffer->last_overrun = overwrite;\n\t}\n\n\tgoto again;\n\n out:\n\t/* Update the read_stamp on the first event */\n\tif (reader && reader->read == 0)\n\t\tcpu_buffer->read_stamp = reader->page->time_stamp;\n\n\tarch_spin_unlock(&cpu_buffer->lock);\n\tlocal_irq_restore(flags);\n\n\treturn reader;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic void rb_advance_reader(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct ring_buffer_event *event;\n\tstruct buffer_page *reader;\n\tunsigned length;\n\n\treader = rb_get_reader_page(cpu_buffer);\n\n\t/* This function should not be called when buffer is empty */\n\tif (RB_WARN_ON(cpu_buffer, !reader))\n\t\treturn;\n\n\tevent = rb_reader_event(cpu_buffer);\n\n\tif (event->type_len <= RINGBUF_TYPE_DATA_TYPE_LEN_MAX)\n\t\tcpu_buffer->read++;\n\n\trb_update_read_stamp(cpu_buffer, event);\n\n\tlength = rb_event_length(event);\n\tcpu_buffer->reader_page->read += length;\n}"
  },
  {
    "function_name": "rb_get_reader_page",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3631-3762",
    "snippet": "static struct buffer_page *\nrb_get_reader_page(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *reader = NULL;\n\tunsigned long overwrite;\n\tunsigned long flags;\n\tint nr_loops = 0;\n\tint ret;\n\n\tlocal_irq_save(flags);\n\tarch_spin_lock(&cpu_buffer->lock);\n\n again:\n\t/*\n\t * This should normally only loop twice. But because the\n\t * start of the reader inserts an empty page, it causes\n\t * a case where we will loop three times. There should be no\n\t * reason to loop four times (that I know of).\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 3)) {\n\t\treader = NULL;\n\t\tgoto out;\n\t}\n\n\treader = cpu_buffer->reader_page;\n\n\t/* If there's more to read, return this page */\n\tif (cpu_buffer->reader_page->read < rb_page_size(reader))\n\t\tgoto out;\n\n\t/* Never should we have an index greater than the size */\n\tif (RB_WARN_ON(cpu_buffer,\n\t\t       cpu_buffer->reader_page->read > rb_page_size(reader)))\n\t\tgoto out;\n\n\t/* check if we caught up to the tail */\n\treader = NULL;\n\tif (cpu_buffer->commit_page == cpu_buffer->reader_page)\n\t\tgoto out;\n\n\t/* Don't bother swapping if the ring buffer is empty */\n\tif (rb_num_of_entries(cpu_buffer) == 0)\n\t\tgoto out;\n\n\t/*\n\t * Reset the reader page to size zero.\n\t */\n\tlocal_set(&cpu_buffer->reader_page->write, 0);\n\tlocal_set(&cpu_buffer->reader_page->entries, 0);\n\tlocal_set(&cpu_buffer->reader_page->page->commit, 0);\n\tcpu_buffer->reader_page->real_end = 0;\n\n spin:\n\t/*\n\t * Splice the empty reader page into the list around the head.\n\t */\n\treader = rb_set_head_page(cpu_buffer);\n\tif (!reader)\n\t\tgoto out;\n\tcpu_buffer->reader_page->list.next = rb_list_head(reader->list.next);\n\tcpu_buffer->reader_page->list.prev = reader->list.prev;\n\n\t/*\n\t * cpu_buffer->pages just needs to point to the buffer, it\n\t *  has no specific buffer page to point to. Lets move it out\n\t *  of our way so we don't accidentally swap it.\n\t */\n\tcpu_buffer->pages = reader->list.prev;\n\n\t/* The reader page will be pointing to the new head */\n\trb_set_list_to_head(cpu_buffer, &cpu_buffer->reader_page->list);\n\n\t/*\n\t * We want to make sure we read the overruns after we set up our\n\t * pointers to the next object. The writer side does a\n\t * cmpxchg to cross pages which acts as the mb on the writer\n\t * side. Note, the reader will constantly fail the swap\n\t * while the writer is updating the pointers, so this\n\t * guarantees that the overwrite recorded here is the one we\n\t * want to compare with the last_overrun.\n\t */\n\tsmp_mb();\n\toverwrite = local_read(&(cpu_buffer->overrun));\n\n\t/*\n\t * Here's the tricky part.\n\t *\n\t * We need to move the pointer past the header page.\n\t * But we can only do that if a writer is not currently\n\t * moving it. The page before the header page has the\n\t * flag bit '1' set if it is pointing to the page we want.\n\t * but if the writer is in the process of moving it\n\t * than it will be '2' or already moved '0'.\n\t */\n\n\tret = rb_head_page_replace(reader, cpu_buffer->reader_page);\n\n\t/*\n\t * If we did not convert it, then we must try again.\n\t */\n\tif (!ret)\n\t\tgoto spin;\n\n\t/*\n\t * Yeah! We succeeded in replacing the page.\n\t *\n\t * Now make the new head point back to the reader page.\n\t */\n\trb_list_head(reader->list.next)->prev = &cpu_buffer->reader_page->list;\n\trb_inc_page(cpu_buffer, &cpu_buffer->head_page);\n\n\t/* Finally update the reader page to the new head */\n\tcpu_buffer->reader_page = reader;\n\tcpu_buffer->reader_page->read = 0;\n\n\tif (overwrite != cpu_buffer->last_overrun) {\n\t\tcpu_buffer->lost_events = overwrite - cpu_buffer->last_overrun;\n\t\tcpu_buffer->last_overrun = overwrite;\n\t}\n\n\tgoto again;\n\n out:\n\t/* Update the read_stamp on the first event */\n\tif (reader && reader->read == 0)\n\t\tcpu_buffer->read_stamp = reader->page->time_stamp;\n\n\tarch_spin_unlock(&cpu_buffer->lock);\n\tlocal_irq_restore(flags);\n\n\treturn reader;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_irq_restore",
          "args": [
            "flags"
          ],
          "line": 3759
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "arch_spin_unlock",
          "args": [
            "&cpu_buffer->lock"
          ],
          "line": 3758
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_inc_page",
          "args": [
            "cpu_buffer",
            "&cpu_buffer->head_page"
          ],
          "line": 3740
        },
        "resolved": true,
        "details": {
          "function_name": "rb_inc_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "974-980",
          "snippet": "static inline void rb_inc_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t       struct buffer_page **bpage)\n{\n\tstruct list_head *p = rb_list_head((*bpage)->list.next);\n\n\t*bpage = list_entry(p, struct buffer_page, list);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline void rb_inc_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t       struct buffer_page **bpage)\n{\n\tstruct list_head *p = rb_list_head((*bpage)->list.next);\n\n\t*bpage = list_entry(p, struct buffer_page, list);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_list_head",
          "args": [
            "reader->list.next"
          ],
          "line": 3739
        },
        "resolved": true,
        "details": {
          "function_name": "rb_list_head_clear",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "902-907",
          "snippet": "static void rb_list_head_clear(struct list_head *list)\n{\n\tunsigned long *ptr = (unsigned long *)&list->next;\n\n\t*ptr &= ~RB_FLAG_MASK;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_FLAG_MASK\t\t3UL"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_FLAG_MASK\t\t3UL\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_list_head_clear(struct list_head *list)\n{\n\tunsigned long *ptr = (unsigned long *)&list->next;\n\n\t*ptr &= ~RB_FLAG_MASK;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_head_page_replace",
          "args": [
            "reader",
            "cpu_buffer->reader_page"
          ],
          "line": 3726
        },
        "resolved": true,
        "details": {
          "function_name": "rb_head_page_replace",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1020-1033",
          "snippet": "static int rb_head_page_replace(struct buffer_page *old,\n\t\t\t\tstruct buffer_page *new)\n{\n\tunsigned long *ptr = (unsigned long *)&old->list.prev->next;\n\tunsigned long val;\n\tunsigned long ret;\n\n\tval = *ptr & ~RB_FLAG_MASK;\n\tval |= RB_PAGE_HEAD;\n\n\tret = cmpxchg(ptr, val, (unsigned long)&new->list);\n\n\treturn ret == val;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_FLAG_MASK\t\t3UL",
            "#define RB_PAGE_HEAD\t\t1UL"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_FLAG_MASK\t\t3UL\n#define RB_PAGE_HEAD\t\t1UL\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int rb_head_page_replace(struct buffer_page *old,\n\t\t\t\tstruct buffer_page *new)\n{\n\tunsigned long *ptr = (unsigned long *)&old->list.prev->next;\n\tunsigned long val;\n\tunsigned long ret;\n\n\tval = *ptr & ~RB_FLAG_MASK;\n\tval |= RB_PAGE_HEAD;\n\n\tret = cmpxchg(ptr, val, (unsigned long)&new->list);\n\n\treturn ret == val;\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_read",
          "args": [
            "&(cpu_buffer->overrun)"
          ],
          "line": 3713
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_mb",
          "args": [],
          "line": 3712
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_set_list_to_head",
          "args": [
            "cpu_buffer",
            "&cpu_buffer->reader_page->list"
          ],
          "line": 3701
        },
        "resolved": true,
        "details": {
          "function_name": "rb_set_list_to_head",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "875-883",
          "snippet": "static void rb_set_list_to_head(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\tstruct list_head *list)\n{\n\tunsigned long *ptr;\n\n\tptr = (unsigned long *)&list->next;\n\t*ptr |= RB_PAGE_HEAD;\n\t*ptr &= ~RB_PAGE_UPDATE;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_PAGE_UPDATE\t\t2UL",
            "#define RB_PAGE_HEAD\t\t1UL"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_PAGE_UPDATE\t\t2UL\n#define RB_PAGE_HEAD\t\t1UL\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_set_list_to_head(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\tstruct list_head *list)\n{\n\tunsigned long *ptr;\n\n\tptr = (unsigned long *)&list->next;\n\t*ptr |= RB_PAGE_HEAD;\n\t*ptr &= ~RB_PAGE_UPDATE;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_set_head_page",
          "args": [
            "cpu_buffer"
          ],
          "line": 3687
        },
        "resolved": true,
        "details": {
          "function_name": "rb_set_head_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "982-1018",
          "snippet": "static struct buffer_page *\nrb_set_head_page(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *head;\n\tstruct buffer_page *page;\n\tstruct list_head *list;\n\tint i;\n\n\tif (RB_WARN_ON(cpu_buffer, !cpu_buffer->head_page))\n\t\treturn NULL;\n\n\t/* sanity check */\n\tlist = cpu_buffer->pages;\n\tif (RB_WARN_ON(cpu_buffer, rb_list_head(list->prev->next) != list))\n\t\treturn NULL;\n\n\tpage = head = cpu_buffer->head_page;\n\t/*\n\t * It is possible that the writer moves the header behind\n\t * where we started, and we miss in one loop.\n\t * A second loop should grab the header, but we'll do\n\t * three loops just because I'm paranoid.\n\t */\n\tfor (i = 0; i < 3; i++) {\n\t\tdo {\n\t\t\tif (rb_is_head_page(cpu_buffer, page, page->list.prev)) {\n\t\t\t\tcpu_buffer->head_page = page;\n\t\t\t\treturn page;\n\t\t\t}\n\t\t\trb_inc_page(cpu_buffer, &page);\n\t\t} while (page != head);\n\t}\n\n\tRB_WARN_ON(cpu_buffer, 1);\n\n\treturn NULL;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic struct buffer_page *\nrb_set_head_page(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *head;\n\tstruct buffer_page *page;\n\tstruct list_head *list;\n\tint i;\n\n\tif (RB_WARN_ON(cpu_buffer, !cpu_buffer->head_page))\n\t\treturn NULL;\n\n\t/* sanity check */\n\tlist = cpu_buffer->pages;\n\tif (RB_WARN_ON(cpu_buffer, rb_list_head(list->prev->next) != list))\n\t\treturn NULL;\n\n\tpage = head = cpu_buffer->head_page;\n\t/*\n\t * It is possible that the writer moves the header behind\n\t * where we started, and we miss in one loop.\n\t * A second loop should grab the header, but we'll do\n\t * three loops just because I'm paranoid.\n\t */\n\tfor (i = 0; i < 3; i++) {\n\t\tdo {\n\t\t\tif (rb_is_head_page(cpu_buffer, page, page->list.prev)) {\n\t\t\t\tcpu_buffer->head_page = page;\n\t\t\t\treturn page;\n\t\t\t}\n\t\t\trb_inc_page(cpu_buffer, &page);\n\t\t} while (page != head);\n\t}\n\n\tRB_WARN_ON(cpu_buffer, 1);\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_set",
          "args": [
            "&cpu_buffer->reader_page->page->commit",
            "0"
          ],
          "line": 3680
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_set",
          "args": [
            "&cpu_buffer->reader_page->entries",
            "0"
          ],
          "line": 3679
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_set",
          "args": [
            "&cpu_buffer->reader_page->write",
            "0"
          ],
          "line": 3678
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_num_of_entries",
          "args": [
            "cpu_buffer"
          ],
          "line": 3672
        },
        "resolved": true,
        "details": {
          "function_name": "rb_num_of_entries",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3296-3301",
          "snippet": "static inline unsigned long\nrb_num_of_entries(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn local_read(&cpu_buffer->entries) -\n\t\t(local_read(&cpu_buffer->overrun) + cpu_buffer->read);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline unsigned long\nrb_num_of_entries(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn local_read(&cpu_buffer->entries) -\n\t\t(local_read(&cpu_buffer->overrun) + cpu_buffer->read);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "cpu_buffer->reader_page->read > rb_page_size(reader)"
          ],
          "line": 3662
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_page_size",
          "args": [
            "reader"
          ],
          "line": 3663
        },
        "resolved": true,
        "details": {
          "function_name": "rb_page_size",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1904-1907",
          "snippet": "static __always_inline unsigned rb_page_size(struct buffer_page *bpage)\n{\n\treturn rb_page_commit(bpage);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline unsigned rb_page_size(struct buffer_page *bpage)\n{\n\treturn rb_page_commit(bpage);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "++nr_loops > 3"
          ],
          "line": 3650
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "arch_spin_lock",
          "args": [
            "&cpu_buffer->lock"
          ],
          "line": 3641
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_irq_save",
          "args": [
            "flags"
          ],
          "line": 3640
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic struct buffer_page *\nrb_get_reader_page(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *reader = NULL;\n\tunsigned long overwrite;\n\tunsigned long flags;\n\tint nr_loops = 0;\n\tint ret;\n\n\tlocal_irq_save(flags);\n\tarch_spin_lock(&cpu_buffer->lock);\n\n again:\n\t/*\n\t * This should normally only loop twice. But because the\n\t * start of the reader inserts an empty page, it causes\n\t * a case where we will loop three times. There should be no\n\t * reason to loop four times (that I know of).\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 3)) {\n\t\treader = NULL;\n\t\tgoto out;\n\t}\n\n\treader = cpu_buffer->reader_page;\n\n\t/* If there's more to read, return this page */\n\tif (cpu_buffer->reader_page->read < rb_page_size(reader))\n\t\tgoto out;\n\n\t/* Never should we have an index greater than the size */\n\tif (RB_WARN_ON(cpu_buffer,\n\t\t       cpu_buffer->reader_page->read > rb_page_size(reader)))\n\t\tgoto out;\n\n\t/* check if we caught up to the tail */\n\treader = NULL;\n\tif (cpu_buffer->commit_page == cpu_buffer->reader_page)\n\t\tgoto out;\n\n\t/* Don't bother swapping if the ring buffer is empty */\n\tif (rb_num_of_entries(cpu_buffer) == 0)\n\t\tgoto out;\n\n\t/*\n\t * Reset the reader page to size zero.\n\t */\n\tlocal_set(&cpu_buffer->reader_page->write, 0);\n\tlocal_set(&cpu_buffer->reader_page->entries, 0);\n\tlocal_set(&cpu_buffer->reader_page->page->commit, 0);\n\tcpu_buffer->reader_page->real_end = 0;\n\n spin:\n\t/*\n\t * Splice the empty reader page into the list around the head.\n\t */\n\treader = rb_set_head_page(cpu_buffer);\n\tif (!reader)\n\t\tgoto out;\n\tcpu_buffer->reader_page->list.next = rb_list_head(reader->list.next);\n\tcpu_buffer->reader_page->list.prev = reader->list.prev;\n\n\t/*\n\t * cpu_buffer->pages just needs to point to the buffer, it\n\t *  has no specific buffer page to point to. Lets move it out\n\t *  of our way so we don't accidentally swap it.\n\t */\n\tcpu_buffer->pages = reader->list.prev;\n\n\t/* The reader page will be pointing to the new head */\n\trb_set_list_to_head(cpu_buffer, &cpu_buffer->reader_page->list);\n\n\t/*\n\t * We want to make sure we read the overruns after we set up our\n\t * pointers to the next object. The writer side does a\n\t * cmpxchg to cross pages which acts as the mb on the writer\n\t * side. Note, the reader will constantly fail the swap\n\t * while the writer is updating the pointers, so this\n\t * guarantees that the overwrite recorded here is the one we\n\t * want to compare with the last_overrun.\n\t */\n\tsmp_mb();\n\toverwrite = local_read(&(cpu_buffer->overrun));\n\n\t/*\n\t * Here's the tricky part.\n\t *\n\t * We need to move the pointer past the header page.\n\t * But we can only do that if a writer is not currently\n\t * moving it. The page before the header page has the\n\t * flag bit '1' set if it is pointing to the page we want.\n\t * but if the writer is in the process of moving it\n\t * than it will be '2' or already moved '0'.\n\t */\n\n\tret = rb_head_page_replace(reader, cpu_buffer->reader_page);\n\n\t/*\n\t * If we did not convert it, then we must try again.\n\t */\n\tif (!ret)\n\t\tgoto spin;\n\n\t/*\n\t * Yeah! We succeeded in replacing the page.\n\t *\n\t * Now make the new head point back to the reader page.\n\t */\n\trb_list_head(reader->list.next)->prev = &cpu_buffer->reader_page->list;\n\trb_inc_page(cpu_buffer, &cpu_buffer->head_page);\n\n\t/* Finally update the reader page to the new head */\n\tcpu_buffer->reader_page = reader;\n\tcpu_buffer->reader_page->read = 0;\n\n\tif (overwrite != cpu_buffer->last_overrun) {\n\t\tcpu_buffer->lost_events = overwrite - cpu_buffer->last_overrun;\n\t\tcpu_buffer->last_overrun = overwrite;\n\t}\n\n\tgoto again;\n\n out:\n\t/* Update the read_stamp on the first event */\n\tif (reader && reader->read == 0)\n\t\tcpu_buffer->read_stamp = reader->page->time_stamp;\n\n\tarch_spin_unlock(&cpu_buffer->lock);\n\tlocal_irq_restore(flags);\n\n\treturn reader;\n}"
  },
  {
    "function_name": "rb_update_iter_read_stamp",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3601-3629",
    "snippet": "static void\nrb_update_iter_read_stamp(struct ring_buffer_iter *iter,\n\t\t\t  struct ring_buffer_event *event)\n{\n\tu64 delta;\n\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\treturn;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\titer->read_stamp += delta;\n\t\treturn;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\titer->read_stamp = delta;\n\t\treturn;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\titer->read_stamp += event->time_delta;\n\t\treturn;\n\n\tdefault:\n\t\tBUG();\n\t}\n\treturn;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX"
    ],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "BUG",
          "args": [],
          "line": 3626
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ring_buffer_event_time_stamp",
          "args": [
            "event"
          ],
          "line": 3617
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_event_time_stamp",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "295-304",
          "snippet": "u64 ring_buffer_event_time_stamp(struct ring_buffer_event *event)\n{\n\tu64 ts;\n\n\tts = event->array[0];\n\tts <<= TS_SHIFT;\n\tts += event->time_delta;\n\n\treturn ts;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define TS_SHIFT\t27"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define TS_SHIFT\t27\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nu64 ring_buffer_event_time_stamp(struct ring_buffer_event *event)\n{\n\tu64 ts;\n\n\tts = event->array[0];\n\tts <<= TS_SHIFT;\n\tts += event->time_delta;\n\n\treturn ts;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic void\nrb_update_iter_read_stamp(struct ring_buffer_iter *iter,\n\t\t\t  struct ring_buffer_event *event)\n{\n\tu64 delta;\n\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\treturn;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\titer->read_stamp += delta;\n\t\treturn;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\titer->read_stamp = delta;\n\t\treturn;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\titer->read_stamp += event->time_delta;\n\t\treturn;\n\n\tdefault:\n\t\tBUG();\n\t}\n\treturn;\n}"
  },
  {
    "function_name": "rb_update_read_stamp",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3571-3599",
    "snippet": "static void\nrb_update_read_stamp(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t     struct ring_buffer_event *event)\n{\n\tu64 delta;\n\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\treturn;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\tcpu_buffer->read_stamp += delta;\n\t\treturn;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\tcpu_buffer->read_stamp = delta;\n\t\treturn;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\tcpu_buffer->read_stamp += event->time_delta;\n\t\treturn;\n\n\tdefault:\n\t\tBUG();\n\t}\n\treturn;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX"
    ],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "BUG",
          "args": [],
          "line": 3596
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ring_buffer_event_time_stamp",
          "args": [
            "event"
          ],
          "line": 3587
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_event_time_stamp",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "295-304",
          "snippet": "u64 ring_buffer_event_time_stamp(struct ring_buffer_event *event)\n{\n\tu64 ts;\n\n\tts = event->array[0];\n\tts <<= TS_SHIFT;\n\tts += event->time_delta;\n\n\treturn ts;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define TS_SHIFT\t27"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define TS_SHIFT\t27\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nu64 ring_buffer_event_time_stamp(struct ring_buffer_event *event)\n{\n\tu64 ts;\n\n\tts = event->array[0];\n\tts <<= TS_SHIFT;\n\tts += event->time_delta;\n\n\treturn ts;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic void\nrb_update_read_stamp(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t     struct ring_buffer_event *event)\n{\n\tu64 delta;\n\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\treturn;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\tcpu_buffer->read_stamp += delta;\n\t\treturn;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\tcpu_buffer->read_stamp = delta;\n\t\treturn;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\tcpu_buffer->read_stamp += event->time_delta;\n\t\treturn;\n\n\tdefault:\n\t\tBUG();\n\t}\n\treturn;\n}"
  },
  {
    "function_name": "ring_buffer_iter_empty",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3548-3568",
    "snippet": "int ring_buffer_iter_empty(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct buffer_page *reader;\n\tstruct buffer_page *head_page;\n\tstruct buffer_page *commit_page;\n\tunsigned commit;\n\n\tcpu_buffer = iter->cpu_buffer;\n\n\t/* Remember, trace recording is off when iterator is in use */\n\treader = cpu_buffer->reader_page;\n\thead_page = cpu_buffer->head_page;\n\tcommit_page = cpu_buffer->commit_page;\n\tcommit = rb_page_commit(commit_page);\n\n\treturn ((iter->head_page == commit_page && iter->head == commit) ||\n\t\t(iter->head_page == reader && commit_page == head_page &&\n\t\t head_page->read == commit &&\n\t\t iter->head == rb_page_commit(cpu_buffer->reader_page)));\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_page_commit",
          "args": [
            "cpu_buffer->reader_page"
          ],
          "line": 3567
        },
        "resolved": true,
        "details": {
          "function_name": "rb_page_commit",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1898-1901",
          "snippet": "static __always_inline unsigned rb_page_commit(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->page->commit);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline unsigned rb_page_commit(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->page->commit);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nint ring_buffer_iter_empty(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct buffer_page *reader;\n\tstruct buffer_page *head_page;\n\tstruct buffer_page *commit_page;\n\tunsigned commit;\n\n\tcpu_buffer = iter->cpu_buffer;\n\n\t/* Remember, trace recording is off when iterator is in use */\n\treader = cpu_buffer->reader_page;\n\thead_page = cpu_buffer->head_page;\n\tcommit_page = cpu_buffer->commit_page;\n\tcommit = rb_page_commit(commit_page);\n\n\treturn ((iter->head_page == commit_page && iter->head == commit) ||\n\t\t(iter->head_page == reader && commit_page == head_page &&\n\t\t head_page->read == commit &&\n\t\t iter->head == rb_page_commit(cpu_buffer->reader_page)));\n}"
  },
  {
    "function_name": "ring_buffer_iter_reset",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3528-3541",
    "snippet": "void ring_buffer_iter_reset(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long flags;\n\n\tif (!iter)\n\t\treturn;\n\n\tcpu_buffer = iter->cpu_buffer;\n\n\traw_spin_lock_irqsave(&cpu_buffer->reader_lock, flags);\n\trb_iter_reset(iter);\n\traw_spin_unlock_irqrestore(&cpu_buffer->reader_lock, flags);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore",
          "args": [
            "&cpu_buffer->reader_lock",
            "flags"
          ],
          "line": 3540
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_irqrestore",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "182-185",
          "snippet": "void __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_iter_reset",
          "args": [
            "iter"
          ],
          "line": 3539
        },
        "resolved": true,
        "details": {
          "function_name": "rb_iter_reset",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3504-3519",
          "snippet": "static void rb_iter_reset(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = iter->cpu_buffer;\n\n\t/* Iterator usage is expected to have record disabled */\n\titer->head_page = cpu_buffer->reader_page;\n\titer->head = cpu_buffer->reader_page->read;\n\n\titer->cache_reader_page = iter->head_page;\n\titer->cache_read = cpu_buffer->read;\n\n\tif (iter->head)\n\t\titer->read_stamp = cpu_buffer->read_stamp;\n\telse\n\t\titer->read_stamp = iter->head_page->page->time_stamp;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_iter_reset(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = iter->cpu_buffer;\n\n\t/* Iterator usage is expected to have record disabled */\n\titer->head_page = cpu_buffer->reader_page;\n\titer->head = cpu_buffer->reader_page->read;\n\n\titer->cache_reader_page = iter->head_page;\n\titer->cache_read = cpu_buffer->read;\n\n\tif (iter->head)\n\t\titer->read_stamp = cpu_buffer->read_stamp;\n\telse\n\t\titer->read_stamp = iter->head_page->page->time_stamp;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irqsave",
          "args": [
            "&cpu_buffer->reader_lock",
            "flags"
          ],
          "line": 3538
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_irqsave_nested",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "359-370",
          "snippet": "unsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED_FLAGS(lock, do_raw_spin_trylock, do_raw_spin_lock,\n\t\t\t\tdo_raw_spin_lock_flags, &flags);\n\treturn flags;\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nunsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED_FLAGS(lock, do_raw_spin_trylock, do_raw_spin_lock,\n\t\t\t\tdo_raw_spin_lock_flags, &flags);\n\treturn flags;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid ring_buffer_iter_reset(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long flags;\n\n\tif (!iter)\n\t\treturn;\n\n\tcpu_buffer = iter->cpu_buffer;\n\n\traw_spin_lock_irqsave(&cpu_buffer->reader_lock, flags);\n\trb_iter_reset(iter);\n\traw_spin_unlock_irqrestore(&cpu_buffer->reader_lock, flags);\n}"
  },
  {
    "function_name": "rb_iter_reset",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3504-3519",
    "snippet": "static void rb_iter_reset(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = iter->cpu_buffer;\n\n\t/* Iterator usage is expected to have record disabled */\n\titer->head_page = cpu_buffer->reader_page;\n\titer->head = cpu_buffer->reader_page->read;\n\n\titer->cache_reader_page = iter->head_page;\n\titer->cache_read = cpu_buffer->read;\n\n\tif (iter->head)\n\t\titer->read_stamp = cpu_buffer->read_stamp;\n\telse\n\t\titer->read_stamp = iter->head_page->page->time_stamp;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_iter_reset(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = iter->cpu_buffer;\n\n\t/* Iterator usage is expected to have record disabled */\n\titer->head_page = cpu_buffer->reader_page;\n\titer->head = cpu_buffer->reader_page->read;\n\n\titer->cache_reader_page = iter->head_page;\n\titer->cache_read = cpu_buffer->read;\n\n\tif (iter->head)\n\t\titer->read_stamp = cpu_buffer->read_stamp;\n\telse\n\t\titer->read_stamp = iter->head_page->page->time_stamp;\n}"
  },
  {
    "function_name": "ring_buffer_overruns",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3488-3501",
    "snippet": "unsigned long ring_buffer_overruns(struct ring_buffer *buffer)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long overruns = 0;\n\tint cpu;\n\n\t/* if you care about this being correct, lock the buffer */\n\tfor_each_buffer_cpu(buffer, cpu) {\n\t\tcpu_buffer = buffer->buffers[cpu];\n\t\toverruns += local_read(&cpu_buffer->overrun);\n\t}\n\n\treturn overruns;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_read",
          "args": [
            "&cpu_buffer->overrun"
          ],
          "line": 3497
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "for_each_buffer_cpu",
          "args": [
            "buffer",
            "cpu"
          ],
          "line": 3495
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nunsigned long ring_buffer_overruns(struct ring_buffer *buffer)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long overruns = 0;\n\tint cpu;\n\n\t/* if you care about this being correct, lock the buffer */\n\tfor_each_buffer_cpu(buffer, cpu) {\n\t\tcpu_buffer = buffer->buffers[cpu];\n\t\toverruns += local_read(&cpu_buffer->overrun);\n\t}\n\n\treturn overruns;\n}"
  },
  {
    "function_name": "ring_buffer_entries",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3465-3478",
    "snippet": "unsigned long ring_buffer_entries(struct ring_buffer *buffer)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long entries = 0;\n\tint cpu;\n\n\t/* if you care about this being correct, lock the buffer */\n\tfor_each_buffer_cpu(buffer, cpu) {\n\t\tcpu_buffer = buffer->buffers[cpu];\n\t\tentries += rb_num_of_entries(cpu_buffer);\n\t}\n\n\treturn entries;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_num_of_entries",
          "args": [
            "cpu_buffer"
          ],
          "line": 3474
        },
        "resolved": true,
        "details": {
          "function_name": "rb_num_of_entries",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3296-3301",
          "snippet": "static inline unsigned long\nrb_num_of_entries(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn local_read(&cpu_buffer->entries) -\n\t\t(local_read(&cpu_buffer->overrun) + cpu_buffer->read);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline unsigned long\nrb_num_of_entries(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn local_read(&cpu_buffer->entries) -\n\t\t(local_read(&cpu_buffer->overrun) + cpu_buffer->read);\n}"
        }
      },
      {
        "call_info": {
          "callee": "for_each_buffer_cpu",
          "args": [
            "buffer",
            "cpu"
          ],
          "line": 3472
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nunsigned long ring_buffer_entries(struct ring_buffer *buffer)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long entries = 0;\n\tint cpu;\n\n\t/* if you care about this being correct, lock the buffer */\n\tfor_each_buffer_cpu(buffer, cpu) {\n\t\tcpu_buffer = buffer->buffers[cpu];\n\t\tentries += rb_num_of_entries(cpu_buffer);\n\t}\n\n\treturn entries;\n}"
  },
  {
    "function_name": "ring_buffer_read_events_cpu",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3445-3455",
    "snippet": "unsigned long\nring_buffer_read_events_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn 0;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\treturn cpu_buffer->read;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "buffer->cpumask"
          ],
          "line": 3450
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nunsigned long\nring_buffer_read_events_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn 0;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\treturn cpu_buffer->read;\n}"
  },
  {
    "function_name": "ring_buffer_dropped_events_cpu",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3424-3437",
    "snippet": "unsigned long\nring_buffer_dropped_events_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long ret;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn 0;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tret = local_read(&cpu_buffer->dropped_events);\n\n\treturn ret;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_read",
          "args": [
            "&cpu_buffer->dropped_events"
          ],
          "line": 3434
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "buffer->cpumask"
          ],
          "line": 3430
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nunsigned long\nring_buffer_dropped_events_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long ret;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn 0;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tret = local_read(&cpu_buffer->dropped_events);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "ring_buffer_commit_overrun_cpu",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3402-3415",
    "snippet": "unsigned long\nring_buffer_commit_overrun_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long ret;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn 0;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tret = local_read(&cpu_buffer->commit_overrun);\n\n\treturn ret;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_read",
          "args": [
            "&cpu_buffer->commit_overrun"
          ],
          "line": 3412
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "buffer->cpumask"
          ],
          "line": 3408
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nunsigned long\nring_buffer_commit_overrun_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long ret;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn 0;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tret = local_read(&cpu_buffer->commit_overrun);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "ring_buffer_overrun_cpu",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3380-3392",
    "snippet": "unsigned long ring_buffer_overrun_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long ret;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn 0;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tret = local_read(&cpu_buffer->overrun);\n\n\treturn ret;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_read",
          "args": [
            "&cpu_buffer->overrun"
          ],
          "line": 3389
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "buffer->cpumask"
          ],
          "line": 3385
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nunsigned long ring_buffer_overrun_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long ret;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn 0;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tret = local_read(&cpu_buffer->overrun);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "ring_buffer_entries_cpu",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3361-3371",
    "snippet": "unsigned long ring_buffer_entries_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn 0;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\n\treturn rb_num_of_entries(cpu_buffer);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_num_of_entries",
          "args": [
            "cpu_buffer"
          ],
          "line": 3370
        },
        "resolved": true,
        "details": {
          "function_name": "rb_num_of_entries",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "3296-3301",
          "snippet": "static inline unsigned long\nrb_num_of_entries(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn local_read(&cpu_buffer->entries) -\n\t\t(local_read(&cpu_buffer->overrun) + cpu_buffer->read);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline unsigned long\nrb_num_of_entries(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn local_read(&cpu_buffer->entries) -\n\t\t(local_read(&cpu_buffer->overrun) + cpu_buffer->read);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "buffer->cpumask"
          ],
          "line": 3365
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nunsigned long ring_buffer_entries_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn 0;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\n\treturn rb_num_of_entries(cpu_buffer);\n}"
  },
  {
    "function_name": "ring_buffer_bytes_cpu",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3341-3353",
    "snippet": "unsigned long ring_buffer_bytes_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long ret;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn 0;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tret = local_read(&cpu_buffer->entries_bytes) - cpu_buffer->read_bytes;\n\n\treturn ret;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_read",
          "args": [
            "&cpu_buffer->entries_bytes"
          ],
          "line": 3350
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "buffer->cpumask"
          ],
          "line": 3346
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nunsigned long ring_buffer_bytes_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long ret;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn 0;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tret = local_read(&cpu_buffer->entries_bytes) - cpu_buffer->read_bytes;\n\n\treturn ret;\n}"
  },
  {
    "function_name": "ring_buffer_oldest_event_ts",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3308-3333",
    "snippet": "u64 ring_buffer_oldest_event_ts(struct ring_buffer *buffer, int cpu)\n{\n\tunsigned long flags;\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct buffer_page *bpage;\n\tu64 ret = 0;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn 0;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\traw_spin_lock_irqsave(&cpu_buffer->reader_lock, flags);\n\t/*\n\t * if the tail is on reader_page, oldest time stamp is on the reader\n\t * page\n\t */\n\tif (cpu_buffer->tail_page == cpu_buffer->reader_page)\n\t\tbpage = cpu_buffer->reader_page;\n\telse\n\t\tbpage = rb_set_head_page(cpu_buffer);\n\tif (bpage)\n\t\tret = bpage->page->time_stamp;\n\traw_spin_unlock_irqrestore(&cpu_buffer->reader_lock, flags);\n\n\treturn ret;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore",
          "args": [
            "&cpu_buffer->reader_lock",
            "flags"
          ],
          "line": 3330
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_irqrestore",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "182-185",
          "snippet": "void __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_set_head_page",
          "args": [
            "cpu_buffer"
          ],
          "line": 3327
        },
        "resolved": true,
        "details": {
          "function_name": "rb_set_head_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "982-1018",
          "snippet": "static struct buffer_page *\nrb_set_head_page(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *head;\n\tstruct buffer_page *page;\n\tstruct list_head *list;\n\tint i;\n\n\tif (RB_WARN_ON(cpu_buffer, !cpu_buffer->head_page))\n\t\treturn NULL;\n\n\t/* sanity check */\n\tlist = cpu_buffer->pages;\n\tif (RB_WARN_ON(cpu_buffer, rb_list_head(list->prev->next) != list))\n\t\treturn NULL;\n\n\tpage = head = cpu_buffer->head_page;\n\t/*\n\t * It is possible that the writer moves the header behind\n\t * where we started, and we miss in one loop.\n\t * A second loop should grab the header, but we'll do\n\t * three loops just because I'm paranoid.\n\t */\n\tfor (i = 0; i < 3; i++) {\n\t\tdo {\n\t\t\tif (rb_is_head_page(cpu_buffer, page, page->list.prev)) {\n\t\t\t\tcpu_buffer->head_page = page;\n\t\t\t\treturn page;\n\t\t\t}\n\t\t\trb_inc_page(cpu_buffer, &page);\n\t\t} while (page != head);\n\t}\n\n\tRB_WARN_ON(cpu_buffer, 1);\n\n\treturn NULL;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic struct buffer_page *\nrb_set_head_page(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *head;\n\tstruct buffer_page *page;\n\tstruct list_head *list;\n\tint i;\n\n\tif (RB_WARN_ON(cpu_buffer, !cpu_buffer->head_page))\n\t\treturn NULL;\n\n\t/* sanity check */\n\tlist = cpu_buffer->pages;\n\tif (RB_WARN_ON(cpu_buffer, rb_list_head(list->prev->next) != list))\n\t\treturn NULL;\n\n\tpage = head = cpu_buffer->head_page;\n\t/*\n\t * It is possible that the writer moves the header behind\n\t * where we started, and we miss in one loop.\n\t * A second loop should grab the header, but we'll do\n\t * three loops just because I'm paranoid.\n\t */\n\tfor (i = 0; i < 3; i++) {\n\t\tdo {\n\t\t\tif (rb_is_head_page(cpu_buffer, page, page->list.prev)) {\n\t\t\t\tcpu_buffer->head_page = page;\n\t\t\t\treturn page;\n\t\t\t}\n\t\t\trb_inc_page(cpu_buffer, &page);\n\t\t} while (page != head);\n\t}\n\n\tRB_WARN_ON(cpu_buffer, 1);\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irqsave",
          "args": [
            "&cpu_buffer->reader_lock",
            "flags"
          ],
          "line": 3319
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_irqsave_nested",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "359-370",
          "snippet": "unsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED_FLAGS(lock, do_raw_spin_trylock, do_raw_spin_lock,\n\t\t\t\tdo_raw_spin_lock_flags, &flags);\n\treturn flags;\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nunsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED_FLAGS(lock, do_raw_spin_trylock, do_raw_spin_lock,\n\t\t\t\tdo_raw_spin_lock_flags, &flags);\n\treturn flags;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "buffer->cpumask"
          ],
          "line": 3315
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nu64 ring_buffer_oldest_event_ts(struct ring_buffer *buffer, int cpu)\n{\n\tunsigned long flags;\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct buffer_page *bpage;\n\tu64 ret = 0;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn 0;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\traw_spin_lock_irqsave(&cpu_buffer->reader_lock, flags);\n\t/*\n\t * if the tail is on reader_page, oldest time stamp is on the reader\n\t * page\n\t */\n\tif (cpu_buffer->tail_page == cpu_buffer->reader_page)\n\t\tbpage = cpu_buffer->reader_page;\n\telse\n\t\tbpage = rb_set_head_page(cpu_buffer);\n\tif (bpage)\n\t\tret = bpage->page->time_stamp;\n\traw_spin_unlock_irqrestore(&cpu_buffer->reader_lock, flags);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "rb_num_of_entries",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3296-3301",
    "snippet": "static inline unsigned long\nrb_num_of_entries(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn local_read(&cpu_buffer->entries) -\n\t\t(local_read(&cpu_buffer->overrun) + cpu_buffer->read);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_read",
          "args": [
            "&cpu_buffer->overrun"
          ],
          "line": 3300
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_read",
          "args": [
            "&cpu_buffer->entries"
          ],
          "line": 3299
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline unsigned long\nrb_num_of_entries(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn local_read(&cpu_buffer->entries) -\n\t\t(local_read(&cpu_buffer->overrun) + cpu_buffer->read);\n}"
  },
  {
    "function_name": "ring_buffer_record_enable_cpu",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3278-3287",
    "snippet": "void ring_buffer_record_enable_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tatomic_dec(&cpu_buffer->record_disabled);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_dec",
          "args": [
            "&cpu_buffer->record_disabled"
          ],
          "line": 3286
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "buffer->cpumask"
          ],
          "line": 3282
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid ring_buffer_record_enable_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tatomic_dec(&cpu_buffer->record_disabled);\n}"
  },
  {
    "function_name": "ring_buffer_record_disable_cpu",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3258-3267",
    "snippet": "void ring_buffer_record_disable_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tatomic_inc(&cpu_buffer->record_disabled);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_inc",
          "args": [
            "&cpu_buffer->record_disabled"
          ],
          "line": 3266
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "buffer->cpumask"
          ],
          "line": 3262
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid ring_buffer_record_disable_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tatomic_inc(&cpu_buffer->record_disabled);\n}"
  },
  {
    "function_name": "ring_buffer_record_is_set_on",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3243-3246",
    "snippet": "bool ring_buffer_record_is_set_on(struct ring_buffer *buffer)\n{\n\treturn !(atomic_read(&buffer->record_disabled) & RB_BUFFER_OFF);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_BUFFER_OFF\t\t(1 << 20)"
    ],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&buffer->record_disabled"
          ],
          "line": 3245
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_BUFFER_OFF\t\t(1 << 20)\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nbool ring_buffer_record_is_set_on(struct ring_buffer *buffer)\n{\n\treturn !(atomic_read(&buffer->record_disabled) & RB_BUFFER_OFF);\n}"
  },
  {
    "function_name": "ring_buffer_record_is_on",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3227-3230",
    "snippet": "bool ring_buffer_record_is_on(struct ring_buffer *buffer)\n{\n\treturn !atomic_read(&buffer->record_disabled);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&buffer->record_disabled"
          ],
          "line": 3229
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nbool ring_buffer_record_is_on(struct ring_buffer *buffer)\n{\n\treturn !atomic_read(&buffer->record_disabled);\n}"
  },
  {
    "function_name": "ring_buffer_record_on",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3209-3218",
    "snippet": "void ring_buffer_record_on(struct ring_buffer *buffer)\n{\n\tunsigned int rd;\n\tunsigned int new_rd;\n\n\tdo {\n\t\trd = atomic_read(&buffer->record_disabled);\n\t\tnew_rd = rd & ~RB_BUFFER_OFF;\n\t} while (atomic_cmpxchg(&buffer->record_disabled, rd, new_rd) != rd);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_BUFFER_OFF\t\t(1 << 20)"
    ],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_cmpxchg",
          "args": [
            "&buffer->record_disabled",
            "rd",
            "new_rd"
          ],
          "line": 3217
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&buffer->record_disabled"
          ],
          "line": 3215
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_BUFFER_OFF\t\t(1 << 20)\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid ring_buffer_record_on(struct ring_buffer *buffer)\n{\n\tunsigned int rd;\n\tunsigned int new_rd;\n\n\tdo {\n\t\trd = atomic_read(&buffer->record_disabled);\n\t\tnew_rd = rd & ~RB_BUFFER_OFF;\n\t} while (atomic_cmpxchg(&buffer->record_disabled, rd, new_rd) != rd);\n}"
  },
  {
    "function_name": "ring_buffer_record_off",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3186-3195",
    "snippet": "void ring_buffer_record_off(struct ring_buffer *buffer)\n{\n\tunsigned int rd;\n\tunsigned int new_rd;\n\n\tdo {\n\t\trd = atomic_read(&buffer->record_disabled);\n\t\tnew_rd = rd | RB_BUFFER_OFF;\n\t} while (atomic_cmpxchg(&buffer->record_disabled, rd, new_rd) != rd);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_BUFFER_OFF\t\t(1 << 20)"
    ],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_cmpxchg",
          "args": [
            "&buffer->record_disabled",
            "rd",
            "new_rd"
          ],
          "line": 3194
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&buffer->record_disabled"
          ],
          "line": 3192
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_BUFFER_OFF\t\t(1 << 20)\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid ring_buffer_record_off(struct ring_buffer *buffer)\n{\n\tunsigned int rd;\n\tunsigned int new_rd;\n\n\tdo {\n\t\trd = atomic_read(&buffer->record_disabled);\n\t\tnew_rd = rd | RB_BUFFER_OFF;\n\t} while (atomic_cmpxchg(&buffer->record_disabled, rd, new_rd) != rd);\n}"
  },
  {
    "function_name": "ring_buffer_record_enable",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3169-3172",
    "snippet": "void ring_buffer_record_enable(struct ring_buffer *buffer)\n{\n\tatomic_dec(&buffer->record_disabled);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_dec",
          "args": [
            "&buffer->record_disabled"
          ],
          "line": 3171
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid ring_buffer_record_enable(struct ring_buffer *buffer)\n{\n\tatomic_dec(&buffer->record_disabled);\n}"
  },
  {
    "function_name": "ring_buffer_record_disable",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3156-3159",
    "snippet": "void ring_buffer_record_disable(struct ring_buffer *buffer)\n{\n\tatomic_inc(&buffer->record_disabled);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_inc",
          "args": [
            "&buffer->record_disabled"
          ],
          "line": 3158
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid ring_buffer_record_disable(struct ring_buffer *buffer)\n{\n\tatomic_inc(&buffer->record_disabled);\n}"
  },
  {
    "function_name": "rb_per_cpu_empty",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3131-3145",
    "snippet": "static bool rb_per_cpu_empty(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *reader = cpu_buffer->reader_page;\n\tstruct buffer_page *head = rb_set_head_page(cpu_buffer);\n\tstruct buffer_page *commit = cpu_buffer->commit_page;\n\n\t/* In case of error, head will be NULL */\n\tif (unlikely(!head))\n\t\treturn true;\n\n\treturn reader->read == rb_page_commit(reader) &&\n\t\t(commit == reader ||\n\t\t (commit == head &&\n\t\t  head->read == rb_page_commit(commit)));\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_page_commit",
          "args": [
            "commit"
          ],
          "line": 3144
        },
        "resolved": true,
        "details": {
          "function_name": "rb_page_commit",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1898-1901",
          "snippet": "static __always_inline unsigned rb_page_commit(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->page->commit);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline unsigned rb_page_commit(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->page->commit);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!head"
          ],
          "line": 3138
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_set_head_page",
          "args": [
            "cpu_buffer"
          ],
          "line": 3134
        },
        "resolved": true,
        "details": {
          "function_name": "rb_set_head_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "982-1018",
          "snippet": "static struct buffer_page *\nrb_set_head_page(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *head;\n\tstruct buffer_page *page;\n\tstruct list_head *list;\n\tint i;\n\n\tif (RB_WARN_ON(cpu_buffer, !cpu_buffer->head_page))\n\t\treturn NULL;\n\n\t/* sanity check */\n\tlist = cpu_buffer->pages;\n\tif (RB_WARN_ON(cpu_buffer, rb_list_head(list->prev->next) != list))\n\t\treturn NULL;\n\n\tpage = head = cpu_buffer->head_page;\n\t/*\n\t * It is possible that the writer moves the header behind\n\t * where we started, and we miss in one loop.\n\t * A second loop should grab the header, but we'll do\n\t * three loops just because I'm paranoid.\n\t */\n\tfor (i = 0; i < 3; i++) {\n\t\tdo {\n\t\t\tif (rb_is_head_page(cpu_buffer, page, page->list.prev)) {\n\t\t\t\tcpu_buffer->head_page = page;\n\t\t\t\treturn page;\n\t\t\t}\n\t\t\trb_inc_page(cpu_buffer, &page);\n\t\t} while (page != head);\n\t}\n\n\tRB_WARN_ON(cpu_buffer, 1);\n\n\treturn NULL;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic struct buffer_page *\nrb_set_head_page(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *head;\n\tstruct buffer_page *page;\n\tstruct list_head *list;\n\tint i;\n\n\tif (RB_WARN_ON(cpu_buffer, !cpu_buffer->head_page))\n\t\treturn NULL;\n\n\t/* sanity check */\n\tlist = cpu_buffer->pages;\n\tif (RB_WARN_ON(cpu_buffer, rb_list_head(list->prev->next) != list))\n\t\treturn NULL;\n\n\tpage = head = cpu_buffer->head_page;\n\t/*\n\t * It is possible that the writer moves the header behind\n\t * where we started, and we miss in one loop.\n\t * A second loop should grab the header, but we'll do\n\t * three loops just because I'm paranoid.\n\t */\n\tfor (i = 0; i < 3; i++) {\n\t\tdo {\n\t\t\tif (rb_is_head_page(cpu_buffer, page, page->list.prev)) {\n\t\t\t\tcpu_buffer->head_page = page;\n\t\t\t\treturn page;\n\t\t\t}\n\t\t\trb_inc_page(cpu_buffer, &page);\n\t\t} while (page != head);\n\t}\n\n\tRB_WARN_ON(cpu_buffer, 1);\n\n\treturn NULL;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic bool rb_per_cpu_empty(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *reader = cpu_buffer->reader_page;\n\tstruct buffer_page *head = rb_set_head_page(cpu_buffer);\n\tstruct buffer_page *commit = cpu_buffer->commit_page;\n\n\t/* In case of error, head will be NULL */\n\tif (unlikely(!head))\n\t\treturn true;\n\n\treturn reader->read == rb_page_commit(reader) &&\n\t\t(commit == reader ||\n\t\t (commit == head &&\n\t\t  head->read == rb_page_commit(commit)));\n}"
  },
  {
    "function_name": "ring_buffer_write",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3076-3128",
    "snippet": "int ring_buffer_write(struct ring_buffer *buffer,\n\t\t      unsigned long length,\n\t\t      void *data)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct ring_buffer_event *event;\n\tvoid *body;\n\tint ret = -EBUSY;\n\tint cpu;\n\n\tpreempt_disable_notrace();\n\n\tif (atomic_read(&buffer->record_disabled))\n\t\tgoto out;\n\n\tcpu = raw_smp_processor_id();\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\tgoto out;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\n\tif (atomic_read(&cpu_buffer->record_disabled))\n\t\tgoto out;\n\n\tif (length > BUF_MAX_DATA_SIZE)\n\t\tgoto out;\n\n\tif (unlikely(trace_recursive_lock(cpu_buffer)))\n\t\tgoto out;\n\n\tevent = rb_reserve_next_event(buffer, cpu_buffer, length);\n\tif (!event)\n\t\tgoto out_unlock;\n\n\tbody = rb_event_data(event);\n\n\tmemcpy(body, data, length);\n\n\trb_commit(cpu_buffer, event);\n\n\trb_wakeups(buffer, cpu_buffer);\n\n\tret = 0;\n\n out_unlock:\n\ttrace_recursive_unlock(cpu_buffer);\n\n out:\n\tpreempt_enable_notrace();\n\n\treturn ret;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define BUF_MAX_DATA_SIZE (BUF_PAGE_SIZE - (sizeof(u32) * 2))"
    ],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "preempt_enable_notrace",
          "args": [],
          "line": 3125
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_recursive_unlock",
          "args": [
            "cpu_buffer"
          ],
          "line": 3122
        },
        "resolved": true,
        "details": {
          "function_name": "trace_recursive_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2673-2678",
          "snippet": "static __always_inline void\ntrace_recursive_unlock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tcpu_buffer->current_context &=\n\t\tcpu_buffer->current_context - (1 << cpu_buffer->nest);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline void\ntrace_recursive_unlock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tcpu_buffer->current_context &=\n\t\tcpu_buffer->current_context - (1 << cpu_buffer->nest);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_wakeups",
          "args": [
            "buffer",
            "cpu_buffer"
          ],
          "line": 3117
        },
        "resolved": true,
        "details": {
          "function_name": "rb_wakeups",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2586-2611",
          "snippet": "static __always_inline void\nrb_wakeups(struct ring_buffer *buffer, struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tbool pagebusy;\n\n\tif (buffer->irq_work.waiters_pending) {\n\t\tbuffer->irq_work.waiters_pending = false;\n\t\t/* irq_work_queue() supplies it's own memory barriers */\n\t\tirq_work_queue(&buffer->irq_work.work);\n\t}\n\n\tif (cpu_buffer->irq_work.waiters_pending) {\n\t\tcpu_buffer->irq_work.waiters_pending = false;\n\t\t/* irq_work_queue() supplies it's own memory barriers */\n\t\tirq_work_queue(&cpu_buffer->irq_work.work);\n\t}\n\n\tpagebusy = cpu_buffer->reader_page == cpu_buffer->commit_page;\n\n\tif (!pagebusy && cpu_buffer->irq_work.full_waiters_pending) {\n\t\tcpu_buffer->irq_work.wakeup_full = true;\n\t\tcpu_buffer->irq_work.full_waiters_pending = false;\n\t\t/* irq_work_queue() supplies it's own memory barriers */\n\t\tirq_work_queue(&cpu_buffer->irq_work.work);\n\t}\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void update_pages_handler(struct work_struct *work);",
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void update_pages_handler(struct work_struct *work);\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline void\nrb_wakeups(struct ring_buffer *buffer, struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tbool pagebusy;\n\n\tif (buffer->irq_work.waiters_pending) {\n\t\tbuffer->irq_work.waiters_pending = false;\n\t\t/* irq_work_queue() supplies it's own memory barriers */\n\t\tirq_work_queue(&buffer->irq_work.work);\n\t}\n\n\tif (cpu_buffer->irq_work.waiters_pending) {\n\t\tcpu_buffer->irq_work.waiters_pending = false;\n\t\t/* irq_work_queue() supplies it's own memory barriers */\n\t\tirq_work_queue(&cpu_buffer->irq_work.work);\n\t}\n\n\tpagebusy = cpu_buffer->reader_page == cpu_buffer->commit_page;\n\n\tif (!pagebusy && cpu_buffer->irq_work.full_waiters_pending) {\n\t\tcpu_buffer->irq_work.wakeup_full = true;\n\t\tcpu_buffer->irq_work.full_waiters_pending = false;\n\t\t/* irq_work_queue() supplies it's own memory barriers */\n\t\tirq_work_queue(&cpu_buffer->irq_work.work);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_commit",
          "args": [
            "cpu_buffer",
            "event"
          ],
          "line": 3115
        },
        "resolved": true,
        "details": {
          "function_name": "rb_commit",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2578-2584",
          "snippet": "static void rb_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t      struct ring_buffer_event *event)\n{\n\tlocal_inc(&cpu_buffer->entries);\n\trb_update_write_stamp(cpu_buffer, event);\n\trb_end_commit(cpu_buffer);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic void rb_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t      struct ring_buffer_event *event)\n{\n\tlocal_inc(&cpu_buffer->entries);\n\trb_update_write_stamp(cpu_buffer, event);\n\trb_end_commit(cpu_buffer);\n}"
        }
      },
      {
        "call_info": {
          "callee": "memcpy",
          "args": [
            "body",
            "data",
            "length"
          ],
          "line": 3113
        },
        "resolved": true,
        "details": {
          "function_name": "memcpy_skip",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/events/internal.h",
          "lines": "178-182",
          "snippet": "static inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}",
          "includes": [
            "#include <linux/uaccess.h>",
            "#include <linux/hardirq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/uaccess.h>\n#include <linux/hardirq.h>\n\nstatic inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_event_data",
          "args": [
            "event"
          ],
          "line": 3111
        },
        "resolved": true,
        "details": {
          "function_name": "rb_event_data",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "255-266",
          "snippet": "static __always_inline void *\nrb_event_data(struct ring_buffer_event *event)\n{\n\tif (extended_time(event))\n\t\tevent = skip_time_extend(event);\n\tBUG_ON(event->type_len > RINGBUF_TYPE_DATA_TYPE_LEN_MAX);\n\t/* If length is in len field, then array[0] has the data */\n\tif (event->type_len)\n\t\treturn (void *)&event->array[0];\n\t/* Otherwise length is in array[0] and array[1] has the data */\n\treturn (void *)&event->array[1];\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic __always_inline void *\nrb_event_data(struct ring_buffer_event *event)\n{\n\tif (extended_time(event))\n\t\tevent = skip_time_extend(event);\n\tBUG_ON(event->type_len > RINGBUF_TYPE_DATA_TYPE_LEN_MAX);\n\t/* If length is in len field, then array[0] has the data */\n\tif (event->type_len)\n\t\treturn (void *)&event->array[0];\n\t/* Otherwise length is in array[0] and array[1] has the data */\n\treturn (void *)&event->array[1];\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_reserve_next_event",
          "args": [
            "buffer",
            "cpu_buffer",
            "length"
          ],
          "line": 3107
        },
        "resolved": true,
        "details": {
          "function_name": "rb_reserve_next_event",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2830-2906",
          "snippet": "ring_buffer_event *\nrb_reserve_next_event(struct ring_buffer *buffer,\n\t\t      struct ring_buffer_per_cpu *cpu_buffer,\n\t\t      unsigned long length)\n{\n\tstruct ring_buffer_event *event;\n\tstruct rb_event_info info;\n\tint nr_loops = 0;\n\tu64 diff;\n\n\trb_start_commit(cpu_buffer);\n\n#ifdef CONFIG_RING_BUFFER_ALLOW_SWAP\n\t/*\n\t * Due to the ability to swap a cpu buffer from a buffer\n\t * it is possible it was swapped before we committed.\n\t * (committing stops a swap). We check for it here and\n\t * if it happened, we have to fail the write.\n\t */\n\tbarrier();\n\tif (unlikely(READ_ONCE(cpu_buffer->buffer) != buffer)) {\n\t\tlocal_dec(&cpu_buffer->committing);\n\t\tlocal_dec(&cpu_buffer->commits);\n\t\treturn NULL;\n\t}\n#endif\n\n\tinfo.length = rb_calculate_event_length(length);\n again:\n\tinfo.add_timestamp = 0;\n\tinfo.delta = 0;\n\n\t/*\n\t * We allow for interrupts to reenter here and do a trace.\n\t * If one does, it will cause this original code to loop\n\t * back here. Even with heavy interrupts happening, this\n\t * should only happen a few times in a row. If this happens\n\t * 1000 times in a row, there must be either an interrupt\n\t * storm or we have something buggy.\n\t * Bail!\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 1000))\n\t\tgoto out_fail;\n\n\tinfo.ts = rb_time_stamp(cpu_buffer->buffer);\n\tdiff = info.ts - cpu_buffer->write_stamp;\n\n\t/* make sure this diff is calculated here */\n\tbarrier();\n\n\tif (ring_buffer_time_stamp_abs(buffer)) {\n\t\tinfo.delta = info.ts;\n\t\trb_handle_timestamp(cpu_buffer, &info);\n\t} else /* Did the write stamp get updated already? */\n\t\tif (likely(info.ts >= cpu_buffer->write_stamp)) {\n\t\tinfo.delta = diff;\n\t\tif (unlikely(test_time_stamp(info.delta)))\n\t\t\trb_handle_timestamp(cpu_buffer, &info);\n\t}\n\n\tevent = __rb_reserve_next(cpu_buffer, &info);\n\n\tif (unlikely(PTR_ERR(event) == -EAGAIN)) {\n\t\tif (info.add_timestamp)\n\t\t\tinfo.length -= RB_LEN_TIME_EXTEND;\n\t\tgoto again;\n\t}\n\n\tif (!event)\n\t\tgoto out_fail;\n\n\treturn event;\n\n out_fail:\n\trb_end_commit(cpu_buffer);\n\treturn NULL;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nring_buffer_event *\nrb_reserve_next_event(struct ring_buffer *buffer,\n\t\t      struct ring_buffer_per_cpu *cpu_buffer,\n\t\t      unsigned long length)\n{\n\tstruct ring_buffer_event *event;\n\tstruct rb_event_info info;\n\tint nr_loops = 0;\n\tu64 diff;\n\n\trb_start_commit(cpu_buffer);\n\n#ifdef CONFIG_RING_BUFFER_ALLOW_SWAP\n\t/*\n\t * Due to the ability to swap a cpu buffer from a buffer\n\t * it is possible it was swapped before we committed.\n\t * (committing stops a swap). We check for it here and\n\t * if it happened, we have to fail the write.\n\t */\n\tbarrier();\n\tif (unlikely(READ_ONCE(cpu_buffer->buffer) != buffer)) {\n\t\tlocal_dec(&cpu_buffer->committing);\n\t\tlocal_dec(&cpu_buffer->commits);\n\t\treturn NULL;\n\t}\n#endif\n\n\tinfo.length = rb_calculate_event_length(length);\n again:\n\tinfo.add_timestamp = 0;\n\tinfo.delta = 0;\n\n\t/*\n\t * We allow for interrupts to reenter here and do a trace.\n\t * If one does, it will cause this original code to loop\n\t * back here. Even with heavy interrupts happening, this\n\t * should only happen a few times in a row. If this happens\n\t * 1000 times in a row, there must be either an interrupt\n\t * storm or we have something buggy.\n\t * Bail!\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 1000))\n\t\tgoto out_fail;\n\n\tinfo.ts = rb_time_stamp(cpu_buffer->buffer);\n\tdiff = info.ts - cpu_buffer->write_stamp;\n\n\t/* make sure this diff is calculated here */\n\tbarrier();\n\n\tif (ring_buffer_time_stamp_abs(buffer)) {\n\t\tinfo.delta = info.ts;\n\t\trb_handle_timestamp(cpu_buffer, &info);\n\t} else /* Did the write stamp get updated already? */\n\t\tif (likely(info.ts >= cpu_buffer->write_stamp)) {\n\t\tinfo.delta = diff;\n\t\tif (unlikely(test_time_stamp(info.delta)))\n\t\t\trb_handle_timestamp(cpu_buffer, &info);\n\t}\n\n\tevent = __rb_reserve_next(cpu_buffer, &info);\n\n\tif (unlikely(PTR_ERR(event) == -EAGAIN)) {\n\t\tif (info.add_timestamp)\n\t\t\tinfo.length -= RB_LEN_TIME_EXTEND;\n\t\tgoto again;\n\t}\n\n\tif (!event)\n\t\tgoto out_fail;\n\n\treturn event;\n\n out_fail:\n\trb_end_commit(cpu_buffer);\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "trace_recursive_lock(cpu_buffer)"
          ],
          "line": 3104
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_recursive_lock",
          "args": [
            "cpu_buffer"
          ],
          "line": 3104
        },
        "resolved": true,
        "details": {
          "function_name": "trace_recursive_lock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2651-2671",
          "snippet": "static __always_inline int\ntrace_recursive_lock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tunsigned int val = cpu_buffer->current_context;\n\tunsigned long pc = preempt_count();\n\tint bit;\n\n\tif (!(pc & (NMI_MASK | HARDIRQ_MASK | SOFTIRQ_OFFSET)))\n\t\tbit = RB_CTX_NORMAL;\n\telse\n\t\tbit = pc & NMI_MASK ? RB_CTX_NMI :\n\t\t\tpc & HARDIRQ_MASK ? RB_CTX_IRQ : RB_CTX_SOFTIRQ;\n\n\tif (unlikely(val & (1 << (bit + cpu_buffer->nest))))\n\t\treturn 1;\n\n\tval |= (1 << (bit + cpu_buffer->nest));\n\tcpu_buffer->current_context = val;\n\n\treturn 0;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline int\ntrace_recursive_lock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tunsigned int val = cpu_buffer->current_context;\n\tunsigned long pc = preempt_count();\n\tint bit;\n\n\tif (!(pc & (NMI_MASK | HARDIRQ_MASK | SOFTIRQ_OFFSET)))\n\t\tbit = RB_CTX_NORMAL;\n\telse\n\t\tbit = pc & NMI_MASK ? RB_CTX_NMI :\n\t\t\tpc & HARDIRQ_MASK ? RB_CTX_IRQ : RB_CTX_SOFTIRQ;\n\n\tif (unlikely(val & (1 << (bit + cpu_buffer->nest))))\n\t\treturn 1;\n\n\tval |= (1 << (bit + cpu_buffer->nest));\n\tcpu_buffer->current_context = val;\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&cpu_buffer->record_disabled"
          ],
          "line": 3098
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "buffer->cpumask"
          ],
          "line": 3093
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_smp_processor_id",
          "args": [],
          "line": 3091
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&buffer->record_disabled"
          ],
          "line": 3088
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "preempt_disable_notrace",
          "args": [],
          "line": 3086
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define BUF_MAX_DATA_SIZE (BUF_PAGE_SIZE - (sizeof(u32) * 2))\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nint ring_buffer_write(struct ring_buffer *buffer,\n\t\t      unsigned long length,\n\t\t      void *data)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct ring_buffer_event *event;\n\tvoid *body;\n\tint ret = -EBUSY;\n\tint cpu;\n\n\tpreempt_disable_notrace();\n\n\tif (atomic_read(&buffer->record_disabled))\n\t\tgoto out;\n\n\tcpu = raw_smp_processor_id();\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\tgoto out;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\n\tif (atomic_read(&cpu_buffer->record_disabled))\n\t\tgoto out;\n\n\tif (length > BUF_MAX_DATA_SIZE)\n\t\tgoto out;\n\n\tif (unlikely(trace_recursive_lock(cpu_buffer)))\n\t\tgoto out;\n\n\tevent = rb_reserve_next_event(buffer, cpu_buffer, length);\n\tif (!event)\n\t\tgoto out_unlock;\n\n\tbody = rb_event_data(event);\n\n\tmemcpy(body, data, length);\n\n\trb_commit(cpu_buffer, event);\n\n\trb_wakeups(buffer, cpu_buffer);\n\n\tret = 0;\n\n out_unlock:\n\ttrace_recursive_unlock(cpu_buffer);\n\n out:\n\tpreempt_enable_notrace();\n\n\treturn ret;\n}"
  },
  {
    "function_name": "ring_buffer_discard_commit",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "3025-3060",
    "snippet": "void ring_buffer_discard_commit(struct ring_buffer *buffer,\n\t\t\t\tstruct ring_buffer_event *event)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tint cpu;\n\n\t/* The event is discarded regardless */\n\trb_event_discard(event);\n\n\tcpu = smp_processor_id();\n\tcpu_buffer = buffer->buffers[cpu];\n\n\t/*\n\t * This must only be called if the event has not been\n\t * committed yet. Thus we can assume that preemption\n\t * is still disabled.\n\t */\n\tRB_WARN_ON(buffer, !local_read(&cpu_buffer->committing));\n\n\trb_decrement_entry(cpu_buffer, event);\n\tif (rb_try_to_discard(cpu_buffer, event))\n\t\tgoto out;\n\n\t/*\n\t * The commit is still visible by the reader, so we\n\t * must still update the timestamp.\n\t */\n\trb_update_write_stamp(cpu_buffer, event);\n out:\n\trb_end_commit(cpu_buffer);\n\n\ttrace_recursive_unlock(cpu_buffer);\n\n\tpreempt_enable_notrace();\n\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "preempt_enable_notrace",
          "args": [],
          "line": 3058
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_recursive_unlock",
          "args": [
            "cpu_buffer"
          ],
          "line": 3056
        },
        "resolved": true,
        "details": {
          "function_name": "trace_recursive_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2673-2678",
          "snippet": "static __always_inline void\ntrace_recursive_unlock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tcpu_buffer->current_context &=\n\t\tcpu_buffer->current_context - (1 << cpu_buffer->nest);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline void\ntrace_recursive_unlock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tcpu_buffer->current_context &=\n\t\tcpu_buffer->current_context - (1 << cpu_buffer->nest);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_end_commit",
          "args": [
            "cpu_buffer"
          ],
          "line": 3054
        },
        "resolved": true,
        "details": {
          "function_name": "rb_end_commit",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2490-2520",
          "snippet": "static __always_inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tunsigned long commits;\n\n\tif (RB_WARN_ON(cpu_buffer,\n\t\t       !local_read(&cpu_buffer->committing)))\n\t\treturn;\n\n again:\n\tcommits = local_read(&cpu_buffer->commits);\n\t/* synchronize with interrupts */\n\tbarrier();\n\tif (local_read(&cpu_buffer->committing) == 1)\n\t\trb_set_commit_to_write(cpu_buffer);\n\n\tlocal_dec(&cpu_buffer->committing);\n\n\t/* synchronize with interrupts */\n\tbarrier();\n\n\t/*\n\t * Need to account for interrupts coming in between the\n\t * updating of the commit page and the clearing of the\n\t * committing counter.\n\t */\n\tif (unlikely(local_read(&cpu_buffer->commits) != commits) &&\n\t    !local_read(&cpu_buffer->committing)) {\n\t\tlocal_inc(&cpu_buffer->committing);\n\t\tgoto again;\n\t}\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tunsigned long commits;\n\n\tif (RB_WARN_ON(cpu_buffer,\n\t\t       !local_read(&cpu_buffer->committing)))\n\t\treturn;\n\n again:\n\tcommits = local_read(&cpu_buffer->commits);\n\t/* synchronize with interrupts */\n\tbarrier();\n\tif (local_read(&cpu_buffer->committing) == 1)\n\t\trb_set_commit_to_write(cpu_buffer);\n\n\tlocal_dec(&cpu_buffer->committing);\n\n\t/* synchronize with interrupts */\n\tbarrier();\n\n\t/*\n\t * Need to account for interrupts coming in between the\n\t * updating of the commit page and the clearing of the\n\t * committing counter.\n\t */\n\tif (unlikely(local_read(&cpu_buffer->commits) != commits) &&\n\t    !local_read(&cpu_buffer->committing)) {\n\t\tlocal_inc(&cpu_buffer->committing);\n\t\tgoto again;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_update_write_stamp",
          "args": [
            "cpu_buffer",
            "event"
          ],
          "line": 3052
        },
        "resolved": true,
        "details": {
          "function_name": "rb_update_write_stamp",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2549-2576",
          "snippet": "static __always_inline void\nrb_update_write_stamp(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t      struct ring_buffer_event *event)\n{\n\tu64 delta;\n\n\t/*\n\t * The event first in the commit queue updates the\n\t * time stamp.\n\t */\n\tif (rb_event_is_commit(cpu_buffer, event)) {\n\t\t/*\n\t\t * A commit event that is first on a page\n\t\t * updates the write timestamp with the page stamp\n\t\t */\n\t\tif (!rb_event_index(event))\n\t\t\tcpu_buffer->write_stamp =\n\t\t\t\tcpu_buffer->commit_page->page->time_stamp;\n\t\telse if (event->type_len == RINGBUF_TYPE_TIME_EXTEND) {\n\t\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\t\tcpu_buffer->write_stamp += delta;\n\t\t} else if (event->type_len == RINGBUF_TYPE_TIME_STAMP) {\n\t\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\t\tcpu_buffer->write_stamp = delta;\n\t\t} else\n\t\t\tcpu_buffer->write_stamp += event->time_delta;\n\t}\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic __always_inline void\nrb_update_write_stamp(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t      struct ring_buffer_event *event)\n{\n\tu64 delta;\n\n\t/*\n\t * The event first in the commit queue updates the\n\t * time stamp.\n\t */\n\tif (rb_event_is_commit(cpu_buffer, event)) {\n\t\t/*\n\t\t * A commit event that is first on a page\n\t\t * updates the write timestamp with the page stamp\n\t\t */\n\t\tif (!rb_event_index(event))\n\t\t\tcpu_buffer->write_stamp =\n\t\t\t\tcpu_buffer->commit_page->page->time_stamp;\n\t\telse if (event->type_len == RINGBUF_TYPE_TIME_EXTEND) {\n\t\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\t\tcpu_buffer->write_stamp += delta;\n\t\t} else if (event->type_len == RINGBUF_TYPE_TIME_STAMP) {\n\t\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\t\tcpu_buffer->write_stamp = delta;\n\t\t} else\n\t\t\tcpu_buffer->write_stamp += event->time_delta;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_try_to_discard",
          "args": [
            "cpu_buffer",
            "event"
          ],
          "line": 3045
        },
        "resolved": true,
        "details": {
          "function_name": "rb_try_to_discard",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2389-2427",
          "snippet": "static inline int\nrb_try_to_discard(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t  struct ring_buffer_event *event)\n{\n\tunsigned long new_index, old_index;\n\tstruct buffer_page *bpage;\n\tunsigned long index;\n\tunsigned long addr;\n\n\tnew_index = rb_event_index(event);\n\told_index = new_index + rb_event_ts_length(event);\n\taddr = (unsigned long)event;\n\taddr &= PAGE_MASK;\n\n\tbpage = READ_ONCE(cpu_buffer->tail_page);\n\n\tif (bpage->page == (void *)addr && rb_page_write(bpage) == old_index) {\n\t\tunsigned long write_mask =\n\t\t\tlocal_read(&bpage->write) & ~RB_WRITE_MASK;\n\t\tunsigned long event_length = rb_event_length(event);\n\t\t/*\n\t\t * This is on the tail page. It is possible that\n\t\t * a write could come in and move the tail page\n\t\t * and write to the next page. That is fine\n\t\t * because we just shorten what is on this page.\n\t\t */\n\t\told_index += write_mask;\n\t\tnew_index += write_mask;\n\t\tindex = local_cmpxchg(&bpage->write, old_index, new_index);\n\t\tif (index == old_index) {\n\t\t\t/* update counters */\n\t\t\tlocal_sub(event_length, &cpu_buffer->entries_bytes);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* could not discard */\n\treturn 0;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_WRITE_MASK\t\t0xfffff"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_WRITE_MASK\t\t0xfffff\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic inline int\nrb_try_to_discard(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t  struct ring_buffer_event *event)\n{\n\tunsigned long new_index, old_index;\n\tstruct buffer_page *bpage;\n\tunsigned long index;\n\tunsigned long addr;\n\n\tnew_index = rb_event_index(event);\n\told_index = new_index + rb_event_ts_length(event);\n\taddr = (unsigned long)event;\n\taddr &= PAGE_MASK;\n\n\tbpage = READ_ONCE(cpu_buffer->tail_page);\n\n\tif (bpage->page == (void *)addr && rb_page_write(bpage) == old_index) {\n\t\tunsigned long write_mask =\n\t\t\tlocal_read(&bpage->write) & ~RB_WRITE_MASK;\n\t\tunsigned long event_length = rb_event_length(event);\n\t\t/*\n\t\t * This is on the tail page. It is possible that\n\t\t * a write could come in and move the tail page\n\t\t * and write to the next page. That is fine\n\t\t * because we just shorten what is on this page.\n\t\t */\n\t\told_index += write_mask;\n\t\tnew_index += write_mask;\n\t\tindex = local_cmpxchg(&bpage->write, old_index, new_index);\n\t\tif (index == old_index) {\n\t\t\t/* update counters */\n\t\t\tlocal_sub(event_length, &cpu_buffer->entries_bytes);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* could not discard */\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_decrement_entry",
          "args": [
            "cpu_buffer",
            "event"
          ],
          "line": 3044
        },
        "resolved": true,
        "details": {
          "function_name": "rb_decrement_entry",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2972-3004",
          "snippet": "static inline void\nrb_decrement_entry(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t   struct ring_buffer_event *event)\n{\n\tunsigned long addr = (unsigned long)event;\n\tstruct buffer_page *bpage = cpu_buffer->commit_page;\n\tstruct buffer_page *start;\n\n\taddr &= PAGE_MASK;\n\n\t/* Do the likely case first */\n\tif (likely(bpage->page == (void *)addr)) {\n\t\tlocal_dec(&bpage->entries);\n\t\treturn;\n\t}\n\n\t/*\n\t * Because the commit page may be on the reader page we\n\t * start with the next page and check the end loop there.\n\t */\n\trb_inc_page(cpu_buffer, &bpage);\n\tstart = bpage;\n\tdo {\n\t\tif (bpage->page == (void *)addr) {\n\t\t\tlocal_dec(&bpage->entries);\n\t\t\treturn;\n\t\t}\n\t\trb_inc_page(cpu_buffer, &bpage);\n\t} while (bpage != start);\n\n\t/* commit not part of this buffer?? */\n\tRB_WARN_ON(cpu_buffer, 1);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic inline void\nrb_decrement_entry(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t   struct ring_buffer_event *event)\n{\n\tunsigned long addr = (unsigned long)event;\n\tstruct buffer_page *bpage = cpu_buffer->commit_page;\n\tstruct buffer_page *start;\n\n\taddr &= PAGE_MASK;\n\n\t/* Do the likely case first */\n\tif (likely(bpage->page == (void *)addr)) {\n\t\tlocal_dec(&bpage->entries);\n\t\treturn;\n\t}\n\n\t/*\n\t * Because the commit page may be on the reader page we\n\t * start with the next page and check the end loop there.\n\t */\n\trb_inc_page(cpu_buffer, &bpage);\n\tstart = bpage;\n\tdo {\n\t\tif (bpage->page == (void *)addr) {\n\t\t\tlocal_dec(&bpage->entries);\n\t\t\treturn;\n\t\t}\n\t\trb_inc_page(cpu_buffer, &bpage);\n\t} while (bpage != start);\n\n\t/* commit not part of this buffer?? */\n\tRB_WARN_ON(cpu_buffer, 1);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "buffer",
            "!local_read(&cpu_buffer->committing)"
          ],
          "line": 3042
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_read",
          "args": [
            "&cpu_buffer->committing"
          ],
          "line": 3042
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_processor_id",
          "args": [],
          "line": 3034
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_event_discard",
          "args": [
            "event"
          ],
          "line": 3032
        },
        "resolved": true,
        "details": {
          "function_name": "rb_event_discard",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2522-2533",
          "snippet": "static inline void rb_event_discard(struct ring_buffer_event *event)\n{\n\tif (extended_time(event))\n\t\tevent = skip_time_extend(event);\n\n\t/* array[0] holds the actual length for the discarded event */\n\tevent->array[0] = rb_event_data_length(event) - RB_EVNT_HDR_SIZE;\n\tevent->type_len = RINGBUF_TYPE_PADDING;\n\t/* time delta must be non zero */\n\tif (!event->time_delta)\n\t\tevent->time_delta = 1;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic inline void rb_event_discard(struct ring_buffer_event *event)\n{\n\tif (extended_time(event))\n\t\tevent = skip_time_extend(event);\n\n\t/* array[0] holds the actual length for the discarded event */\n\tevent->array[0] = rb_event_data_length(event) - RB_EVNT_HDR_SIZE;\n\tevent->type_len = RINGBUF_TYPE_PADDING;\n\t/* time delta must be non zero */\n\tif (!event->time_delta)\n\t\tevent->time_delta = 1;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nvoid ring_buffer_discard_commit(struct ring_buffer *buffer,\n\t\t\t\tstruct ring_buffer_event *event)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tint cpu;\n\n\t/* The event is discarded regardless */\n\trb_event_discard(event);\n\n\tcpu = smp_processor_id();\n\tcpu_buffer = buffer->buffers[cpu];\n\n\t/*\n\t * This must only be called if the event has not been\n\t * committed yet. Thus we can assume that preemption\n\t * is still disabled.\n\t */\n\tRB_WARN_ON(buffer, !local_read(&cpu_buffer->committing));\n\n\trb_decrement_entry(cpu_buffer, event);\n\tif (rb_try_to_discard(cpu_buffer, event))\n\t\tgoto out;\n\n\t/*\n\t * The commit is still visible by the reader, so we\n\t * must still update the timestamp.\n\t */\n\trb_update_write_stamp(cpu_buffer, event);\n out:\n\trb_end_commit(cpu_buffer);\n\n\ttrace_recursive_unlock(cpu_buffer);\n\n\tpreempt_enable_notrace();\n\n}"
  },
  {
    "function_name": "rb_decrement_entry",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2972-3004",
    "snippet": "static inline void\nrb_decrement_entry(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t   struct ring_buffer_event *event)\n{\n\tunsigned long addr = (unsigned long)event;\n\tstruct buffer_page *bpage = cpu_buffer->commit_page;\n\tstruct buffer_page *start;\n\n\taddr &= PAGE_MASK;\n\n\t/* Do the likely case first */\n\tif (likely(bpage->page == (void *)addr)) {\n\t\tlocal_dec(&bpage->entries);\n\t\treturn;\n\t}\n\n\t/*\n\t * Because the commit page may be on the reader page we\n\t * start with the next page and check the end loop there.\n\t */\n\trb_inc_page(cpu_buffer, &bpage);\n\tstart = bpage;\n\tdo {\n\t\tif (bpage->page == (void *)addr) {\n\t\t\tlocal_dec(&bpage->entries);\n\t\t\treturn;\n\t\t}\n\t\trb_inc_page(cpu_buffer, &bpage);\n\t} while (bpage != start);\n\n\t/* commit not part of this buffer?? */\n\tRB_WARN_ON(cpu_buffer, 1);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "1"
          ],
          "line": 3003
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_inc_page",
          "args": [
            "cpu_buffer",
            "&bpage"
          ],
          "line": 2999
        },
        "resolved": true,
        "details": {
          "function_name": "rb_inc_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "974-980",
          "snippet": "static inline void rb_inc_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t       struct buffer_page **bpage)\n{\n\tstruct list_head *p = rb_list_head((*bpage)->list.next);\n\n\t*bpage = list_entry(p, struct buffer_page, list);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline void rb_inc_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t       struct buffer_page **bpage)\n{\n\tstruct list_head *p = rb_list_head((*bpage)->list.next);\n\n\t*bpage = list_entry(p, struct buffer_page, list);\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_dec",
          "args": [
            "&bpage->entries"
          ],
          "line": 2996
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_dec",
          "args": [
            "&bpage->entries"
          ],
          "line": 2984
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "bpage->page == (void *)addr"
          ],
          "line": 2983
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic inline void\nrb_decrement_entry(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t   struct ring_buffer_event *event)\n{\n\tunsigned long addr = (unsigned long)event;\n\tstruct buffer_page *bpage = cpu_buffer->commit_page;\n\tstruct buffer_page *start;\n\n\taddr &= PAGE_MASK;\n\n\t/* Do the likely case first */\n\tif (likely(bpage->page == (void *)addr)) {\n\t\tlocal_dec(&bpage->entries);\n\t\treturn;\n\t}\n\n\t/*\n\t * Because the commit page may be on the reader page we\n\t * start with the next page and check the end loop there.\n\t */\n\trb_inc_page(cpu_buffer, &bpage);\n\tstart = bpage;\n\tdo {\n\t\tif (bpage->page == (void *)addr) {\n\t\t\tlocal_dec(&bpage->entries);\n\t\t\treturn;\n\t\t}\n\t\trb_inc_page(cpu_buffer, &bpage);\n\t} while (bpage != start);\n\n\t/* commit not part of this buffer?? */\n\tRB_WARN_ON(cpu_buffer, 1);\n}"
  },
  {
    "function_name": "ring_buffer_lock_reserve",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2923-2963",
    "snippet": "struct ring_buffer_event *\nring_buffer_lock_reserve(struct ring_buffer *buffer, unsigned long length)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct ring_buffer_event *event;\n\tint cpu;\n\n\t/* If we are tracing schedule, we don't want to recurse */\n\tpreempt_disable_notrace();\n\n\tif (unlikely(atomic_read(&buffer->record_disabled)))\n\t\tgoto out;\n\n\tcpu = raw_smp_processor_id();\n\n\tif (unlikely(!cpumask_test_cpu(cpu, buffer->cpumask)))\n\t\tgoto out;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\n\tif (unlikely(atomic_read(&cpu_buffer->record_disabled)))\n\t\tgoto out;\n\n\tif (unlikely(length > BUF_MAX_DATA_SIZE))\n\t\tgoto out;\n\n\tif (unlikely(trace_recursive_lock(cpu_buffer)))\n\t\tgoto out;\n\n\tevent = rb_reserve_next_event(buffer, cpu_buffer, length);\n\tif (!event)\n\t\tgoto out_unlock;\n\n\treturn event;\n\n out_unlock:\n\ttrace_recursive_unlock(cpu_buffer);\n out:\n\tpreempt_enable_notrace();\n\treturn NULL;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define BUF_MAX_DATA_SIZE (BUF_PAGE_SIZE - (sizeof(u32) * 2))"
    ],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "preempt_enable_notrace",
          "args": [],
          "line": 2961
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_recursive_unlock",
          "args": [
            "cpu_buffer"
          ],
          "line": 2959
        },
        "resolved": true,
        "details": {
          "function_name": "trace_recursive_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2673-2678",
          "snippet": "static __always_inline void\ntrace_recursive_unlock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tcpu_buffer->current_context &=\n\t\tcpu_buffer->current_context - (1 << cpu_buffer->nest);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline void\ntrace_recursive_unlock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tcpu_buffer->current_context &=\n\t\tcpu_buffer->current_context - (1 << cpu_buffer->nest);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_reserve_next_event",
          "args": [
            "buffer",
            "cpu_buffer",
            "length"
          ],
          "line": 2952
        },
        "resolved": true,
        "details": {
          "function_name": "rb_reserve_next_event",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2830-2906",
          "snippet": "ring_buffer_event *\nrb_reserve_next_event(struct ring_buffer *buffer,\n\t\t      struct ring_buffer_per_cpu *cpu_buffer,\n\t\t      unsigned long length)\n{\n\tstruct ring_buffer_event *event;\n\tstruct rb_event_info info;\n\tint nr_loops = 0;\n\tu64 diff;\n\n\trb_start_commit(cpu_buffer);\n\n#ifdef CONFIG_RING_BUFFER_ALLOW_SWAP\n\t/*\n\t * Due to the ability to swap a cpu buffer from a buffer\n\t * it is possible it was swapped before we committed.\n\t * (committing stops a swap). We check for it here and\n\t * if it happened, we have to fail the write.\n\t */\n\tbarrier();\n\tif (unlikely(READ_ONCE(cpu_buffer->buffer) != buffer)) {\n\t\tlocal_dec(&cpu_buffer->committing);\n\t\tlocal_dec(&cpu_buffer->commits);\n\t\treturn NULL;\n\t}\n#endif\n\n\tinfo.length = rb_calculate_event_length(length);\n again:\n\tinfo.add_timestamp = 0;\n\tinfo.delta = 0;\n\n\t/*\n\t * We allow for interrupts to reenter here and do a trace.\n\t * If one does, it will cause this original code to loop\n\t * back here. Even with heavy interrupts happening, this\n\t * should only happen a few times in a row. If this happens\n\t * 1000 times in a row, there must be either an interrupt\n\t * storm or we have something buggy.\n\t * Bail!\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 1000))\n\t\tgoto out_fail;\n\n\tinfo.ts = rb_time_stamp(cpu_buffer->buffer);\n\tdiff = info.ts - cpu_buffer->write_stamp;\n\n\t/* make sure this diff is calculated here */\n\tbarrier();\n\n\tif (ring_buffer_time_stamp_abs(buffer)) {\n\t\tinfo.delta = info.ts;\n\t\trb_handle_timestamp(cpu_buffer, &info);\n\t} else /* Did the write stamp get updated already? */\n\t\tif (likely(info.ts >= cpu_buffer->write_stamp)) {\n\t\tinfo.delta = diff;\n\t\tif (unlikely(test_time_stamp(info.delta)))\n\t\t\trb_handle_timestamp(cpu_buffer, &info);\n\t}\n\n\tevent = __rb_reserve_next(cpu_buffer, &info);\n\n\tif (unlikely(PTR_ERR(event) == -EAGAIN)) {\n\t\tif (info.add_timestamp)\n\t\t\tinfo.length -= RB_LEN_TIME_EXTEND;\n\t\tgoto again;\n\t}\n\n\tif (!event)\n\t\tgoto out_fail;\n\n\treturn event;\n\n out_fail:\n\trb_end_commit(cpu_buffer);\n\treturn NULL;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nring_buffer_event *\nrb_reserve_next_event(struct ring_buffer *buffer,\n\t\t      struct ring_buffer_per_cpu *cpu_buffer,\n\t\t      unsigned long length)\n{\n\tstruct ring_buffer_event *event;\n\tstruct rb_event_info info;\n\tint nr_loops = 0;\n\tu64 diff;\n\n\trb_start_commit(cpu_buffer);\n\n#ifdef CONFIG_RING_BUFFER_ALLOW_SWAP\n\t/*\n\t * Due to the ability to swap a cpu buffer from a buffer\n\t * it is possible it was swapped before we committed.\n\t * (committing stops a swap). We check for it here and\n\t * if it happened, we have to fail the write.\n\t */\n\tbarrier();\n\tif (unlikely(READ_ONCE(cpu_buffer->buffer) != buffer)) {\n\t\tlocal_dec(&cpu_buffer->committing);\n\t\tlocal_dec(&cpu_buffer->commits);\n\t\treturn NULL;\n\t}\n#endif\n\n\tinfo.length = rb_calculate_event_length(length);\n again:\n\tinfo.add_timestamp = 0;\n\tinfo.delta = 0;\n\n\t/*\n\t * We allow for interrupts to reenter here and do a trace.\n\t * If one does, it will cause this original code to loop\n\t * back here. Even with heavy interrupts happening, this\n\t * should only happen a few times in a row. If this happens\n\t * 1000 times in a row, there must be either an interrupt\n\t * storm or we have something buggy.\n\t * Bail!\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 1000))\n\t\tgoto out_fail;\n\n\tinfo.ts = rb_time_stamp(cpu_buffer->buffer);\n\tdiff = info.ts - cpu_buffer->write_stamp;\n\n\t/* make sure this diff is calculated here */\n\tbarrier();\n\n\tif (ring_buffer_time_stamp_abs(buffer)) {\n\t\tinfo.delta = info.ts;\n\t\trb_handle_timestamp(cpu_buffer, &info);\n\t} else /* Did the write stamp get updated already? */\n\t\tif (likely(info.ts >= cpu_buffer->write_stamp)) {\n\t\tinfo.delta = diff;\n\t\tif (unlikely(test_time_stamp(info.delta)))\n\t\t\trb_handle_timestamp(cpu_buffer, &info);\n\t}\n\n\tevent = __rb_reserve_next(cpu_buffer, &info);\n\n\tif (unlikely(PTR_ERR(event) == -EAGAIN)) {\n\t\tif (info.add_timestamp)\n\t\t\tinfo.length -= RB_LEN_TIME_EXTEND;\n\t\tgoto again;\n\t}\n\n\tif (!event)\n\t\tgoto out_fail;\n\n\treturn event;\n\n out_fail:\n\trb_end_commit(cpu_buffer);\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "trace_recursive_lock(cpu_buffer)"
          ],
          "line": 2949
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_recursive_lock",
          "args": [
            "cpu_buffer"
          ],
          "line": 2949
        },
        "resolved": true,
        "details": {
          "function_name": "trace_recursive_lock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2651-2671",
          "snippet": "static __always_inline int\ntrace_recursive_lock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tunsigned int val = cpu_buffer->current_context;\n\tunsigned long pc = preempt_count();\n\tint bit;\n\n\tif (!(pc & (NMI_MASK | HARDIRQ_MASK | SOFTIRQ_OFFSET)))\n\t\tbit = RB_CTX_NORMAL;\n\telse\n\t\tbit = pc & NMI_MASK ? RB_CTX_NMI :\n\t\t\tpc & HARDIRQ_MASK ? RB_CTX_IRQ : RB_CTX_SOFTIRQ;\n\n\tif (unlikely(val & (1 << (bit + cpu_buffer->nest))))\n\t\treturn 1;\n\n\tval |= (1 << (bit + cpu_buffer->nest));\n\tcpu_buffer->current_context = val;\n\n\treturn 0;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline int\ntrace_recursive_lock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tunsigned int val = cpu_buffer->current_context;\n\tunsigned long pc = preempt_count();\n\tint bit;\n\n\tif (!(pc & (NMI_MASK | HARDIRQ_MASK | SOFTIRQ_OFFSET)))\n\t\tbit = RB_CTX_NORMAL;\n\telse\n\t\tbit = pc & NMI_MASK ? RB_CTX_NMI :\n\t\t\tpc & HARDIRQ_MASK ? RB_CTX_IRQ : RB_CTX_SOFTIRQ;\n\n\tif (unlikely(val & (1 << (bit + cpu_buffer->nest))))\n\t\treturn 1;\n\n\tval |= (1 << (bit + cpu_buffer->nest));\n\tcpu_buffer->current_context = val;\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "length > BUF_MAX_DATA_SIZE"
          ],
          "line": 2946
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "atomic_read(&cpu_buffer->record_disabled)"
          ],
          "line": 2943
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&cpu_buffer->record_disabled"
          ],
          "line": 2943
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!cpumask_test_cpu(cpu, buffer->cpumask)"
          ],
          "line": 2938
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "buffer->cpumask"
          ],
          "line": 2938
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_smp_processor_id",
          "args": [],
          "line": 2936
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "atomic_read(&buffer->record_disabled)"
          ],
          "line": 2933
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&buffer->record_disabled"
          ],
          "line": 2933
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "preempt_disable_notrace",
          "args": [],
          "line": 2931
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define BUF_MAX_DATA_SIZE (BUF_PAGE_SIZE - (sizeof(u32) * 2))\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstruct ring_buffer_event *\nring_buffer_lock_reserve(struct ring_buffer *buffer, unsigned long length)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct ring_buffer_event *event;\n\tint cpu;\n\n\t/* If we are tracing schedule, we don't want to recurse */\n\tpreempt_disable_notrace();\n\n\tif (unlikely(atomic_read(&buffer->record_disabled)))\n\t\tgoto out;\n\n\tcpu = raw_smp_processor_id();\n\n\tif (unlikely(!cpumask_test_cpu(cpu, buffer->cpumask)))\n\t\tgoto out;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\n\tif (unlikely(atomic_read(&cpu_buffer->record_disabled)))\n\t\tgoto out;\n\n\tif (unlikely(length > BUF_MAX_DATA_SIZE))\n\t\tgoto out;\n\n\tif (unlikely(trace_recursive_lock(cpu_buffer)))\n\t\tgoto out;\n\n\tevent = rb_reserve_next_event(buffer, cpu_buffer, length);\n\tif (!event)\n\t\tgoto out_unlock;\n\n\treturn event;\n\n out_unlock:\n\ttrace_recursive_unlock(cpu_buffer);\n out:\n\tpreempt_enable_notrace();\n\treturn NULL;\n}"
  },
  {
    "function_name": "rb_reserve_next_event",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2830-2906",
    "snippet": "ring_buffer_event *\nrb_reserve_next_event(struct ring_buffer *buffer,\n\t\t      struct ring_buffer_per_cpu *cpu_buffer,\n\t\t      unsigned long length)\n{\n\tstruct ring_buffer_event *event;\n\tstruct rb_event_info info;\n\tint nr_loops = 0;\n\tu64 diff;\n\n\trb_start_commit(cpu_buffer);\n\n#ifdef CONFIG_RING_BUFFER_ALLOW_SWAP\n\t/*\n\t * Due to the ability to swap a cpu buffer from a buffer\n\t * it is possible it was swapped before we committed.\n\t * (committing stops a swap). We check for it here and\n\t * if it happened, we have to fail the write.\n\t */\n\tbarrier();\n\tif (unlikely(READ_ONCE(cpu_buffer->buffer) != buffer)) {\n\t\tlocal_dec(&cpu_buffer->committing);\n\t\tlocal_dec(&cpu_buffer->commits);\n\t\treturn NULL;\n\t}\n#endif\n\n\tinfo.length = rb_calculate_event_length(length);\n again:\n\tinfo.add_timestamp = 0;\n\tinfo.delta = 0;\n\n\t/*\n\t * We allow for interrupts to reenter here and do a trace.\n\t * If one does, it will cause this original code to loop\n\t * back here. Even with heavy interrupts happening, this\n\t * should only happen a few times in a row. If this happens\n\t * 1000 times in a row, there must be either an interrupt\n\t * storm or we have something buggy.\n\t * Bail!\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 1000))\n\t\tgoto out_fail;\n\n\tinfo.ts = rb_time_stamp(cpu_buffer->buffer);\n\tdiff = info.ts - cpu_buffer->write_stamp;\n\n\t/* make sure this diff is calculated here */\n\tbarrier();\n\n\tif (ring_buffer_time_stamp_abs(buffer)) {\n\t\tinfo.delta = info.ts;\n\t\trb_handle_timestamp(cpu_buffer, &info);\n\t} else /* Did the write stamp get updated already? */\n\t\tif (likely(info.ts >= cpu_buffer->write_stamp)) {\n\t\tinfo.delta = diff;\n\t\tif (unlikely(test_time_stamp(info.delta)))\n\t\t\trb_handle_timestamp(cpu_buffer, &info);\n\t}\n\n\tevent = __rb_reserve_next(cpu_buffer, &info);\n\n\tif (unlikely(PTR_ERR(event) == -EAGAIN)) {\n\t\tif (info.add_timestamp)\n\t\t\tinfo.length -= RB_LEN_TIME_EXTEND;\n\t\tgoto again;\n\t}\n\n\tif (!event)\n\t\tgoto out_fail;\n\n\treturn event;\n\n out_fail:\n\trb_end_commit(cpu_buffer);\n\treturn NULL;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_end_commit",
          "args": [
            "cpu_buffer"
          ],
          "line": 2904
        },
        "resolved": true,
        "details": {
          "function_name": "rb_end_commit",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2490-2520",
          "snippet": "static __always_inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tunsigned long commits;\n\n\tif (RB_WARN_ON(cpu_buffer,\n\t\t       !local_read(&cpu_buffer->committing)))\n\t\treturn;\n\n again:\n\tcommits = local_read(&cpu_buffer->commits);\n\t/* synchronize with interrupts */\n\tbarrier();\n\tif (local_read(&cpu_buffer->committing) == 1)\n\t\trb_set_commit_to_write(cpu_buffer);\n\n\tlocal_dec(&cpu_buffer->committing);\n\n\t/* synchronize with interrupts */\n\tbarrier();\n\n\t/*\n\t * Need to account for interrupts coming in between the\n\t * updating of the commit page and the clearing of the\n\t * committing counter.\n\t */\n\tif (unlikely(local_read(&cpu_buffer->commits) != commits) &&\n\t    !local_read(&cpu_buffer->committing)) {\n\t\tlocal_inc(&cpu_buffer->committing);\n\t\tgoto again;\n\t}\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tunsigned long commits;\n\n\tif (RB_WARN_ON(cpu_buffer,\n\t\t       !local_read(&cpu_buffer->committing)))\n\t\treturn;\n\n again:\n\tcommits = local_read(&cpu_buffer->commits);\n\t/* synchronize with interrupts */\n\tbarrier();\n\tif (local_read(&cpu_buffer->committing) == 1)\n\t\trb_set_commit_to_write(cpu_buffer);\n\n\tlocal_dec(&cpu_buffer->committing);\n\n\t/* synchronize with interrupts */\n\tbarrier();\n\n\t/*\n\t * Need to account for interrupts coming in between the\n\t * updating of the commit page and the clearing of the\n\t * committing counter.\n\t */\n\tif (unlikely(local_read(&cpu_buffer->commits) != commits) &&\n\t    !local_read(&cpu_buffer->committing)) {\n\t\tlocal_inc(&cpu_buffer->committing);\n\t\tgoto again;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "PTR_ERR(event) == -EAGAIN"
          ],
          "line": 2892
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "PTR_ERR",
          "args": [
            "event"
          ],
          "line": 2892
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__rb_reserve_next",
          "args": [
            "cpu_buffer",
            "&info"
          ],
          "line": 2890
        },
        "resolved": true,
        "details": {
          "function_name": "__rb_reserve_next",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2775-2828",
          "snippet": "static struct ring_buffer_event *\n__rb_reserve_next(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t  struct rb_event_info *info)\n{\n\tstruct ring_buffer_event *event;\n\tstruct buffer_page *tail_page;\n\tunsigned long tail, write;\n\n\t/*\n\t * If the time delta since the last event is too big to\n\t * hold in the time field of the event, then we append a\n\t * TIME EXTEND event ahead of the data event.\n\t */\n\tif (unlikely(info->add_timestamp))\n\t\tinfo->length += RB_LEN_TIME_EXTEND;\n\n\t/* Don't let the compiler play games with cpu_buffer->tail_page */\n\ttail_page = info->tail_page = READ_ONCE(cpu_buffer->tail_page);\n\twrite = local_add_return(info->length, &tail_page->write);\n\n\t/* set write to only the index of the write */\n\twrite &= RB_WRITE_MASK;\n\ttail = write - info->length;\n\n\t/*\n\t * If this is the first commit on the page, then it has the same\n\t * timestamp as the page itself.\n\t */\n\tif (!tail && !ring_buffer_time_stamp_abs(cpu_buffer->buffer))\n\t\tinfo->delta = 0;\n\n\t/* See if we shot pass the end of this buffer page */\n\tif (unlikely(write > BUF_PAGE_SIZE))\n\t\treturn rb_move_tail(cpu_buffer, tail, info);\n\n\t/* We reserved something on the buffer */\n\n\tevent = __rb_page_index(tail_page, tail);\n\trb_update_event(cpu_buffer, event, info);\n\n\tlocal_inc(&tail_page->entries);\n\n\t/*\n\t * If this is the first commit on the page, then update\n\t * its timestamp.\n\t */\n\tif (!tail)\n\t\ttail_page->page->time_stamp = info->ts;\n\n\t/* account for these added bytes */\n\tlocal_add(info->length, &cpu_buffer->entries_bytes);\n\n\treturn event;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)",
            "#define RB_WRITE_MASK\t\t0xfffff"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)\n#define RB_WRITE_MASK\t\t0xfffff\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic struct ring_buffer_event *\n__rb_reserve_next(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t  struct rb_event_info *info)\n{\n\tstruct ring_buffer_event *event;\n\tstruct buffer_page *tail_page;\n\tunsigned long tail, write;\n\n\t/*\n\t * If the time delta since the last event is too big to\n\t * hold in the time field of the event, then we append a\n\t * TIME EXTEND event ahead of the data event.\n\t */\n\tif (unlikely(info->add_timestamp))\n\t\tinfo->length += RB_LEN_TIME_EXTEND;\n\n\t/* Don't let the compiler play games with cpu_buffer->tail_page */\n\ttail_page = info->tail_page = READ_ONCE(cpu_buffer->tail_page);\n\twrite = local_add_return(info->length, &tail_page->write);\n\n\t/* set write to only the index of the write */\n\twrite &= RB_WRITE_MASK;\n\ttail = write - info->length;\n\n\t/*\n\t * If this is the first commit on the page, then it has the same\n\t * timestamp as the page itself.\n\t */\n\tif (!tail && !ring_buffer_time_stamp_abs(cpu_buffer->buffer))\n\t\tinfo->delta = 0;\n\n\t/* See if we shot pass the end of this buffer page */\n\tif (unlikely(write > BUF_PAGE_SIZE))\n\t\treturn rb_move_tail(cpu_buffer, tail, info);\n\n\t/* We reserved something on the buffer */\n\n\tevent = __rb_page_index(tail_page, tail);\n\trb_update_event(cpu_buffer, event, info);\n\n\tlocal_inc(&tail_page->entries);\n\n\t/*\n\t * If this is the first commit on the page, then update\n\t * its timestamp.\n\t */\n\tif (!tail)\n\t\ttail_page->page->time_stamp = info->ts;\n\n\t/* account for these added bytes */\n\tlocal_add(info->length, &cpu_buffer->entries_bytes);\n\n\treturn event;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_handle_timestamp",
          "args": [
            "cpu_buffer",
            "&info"
          ],
          "line": 2887
        },
        "resolved": true,
        "details": {
          "function_name": "rb_handle_timestamp",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2758-2773",
          "snippet": "static noinline void\nrb_handle_timestamp(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t    struct rb_event_info *info)\n{\n\tWARN_ONCE(info->delta > (1ULL << 59),\n\t\t  KERN_WARNING \"Delta way too big! %llu ts=%llu write stamp = %llu\\n%s\",\n\t\t  (unsigned long long)info->delta,\n\t\t  (unsigned long long)info->ts,\n\t\t  (unsigned long long)cpu_buffer->write_stamp,\n\t\t  sched_clock_stable() ? \"\" :\n\t\t  \"If you just came from a suspend/resume,\\n\"\n\t\t  \"please switch to the trace global clock:\\n\"\n\t\t  \"  echo global > /sys/kernel/debug/tracing/trace_clock\\n\"\n\t\t  \"or add trace_clock=global to the kernel command line\\n\");\n\tinfo->add_timestamp = 1;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic noinline void\nrb_handle_timestamp(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t    struct rb_event_info *info)\n{\n\tWARN_ONCE(info->delta > (1ULL << 59),\n\t\t  KERN_WARNING \"Delta way too big! %llu ts=%llu write stamp = %llu\\n%s\",\n\t\t  (unsigned long long)info->delta,\n\t\t  (unsigned long long)info->ts,\n\t\t  (unsigned long long)cpu_buffer->write_stamp,\n\t\t  sched_clock_stable() ? \"\" :\n\t\t  \"If you just came from a suspend/resume,\\n\"\n\t\t  \"please switch to the trace global clock:\\n\"\n\t\t  \"  echo global > /sys/kernel/debug/tracing/trace_clock\\n\"\n\t\t  \"or add trace_clock=global to the kernel command line\\n\");\n\tinfo->add_timestamp = 1;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "test_time_stamp(info.delta)"
          ],
          "line": 2886
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "test_time_stamp",
          "args": [
            "info.delta"
          ],
          "line": 2886
        },
        "resolved": true,
        "details": {
          "function_name": "test_time_stamp",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "383-388",
          "snippet": "static inline int test_time_stamp(u64 delta)\n{\n\tif (delta & TS_DELTA_TEST)\n\t\treturn 1;\n\treturn 0;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define TS_DELTA_TEST\t(~TS_MASK)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define TS_DELTA_TEST\t(~TS_MASK)\n\nstatic inline int test_time_stamp(u64 delta)\n{\n\tif (delta & TS_DELTA_TEST)\n\t\treturn 1;\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "info.ts >= cpu_buffer->write_stamp"
          ],
          "line": 2884
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ring_buffer_time_stamp_abs",
          "args": [
            "buffer"
          ],
          "line": 2880
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_time_stamp_abs",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1452-1455",
          "snippet": "bool ring_buffer_time_stamp_abs(struct ring_buffer *buffer)\n{\n\treturn buffer->time_stamp_abs;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nbool ring_buffer_time_stamp_abs(struct ring_buffer *buffer)\n{\n\treturn buffer->time_stamp_abs;\n}"
        }
      },
      {
        "call_info": {
          "callee": "barrier",
          "args": [],
          "line": 2878
        },
        "resolved": true,
        "details": {
          "function_name": "membarrier_register_global_expedited",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/membarrier.c",
          "lines": "189-219",
          "snippet": "static int membarrier_register_global_expedited(void)\n{\n\tstruct task_struct *p = current;\n\tstruct mm_struct *mm = p->mm;\n\n\tif (atomic_read(&mm->membarrier_state) &\n\t    MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY)\n\t\treturn 0;\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED, &mm->membarrier_state);\n\tif (atomic_read(&mm->mm_users) == 1 && get_nr_threads(p) == 1) {\n\t\t/*\n\t\t * For single mm user, single threaded process, we can\n\t\t * simply issue a memory barrier after setting\n\t\t * MEMBARRIER_STATE_GLOBAL_EXPEDITED to guarantee that\n\t\t * no memory access following registration is reordered\n\t\t * before registration.\n\t\t */\n\t\tsmp_mb();\n\t} else {\n\t\t/*\n\t\t * For multi-mm user threads, we need to ensure all\n\t\t * future scheduler executions will observe the new\n\t\t * thread flag state for this mm.\n\t\t */\n\t\tsynchronize_sched();\n\t}\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY,\n\t\t  &mm->membarrier_state);\n\n\treturn 0;\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nstatic int membarrier_register_global_expedited(void)\n{\n\tstruct task_struct *p = current;\n\tstruct mm_struct *mm = p->mm;\n\n\tif (atomic_read(&mm->membarrier_state) &\n\t    MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY)\n\t\treturn 0;\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED, &mm->membarrier_state);\n\tif (atomic_read(&mm->mm_users) == 1 && get_nr_threads(p) == 1) {\n\t\t/*\n\t\t * For single mm user, single threaded process, we can\n\t\t * simply issue a memory barrier after setting\n\t\t * MEMBARRIER_STATE_GLOBAL_EXPEDITED to guarantee that\n\t\t * no memory access following registration is reordered\n\t\t * before registration.\n\t\t */\n\t\tsmp_mb();\n\t} else {\n\t\t/*\n\t\t * For multi-mm user threads, we need to ensure all\n\t\t * future scheduler executions will observe the new\n\t\t * thread flag state for this mm.\n\t\t */\n\t\tsynchronize_sched();\n\t}\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY,\n\t\t  &mm->membarrier_state);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_time_stamp",
          "args": [
            "cpu_buffer->buffer"
          ],
          "line": 2874
        },
        "resolved": true,
        "details": {
          "function_name": "rb_time_stamp",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "721-725",
          "snippet": "static inline u64 rb_time_stamp(struct ring_buffer *buffer)\n{\n\t/* shift to debug/test normalization and TIME_EXTENTS */\n\treturn buffer->clock() << DEBUG_SHIFT;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define DEBUG_SHIFT 0"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define DEBUG_SHIFT 0\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline u64 rb_time_stamp(struct ring_buffer *buffer)\n{\n\t/* shift to debug/test normalization and TIME_EXTENTS */\n\treturn buffer->clock() << DEBUG_SHIFT;\n}"
        }
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "++nr_loops > 1000"
          ],
          "line": 2871
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_calculate_event_length",
          "args": [
            "length"
          ],
          "line": 2857
        },
        "resolved": true,
        "details": {
          "function_name": "rb_calculate_event_length",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2350-2380",
          "snippet": "static unsigned rb_calculate_event_length(unsigned length)\n{\n\tstruct ring_buffer_event event; /* Used only for sizeof array */\n\n\t/* zero length can cause confusions */\n\tif (!length)\n\t\tlength++;\n\n\tif (length > RB_MAX_SMALL_DATA || RB_FORCE_8BYTE_ALIGNMENT)\n\t\tlength += sizeof(event.array[0]);\n\n\tlength += RB_EVNT_HDR_SIZE;\n\tlength = ALIGN(length, RB_ARCH_ALIGNMENT);\n\n\t/*\n\t * In case the time delta is larger than the 27 bits for it\n\t * in the header, we need to add a timestamp. If another\n\t * event comes in when trying to discard this one to increase\n\t * the length, then the timestamp will be added in the allocated\n\t * space of this event. If length is bigger than the size needed\n\t * for the TIME_EXTEND, then padding has to be used. The events\n\t * length must be either RB_LEN_TIME_EXTEND, or greater than or equal\n\t * to RB_LEN_TIME_EXTEND + 8, as 8 is the minimum size for padding.\n\t * As length is a multiple of 4, we only need to worry if it\n\t * is 12 (RB_LEN_TIME_EXTEND + 4).\n\t */\n\tif (length == RB_LEN_TIME_EXTEND + RB_ALIGNMENT)\n\t\tlength += RB_ALIGNMENT;\n\n\treturn length;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_MAX_SMALL_DATA\t(RB_ALIGNMENT * RINGBUF_TYPE_DATA_TYPE_LEN_MAX)",
            "#define RB_ALIGNMENT\t\t4U",
            "#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_MAX_SMALL_DATA\t(RB_ALIGNMENT * RINGBUF_TYPE_DATA_TYPE_LEN_MAX)\n#define RB_ALIGNMENT\t\t4U\n#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic unsigned rb_calculate_event_length(unsigned length)\n{\n\tstruct ring_buffer_event event; /* Used only for sizeof array */\n\n\t/* zero length can cause confusions */\n\tif (!length)\n\t\tlength++;\n\n\tif (length > RB_MAX_SMALL_DATA || RB_FORCE_8BYTE_ALIGNMENT)\n\t\tlength += sizeof(event.array[0]);\n\n\tlength += RB_EVNT_HDR_SIZE;\n\tlength = ALIGN(length, RB_ARCH_ALIGNMENT);\n\n\t/*\n\t * In case the time delta is larger than the 27 bits for it\n\t * in the header, we need to add a timestamp. If another\n\t * event comes in when trying to discard this one to increase\n\t * the length, then the timestamp will be added in the allocated\n\t * space of this event. If length is bigger than the size needed\n\t * for the TIME_EXTEND, then padding has to be used. The events\n\t * length must be either RB_LEN_TIME_EXTEND, or greater than or equal\n\t * to RB_LEN_TIME_EXTEND + 8, as 8 is the minimum size for padding.\n\t * As length is a multiple of 4, we only need to worry if it\n\t * is 12 (RB_LEN_TIME_EXTEND + 4).\n\t */\n\tif (length == RB_LEN_TIME_EXTEND + RB_ALIGNMENT)\n\t\tlength += RB_ALIGNMENT;\n\n\treturn length;\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_dec",
          "args": [
            "&cpu_buffer->commits"
          ],
          "line": 2852
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_dec",
          "args": [
            "&cpu_buffer->committing"
          ],
          "line": 2851
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "READ_ONCE(cpu_buffer->buffer) != buffer"
          ],
          "line": 2850
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "cpu_buffer->buffer"
          ],
          "line": 2850
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_start_commit",
          "args": [
            "cpu_buffer"
          ],
          "line": 2840
        },
        "resolved": true,
        "details": {
          "function_name": "rb_start_commit",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2429-2433",
          "snippet": "static void rb_start_commit(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tlocal_inc(&cpu_buffer->committing);\n\tlocal_inc(&cpu_buffer->commits);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_start_commit(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tlocal_inc(&cpu_buffer->committing);\n\tlocal_inc(&cpu_buffer->commits);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nring_buffer_event *\nrb_reserve_next_event(struct ring_buffer *buffer,\n\t\t      struct ring_buffer_per_cpu *cpu_buffer,\n\t\t      unsigned long length)\n{\n\tstruct ring_buffer_event *event;\n\tstruct rb_event_info info;\n\tint nr_loops = 0;\n\tu64 diff;\n\n\trb_start_commit(cpu_buffer);\n\n#ifdef CONFIG_RING_BUFFER_ALLOW_SWAP\n\t/*\n\t * Due to the ability to swap a cpu buffer from a buffer\n\t * it is possible it was swapped before we committed.\n\t * (committing stops a swap). We check for it here and\n\t * if it happened, we have to fail the write.\n\t */\n\tbarrier();\n\tif (unlikely(READ_ONCE(cpu_buffer->buffer) != buffer)) {\n\t\tlocal_dec(&cpu_buffer->committing);\n\t\tlocal_dec(&cpu_buffer->commits);\n\t\treturn NULL;\n\t}\n#endif\n\n\tinfo.length = rb_calculate_event_length(length);\n again:\n\tinfo.add_timestamp = 0;\n\tinfo.delta = 0;\n\n\t/*\n\t * We allow for interrupts to reenter here and do a trace.\n\t * If one does, it will cause this original code to loop\n\t * back here. Even with heavy interrupts happening, this\n\t * should only happen a few times in a row. If this happens\n\t * 1000 times in a row, there must be either an interrupt\n\t * storm or we have something buggy.\n\t * Bail!\n\t */\n\tif (RB_WARN_ON(cpu_buffer, ++nr_loops > 1000))\n\t\tgoto out_fail;\n\n\tinfo.ts = rb_time_stamp(cpu_buffer->buffer);\n\tdiff = info.ts - cpu_buffer->write_stamp;\n\n\t/* make sure this diff is calculated here */\n\tbarrier();\n\n\tif (ring_buffer_time_stamp_abs(buffer)) {\n\t\tinfo.delta = info.ts;\n\t\trb_handle_timestamp(cpu_buffer, &info);\n\t} else /* Did the write stamp get updated already? */\n\t\tif (likely(info.ts >= cpu_buffer->write_stamp)) {\n\t\tinfo.delta = diff;\n\t\tif (unlikely(test_time_stamp(info.delta)))\n\t\t\trb_handle_timestamp(cpu_buffer, &info);\n\t}\n\n\tevent = __rb_reserve_next(cpu_buffer, &info);\n\n\tif (unlikely(PTR_ERR(event) == -EAGAIN)) {\n\t\tif (info.add_timestamp)\n\t\t\tinfo.length -= RB_LEN_TIME_EXTEND;\n\t\tgoto again;\n\t}\n\n\tif (!event)\n\t\tgoto out_fail;\n\n\treturn event;\n\n out_fail:\n\trb_end_commit(cpu_buffer);\n\treturn NULL;\n}"
  },
  {
    "function_name": "__rb_reserve_next",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2775-2828",
    "snippet": "static struct ring_buffer_event *\n__rb_reserve_next(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t  struct rb_event_info *info)\n{\n\tstruct ring_buffer_event *event;\n\tstruct buffer_page *tail_page;\n\tunsigned long tail, write;\n\n\t/*\n\t * If the time delta since the last event is too big to\n\t * hold in the time field of the event, then we append a\n\t * TIME EXTEND event ahead of the data event.\n\t */\n\tif (unlikely(info->add_timestamp))\n\t\tinfo->length += RB_LEN_TIME_EXTEND;\n\n\t/* Don't let the compiler play games with cpu_buffer->tail_page */\n\ttail_page = info->tail_page = READ_ONCE(cpu_buffer->tail_page);\n\twrite = local_add_return(info->length, &tail_page->write);\n\n\t/* set write to only the index of the write */\n\twrite &= RB_WRITE_MASK;\n\ttail = write - info->length;\n\n\t/*\n\t * If this is the first commit on the page, then it has the same\n\t * timestamp as the page itself.\n\t */\n\tif (!tail && !ring_buffer_time_stamp_abs(cpu_buffer->buffer))\n\t\tinfo->delta = 0;\n\n\t/* See if we shot pass the end of this buffer page */\n\tif (unlikely(write > BUF_PAGE_SIZE))\n\t\treturn rb_move_tail(cpu_buffer, tail, info);\n\n\t/* We reserved something on the buffer */\n\n\tevent = __rb_page_index(tail_page, tail);\n\trb_update_event(cpu_buffer, event, info);\n\n\tlocal_inc(&tail_page->entries);\n\n\t/*\n\t * If this is the first commit on the page, then update\n\t * its timestamp.\n\t */\n\tif (!tail)\n\t\ttail_page->page->time_stamp = info->ts;\n\n\t/* account for these added bytes */\n\tlocal_add(info->length, &cpu_buffer->entries_bytes);\n\n\treturn event;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)",
      "#define RB_WRITE_MASK\t\t0xfffff"
    ],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_add",
          "args": [
            "info->length",
            "&cpu_buffer->entries_bytes"
          ],
          "line": 2825
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_inc",
          "args": [
            "&tail_page->entries"
          ],
          "line": 2815
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_update_event",
          "args": [
            "cpu_buffer",
            "event",
            "info"
          ],
          "line": 2813
        },
        "resolved": true,
        "details": {
          "function_name": "rb_update_event",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2317-2348",
          "snippet": "static void\nrb_update_event(struct ring_buffer_per_cpu *cpu_buffer,\n\t\tstruct ring_buffer_event *event,\n\t\tstruct rb_event_info *info)\n{\n\tunsigned length = info->length;\n\tu64 delta = info->delta;\n\n\t/* Only a commit updates the timestamp */\n\tif (unlikely(!rb_event_is_commit(cpu_buffer, event)))\n\t\tdelta = 0;\n\n\t/*\n\t * If we need to add a timestamp, then we\n\t * add it to the start of the reserved space.\n\t */\n\tif (unlikely(info->add_timestamp)) {\n\t\tbool abs = ring_buffer_time_stamp_abs(cpu_buffer->buffer);\n\n\t\tevent = rb_add_time_stamp(event, info->delta, abs);\n\t\tlength -= RB_LEN_TIME_EXTEND;\n\t\tdelta = 0;\n\t}\n\n\tevent->time_delta = delta;\n\tlength -= RB_EVNT_HDR_SIZE;\n\tif (length > RB_MAX_SMALL_DATA || RB_FORCE_8BYTE_ALIGNMENT) {\n\t\tevent->type_len = 0;\n\t\tevent->array[0] = length;\n\t} else\n\t\tevent->type_len = DIV_ROUND_UP(length, RB_ALIGNMENT);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_MAX_SMALL_DATA\t(RB_ALIGNMENT * RINGBUF_TYPE_DATA_TYPE_LEN_MAX)",
            "#define RB_ALIGNMENT\t\t4U",
            "#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_MAX_SMALL_DATA\t(RB_ALIGNMENT * RINGBUF_TYPE_DATA_TYPE_LEN_MAX)\n#define RB_ALIGNMENT\t\t4U\n#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic void\nrb_update_event(struct ring_buffer_per_cpu *cpu_buffer,\n\t\tstruct ring_buffer_event *event,\n\t\tstruct rb_event_info *info)\n{\n\tunsigned length = info->length;\n\tu64 delta = info->delta;\n\n\t/* Only a commit updates the timestamp */\n\tif (unlikely(!rb_event_is_commit(cpu_buffer, event)))\n\t\tdelta = 0;\n\n\t/*\n\t * If we need to add a timestamp, then we\n\t * add it to the start of the reserved space.\n\t */\n\tif (unlikely(info->add_timestamp)) {\n\t\tbool abs = ring_buffer_time_stamp_abs(cpu_buffer->buffer);\n\n\t\tevent = rb_add_time_stamp(event, info->delta, abs);\n\t\tlength -= RB_LEN_TIME_EXTEND;\n\t\tdelta = 0;\n\t}\n\n\tevent->time_delta = delta;\n\tlength -= RB_EVNT_HDR_SIZE;\n\tif (length > RB_MAX_SMALL_DATA || RB_FORCE_8BYTE_ALIGNMENT) {\n\t\tevent->type_len = 0;\n\t\tevent->array[0] = length;\n\t} else\n\t\tevent->type_len = DIV_ROUND_UP(length, RB_ALIGNMENT);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__rb_page_index",
          "args": [
            "tail_page",
            "tail"
          ],
          "line": 2812
        },
        "resolved": true,
        "details": {
          "function_name": "__rb_page_index",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1880-1883",
          "snippet": "static __always_inline void *__rb_page_index(struct buffer_page *bpage, unsigned index)\n{\n\treturn bpage->page->data + index;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline void *__rb_page_index(struct buffer_page *bpage, unsigned index)\n{\n\treturn bpage->page->data + index;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_move_tail",
          "args": [
            "cpu_buffer",
            "tail",
            "info"
          ],
          "line": 2808
        },
        "resolved": true,
        "details": {
          "function_name": "rb_move_tail",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2178-2279",
          "snippet": "ring_buffer_event *\nrb_move_tail(struct ring_buffer_per_cpu *cpu_buffer,\n\t     unsigned long tail, struct rb_event_info *info)\n{\n\tstruct buffer_page *tail_page = info->tail_page;\n\tstruct buffer_page *commit_page = cpu_buffer->commit_page;\n\tstruct ring_buffer *buffer = cpu_buffer->buffer;\n\tstruct buffer_page *next_page;\n\tint ret;\n\n\tnext_page = tail_page;\n\n\trb_inc_page(cpu_buffer, &next_page);\n\n\t/*\n\t * If for some reason, we had an interrupt storm that made\n\t * it all the way around the buffer, bail, and warn\n\t * about it.\n\t */\n\tif (unlikely(next_page == commit_page)) {\n\t\tlocal_inc(&cpu_buffer->commit_overrun);\n\t\tgoto out_reset;\n\t}\n\n\t/*\n\t * This is where the fun begins!\n\t *\n\t * We are fighting against races between a reader that\n\t * could be on another CPU trying to swap its reader\n\t * page with the buffer head.\n\t *\n\t * We are also fighting against interrupts coming in and\n\t * moving the head or tail on us as well.\n\t *\n\t * If the next page is the head page then we have filled\n\t * the buffer, unless the commit page is still on the\n\t * reader page.\n\t */\n\tif (rb_is_head_page(cpu_buffer, next_page, &tail_page->list)) {\n\n\t\t/*\n\t\t * If the commit is not on the reader page, then\n\t\t * move the header page.\n\t\t */\n\t\tif (!rb_is_reader_page(cpu_buffer->commit_page)) {\n\t\t\t/*\n\t\t\t * If we are not in overwrite mode,\n\t\t\t * this is easy, just stop here.\n\t\t\t */\n\t\t\tif (!(buffer->flags & RB_FL_OVERWRITE)) {\n\t\t\t\tlocal_inc(&cpu_buffer->dropped_events);\n\t\t\t\tgoto out_reset;\n\t\t\t}\n\n\t\t\tret = rb_handle_head_page(cpu_buffer,\n\t\t\t\t\t\t  tail_page,\n\t\t\t\t\t\t  next_page);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out_reset;\n\t\t\tif (ret)\n\t\t\t\tgoto out_again;\n\t\t} else {\n\t\t\t/*\n\t\t\t * We need to be careful here too. The\n\t\t\t * commit page could still be on the reader\n\t\t\t * page. We could have a small buffer, and\n\t\t\t * have filled up the buffer with events\n\t\t\t * from interrupts and such, and wrapped.\n\t\t\t *\n\t\t\t * Note, if the tail page is also the on the\n\t\t\t * reader_page, we let it move out.\n\t\t\t */\n\t\t\tif (unlikely((cpu_buffer->commit_page !=\n\t\t\t\t      cpu_buffer->tail_page) &&\n\t\t\t\t     (cpu_buffer->commit_page ==\n\t\t\t\t      cpu_buffer->reader_page))) {\n\t\t\t\tlocal_inc(&cpu_buffer->commit_overrun);\n\t\t\t\tgoto out_reset;\n\t\t\t}\n\t\t}\n\t}\n\n\trb_tail_page_update(cpu_buffer, tail_page, next_page);\n\n out_again:\n\n\trb_reset_tail(cpu_buffer, tail, info);\n\n\t/* Commit what we have for now. */\n\trb_end_commit(cpu_buffer);\n\t/* rb_end_commit() decs committing */\n\tlocal_inc(&cpu_buffer->committing);\n\n\t/* fail and let the caller try again */\n\treturn ERR_PTR(-EAGAIN);\n\n out_reset:\n\t/* reset write */\n\trb_reset_tail(cpu_buffer, tail, info);\n\n\treturn NULL;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nring_buffer_event *\nrb_move_tail(struct ring_buffer_per_cpu *cpu_buffer,\n\t     unsigned long tail, struct rb_event_info *info)\n{\n\tstruct buffer_page *tail_page = info->tail_page;\n\tstruct buffer_page *commit_page = cpu_buffer->commit_page;\n\tstruct ring_buffer *buffer = cpu_buffer->buffer;\n\tstruct buffer_page *next_page;\n\tint ret;\n\n\tnext_page = tail_page;\n\n\trb_inc_page(cpu_buffer, &next_page);\n\n\t/*\n\t * If for some reason, we had an interrupt storm that made\n\t * it all the way around the buffer, bail, and warn\n\t * about it.\n\t */\n\tif (unlikely(next_page == commit_page)) {\n\t\tlocal_inc(&cpu_buffer->commit_overrun);\n\t\tgoto out_reset;\n\t}\n\n\t/*\n\t * This is where the fun begins!\n\t *\n\t * We are fighting against races between a reader that\n\t * could be on another CPU trying to swap its reader\n\t * page with the buffer head.\n\t *\n\t * We are also fighting against interrupts coming in and\n\t * moving the head or tail on us as well.\n\t *\n\t * If the next page is the head page then we have filled\n\t * the buffer, unless the commit page is still on the\n\t * reader page.\n\t */\n\tif (rb_is_head_page(cpu_buffer, next_page, &tail_page->list)) {\n\n\t\t/*\n\t\t * If the commit is not on the reader page, then\n\t\t * move the header page.\n\t\t */\n\t\tif (!rb_is_reader_page(cpu_buffer->commit_page)) {\n\t\t\t/*\n\t\t\t * If we are not in overwrite mode,\n\t\t\t * this is easy, just stop here.\n\t\t\t */\n\t\t\tif (!(buffer->flags & RB_FL_OVERWRITE)) {\n\t\t\t\tlocal_inc(&cpu_buffer->dropped_events);\n\t\t\t\tgoto out_reset;\n\t\t\t}\n\n\t\t\tret = rb_handle_head_page(cpu_buffer,\n\t\t\t\t\t\t  tail_page,\n\t\t\t\t\t\t  next_page);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out_reset;\n\t\t\tif (ret)\n\t\t\t\tgoto out_again;\n\t\t} else {\n\t\t\t/*\n\t\t\t * We need to be careful here too. The\n\t\t\t * commit page could still be on the reader\n\t\t\t * page. We could have a small buffer, and\n\t\t\t * have filled up the buffer with events\n\t\t\t * from interrupts and such, and wrapped.\n\t\t\t *\n\t\t\t * Note, if the tail page is also the on the\n\t\t\t * reader_page, we let it move out.\n\t\t\t */\n\t\t\tif (unlikely((cpu_buffer->commit_page !=\n\t\t\t\t      cpu_buffer->tail_page) &&\n\t\t\t\t     (cpu_buffer->commit_page ==\n\t\t\t\t      cpu_buffer->reader_page))) {\n\t\t\t\tlocal_inc(&cpu_buffer->commit_overrun);\n\t\t\t\tgoto out_reset;\n\t\t\t}\n\t\t}\n\t}\n\n\trb_tail_page_update(cpu_buffer, tail_page, next_page);\n\n out_again:\n\n\trb_reset_tail(cpu_buffer, tail, info);\n\n\t/* Commit what we have for now. */\n\trb_end_commit(cpu_buffer);\n\t/* rb_end_commit() decs committing */\n\tlocal_inc(&cpu_buffer->committing);\n\n\t/* fail and let the caller try again */\n\treturn ERR_PTR(-EAGAIN);\n\n out_reset:\n\t/* reset write */\n\trb_reset_tail(cpu_buffer, tail, info);\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "write > BUF_PAGE_SIZE"
          ],
          "line": 2807
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ring_buffer_time_stamp_abs",
          "args": [
            "cpu_buffer->buffer"
          ],
          "line": 2803
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_time_stamp_abs",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1452-1455",
          "snippet": "bool ring_buffer_time_stamp_abs(struct ring_buffer *buffer)\n{\n\treturn buffer->time_stamp_abs;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nbool ring_buffer_time_stamp_abs(struct ring_buffer *buffer)\n{\n\treturn buffer->time_stamp_abs;\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_add_return",
          "args": [
            "info->length",
            "&tail_page->write"
          ],
          "line": 2793
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "cpu_buffer->tail_page"
          ],
          "line": 2792
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "info->add_timestamp"
          ],
          "line": 2788
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)\n#define RB_WRITE_MASK\t\t0xfffff\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic struct ring_buffer_event *\n__rb_reserve_next(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t  struct rb_event_info *info)\n{\n\tstruct ring_buffer_event *event;\n\tstruct buffer_page *tail_page;\n\tunsigned long tail, write;\n\n\t/*\n\t * If the time delta since the last event is too big to\n\t * hold in the time field of the event, then we append a\n\t * TIME EXTEND event ahead of the data event.\n\t */\n\tif (unlikely(info->add_timestamp))\n\t\tinfo->length += RB_LEN_TIME_EXTEND;\n\n\t/* Don't let the compiler play games with cpu_buffer->tail_page */\n\ttail_page = info->tail_page = READ_ONCE(cpu_buffer->tail_page);\n\twrite = local_add_return(info->length, &tail_page->write);\n\n\t/* set write to only the index of the write */\n\twrite &= RB_WRITE_MASK;\n\ttail = write - info->length;\n\n\t/*\n\t * If this is the first commit on the page, then it has the same\n\t * timestamp as the page itself.\n\t */\n\tif (!tail && !ring_buffer_time_stamp_abs(cpu_buffer->buffer))\n\t\tinfo->delta = 0;\n\n\t/* See if we shot pass the end of this buffer page */\n\tif (unlikely(write > BUF_PAGE_SIZE))\n\t\treturn rb_move_tail(cpu_buffer, tail, info);\n\n\t/* We reserved something on the buffer */\n\n\tevent = __rb_page_index(tail_page, tail);\n\trb_update_event(cpu_buffer, event, info);\n\n\tlocal_inc(&tail_page->entries);\n\n\t/*\n\t * If this is the first commit on the page, then update\n\t * its timestamp.\n\t */\n\tif (!tail)\n\t\ttail_page->page->time_stamp = info->ts;\n\n\t/* account for these added bytes */\n\tlocal_add(info->length, &cpu_buffer->entries_bytes);\n\n\treturn event;\n}"
  },
  {
    "function_name": "rb_handle_timestamp",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2758-2773",
    "snippet": "static noinline void\nrb_handle_timestamp(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t    struct rb_event_info *info)\n{\n\tWARN_ONCE(info->delta > (1ULL << 59),\n\t\t  KERN_WARNING \"Delta way too big! %llu ts=%llu write stamp = %llu\\n%s\",\n\t\t  (unsigned long long)info->delta,\n\t\t  (unsigned long long)info->ts,\n\t\t  (unsigned long long)cpu_buffer->write_stamp,\n\t\t  sched_clock_stable() ? \"\" :\n\t\t  \"If you just came from a suspend/resume,\\n\"\n\t\t  \"please switch to the trace global clock:\\n\"\n\t\t  \"  echo global > /sys/kernel/debug/tracing/trace_clock\\n\"\n\t\t  \"or add trace_clock=global to the kernel command line\\n\");\n\tinfo->add_timestamp = 1;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "WARN_ONCE",
          "args": [
            "info->delta > (1ULL << 59)",
            "KERN_WARNING \"Delta way too big! %llu ts=%llu write stamp = %llu\\n%s\"",
            "(unsigned long long)info->delta",
            "(unsigned long long)info->ts",
            "(unsigned long long)cpu_buffer->write_stamp",
            "sched_clock_stable() ? \"\" :\n\t\t  \"If you just came from a suspend/resume,\\n\"\n\t\t  \"please switch to the trace global clock:\\n\"\n\t\t  \"  echo global > /sys/kernel/debug/tracing/trace_clock\\n\"\n\t\t  \"or add trace_clock=global to the kernel command line\\n\""
          ],
          "line": 2762
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sched_clock_stable",
          "args": [],
          "line": 2767
        },
        "resolved": true,
        "details": {
          "function_name": "sched_clock_stable",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2383-2386",
          "snippet": "static inline bool sched_clock_stable(void)\n{\n\treturn true;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic inline bool sched_clock_stable(void)\n{\n\treturn true;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic noinline void\nrb_handle_timestamp(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t    struct rb_event_info *info)\n{\n\tWARN_ONCE(info->delta > (1ULL << 59),\n\t\t  KERN_WARNING \"Delta way too big! %llu ts=%llu write stamp = %llu\\n%s\",\n\t\t  (unsigned long long)info->delta,\n\t\t  (unsigned long long)info->ts,\n\t\t  (unsigned long long)cpu_buffer->write_stamp,\n\t\t  sched_clock_stable() ? \"\" :\n\t\t  \"If you just came from a suspend/resume,\\n\"\n\t\t  \"please switch to the trace global clock:\\n\"\n\t\t  \"  echo global > /sys/kernel/debug/tracing/trace_clock\\n\"\n\t\t  \"or add trace_clock=global to the kernel command line\\n\");\n\tinfo->add_timestamp = 1;\n}"
  },
  {
    "function_name": "ring_buffer_unlock_commit",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2738-2755",
    "snippet": "int ring_buffer_unlock_commit(struct ring_buffer *buffer,\n\t\t\t      struct ring_buffer_event *event)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tint cpu = raw_smp_processor_id();\n\n\tcpu_buffer = buffer->buffers[cpu];\n\n\trb_commit(cpu_buffer, event);\n\n\trb_wakeups(buffer, cpu_buffer);\n\n\ttrace_recursive_unlock(cpu_buffer);\n\n\tpreempt_enable_notrace();\n\n\treturn 0;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "preempt_enable_notrace",
          "args": [],
          "line": 2752
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_recursive_unlock",
          "args": [
            "cpu_buffer"
          ],
          "line": 2750
        },
        "resolved": true,
        "details": {
          "function_name": "trace_recursive_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2673-2678",
          "snippet": "static __always_inline void\ntrace_recursive_unlock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tcpu_buffer->current_context &=\n\t\tcpu_buffer->current_context - (1 << cpu_buffer->nest);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline void\ntrace_recursive_unlock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tcpu_buffer->current_context &=\n\t\tcpu_buffer->current_context - (1 << cpu_buffer->nest);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_wakeups",
          "args": [
            "buffer",
            "cpu_buffer"
          ],
          "line": 2748
        },
        "resolved": true,
        "details": {
          "function_name": "rb_wakeups",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2586-2611",
          "snippet": "static __always_inline void\nrb_wakeups(struct ring_buffer *buffer, struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tbool pagebusy;\n\n\tif (buffer->irq_work.waiters_pending) {\n\t\tbuffer->irq_work.waiters_pending = false;\n\t\t/* irq_work_queue() supplies it's own memory barriers */\n\t\tirq_work_queue(&buffer->irq_work.work);\n\t}\n\n\tif (cpu_buffer->irq_work.waiters_pending) {\n\t\tcpu_buffer->irq_work.waiters_pending = false;\n\t\t/* irq_work_queue() supplies it's own memory barriers */\n\t\tirq_work_queue(&cpu_buffer->irq_work.work);\n\t}\n\n\tpagebusy = cpu_buffer->reader_page == cpu_buffer->commit_page;\n\n\tif (!pagebusy && cpu_buffer->irq_work.full_waiters_pending) {\n\t\tcpu_buffer->irq_work.wakeup_full = true;\n\t\tcpu_buffer->irq_work.full_waiters_pending = false;\n\t\t/* irq_work_queue() supplies it's own memory barriers */\n\t\tirq_work_queue(&cpu_buffer->irq_work.work);\n\t}\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void update_pages_handler(struct work_struct *work);",
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void update_pages_handler(struct work_struct *work);\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline void\nrb_wakeups(struct ring_buffer *buffer, struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tbool pagebusy;\n\n\tif (buffer->irq_work.waiters_pending) {\n\t\tbuffer->irq_work.waiters_pending = false;\n\t\t/* irq_work_queue() supplies it's own memory barriers */\n\t\tirq_work_queue(&buffer->irq_work.work);\n\t}\n\n\tif (cpu_buffer->irq_work.waiters_pending) {\n\t\tcpu_buffer->irq_work.waiters_pending = false;\n\t\t/* irq_work_queue() supplies it's own memory barriers */\n\t\tirq_work_queue(&cpu_buffer->irq_work.work);\n\t}\n\n\tpagebusy = cpu_buffer->reader_page == cpu_buffer->commit_page;\n\n\tif (!pagebusy && cpu_buffer->irq_work.full_waiters_pending) {\n\t\tcpu_buffer->irq_work.wakeup_full = true;\n\t\tcpu_buffer->irq_work.full_waiters_pending = false;\n\t\t/* irq_work_queue() supplies it's own memory barriers */\n\t\tirq_work_queue(&cpu_buffer->irq_work.work);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_commit",
          "args": [
            "cpu_buffer",
            "event"
          ],
          "line": 2746
        },
        "resolved": true,
        "details": {
          "function_name": "rb_commit",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2578-2584",
          "snippet": "static void rb_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t      struct ring_buffer_event *event)\n{\n\tlocal_inc(&cpu_buffer->entries);\n\trb_update_write_stamp(cpu_buffer, event);\n\trb_end_commit(cpu_buffer);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic void rb_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t      struct ring_buffer_event *event)\n{\n\tlocal_inc(&cpu_buffer->entries);\n\trb_update_write_stamp(cpu_buffer, event);\n\trb_end_commit(cpu_buffer);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_smp_processor_id",
          "args": [],
          "line": 2742
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nint ring_buffer_unlock_commit(struct ring_buffer *buffer,\n\t\t\t      struct ring_buffer_event *event)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tint cpu = raw_smp_processor_id();\n\n\tcpu_buffer = buffer->buffers[cpu];\n\n\trb_commit(cpu_buffer, event);\n\n\trb_wakeups(buffer, cpu_buffer);\n\n\ttrace_recursive_unlock(cpu_buffer);\n\n\tpreempt_enable_notrace();\n\n\treturn 0;\n}"
  },
  {
    "function_name": "ring_buffer_nest_end",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2716-2727",
    "snippet": "void ring_buffer_nest_end(struct ring_buffer *buffer)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tint cpu;\n\n\t/* disabled by ring_buffer_nest_start() */\n\tcpu = raw_smp_processor_id();\n\tcpu_buffer = buffer->buffers[cpu];\n\t/* This is the shift value for the above recursive locking */\n\tcpu_buffer->nest -= NESTED_BITS;\n\tpreempt_enable_notrace();\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define NESTED_BITS 4"
    ],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "preempt_enable_notrace",
          "args": [],
          "line": 2726
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_smp_processor_id",
          "args": [],
          "line": 2722
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define NESTED_BITS 4\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid ring_buffer_nest_end(struct ring_buffer *buffer)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tint cpu;\n\n\t/* disabled by ring_buffer_nest_start() */\n\tcpu = raw_smp_processor_id();\n\tcpu_buffer = buffer->buffers[cpu];\n\t/* This is the shift value for the above recursive locking */\n\tcpu_buffer->nest -= NESTED_BITS;\n\tpreempt_enable_notrace();\n}"
  },
  {
    "function_name": "ring_buffer_nest_start",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2696-2707",
    "snippet": "void ring_buffer_nest_start(struct ring_buffer *buffer)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tint cpu;\n\n\t/* Enabled by ring_buffer_nest_end() */\n\tpreempt_disable_notrace();\n\tcpu = raw_smp_processor_id();\n\tcpu_buffer = buffer->buffers[cpu];\n\t/* This is the shift value for the above recursive locking */\n\tcpu_buffer->nest += NESTED_BITS;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define NESTED_BITS 4"
    ],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_smp_processor_id",
          "args": [],
          "line": 2703
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "preempt_disable_notrace",
          "args": [],
          "line": 2702
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define NESTED_BITS 4\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid ring_buffer_nest_start(struct ring_buffer *buffer)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tint cpu;\n\n\t/* Enabled by ring_buffer_nest_end() */\n\tpreempt_disable_notrace();\n\tcpu = raw_smp_processor_id();\n\tcpu_buffer = buffer->buffers[cpu];\n\t/* This is the shift value for the above recursive locking */\n\tcpu_buffer->nest += NESTED_BITS;\n}"
  },
  {
    "function_name": "trace_recursive_unlock",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2673-2678",
    "snippet": "static __always_inline void\ntrace_recursive_unlock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tcpu_buffer->current_context &=\n\t\tcpu_buffer->current_context - (1 << cpu_buffer->nest);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline void\ntrace_recursive_unlock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tcpu_buffer->current_context &=\n\t\tcpu_buffer->current_context - (1 << cpu_buffer->nest);\n}"
  },
  {
    "function_name": "trace_recursive_lock",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2651-2671",
    "snippet": "static __always_inline int\ntrace_recursive_lock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tunsigned int val = cpu_buffer->current_context;\n\tunsigned long pc = preempt_count();\n\tint bit;\n\n\tif (!(pc & (NMI_MASK | HARDIRQ_MASK | SOFTIRQ_OFFSET)))\n\t\tbit = RB_CTX_NORMAL;\n\telse\n\t\tbit = pc & NMI_MASK ? RB_CTX_NMI :\n\t\t\tpc & HARDIRQ_MASK ? RB_CTX_IRQ : RB_CTX_SOFTIRQ;\n\n\tif (unlikely(val & (1 << (bit + cpu_buffer->nest))))\n\t\treturn 1;\n\n\tval |= (1 << (bit + cpu_buffer->nest));\n\tcpu_buffer->current_context = val;\n\n\treturn 0;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "val & (1 << (bit + cpu_buffer->nest))"
          ],
          "line": 2664
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "preempt_count",
          "args": [],
          "line": 2655
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline int\ntrace_recursive_lock(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tunsigned int val = cpu_buffer->current_context;\n\tunsigned long pc = preempt_count();\n\tint bit;\n\n\tif (!(pc & (NMI_MASK | HARDIRQ_MASK | SOFTIRQ_OFFSET)))\n\t\tbit = RB_CTX_NORMAL;\n\telse\n\t\tbit = pc & NMI_MASK ? RB_CTX_NMI :\n\t\t\tpc & HARDIRQ_MASK ? RB_CTX_IRQ : RB_CTX_SOFTIRQ;\n\n\tif (unlikely(val & (1 << (bit + cpu_buffer->nest))))\n\t\treturn 1;\n\n\tval |= (1 << (bit + cpu_buffer->nest));\n\tcpu_buffer->current_context = val;\n\n\treturn 0;\n}"
  },
  {
    "function_name": "rb_wakeups",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2586-2611",
    "snippet": "static __always_inline void\nrb_wakeups(struct ring_buffer *buffer, struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tbool pagebusy;\n\n\tif (buffer->irq_work.waiters_pending) {\n\t\tbuffer->irq_work.waiters_pending = false;\n\t\t/* irq_work_queue() supplies it's own memory barriers */\n\t\tirq_work_queue(&buffer->irq_work.work);\n\t}\n\n\tif (cpu_buffer->irq_work.waiters_pending) {\n\t\tcpu_buffer->irq_work.waiters_pending = false;\n\t\t/* irq_work_queue() supplies it's own memory barriers */\n\t\tirq_work_queue(&cpu_buffer->irq_work.work);\n\t}\n\n\tpagebusy = cpu_buffer->reader_page == cpu_buffer->commit_page;\n\n\tif (!pagebusy && cpu_buffer->irq_work.full_waiters_pending) {\n\t\tcpu_buffer->irq_work.wakeup_full = true;\n\t\tcpu_buffer->irq_work.full_waiters_pending = false;\n\t\t/* irq_work_queue() supplies it's own memory barriers */\n\t\tirq_work_queue(&cpu_buffer->irq_work.work);\n\t}\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void update_pages_handler(struct work_struct *work);",
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "irq_work_queue",
          "args": [
            "&cpu_buffer->irq_work.work"
          ],
          "line": 2609
        },
        "resolved": true,
        "details": {
          "function_name": "irq_work_queue",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/irq_work.c",
          "lines": "90-112",
          "snippet": "bool irq_work_queue(struct irq_work *work)\n{\n\t/* Only queue if not already pending */\n\tif (!irq_work_claim(work))\n\t\treturn false;\n\n\t/* Queue the entry and raise the IPI if needed. */\n\tpreempt_disable();\n\n\t/* If the work is \"lazy\", handle it from next tick if any */\n\tif (work->flags & IRQ_WORK_LAZY) {\n\t\tif (llist_add(&work->llnode, this_cpu_ptr(&lazy_list)) &&\n\t\t    tick_nohz_tick_stopped())\n\t\t\tarch_irq_work_raise();\n\t} else {\n\t\tif (llist_add(&work->llnode, this_cpu_ptr(&raised_list)))\n\t\t\tarch_irq_work_raise();\n\t}\n\n\tpreempt_enable();\n\n\treturn true;\n}",
          "includes": [
            "#include <asm/processor.h>",
            "#include <linux/smp.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/tick.h>",
            "#include <linux/sched.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/bug.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(struct llist_head, raised_list);",
            "static DEFINE_PER_CPU(struct llist_head, lazy_list);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/processor.h>\n#include <linux/smp.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/tick.h>\n#include <linux/sched.h>\n#include <linux/irqflags.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/irq_work.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bug.h>\n\nstatic DEFINE_PER_CPU(struct llist_head, raised_list);\nstatic DEFINE_PER_CPU(struct llist_head, lazy_list);\n\nbool irq_work_queue(struct irq_work *work)\n{\n\t/* Only queue if not already pending */\n\tif (!irq_work_claim(work))\n\t\treturn false;\n\n\t/* Queue the entry and raise the IPI if needed. */\n\tpreempt_disable();\n\n\t/* If the work is \"lazy\", handle it from next tick if any */\n\tif (work->flags & IRQ_WORK_LAZY) {\n\t\tif (llist_add(&work->llnode, this_cpu_ptr(&lazy_list)) &&\n\t\t    tick_nohz_tick_stopped())\n\t\t\tarch_irq_work_raise();\n\t} else {\n\t\tif (llist_add(&work->llnode, this_cpu_ptr(&raised_list)))\n\t\t\tarch_irq_work_raise();\n\t}\n\n\tpreempt_enable();\n\n\treturn true;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void update_pages_handler(struct work_struct *work);\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline void\nrb_wakeups(struct ring_buffer *buffer, struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tbool pagebusy;\n\n\tif (buffer->irq_work.waiters_pending) {\n\t\tbuffer->irq_work.waiters_pending = false;\n\t\t/* irq_work_queue() supplies it's own memory barriers */\n\t\tirq_work_queue(&buffer->irq_work.work);\n\t}\n\n\tif (cpu_buffer->irq_work.waiters_pending) {\n\t\tcpu_buffer->irq_work.waiters_pending = false;\n\t\t/* irq_work_queue() supplies it's own memory barriers */\n\t\tirq_work_queue(&cpu_buffer->irq_work.work);\n\t}\n\n\tpagebusy = cpu_buffer->reader_page == cpu_buffer->commit_page;\n\n\tif (!pagebusy && cpu_buffer->irq_work.full_waiters_pending) {\n\t\tcpu_buffer->irq_work.wakeup_full = true;\n\t\tcpu_buffer->irq_work.full_waiters_pending = false;\n\t\t/* irq_work_queue() supplies it's own memory barriers */\n\t\tirq_work_queue(&cpu_buffer->irq_work.work);\n\t}\n}"
  },
  {
    "function_name": "rb_commit",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2578-2584",
    "snippet": "static void rb_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t      struct ring_buffer_event *event)\n{\n\tlocal_inc(&cpu_buffer->entries);\n\trb_update_write_stamp(cpu_buffer, event);\n\trb_end_commit(cpu_buffer);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_end_commit",
          "args": [
            "cpu_buffer"
          ],
          "line": 2583
        },
        "resolved": true,
        "details": {
          "function_name": "rb_end_commit",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2490-2520",
          "snippet": "static __always_inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tunsigned long commits;\n\n\tif (RB_WARN_ON(cpu_buffer,\n\t\t       !local_read(&cpu_buffer->committing)))\n\t\treturn;\n\n again:\n\tcommits = local_read(&cpu_buffer->commits);\n\t/* synchronize with interrupts */\n\tbarrier();\n\tif (local_read(&cpu_buffer->committing) == 1)\n\t\trb_set_commit_to_write(cpu_buffer);\n\n\tlocal_dec(&cpu_buffer->committing);\n\n\t/* synchronize with interrupts */\n\tbarrier();\n\n\t/*\n\t * Need to account for interrupts coming in between the\n\t * updating of the commit page and the clearing of the\n\t * committing counter.\n\t */\n\tif (unlikely(local_read(&cpu_buffer->commits) != commits) &&\n\t    !local_read(&cpu_buffer->committing)) {\n\t\tlocal_inc(&cpu_buffer->committing);\n\t\tgoto again;\n\t}\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tunsigned long commits;\n\n\tif (RB_WARN_ON(cpu_buffer,\n\t\t       !local_read(&cpu_buffer->committing)))\n\t\treturn;\n\n again:\n\tcommits = local_read(&cpu_buffer->commits);\n\t/* synchronize with interrupts */\n\tbarrier();\n\tif (local_read(&cpu_buffer->committing) == 1)\n\t\trb_set_commit_to_write(cpu_buffer);\n\n\tlocal_dec(&cpu_buffer->committing);\n\n\t/* synchronize with interrupts */\n\tbarrier();\n\n\t/*\n\t * Need to account for interrupts coming in between the\n\t * updating of the commit page and the clearing of the\n\t * committing counter.\n\t */\n\tif (unlikely(local_read(&cpu_buffer->commits) != commits) &&\n\t    !local_read(&cpu_buffer->committing)) {\n\t\tlocal_inc(&cpu_buffer->committing);\n\t\tgoto again;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_update_write_stamp",
          "args": [
            "cpu_buffer",
            "event"
          ],
          "line": 2582
        },
        "resolved": true,
        "details": {
          "function_name": "rb_update_write_stamp",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2549-2576",
          "snippet": "static __always_inline void\nrb_update_write_stamp(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t      struct ring_buffer_event *event)\n{\n\tu64 delta;\n\n\t/*\n\t * The event first in the commit queue updates the\n\t * time stamp.\n\t */\n\tif (rb_event_is_commit(cpu_buffer, event)) {\n\t\t/*\n\t\t * A commit event that is first on a page\n\t\t * updates the write timestamp with the page stamp\n\t\t */\n\t\tif (!rb_event_index(event))\n\t\t\tcpu_buffer->write_stamp =\n\t\t\t\tcpu_buffer->commit_page->page->time_stamp;\n\t\telse if (event->type_len == RINGBUF_TYPE_TIME_EXTEND) {\n\t\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\t\tcpu_buffer->write_stamp += delta;\n\t\t} else if (event->type_len == RINGBUF_TYPE_TIME_STAMP) {\n\t\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\t\tcpu_buffer->write_stamp = delta;\n\t\t} else\n\t\t\tcpu_buffer->write_stamp += event->time_delta;\n\t}\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic __always_inline void\nrb_update_write_stamp(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t      struct ring_buffer_event *event)\n{\n\tu64 delta;\n\n\t/*\n\t * The event first in the commit queue updates the\n\t * time stamp.\n\t */\n\tif (rb_event_is_commit(cpu_buffer, event)) {\n\t\t/*\n\t\t * A commit event that is first on a page\n\t\t * updates the write timestamp with the page stamp\n\t\t */\n\t\tif (!rb_event_index(event))\n\t\t\tcpu_buffer->write_stamp =\n\t\t\t\tcpu_buffer->commit_page->page->time_stamp;\n\t\telse if (event->type_len == RINGBUF_TYPE_TIME_EXTEND) {\n\t\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\t\tcpu_buffer->write_stamp += delta;\n\t\t} else if (event->type_len == RINGBUF_TYPE_TIME_STAMP) {\n\t\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\t\tcpu_buffer->write_stamp = delta;\n\t\t} else\n\t\t\tcpu_buffer->write_stamp += event->time_delta;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_inc",
          "args": [
            "&cpu_buffer->entries"
          ],
          "line": 2581
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic void rb_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t      struct ring_buffer_event *event)\n{\n\tlocal_inc(&cpu_buffer->entries);\n\trb_update_write_stamp(cpu_buffer, event);\n\trb_end_commit(cpu_buffer);\n}"
  },
  {
    "function_name": "rb_update_write_stamp",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2549-2576",
    "snippet": "static __always_inline void\nrb_update_write_stamp(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t      struct ring_buffer_event *event)\n{\n\tu64 delta;\n\n\t/*\n\t * The event first in the commit queue updates the\n\t * time stamp.\n\t */\n\tif (rb_event_is_commit(cpu_buffer, event)) {\n\t\t/*\n\t\t * A commit event that is first on a page\n\t\t * updates the write timestamp with the page stamp\n\t\t */\n\t\tif (!rb_event_index(event))\n\t\t\tcpu_buffer->write_stamp =\n\t\t\t\tcpu_buffer->commit_page->page->time_stamp;\n\t\telse if (event->type_len == RINGBUF_TYPE_TIME_EXTEND) {\n\t\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\t\tcpu_buffer->write_stamp += delta;\n\t\t} else if (event->type_len == RINGBUF_TYPE_TIME_STAMP) {\n\t\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\t\tcpu_buffer->write_stamp = delta;\n\t\t} else\n\t\t\tcpu_buffer->write_stamp += event->time_delta;\n\t}\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "ring_buffer_event_time_stamp",
          "args": [
            "event"
          ],
          "line": 2571
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_event_time_stamp",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "295-304",
          "snippet": "u64 ring_buffer_event_time_stamp(struct ring_buffer_event *event)\n{\n\tu64 ts;\n\n\tts = event->array[0];\n\tts <<= TS_SHIFT;\n\tts += event->time_delta;\n\n\treturn ts;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define TS_SHIFT\t27"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define TS_SHIFT\t27\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nu64 ring_buffer_event_time_stamp(struct ring_buffer_event *event)\n{\n\tu64 ts;\n\n\tts = event->array[0];\n\tts <<= TS_SHIFT;\n\tts += event->time_delta;\n\n\treturn ts;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_event_index",
          "args": [
            "event"
          ],
          "line": 2564
        },
        "resolved": true,
        "details": {
          "function_name": "rb_event_index",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1915-1921",
          "snippet": "static __always_inline unsigned\nrb_event_index(struct ring_buffer_event *event)\n{\n\tunsigned long addr = (unsigned long)event;\n\n\treturn (addr & ~PAGE_MASK) - BUF_PAGE_HDR_SIZE;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define BUF_PAGE_HDR_SIZE offsetof(struct buffer_data_page, data)"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define BUF_PAGE_HDR_SIZE offsetof(struct buffer_data_page, data)\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic __always_inline unsigned\nrb_event_index(struct ring_buffer_event *event)\n{\n\tunsigned long addr = (unsigned long)event;\n\n\treturn (addr & ~PAGE_MASK) - BUF_PAGE_HDR_SIZE;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_event_is_commit",
          "args": [
            "cpu_buffer",
            "event"
          ],
          "line": 2559
        },
        "resolved": true,
        "details": {
          "function_name": "rb_event_is_commit",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2535-2547",
          "snippet": "static __always_inline bool\nrb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t   struct ring_buffer_event *event)\n{\n\tunsigned long addr = (unsigned long)event;\n\tunsigned long index;\n\n\tindex = rb_event_index(event);\n\taddr &= PAGE_MASK;\n\n\treturn cpu_buffer->commit_page->page == (void *)addr &&\n\t\trb_commit_index(cpu_buffer) == index;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic __always_inline bool\nrb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t   struct ring_buffer_event *event)\n{\n\tunsigned long addr = (unsigned long)event;\n\tunsigned long index;\n\n\tindex = rb_event_index(event);\n\taddr &= PAGE_MASK;\n\n\treturn cpu_buffer->commit_page->page == (void *)addr &&\n\t\trb_commit_index(cpu_buffer) == index;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic __always_inline void\nrb_update_write_stamp(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t      struct ring_buffer_event *event)\n{\n\tu64 delta;\n\n\t/*\n\t * The event first in the commit queue updates the\n\t * time stamp.\n\t */\n\tif (rb_event_is_commit(cpu_buffer, event)) {\n\t\t/*\n\t\t * A commit event that is first on a page\n\t\t * updates the write timestamp with the page stamp\n\t\t */\n\t\tif (!rb_event_index(event))\n\t\t\tcpu_buffer->write_stamp =\n\t\t\t\tcpu_buffer->commit_page->page->time_stamp;\n\t\telse if (event->type_len == RINGBUF_TYPE_TIME_EXTEND) {\n\t\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\t\tcpu_buffer->write_stamp += delta;\n\t\t} else if (event->type_len == RINGBUF_TYPE_TIME_STAMP) {\n\t\t\tdelta = ring_buffer_event_time_stamp(event);\n\t\t\tcpu_buffer->write_stamp = delta;\n\t\t} else\n\t\t\tcpu_buffer->write_stamp += event->time_delta;\n\t}\n}"
  },
  {
    "function_name": "rb_event_is_commit",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2535-2547",
    "snippet": "static __always_inline bool\nrb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t   struct ring_buffer_event *event)\n{\n\tunsigned long addr = (unsigned long)event;\n\tunsigned long index;\n\n\tindex = rb_event_index(event);\n\taddr &= PAGE_MASK;\n\n\treturn cpu_buffer->commit_page->page == (void *)addr &&\n\t\trb_commit_index(cpu_buffer) == index;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_commit_index",
          "args": [
            "cpu_buffer"
          ],
          "line": 2546
        },
        "resolved": true,
        "details": {
          "function_name": "rb_commit_index",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1909-1913",
          "snippet": "static __always_inline unsigned\nrb_commit_index(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn rb_page_commit(cpu_buffer->commit_page);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline unsigned\nrb_commit_index(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn rb_page_commit(cpu_buffer->commit_page);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_event_index",
          "args": [
            "event"
          ],
          "line": 2542
        },
        "resolved": true,
        "details": {
          "function_name": "rb_event_index",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1915-1921",
          "snippet": "static __always_inline unsigned\nrb_event_index(struct ring_buffer_event *event)\n{\n\tunsigned long addr = (unsigned long)event;\n\n\treturn (addr & ~PAGE_MASK) - BUF_PAGE_HDR_SIZE;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define BUF_PAGE_HDR_SIZE offsetof(struct buffer_data_page, data)"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define BUF_PAGE_HDR_SIZE offsetof(struct buffer_data_page, data)\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic __always_inline unsigned\nrb_event_index(struct ring_buffer_event *event)\n{\n\tunsigned long addr = (unsigned long)event;\n\n\treturn (addr & ~PAGE_MASK) - BUF_PAGE_HDR_SIZE;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic __always_inline bool\nrb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t   struct ring_buffer_event *event)\n{\n\tunsigned long addr = (unsigned long)event;\n\tunsigned long index;\n\n\tindex = rb_event_index(event);\n\taddr &= PAGE_MASK;\n\n\treturn cpu_buffer->commit_page->page == (void *)addr &&\n\t\trb_commit_index(cpu_buffer) == index;\n}"
  },
  {
    "function_name": "rb_event_discard",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2522-2533",
    "snippet": "static inline void rb_event_discard(struct ring_buffer_event *event)\n{\n\tif (extended_time(event))\n\t\tevent = skip_time_extend(event);\n\n\t/* array[0] holds the actual length for the discarded event */\n\tevent->array[0] = rb_event_data_length(event) - RB_EVNT_HDR_SIZE;\n\tevent->type_len = RINGBUF_TYPE_PADDING;\n\t/* time delta must be non zero */\n\tif (!event->time_delta)\n\t\tevent->time_delta = 1;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))"
    ],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_event_data_length",
          "args": [
            "event"
          ],
          "line": 2528
        },
        "resolved": true,
        "details": {
          "function_name": "rb_event_data_length",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "168-178",
          "snippet": "static unsigned\nrb_event_data_length(struct ring_buffer_event *event)\n{\n\tunsigned length;\n\n\tif (event->type_len)\n\t\tlength = event->type_len * RB_ALIGNMENT;\n\telse\n\t\tlength = event->array[0];\n\treturn length + RB_EVNT_HDR_SIZE;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_ALIGNMENT\t\t4U",
            "#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_ALIGNMENT\t\t4U\n#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic unsigned\nrb_event_data_length(struct ring_buffer_event *event)\n{\n\tunsigned length;\n\n\tif (event->type_len)\n\t\tlength = event->type_len * RB_ALIGNMENT;\n\telse\n\t\tlength = event->array[0];\n\treturn length + RB_EVNT_HDR_SIZE;\n}"
        }
      },
      {
        "call_info": {
          "callee": "skip_time_extend",
          "args": [
            "event"
          ],
          "line": 2525
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "extended_time",
          "args": [
            "event"
          ],
          "line": 2524
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic inline void rb_event_discard(struct ring_buffer_event *event)\n{\n\tif (extended_time(event))\n\t\tevent = skip_time_extend(event);\n\n\t/* array[0] holds the actual length for the discarded event */\n\tevent->array[0] = rb_event_data_length(event) - RB_EVNT_HDR_SIZE;\n\tevent->type_len = RINGBUF_TYPE_PADDING;\n\t/* time delta must be non zero */\n\tif (!event->time_delta)\n\t\tevent->time_delta = 1;\n}"
  },
  {
    "function_name": "rb_end_commit",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2490-2520",
    "snippet": "static __always_inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tunsigned long commits;\n\n\tif (RB_WARN_ON(cpu_buffer,\n\t\t       !local_read(&cpu_buffer->committing)))\n\t\treturn;\n\n again:\n\tcommits = local_read(&cpu_buffer->commits);\n\t/* synchronize with interrupts */\n\tbarrier();\n\tif (local_read(&cpu_buffer->committing) == 1)\n\t\trb_set_commit_to_write(cpu_buffer);\n\n\tlocal_dec(&cpu_buffer->committing);\n\n\t/* synchronize with interrupts */\n\tbarrier();\n\n\t/*\n\t * Need to account for interrupts coming in between the\n\t * updating of the commit page and the clearing of the\n\t * committing counter.\n\t */\n\tif (unlikely(local_read(&cpu_buffer->commits) != commits) &&\n\t    !local_read(&cpu_buffer->committing)) {\n\t\tlocal_inc(&cpu_buffer->committing);\n\t\tgoto again;\n\t}\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_inc",
          "args": [
            "&cpu_buffer->committing"
          ],
          "line": 2517
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_read",
          "args": [
            "&cpu_buffer->committing"
          ],
          "line": 2516
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "local_read(&cpu_buffer->commits) != commits"
          ],
          "line": 2515
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_read",
          "args": [
            "&cpu_buffer->commits"
          ],
          "line": 2515
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "barrier",
          "args": [],
          "line": 2508
        },
        "resolved": true,
        "details": {
          "function_name": "membarrier_register_global_expedited",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/membarrier.c",
          "lines": "189-219",
          "snippet": "static int membarrier_register_global_expedited(void)\n{\n\tstruct task_struct *p = current;\n\tstruct mm_struct *mm = p->mm;\n\n\tif (atomic_read(&mm->membarrier_state) &\n\t    MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY)\n\t\treturn 0;\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED, &mm->membarrier_state);\n\tif (atomic_read(&mm->mm_users) == 1 && get_nr_threads(p) == 1) {\n\t\t/*\n\t\t * For single mm user, single threaded process, we can\n\t\t * simply issue a memory barrier after setting\n\t\t * MEMBARRIER_STATE_GLOBAL_EXPEDITED to guarantee that\n\t\t * no memory access following registration is reordered\n\t\t * before registration.\n\t\t */\n\t\tsmp_mb();\n\t} else {\n\t\t/*\n\t\t * For multi-mm user threads, we need to ensure all\n\t\t * future scheduler executions will observe the new\n\t\t * thread flag state for this mm.\n\t\t */\n\t\tsynchronize_sched();\n\t}\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY,\n\t\t  &mm->membarrier_state);\n\n\treturn 0;\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nstatic int membarrier_register_global_expedited(void)\n{\n\tstruct task_struct *p = current;\n\tstruct mm_struct *mm = p->mm;\n\n\tif (atomic_read(&mm->membarrier_state) &\n\t    MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY)\n\t\treturn 0;\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED, &mm->membarrier_state);\n\tif (atomic_read(&mm->mm_users) == 1 && get_nr_threads(p) == 1) {\n\t\t/*\n\t\t * For single mm user, single threaded process, we can\n\t\t * simply issue a memory barrier after setting\n\t\t * MEMBARRIER_STATE_GLOBAL_EXPEDITED to guarantee that\n\t\t * no memory access following registration is reordered\n\t\t * before registration.\n\t\t */\n\t\tsmp_mb();\n\t} else {\n\t\t/*\n\t\t * For multi-mm user threads, we need to ensure all\n\t\t * future scheduler executions will observe the new\n\t\t * thread flag state for this mm.\n\t\t */\n\t\tsynchronize_sched();\n\t}\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY,\n\t\t  &mm->membarrier_state);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_dec",
          "args": [
            "&cpu_buffer->committing"
          ],
          "line": 2505
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_set_commit_to_write",
          "args": [
            "cpu_buffer"
          ],
          "line": 2503
        },
        "resolved": true,
        "details": {
          "function_name": "rb_set_commit_to_write",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2435-2488",
          "snippet": "static __always_inline void\nrb_set_commit_to_write(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tunsigned long max_count;\n\n\t/*\n\t * We only race with interrupts and NMIs on this CPU.\n\t * If we own the commit event, then we can commit\n\t * all others that interrupted us, since the interruptions\n\t * are in stack format (they finish before they come\n\t * back to us). This allows us to do a simple loop to\n\t * assign the commit to the tail.\n\t */\n again:\n\tmax_count = cpu_buffer->nr_pages * 100;\n\n\twhile (cpu_buffer->commit_page != READ_ONCE(cpu_buffer->tail_page)) {\n\t\tif (RB_WARN_ON(cpu_buffer, !(--max_count)))\n\t\t\treturn;\n\t\tif (RB_WARN_ON(cpu_buffer,\n\t\t\t       rb_is_reader_page(cpu_buffer->tail_page)))\n\t\t\treturn;\n\t\tlocal_set(&cpu_buffer->commit_page->page->commit,\n\t\t\t  rb_page_write(cpu_buffer->commit_page));\n\t\trb_inc_page(cpu_buffer, &cpu_buffer->commit_page);\n\t\t/* Only update the write stamp if the page has an event */\n\t\tif (rb_page_write(cpu_buffer->commit_page))\n\t\t\tcpu_buffer->write_stamp =\n\t\t\t\tcpu_buffer->commit_page->page->time_stamp;\n\t\t/* add barrier to keep gcc from optimizing too much */\n\t\tbarrier();\n\t}\n\twhile (rb_commit_index(cpu_buffer) !=\n\t       rb_page_write(cpu_buffer->commit_page)) {\n\n\t\tlocal_set(&cpu_buffer->commit_page->page->commit,\n\t\t\t  rb_page_write(cpu_buffer->commit_page));\n\t\tRB_WARN_ON(cpu_buffer,\n\t\t\t   local_read(&cpu_buffer->commit_page->page->commit) &\n\t\t\t   ~RB_WRITE_MASK);\n\t\tbarrier();\n\t}\n\n\t/* again, keep gcc from optimizing */\n\tbarrier();\n\n\t/*\n\t * If an interrupt came in just after the first while loop\n\t * and pushed the tail page forward, we will be left with\n\t * a dangling commit that will never go forward.\n\t */\n\tif (unlikely(cpu_buffer->commit_page != READ_ONCE(cpu_buffer->tail_page)))\n\t\tgoto again;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_WRITE_MASK\t\t0xfffff"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_WRITE_MASK\t\t0xfffff\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic __always_inline void\nrb_set_commit_to_write(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tunsigned long max_count;\n\n\t/*\n\t * We only race with interrupts and NMIs on this CPU.\n\t * If we own the commit event, then we can commit\n\t * all others that interrupted us, since the interruptions\n\t * are in stack format (they finish before they come\n\t * back to us). This allows us to do a simple loop to\n\t * assign the commit to the tail.\n\t */\n again:\n\tmax_count = cpu_buffer->nr_pages * 100;\n\n\twhile (cpu_buffer->commit_page != READ_ONCE(cpu_buffer->tail_page)) {\n\t\tif (RB_WARN_ON(cpu_buffer, !(--max_count)))\n\t\t\treturn;\n\t\tif (RB_WARN_ON(cpu_buffer,\n\t\t\t       rb_is_reader_page(cpu_buffer->tail_page)))\n\t\t\treturn;\n\t\tlocal_set(&cpu_buffer->commit_page->page->commit,\n\t\t\t  rb_page_write(cpu_buffer->commit_page));\n\t\trb_inc_page(cpu_buffer, &cpu_buffer->commit_page);\n\t\t/* Only update the write stamp if the page has an event */\n\t\tif (rb_page_write(cpu_buffer->commit_page))\n\t\t\tcpu_buffer->write_stamp =\n\t\t\t\tcpu_buffer->commit_page->page->time_stamp;\n\t\t/* add barrier to keep gcc from optimizing too much */\n\t\tbarrier();\n\t}\n\twhile (rb_commit_index(cpu_buffer) !=\n\t       rb_page_write(cpu_buffer->commit_page)) {\n\n\t\tlocal_set(&cpu_buffer->commit_page->page->commit,\n\t\t\t  rb_page_write(cpu_buffer->commit_page));\n\t\tRB_WARN_ON(cpu_buffer,\n\t\t\t   local_read(&cpu_buffer->commit_page->page->commit) &\n\t\t\t   ~RB_WRITE_MASK);\n\t\tbarrier();\n\t}\n\n\t/* again, keep gcc from optimizing */\n\tbarrier();\n\n\t/*\n\t * If an interrupt came in just after the first while loop\n\t * and pushed the tail page forward, we will be left with\n\t * a dangling commit that will never go forward.\n\t */\n\tif (unlikely(cpu_buffer->commit_page != READ_ONCE(cpu_buffer->tail_page)))\n\t\tgoto again;\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_read",
          "args": [
            "&cpu_buffer->committing"
          ],
          "line": 2502
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_read",
          "args": [
            "&cpu_buffer->commits"
          ],
          "line": 2499
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "!local_read(&cpu_buffer->committing)"
          ],
          "line": 2494
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_read",
          "args": [
            "&cpu_buffer->committing"
          ],
          "line": 2495
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tunsigned long commits;\n\n\tif (RB_WARN_ON(cpu_buffer,\n\t\t       !local_read(&cpu_buffer->committing)))\n\t\treturn;\n\n again:\n\tcommits = local_read(&cpu_buffer->commits);\n\t/* synchronize with interrupts */\n\tbarrier();\n\tif (local_read(&cpu_buffer->committing) == 1)\n\t\trb_set_commit_to_write(cpu_buffer);\n\n\tlocal_dec(&cpu_buffer->committing);\n\n\t/* synchronize with interrupts */\n\tbarrier();\n\n\t/*\n\t * Need to account for interrupts coming in between the\n\t * updating of the commit page and the clearing of the\n\t * committing counter.\n\t */\n\tif (unlikely(local_read(&cpu_buffer->commits) != commits) &&\n\t    !local_read(&cpu_buffer->committing)) {\n\t\tlocal_inc(&cpu_buffer->committing);\n\t\tgoto again;\n\t}\n}"
  },
  {
    "function_name": "rb_set_commit_to_write",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2435-2488",
    "snippet": "static __always_inline void\nrb_set_commit_to_write(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tunsigned long max_count;\n\n\t/*\n\t * We only race with interrupts and NMIs on this CPU.\n\t * If we own the commit event, then we can commit\n\t * all others that interrupted us, since the interruptions\n\t * are in stack format (they finish before they come\n\t * back to us). This allows us to do a simple loop to\n\t * assign the commit to the tail.\n\t */\n again:\n\tmax_count = cpu_buffer->nr_pages * 100;\n\n\twhile (cpu_buffer->commit_page != READ_ONCE(cpu_buffer->tail_page)) {\n\t\tif (RB_WARN_ON(cpu_buffer, !(--max_count)))\n\t\t\treturn;\n\t\tif (RB_WARN_ON(cpu_buffer,\n\t\t\t       rb_is_reader_page(cpu_buffer->tail_page)))\n\t\t\treturn;\n\t\tlocal_set(&cpu_buffer->commit_page->page->commit,\n\t\t\t  rb_page_write(cpu_buffer->commit_page));\n\t\trb_inc_page(cpu_buffer, &cpu_buffer->commit_page);\n\t\t/* Only update the write stamp if the page has an event */\n\t\tif (rb_page_write(cpu_buffer->commit_page))\n\t\t\tcpu_buffer->write_stamp =\n\t\t\t\tcpu_buffer->commit_page->page->time_stamp;\n\t\t/* add barrier to keep gcc from optimizing too much */\n\t\tbarrier();\n\t}\n\twhile (rb_commit_index(cpu_buffer) !=\n\t       rb_page_write(cpu_buffer->commit_page)) {\n\n\t\tlocal_set(&cpu_buffer->commit_page->page->commit,\n\t\t\t  rb_page_write(cpu_buffer->commit_page));\n\t\tRB_WARN_ON(cpu_buffer,\n\t\t\t   local_read(&cpu_buffer->commit_page->page->commit) &\n\t\t\t   ~RB_WRITE_MASK);\n\t\tbarrier();\n\t}\n\n\t/* again, keep gcc from optimizing */\n\tbarrier();\n\n\t/*\n\t * If an interrupt came in just after the first while loop\n\t * and pushed the tail page forward, we will be left with\n\t * a dangling commit that will never go forward.\n\t */\n\tif (unlikely(cpu_buffer->commit_page != READ_ONCE(cpu_buffer->tail_page)))\n\t\tgoto again;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_WRITE_MASK\t\t0xfffff"
    ],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "cpu_buffer->commit_page != READ_ONCE(cpu_buffer->tail_page)"
          ],
          "line": 2486
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "cpu_buffer->tail_page"
          ],
          "line": 2486
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "barrier",
          "args": [],
          "line": 2479
        },
        "resolved": true,
        "details": {
          "function_name": "membarrier_register_global_expedited",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/membarrier.c",
          "lines": "189-219",
          "snippet": "static int membarrier_register_global_expedited(void)\n{\n\tstruct task_struct *p = current;\n\tstruct mm_struct *mm = p->mm;\n\n\tif (atomic_read(&mm->membarrier_state) &\n\t    MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY)\n\t\treturn 0;\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED, &mm->membarrier_state);\n\tif (atomic_read(&mm->mm_users) == 1 && get_nr_threads(p) == 1) {\n\t\t/*\n\t\t * For single mm user, single threaded process, we can\n\t\t * simply issue a memory barrier after setting\n\t\t * MEMBARRIER_STATE_GLOBAL_EXPEDITED to guarantee that\n\t\t * no memory access following registration is reordered\n\t\t * before registration.\n\t\t */\n\t\tsmp_mb();\n\t} else {\n\t\t/*\n\t\t * For multi-mm user threads, we need to ensure all\n\t\t * future scheduler executions will observe the new\n\t\t * thread flag state for this mm.\n\t\t */\n\t\tsynchronize_sched();\n\t}\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY,\n\t\t  &mm->membarrier_state);\n\n\treturn 0;\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nstatic int membarrier_register_global_expedited(void)\n{\n\tstruct task_struct *p = current;\n\tstruct mm_struct *mm = p->mm;\n\n\tif (atomic_read(&mm->membarrier_state) &\n\t    MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY)\n\t\treturn 0;\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED, &mm->membarrier_state);\n\tif (atomic_read(&mm->mm_users) == 1 && get_nr_threads(p) == 1) {\n\t\t/*\n\t\t * For single mm user, single threaded process, we can\n\t\t * simply issue a memory barrier after setting\n\t\t * MEMBARRIER_STATE_GLOBAL_EXPEDITED to guarantee that\n\t\t * no memory access following registration is reordered\n\t\t * before registration.\n\t\t */\n\t\tsmp_mb();\n\t} else {\n\t\t/*\n\t\t * For multi-mm user threads, we need to ensure all\n\t\t * future scheduler executions will observe the new\n\t\t * thread flag state for this mm.\n\t\t */\n\t\tsynchronize_sched();\n\t}\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY,\n\t\t  &mm->membarrier_state);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "local_read(&cpu_buffer->commit_page->page->commit) &\n\t\t\t   ~RB_WRITE_MASK"
          ],
          "line": 2472
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_read",
          "args": [
            "&cpu_buffer->commit_page->page->commit"
          ],
          "line": 2473
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_set",
          "args": [
            "&cpu_buffer->commit_page->page->commit",
            "rb_page_write(cpu_buffer->commit_page)"
          ],
          "line": 2470
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_page_write",
          "args": [
            "cpu_buffer->commit_page"
          ],
          "line": 2471
        },
        "resolved": true,
        "details": {
          "function_name": "rb_page_write",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1464-1467",
          "snippet": "static inline unsigned long rb_page_write(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->write) & RB_WRITE_MASK;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_WRITE_MASK\t\t0xfffff"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_WRITE_MASK\t\t0xfffff\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline unsigned long rb_page_write(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->write) & RB_WRITE_MASK;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_commit_index",
          "args": [
            "cpu_buffer"
          ],
          "line": 2467
        },
        "resolved": true,
        "details": {
          "function_name": "rb_commit_index",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1909-1913",
          "snippet": "static __always_inline unsigned\nrb_commit_index(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn rb_page_commit(cpu_buffer->commit_page);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline unsigned\nrb_commit_index(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn rb_page_commit(cpu_buffer->commit_page);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_inc_page",
          "args": [
            "cpu_buffer",
            "&cpu_buffer->commit_page"
          ],
          "line": 2459
        },
        "resolved": true,
        "details": {
          "function_name": "rb_inc_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "974-980",
          "snippet": "static inline void rb_inc_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t       struct buffer_page **bpage)\n{\n\tstruct list_head *p = rb_list_head((*bpage)->list.next);\n\n\t*bpage = list_entry(p, struct buffer_page, list);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline void rb_inc_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t       struct buffer_page **bpage)\n{\n\tstruct list_head *p = rb_list_head((*bpage)->list.next);\n\n\t*bpage = list_entry(p, struct buffer_page, list);\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_set",
          "args": [
            "&cpu_buffer->commit_page->page->commit",
            "rb_page_write(cpu_buffer->commit_page)"
          ],
          "line": 2457
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "rb_is_reader_page(cpu_buffer->tail_page)"
          ],
          "line": 2454
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_is_reader_page",
          "args": [
            "cpu_buffer->tail_page"
          ],
          "line": 2455
        },
        "resolved": true,
        "details": {
          "function_name": "rb_is_reader_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "865-870",
          "snippet": "static bool rb_is_reader_page(struct buffer_page *page)\n{\n\tstruct list_head *list = page->list.prev;\n\n\treturn rb_list_head(list->next) != &page->list;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic bool rb_is_reader_page(struct buffer_page *page)\n{\n\tstruct list_head *list = page->list.prev;\n\n\treturn rb_list_head(list->next) != &page->list;\n}"
        }
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "!(--max_count)"
          ],
          "line": 2452
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "cpu_buffer->tail_page"
          ],
          "line": 2451
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_WRITE_MASK\t\t0xfffff\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic __always_inline void\nrb_set_commit_to_write(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tunsigned long max_count;\n\n\t/*\n\t * We only race with interrupts and NMIs on this CPU.\n\t * If we own the commit event, then we can commit\n\t * all others that interrupted us, since the interruptions\n\t * are in stack format (they finish before they come\n\t * back to us). This allows us to do a simple loop to\n\t * assign the commit to the tail.\n\t */\n again:\n\tmax_count = cpu_buffer->nr_pages * 100;\n\n\twhile (cpu_buffer->commit_page != READ_ONCE(cpu_buffer->tail_page)) {\n\t\tif (RB_WARN_ON(cpu_buffer, !(--max_count)))\n\t\t\treturn;\n\t\tif (RB_WARN_ON(cpu_buffer,\n\t\t\t       rb_is_reader_page(cpu_buffer->tail_page)))\n\t\t\treturn;\n\t\tlocal_set(&cpu_buffer->commit_page->page->commit,\n\t\t\t  rb_page_write(cpu_buffer->commit_page));\n\t\trb_inc_page(cpu_buffer, &cpu_buffer->commit_page);\n\t\t/* Only update the write stamp if the page has an event */\n\t\tif (rb_page_write(cpu_buffer->commit_page))\n\t\t\tcpu_buffer->write_stamp =\n\t\t\t\tcpu_buffer->commit_page->page->time_stamp;\n\t\t/* add barrier to keep gcc from optimizing too much */\n\t\tbarrier();\n\t}\n\twhile (rb_commit_index(cpu_buffer) !=\n\t       rb_page_write(cpu_buffer->commit_page)) {\n\n\t\tlocal_set(&cpu_buffer->commit_page->page->commit,\n\t\t\t  rb_page_write(cpu_buffer->commit_page));\n\t\tRB_WARN_ON(cpu_buffer,\n\t\t\t   local_read(&cpu_buffer->commit_page->page->commit) &\n\t\t\t   ~RB_WRITE_MASK);\n\t\tbarrier();\n\t}\n\n\t/* again, keep gcc from optimizing */\n\tbarrier();\n\n\t/*\n\t * If an interrupt came in just after the first while loop\n\t * and pushed the tail page forward, we will be left with\n\t * a dangling commit that will never go forward.\n\t */\n\tif (unlikely(cpu_buffer->commit_page != READ_ONCE(cpu_buffer->tail_page)))\n\t\tgoto again;\n}"
  },
  {
    "function_name": "rb_start_commit",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2429-2433",
    "snippet": "static void rb_start_commit(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tlocal_inc(&cpu_buffer->committing);\n\tlocal_inc(&cpu_buffer->commits);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_inc",
          "args": [
            "&cpu_buffer->commits"
          ],
          "line": 2432
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_inc",
          "args": [
            "&cpu_buffer->committing"
          ],
          "line": 2431
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_start_commit(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tlocal_inc(&cpu_buffer->committing);\n\tlocal_inc(&cpu_buffer->commits);\n}"
  },
  {
    "function_name": "rb_try_to_discard",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2389-2427",
    "snippet": "static inline int\nrb_try_to_discard(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t  struct ring_buffer_event *event)\n{\n\tunsigned long new_index, old_index;\n\tstruct buffer_page *bpage;\n\tunsigned long index;\n\tunsigned long addr;\n\n\tnew_index = rb_event_index(event);\n\told_index = new_index + rb_event_ts_length(event);\n\taddr = (unsigned long)event;\n\taddr &= PAGE_MASK;\n\n\tbpage = READ_ONCE(cpu_buffer->tail_page);\n\n\tif (bpage->page == (void *)addr && rb_page_write(bpage) == old_index) {\n\t\tunsigned long write_mask =\n\t\t\tlocal_read(&bpage->write) & ~RB_WRITE_MASK;\n\t\tunsigned long event_length = rb_event_length(event);\n\t\t/*\n\t\t * This is on the tail page. It is possible that\n\t\t * a write could come in and move the tail page\n\t\t * and write to the next page. That is fine\n\t\t * because we just shorten what is on this page.\n\t\t */\n\t\told_index += write_mask;\n\t\tnew_index += write_mask;\n\t\tindex = local_cmpxchg(&bpage->write, old_index, new_index);\n\t\tif (index == old_index) {\n\t\t\t/* update counters */\n\t\t\tlocal_sub(event_length, &cpu_buffer->entries_bytes);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* could not discard */\n\treturn 0;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_WRITE_MASK\t\t0xfffff"
    ],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_sub",
          "args": [
            "event_length",
            "&cpu_buffer->entries_bytes"
          ],
          "line": 2420
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_cmpxchg",
          "args": [
            "&bpage->write",
            "old_index",
            "new_index"
          ],
          "line": 2417
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_event_length",
          "args": [
            "event"
          ],
          "line": 2408
        },
        "resolved": true,
        "details": {
          "function_name": "rb_event_length",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "185-208",
          "snippet": "static inline unsigned\nrb_event_length(struct ring_buffer_event *event)\n{\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event))\n\t\t\t/* undefined */\n\t\t\treturn -1;\n\t\treturn  event->array[0] + RB_EVNT_HDR_SIZE;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\treturn RB_LEN_TIME_EXTEND;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\treturn RB_LEN_TIME_STAMP;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\treturn rb_event_data_length(event);\n\tdefault:\n\t\tBUG();\n\t}\n\t/* not hit */\n\treturn 0;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX",
            "#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX\n#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic inline unsigned\nrb_event_length(struct ring_buffer_event *event)\n{\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event))\n\t\t\t/* undefined */\n\t\t\treturn -1;\n\t\treturn  event->array[0] + RB_EVNT_HDR_SIZE;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\treturn RB_LEN_TIME_EXTEND;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\treturn RB_LEN_TIME_STAMP;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\treturn rb_event_data_length(event);\n\tdefault:\n\t\tBUG();\n\t}\n\t/* not hit */\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_read",
          "args": [
            "&bpage->write"
          ],
          "line": 2407
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_page_write",
          "args": [
            "bpage"
          ],
          "line": 2405
        },
        "resolved": true,
        "details": {
          "function_name": "rb_page_write",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1464-1467",
          "snippet": "static inline unsigned long rb_page_write(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->write) & RB_WRITE_MASK;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_WRITE_MASK\t\t0xfffff"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_WRITE_MASK\t\t0xfffff\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline unsigned long rb_page_write(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->write) & RB_WRITE_MASK;\n}"
        }
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "cpu_buffer->tail_page"
          ],
          "line": 2403
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_event_ts_length",
          "args": [
            "event"
          ],
          "line": 2399
        },
        "resolved": true,
        "details": {
          "function_name": "rb_event_ts_length",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "214-225",
          "snippet": "static inline unsigned\nrb_event_ts_length(struct ring_buffer_event *event)\n{\n\tunsigned len = 0;\n\n\tif (extended_time(event)) {\n\t\t/* time extends include the data event after it */\n\t\tlen = RB_LEN_TIME_EXTEND;\n\t\tevent = skip_time_extend(event);\n\t}\n\treturn len + rb_event_length(event);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic inline unsigned\nrb_event_ts_length(struct ring_buffer_event *event)\n{\n\tunsigned len = 0;\n\n\tif (extended_time(event)) {\n\t\t/* time extends include the data event after it */\n\t\tlen = RB_LEN_TIME_EXTEND;\n\t\tevent = skip_time_extend(event);\n\t}\n\treturn len + rb_event_length(event);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_event_index",
          "args": [
            "event"
          ],
          "line": 2398
        },
        "resolved": true,
        "details": {
          "function_name": "rb_event_index",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1915-1921",
          "snippet": "static __always_inline unsigned\nrb_event_index(struct ring_buffer_event *event)\n{\n\tunsigned long addr = (unsigned long)event;\n\n\treturn (addr & ~PAGE_MASK) - BUF_PAGE_HDR_SIZE;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define BUF_PAGE_HDR_SIZE offsetof(struct buffer_data_page, data)"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define BUF_PAGE_HDR_SIZE offsetof(struct buffer_data_page, data)\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic __always_inline unsigned\nrb_event_index(struct ring_buffer_event *event)\n{\n\tunsigned long addr = (unsigned long)event;\n\n\treturn (addr & ~PAGE_MASK) - BUF_PAGE_HDR_SIZE;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_WRITE_MASK\t\t0xfffff\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic inline int\nrb_try_to_discard(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t  struct ring_buffer_event *event)\n{\n\tunsigned long new_index, old_index;\n\tstruct buffer_page *bpage;\n\tunsigned long index;\n\tunsigned long addr;\n\n\tnew_index = rb_event_index(event);\n\told_index = new_index + rb_event_ts_length(event);\n\taddr = (unsigned long)event;\n\taddr &= PAGE_MASK;\n\n\tbpage = READ_ONCE(cpu_buffer->tail_page);\n\n\tif (bpage->page == (void *)addr && rb_page_write(bpage) == old_index) {\n\t\tunsigned long write_mask =\n\t\t\tlocal_read(&bpage->write) & ~RB_WRITE_MASK;\n\t\tunsigned long event_length = rb_event_length(event);\n\t\t/*\n\t\t * This is on the tail page. It is possible that\n\t\t * a write could come in and move the tail page\n\t\t * and write to the next page. That is fine\n\t\t * because we just shorten what is on this page.\n\t\t */\n\t\told_index += write_mask;\n\t\tnew_index += write_mask;\n\t\tindex = local_cmpxchg(&bpage->write, old_index, new_index);\n\t\tif (index == old_index) {\n\t\t\t/* update counters */\n\t\t\tlocal_sub(event_length, &cpu_buffer->entries_bytes);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t/* could not discard */\n\treturn 0;\n}"
  },
  {
    "function_name": "sched_clock_stable",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2383-2386",
    "snippet": "static inline bool sched_clock_stable(void)\n{\n\treturn true;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic inline bool sched_clock_stable(void)\n{\n\treturn true;\n}"
  },
  {
    "function_name": "rb_calculate_event_length",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2350-2380",
    "snippet": "static unsigned rb_calculate_event_length(unsigned length)\n{\n\tstruct ring_buffer_event event; /* Used only for sizeof array */\n\n\t/* zero length can cause confusions */\n\tif (!length)\n\t\tlength++;\n\n\tif (length > RB_MAX_SMALL_DATA || RB_FORCE_8BYTE_ALIGNMENT)\n\t\tlength += sizeof(event.array[0]);\n\n\tlength += RB_EVNT_HDR_SIZE;\n\tlength = ALIGN(length, RB_ARCH_ALIGNMENT);\n\n\t/*\n\t * In case the time delta is larger than the 27 bits for it\n\t * in the header, we need to add a timestamp. If another\n\t * event comes in when trying to discard this one to increase\n\t * the length, then the timestamp will be added in the allocated\n\t * space of this event. If length is bigger than the size needed\n\t * for the TIME_EXTEND, then padding has to be used. The events\n\t * length must be either RB_LEN_TIME_EXTEND, or greater than or equal\n\t * to RB_LEN_TIME_EXTEND + 8, as 8 is the minimum size for padding.\n\t * As length is a multiple of 4, we only need to worry if it\n\t * is 12 (RB_LEN_TIME_EXTEND + 4).\n\t */\n\tif (length == RB_LEN_TIME_EXTEND + RB_ALIGNMENT)\n\t\tlength += RB_ALIGNMENT;\n\n\treturn length;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_MAX_SMALL_DATA\t(RB_ALIGNMENT * RINGBUF_TYPE_DATA_TYPE_LEN_MAX)",
      "#define RB_ALIGNMENT\t\t4U",
      "#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))"
    ],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "ALIGN",
          "args": [
            "length",
            "RB_ARCH_ALIGNMENT"
          ],
          "line": 2362
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_MAX_SMALL_DATA\t(RB_ALIGNMENT * RINGBUF_TYPE_DATA_TYPE_LEN_MAX)\n#define RB_ALIGNMENT\t\t4U\n#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic unsigned rb_calculate_event_length(unsigned length)\n{\n\tstruct ring_buffer_event event; /* Used only for sizeof array */\n\n\t/* zero length can cause confusions */\n\tif (!length)\n\t\tlength++;\n\n\tif (length > RB_MAX_SMALL_DATA || RB_FORCE_8BYTE_ALIGNMENT)\n\t\tlength += sizeof(event.array[0]);\n\n\tlength += RB_EVNT_HDR_SIZE;\n\tlength = ALIGN(length, RB_ARCH_ALIGNMENT);\n\n\t/*\n\t * In case the time delta is larger than the 27 bits for it\n\t * in the header, we need to add a timestamp. If another\n\t * event comes in when trying to discard this one to increase\n\t * the length, then the timestamp will be added in the allocated\n\t * space of this event. If length is bigger than the size needed\n\t * for the TIME_EXTEND, then padding has to be used. The events\n\t * length must be either RB_LEN_TIME_EXTEND, or greater than or equal\n\t * to RB_LEN_TIME_EXTEND + 8, as 8 is the minimum size for padding.\n\t * As length is a multiple of 4, we only need to worry if it\n\t * is 12 (RB_LEN_TIME_EXTEND + 4).\n\t */\n\tif (length == RB_LEN_TIME_EXTEND + RB_ALIGNMENT)\n\t\tlength += RB_ALIGNMENT;\n\n\treturn length;\n}"
  },
  {
    "function_name": "rb_update_event",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2317-2348",
    "snippet": "static void\nrb_update_event(struct ring_buffer_per_cpu *cpu_buffer,\n\t\tstruct ring_buffer_event *event,\n\t\tstruct rb_event_info *info)\n{\n\tunsigned length = info->length;\n\tu64 delta = info->delta;\n\n\t/* Only a commit updates the timestamp */\n\tif (unlikely(!rb_event_is_commit(cpu_buffer, event)))\n\t\tdelta = 0;\n\n\t/*\n\t * If we need to add a timestamp, then we\n\t * add it to the start of the reserved space.\n\t */\n\tif (unlikely(info->add_timestamp)) {\n\t\tbool abs = ring_buffer_time_stamp_abs(cpu_buffer->buffer);\n\n\t\tevent = rb_add_time_stamp(event, info->delta, abs);\n\t\tlength -= RB_LEN_TIME_EXTEND;\n\t\tdelta = 0;\n\t}\n\n\tevent->time_delta = delta;\n\tlength -= RB_EVNT_HDR_SIZE;\n\tif (length > RB_MAX_SMALL_DATA || RB_FORCE_8BYTE_ALIGNMENT) {\n\t\tevent->type_len = 0;\n\t\tevent->array[0] = length;\n\t} else\n\t\tevent->type_len = DIV_ROUND_UP(length, RB_ALIGNMENT);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_MAX_SMALL_DATA\t(RB_ALIGNMENT * RINGBUF_TYPE_DATA_TYPE_LEN_MAX)",
      "#define RB_ALIGNMENT\t\t4U",
      "#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))"
    ],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "DIV_ROUND_UP",
          "args": [
            "length",
            "RB_ALIGNMENT"
          ],
          "line": 2347
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_add_time_stamp",
          "args": [
            "event",
            "info->delta",
            "abs"
          ],
          "line": 2336
        },
        "resolved": true,
        "details": {
          "function_name": "rb_add_time_stamp",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2282-2301",
          "snippet": "ring_buffer_event *\nrb_add_time_stamp(struct ring_buffer_event *event, u64 delta, bool abs)\n{\n\tif (abs)\n\t\tevent->type_len = RINGBUF_TYPE_TIME_STAMP;\n\telse\n\t\tevent->type_len = RINGBUF_TYPE_TIME_EXTEND;\n\n\t/* Not the first event on the page, or not delta? */\n\tif (abs || rb_event_index(event)) {\n\t\tevent->time_delta = delta & TS_MASK;\n\t\tevent->array[0] = delta >> TS_SHIFT;\n\t} else {\n\t\t/* nope, just zero it */\n\t\tevent->time_delta = 0;\n\t\tevent->array[0] = 0;\n\t}\n\n\treturn skip_time_extend(event);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define TS_MASK\t\t((1ULL << TS_SHIFT) - 1)",
            "#define TS_SHIFT\t27"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define TS_MASK\t\t((1ULL << TS_SHIFT) - 1)\n#define TS_SHIFT\t27\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nring_buffer_event *\nrb_add_time_stamp(struct ring_buffer_event *event, u64 delta, bool abs)\n{\n\tif (abs)\n\t\tevent->type_len = RINGBUF_TYPE_TIME_STAMP;\n\telse\n\t\tevent->type_len = RINGBUF_TYPE_TIME_EXTEND;\n\n\t/* Not the first event on the page, or not delta? */\n\tif (abs || rb_event_index(event)) {\n\t\tevent->time_delta = delta & TS_MASK;\n\t\tevent->array[0] = delta >> TS_SHIFT;\n\t} else {\n\t\t/* nope, just zero it */\n\t\tevent->time_delta = 0;\n\t\tevent->array[0] = 0;\n\t}\n\n\treturn skip_time_extend(event);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ring_buffer_time_stamp_abs",
          "args": [
            "cpu_buffer->buffer"
          ],
          "line": 2334
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_time_stamp_abs",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1452-1455",
          "snippet": "bool ring_buffer_time_stamp_abs(struct ring_buffer *buffer)\n{\n\treturn buffer->time_stamp_abs;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nbool ring_buffer_time_stamp_abs(struct ring_buffer *buffer)\n{\n\treturn buffer->time_stamp_abs;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "info->add_timestamp"
          ],
          "line": 2333
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!rb_event_is_commit(cpu_buffer, event)"
          ],
          "line": 2326
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_event_is_commit",
          "args": [
            "cpu_buffer",
            "event"
          ],
          "line": 2326
        },
        "resolved": true,
        "details": {
          "function_name": "rb_event_is_commit",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2535-2547",
          "snippet": "static __always_inline bool\nrb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t   struct ring_buffer_event *event)\n{\n\tunsigned long addr = (unsigned long)event;\n\tunsigned long index;\n\n\tindex = rb_event_index(event);\n\taddr &= PAGE_MASK;\n\n\treturn cpu_buffer->commit_page->page == (void *)addr &&\n\t\trb_commit_index(cpu_buffer) == index;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic __always_inline bool\nrb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t   struct ring_buffer_event *event)\n{\n\tunsigned long addr = (unsigned long)event;\n\tunsigned long index;\n\n\tindex = rb_event_index(event);\n\taddr &= PAGE_MASK;\n\n\treturn cpu_buffer->commit_page->page == (void *)addr &&\n\t\trb_commit_index(cpu_buffer) == index;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_MAX_SMALL_DATA\t(RB_ALIGNMENT * RINGBUF_TYPE_DATA_TYPE_LEN_MAX)\n#define RB_ALIGNMENT\t\t4U\n#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic void\nrb_update_event(struct ring_buffer_per_cpu *cpu_buffer,\n\t\tstruct ring_buffer_event *event,\n\t\tstruct rb_event_info *info)\n{\n\tunsigned length = info->length;\n\tu64 delta = info->delta;\n\n\t/* Only a commit updates the timestamp */\n\tif (unlikely(!rb_event_is_commit(cpu_buffer, event)))\n\t\tdelta = 0;\n\n\t/*\n\t * If we need to add a timestamp, then we\n\t * add it to the start of the reserved space.\n\t */\n\tif (unlikely(info->add_timestamp)) {\n\t\tbool abs = ring_buffer_time_stamp_abs(cpu_buffer->buffer);\n\n\t\tevent = rb_add_time_stamp(event, info->delta, abs);\n\t\tlength -= RB_LEN_TIME_EXTEND;\n\t\tdelta = 0;\n\t}\n\n\tevent->time_delta = delta;\n\tlength -= RB_EVNT_HDR_SIZE;\n\tif (length > RB_MAX_SMALL_DATA || RB_FORCE_8BYTE_ALIGNMENT) {\n\t\tevent->type_len = 0;\n\t\tevent->array[0] = length;\n\t} else\n\t\tevent->type_len = DIV_ROUND_UP(length, RB_ALIGNMENT);\n}"
  },
  {
    "function_name": "rb_add_time_stamp",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2282-2301",
    "snippet": "ring_buffer_event *\nrb_add_time_stamp(struct ring_buffer_event *event, u64 delta, bool abs)\n{\n\tif (abs)\n\t\tevent->type_len = RINGBUF_TYPE_TIME_STAMP;\n\telse\n\t\tevent->type_len = RINGBUF_TYPE_TIME_EXTEND;\n\n\t/* Not the first event on the page, or not delta? */\n\tif (abs || rb_event_index(event)) {\n\t\tevent->time_delta = delta & TS_MASK;\n\t\tevent->array[0] = delta >> TS_SHIFT;\n\t} else {\n\t\t/* nope, just zero it */\n\t\tevent->time_delta = 0;\n\t\tevent->array[0] = 0;\n\t}\n\n\treturn skip_time_extend(event);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define TS_MASK\t\t((1ULL << TS_SHIFT) - 1)",
      "#define TS_SHIFT\t27"
    ],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "skip_time_extend",
          "args": [
            "event"
          ],
          "line": 2300
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_event_index",
          "args": [
            "event"
          ],
          "line": 2291
        },
        "resolved": true,
        "details": {
          "function_name": "rb_event_index",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1915-1921",
          "snippet": "static __always_inline unsigned\nrb_event_index(struct ring_buffer_event *event)\n{\n\tunsigned long addr = (unsigned long)event;\n\n\treturn (addr & ~PAGE_MASK) - BUF_PAGE_HDR_SIZE;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define BUF_PAGE_HDR_SIZE offsetof(struct buffer_data_page, data)"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define BUF_PAGE_HDR_SIZE offsetof(struct buffer_data_page, data)\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic __always_inline unsigned\nrb_event_index(struct ring_buffer_event *event)\n{\n\tunsigned long addr = (unsigned long)event;\n\n\treturn (addr & ~PAGE_MASK) - BUF_PAGE_HDR_SIZE;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define TS_MASK\t\t((1ULL << TS_SHIFT) - 1)\n#define TS_SHIFT\t27\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nring_buffer_event *\nrb_add_time_stamp(struct ring_buffer_event *event, u64 delta, bool abs)\n{\n\tif (abs)\n\t\tevent->type_len = RINGBUF_TYPE_TIME_STAMP;\n\telse\n\t\tevent->type_len = RINGBUF_TYPE_TIME_EXTEND;\n\n\t/* Not the first event on the page, or not delta? */\n\tif (abs || rb_event_index(event)) {\n\t\tevent->time_delta = delta & TS_MASK;\n\t\tevent->array[0] = delta >> TS_SHIFT;\n\t} else {\n\t\t/* nope, just zero it */\n\t\tevent->time_delta = 0;\n\t\tevent->array[0] = 0;\n\t}\n\n\treturn skip_time_extend(event);\n}"
  },
  {
    "function_name": "rb_move_tail",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2178-2279",
    "snippet": "ring_buffer_event *\nrb_move_tail(struct ring_buffer_per_cpu *cpu_buffer,\n\t     unsigned long tail, struct rb_event_info *info)\n{\n\tstruct buffer_page *tail_page = info->tail_page;\n\tstruct buffer_page *commit_page = cpu_buffer->commit_page;\n\tstruct ring_buffer *buffer = cpu_buffer->buffer;\n\tstruct buffer_page *next_page;\n\tint ret;\n\n\tnext_page = tail_page;\n\n\trb_inc_page(cpu_buffer, &next_page);\n\n\t/*\n\t * If for some reason, we had an interrupt storm that made\n\t * it all the way around the buffer, bail, and warn\n\t * about it.\n\t */\n\tif (unlikely(next_page == commit_page)) {\n\t\tlocal_inc(&cpu_buffer->commit_overrun);\n\t\tgoto out_reset;\n\t}\n\n\t/*\n\t * This is where the fun begins!\n\t *\n\t * We are fighting against races between a reader that\n\t * could be on another CPU trying to swap its reader\n\t * page with the buffer head.\n\t *\n\t * We are also fighting against interrupts coming in and\n\t * moving the head or tail on us as well.\n\t *\n\t * If the next page is the head page then we have filled\n\t * the buffer, unless the commit page is still on the\n\t * reader page.\n\t */\n\tif (rb_is_head_page(cpu_buffer, next_page, &tail_page->list)) {\n\n\t\t/*\n\t\t * If the commit is not on the reader page, then\n\t\t * move the header page.\n\t\t */\n\t\tif (!rb_is_reader_page(cpu_buffer->commit_page)) {\n\t\t\t/*\n\t\t\t * If we are not in overwrite mode,\n\t\t\t * this is easy, just stop here.\n\t\t\t */\n\t\t\tif (!(buffer->flags & RB_FL_OVERWRITE)) {\n\t\t\t\tlocal_inc(&cpu_buffer->dropped_events);\n\t\t\t\tgoto out_reset;\n\t\t\t}\n\n\t\t\tret = rb_handle_head_page(cpu_buffer,\n\t\t\t\t\t\t  tail_page,\n\t\t\t\t\t\t  next_page);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out_reset;\n\t\t\tif (ret)\n\t\t\t\tgoto out_again;\n\t\t} else {\n\t\t\t/*\n\t\t\t * We need to be careful here too. The\n\t\t\t * commit page could still be on the reader\n\t\t\t * page. We could have a small buffer, and\n\t\t\t * have filled up the buffer with events\n\t\t\t * from interrupts and such, and wrapped.\n\t\t\t *\n\t\t\t * Note, if the tail page is also the on the\n\t\t\t * reader_page, we let it move out.\n\t\t\t */\n\t\t\tif (unlikely((cpu_buffer->commit_page !=\n\t\t\t\t      cpu_buffer->tail_page) &&\n\t\t\t\t     (cpu_buffer->commit_page ==\n\t\t\t\t      cpu_buffer->reader_page))) {\n\t\t\t\tlocal_inc(&cpu_buffer->commit_overrun);\n\t\t\t\tgoto out_reset;\n\t\t\t}\n\t\t}\n\t}\n\n\trb_tail_page_update(cpu_buffer, tail_page, next_page);\n\n out_again:\n\n\trb_reset_tail(cpu_buffer, tail, info);\n\n\t/* Commit what we have for now. */\n\trb_end_commit(cpu_buffer);\n\t/* rb_end_commit() decs committing */\n\tlocal_inc(&cpu_buffer->committing);\n\n\t/* fail and let the caller try again */\n\treturn ERR_PTR(-EAGAIN);\n\n out_reset:\n\t/* reset write */\n\trb_reset_tail(cpu_buffer, tail, info);\n\n\treturn NULL;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_reset_tail",
          "args": [
            "cpu_buffer",
            "tail",
            "info"
          ],
          "line": 2276
        },
        "resolved": true,
        "details": {
          "function_name": "rb_reset_tail",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2103-2171",
          "snippet": "static inline void\nrb_reset_tail(struct ring_buffer_per_cpu *cpu_buffer,\n\t      unsigned long tail, struct rb_event_info *info)\n{\n\tstruct buffer_page *tail_page = info->tail_page;\n\tstruct ring_buffer_event *event;\n\tunsigned long length = info->length;\n\n\t/*\n\t * Only the event that crossed the page boundary\n\t * must fill the old tail_page with padding.\n\t */\n\tif (tail >= BUF_PAGE_SIZE) {\n\t\t/*\n\t\t * If the page was filled, then we still need\n\t\t * to update the real_end. Reset it to zero\n\t\t * and the reader will ignore it.\n\t\t */\n\t\tif (tail == BUF_PAGE_SIZE)\n\t\t\ttail_page->real_end = 0;\n\n\t\tlocal_sub(length, &tail_page->write);\n\t\treturn;\n\t}\n\n\tevent = __rb_page_index(tail_page, tail);\n\n\t/* account for padding bytes */\n\tlocal_add(BUF_PAGE_SIZE - tail, &cpu_buffer->entries_bytes);\n\n\t/*\n\t * Save the original length to the meta data.\n\t * This will be used by the reader to add lost event\n\t * counter.\n\t */\n\ttail_page->real_end = tail;\n\n\t/*\n\t * If this event is bigger than the minimum size, then\n\t * we need to be careful that we don't subtract the\n\t * write counter enough to allow another writer to slip\n\t * in on this page.\n\t * We put in a discarded commit instead, to make sure\n\t * that this space is not used again.\n\t *\n\t * If we are less than the minimum size, we don't need to\n\t * worry about it.\n\t */\n\tif (tail > (BUF_PAGE_SIZE - RB_EVNT_MIN_SIZE)) {\n\t\t/* No room for any events */\n\n\t\t/* Mark the rest of the page with padding */\n\t\trb_event_set_padding(event);\n\n\t\t/* Set the write back to the previous setting */\n\t\tlocal_sub(length, &tail_page->write);\n\t\treturn;\n\t}\n\n\t/* Put in a discarded event */\n\tevent->array[0] = (BUF_PAGE_SIZE - tail) - RB_EVNT_HDR_SIZE;\n\tevent->type_len = RINGBUF_TYPE_PADDING;\n\t/* time delta must be non zero */\n\tevent->time_delta = 1;\n\n\t/* Set write to end of buffer */\n\tlength = (tail + length) - BUF_PAGE_SIZE;\n\tlocal_sub(length, &tail_page->write);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)",
            "#define RB_EVNT_MIN_SIZE\t8U\t/* two 32bit words */",
            "#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)\n#define RB_EVNT_MIN_SIZE\t8U\t/* two 32bit words */\n#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic inline void\nrb_reset_tail(struct ring_buffer_per_cpu *cpu_buffer,\n\t      unsigned long tail, struct rb_event_info *info)\n{\n\tstruct buffer_page *tail_page = info->tail_page;\n\tstruct ring_buffer_event *event;\n\tunsigned long length = info->length;\n\n\t/*\n\t * Only the event that crossed the page boundary\n\t * must fill the old tail_page with padding.\n\t */\n\tif (tail >= BUF_PAGE_SIZE) {\n\t\t/*\n\t\t * If the page was filled, then we still need\n\t\t * to update the real_end. Reset it to zero\n\t\t * and the reader will ignore it.\n\t\t */\n\t\tif (tail == BUF_PAGE_SIZE)\n\t\t\ttail_page->real_end = 0;\n\n\t\tlocal_sub(length, &tail_page->write);\n\t\treturn;\n\t}\n\n\tevent = __rb_page_index(tail_page, tail);\n\n\t/* account for padding bytes */\n\tlocal_add(BUF_PAGE_SIZE - tail, &cpu_buffer->entries_bytes);\n\n\t/*\n\t * Save the original length to the meta data.\n\t * This will be used by the reader to add lost event\n\t * counter.\n\t */\n\ttail_page->real_end = tail;\n\n\t/*\n\t * If this event is bigger than the minimum size, then\n\t * we need to be careful that we don't subtract the\n\t * write counter enough to allow another writer to slip\n\t * in on this page.\n\t * We put in a discarded commit instead, to make sure\n\t * that this space is not used again.\n\t *\n\t * If we are less than the minimum size, we don't need to\n\t * worry about it.\n\t */\n\tif (tail > (BUF_PAGE_SIZE - RB_EVNT_MIN_SIZE)) {\n\t\t/* No room for any events */\n\n\t\t/* Mark the rest of the page with padding */\n\t\trb_event_set_padding(event);\n\n\t\t/* Set the write back to the previous setting */\n\t\tlocal_sub(length, &tail_page->write);\n\t\treturn;\n\t}\n\n\t/* Put in a discarded event */\n\tevent->array[0] = (BUF_PAGE_SIZE - tail) - RB_EVNT_HDR_SIZE;\n\tevent->type_len = RINGBUF_TYPE_PADDING;\n\t/* time delta must be non zero */\n\tevent->time_delta = 1;\n\n\t/* Set write to end of buffer */\n\tlength = (tail + length) - BUF_PAGE_SIZE;\n\tlocal_sub(length, &tail_page->write);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-EAGAIN"
          ],
          "line": 2272
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_inc",
          "args": [
            "&cpu_buffer->committing"
          ],
          "line": 2269
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_end_commit",
          "args": [
            "cpu_buffer"
          ],
          "line": 2267
        },
        "resolved": true,
        "details": {
          "function_name": "rb_end_commit",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "2490-2520",
          "snippet": "static __always_inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tunsigned long commits;\n\n\tif (RB_WARN_ON(cpu_buffer,\n\t\t       !local_read(&cpu_buffer->committing)))\n\t\treturn;\n\n again:\n\tcommits = local_read(&cpu_buffer->commits);\n\t/* synchronize with interrupts */\n\tbarrier();\n\tif (local_read(&cpu_buffer->committing) == 1)\n\t\trb_set_commit_to_write(cpu_buffer);\n\n\tlocal_dec(&cpu_buffer->committing);\n\n\t/* synchronize with interrupts */\n\tbarrier();\n\n\t/*\n\t * Need to account for interrupts coming in between the\n\t * updating of the commit page and the clearing of the\n\t * committing counter.\n\t */\n\tif (unlikely(local_read(&cpu_buffer->commits) != commits) &&\n\t    !local_read(&cpu_buffer->committing)) {\n\t\tlocal_inc(&cpu_buffer->committing);\n\t\tgoto again;\n\t}\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tunsigned long commits;\n\n\tif (RB_WARN_ON(cpu_buffer,\n\t\t       !local_read(&cpu_buffer->committing)))\n\t\treturn;\n\n again:\n\tcommits = local_read(&cpu_buffer->commits);\n\t/* synchronize with interrupts */\n\tbarrier();\n\tif (local_read(&cpu_buffer->committing) == 1)\n\t\trb_set_commit_to_write(cpu_buffer);\n\n\tlocal_dec(&cpu_buffer->committing);\n\n\t/* synchronize with interrupts */\n\tbarrier();\n\n\t/*\n\t * Need to account for interrupts coming in between the\n\t * updating of the commit page and the clearing of the\n\t * committing counter.\n\t */\n\tif (unlikely(local_read(&cpu_buffer->commits) != commits) &&\n\t    !local_read(&cpu_buffer->committing)) {\n\t\tlocal_inc(&cpu_buffer->committing);\n\t\tgoto again;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_tail_page_update",
          "args": [
            "cpu_buffer",
            "tail_page",
            "next_page"
          ],
          "line": 2260
        },
        "resolved": true,
        "details": {
          "function_name": "rb_tail_page_update",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1038-1096",
          "snippet": "static void rb_tail_page_update(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t       struct buffer_page *tail_page,\n\t\t\t       struct buffer_page *next_page)\n{\n\tunsigned long old_entries;\n\tunsigned long old_write;\n\n\t/*\n\t * The tail page now needs to be moved forward.\n\t *\n\t * We need to reset the tail page, but without messing\n\t * with possible erasing of data brought in by interrupts\n\t * that have moved the tail page and are currently on it.\n\t *\n\t * We add a counter to the write field to denote this.\n\t */\n\told_write = local_add_return(RB_WRITE_INTCNT, &next_page->write);\n\told_entries = local_add_return(RB_WRITE_INTCNT, &next_page->entries);\n\n\t/*\n\t * Just make sure we have seen our old_write and synchronize\n\t * with any interrupts that come in.\n\t */\n\tbarrier();\n\n\t/*\n\t * If the tail page is still the same as what we think\n\t * it is, then it is up to us to update the tail\n\t * pointer.\n\t */\n\tif (tail_page == READ_ONCE(cpu_buffer->tail_page)) {\n\t\t/* Zero the write counter */\n\t\tunsigned long val = old_write & ~RB_WRITE_MASK;\n\t\tunsigned long eval = old_entries & ~RB_WRITE_MASK;\n\n\t\t/*\n\t\t * This will only succeed if an interrupt did\n\t\t * not come in and change it. In which case, we\n\t\t * do not want to modify it.\n\t\t *\n\t\t * We add (void) to let the compiler know that we do not care\n\t\t * about the return value of these functions. We use the\n\t\t * cmpxchg to only update if an interrupt did not already\n\t\t * do it for us. If the cmpxchg fails, we don't care.\n\t\t */\n\t\t(void)local_cmpxchg(&next_page->write, old_write, val);\n\t\t(void)local_cmpxchg(&next_page->entries, old_entries, eval);\n\n\t\t/*\n\t\t * No need to worry about races with clearing out the commit.\n\t\t * it only can increment when a commit takes place. But that\n\t\t * only happens in the outer most nested commit.\n\t\t */\n\t\tlocal_set(&next_page->page->commit, 0);\n\n\t\t/* Again, either we update tail_page or an interrupt does */\n\t\t(void)cmpxchg(&cpu_buffer->tail_page, tail_page, next_page);\n\t}\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_WRITE_INTCNT\t\t(1 << 20)",
            "#define RB_WRITE_MASK\t\t0xfffff"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_WRITE_INTCNT\t\t(1 << 20)\n#define RB_WRITE_MASK\t\t0xfffff\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_tail_page_update(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t       struct buffer_page *tail_page,\n\t\t\t       struct buffer_page *next_page)\n{\n\tunsigned long old_entries;\n\tunsigned long old_write;\n\n\t/*\n\t * The tail page now needs to be moved forward.\n\t *\n\t * We need to reset the tail page, but without messing\n\t * with possible erasing of data brought in by interrupts\n\t * that have moved the tail page and are currently on it.\n\t *\n\t * We add a counter to the write field to denote this.\n\t */\n\told_write = local_add_return(RB_WRITE_INTCNT, &next_page->write);\n\told_entries = local_add_return(RB_WRITE_INTCNT, &next_page->entries);\n\n\t/*\n\t * Just make sure we have seen our old_write and synchronize\n\t * with any interrupts that come in.\n\t */\n\tbarrier();\n\n\t/*\n\t * If the tail page is still the same as what we think\n\t * it is, then it is up to us to update the tail\n\t * pointer.\n\t */\n\tif (tail_page == READ_ONCE(cpu_buffer->tail_page)) {\n\t\t/* Zero the write counter */\n\t\tunsigned long val = old_write & ~RB_WRITE_MASK;\n\t\tunsigned long eval = old_entries & ~RB_WRITE_MASK;\n\n\t\t/*\n\t\t * This will only succeed if an interrupt did\n\t\t * not come in and change it. In which case, we\n\t\t * do not want to modify it.\n\t\t *\n\t\t * We add (void) to let the compiler know that we do not care\n\t\t * about the return value of these functions. We use the\n\t\t * cmpxchg to only update if an interrupt did not already\n\t\t * do it for us. If the cmpxchg fails, we don't care.\n\t\t */\n\t\t(void)local_cmpxchg(&next_page->write, old_write, val);\n\t\t(void)local_cmpxchg(&next_page->entries, old_entries, eval);\n\n\t\t/*\n\t\t * No need to worry about races with clearing out the commit.\n\t\t * it only can increment when a commit takes place. But that\n\t\t * only happens in the outer most nested commit.\n\t\t */\n\t\tlocal_set(&next_page->page->commit, 0);\n\n\t\t/* Again, either we update tail_page or an interrupt does */\n\t\t(void)cmpxchg(&cpu_buffer->tail_page, tail_page, next_page);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_inc",
          "args": [
            "&cpu_buffer->commit_overrun"
          ],
          "line": 2254
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "(cpu_buffer->commit_page !=\n\t\t\t\t      cpu_buffer->tail_page) &&\n\t\t\t\t     (cpu_buffer->commit_page ==\n\t\t\t\t      cpu_buffer->reader_page)"
          ],
          "line": 2250
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_handle_head_page",
          "args": [
            "cpu_buffer",
            "tail_page",
            "next_page"
          ],
          "line": 2232
        },
        "resolved": true,
        "details": {
          "function_name": "rb_handle_head_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1949-2101",
          "snippet": "static int\nrb_handle_head_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t    struct buffer_page *tail_page,\n\t\t    struct buffer_page *next_page)\n{\n\tstruct buffer_page *new_head;\n\tint entries;\n\tint type;\n\tint ret;\n\n\tentries = rb_page_entries(next_page);\n\n\t/*\n\t * The hard part is here. We need to move the head\n\t * forward, and protect against both readers on\n\t * other CPUs and writers coming in via interrupts.\n\t */\n\ttype = rb_head_page_set_update(cpu_buffer, next_page, tail_page,\n\t\t\t\t       RB_PAGE_HEAD);\n\n\t/*\n\t * type can be one of four:\n\t *  NORMAL - an interrupt already moved it for us\n\t *  HEAD   - we are the first to get here.\n\t *  UPDATE - we are the interrupt interrupting\n\t *           a current move.\n\t *  MOVED  - a reader on another CPU moved the next\n\t *           pointer to its reader page. Give up\n\t *           and try again.\n\t */\n\n\tswitch (type) {\n\tcase RB_PAGE_HEAD:\n\t\t/*\n\t\t * We changed the head to UPDATE, thus\n\t\t * it is our responsibility to update\n\t\t * the counters.\n\t\t */\n\t\tlocal_add(entries, &cpu_buffer->overrun);\n\t\tlocal_sub(BUF_PAGE_SIZE, &cpu_buffer->entries_bytes);\n\n\t\t/*\n\t\t * The entries will be zeroed out when we move the\n\t\t * tail page.\n\t\t */\n\n\t\t/* still more to do */\n\t\tbreak;\n\n\tcase RB_PAGE_UPDATE:\n\t\t/*\n\t\t * This is an interrupt that interrupt the\n\t\t * previous update. Still more to do.\n\t\t */\n\t\tbreak;\n\tcase RB_PAGE_NORMAL:\n\t\t/*\n\t\t * An interrupt came in before the update\n\t\t * and processed this for us.\n\t\t * Nothing left to do.\n\t\t */\n\t\treturn 1;\n\tcase RB_PAGE_MOVED:\n\t\t/*\n\t\t * The reader is on another CPU and just did\n\t\t * a swap with our next_page.\n\t\t * Try again.\n\t\t */\n\t\treturn 1;\n\tdefault:\n\t\tRB_WARN_ON(cpu_buffer, 1); /* WTF??? */\n\t\treturn -1;\n\t}\n\n\t/*\n\t * Now that we are here, the old head pointer is\n\t * set to UPDATE. This will keep the reader from\n\t * swapping the head page with the reader page.\n\t * The reader (on another CPU) will spin till\n\t * we are finished.\n\t *\n\t * We just need to protect against interrupts\n\t * doing the job. We will set the next pointer\n\t * to HEAD. After that, we set the old pointer\n\t * to NORMAL, but only if it was HEAD before.\n\t * otherwise we are an interrupt, and only\n\t * want the outer most commit to reset it.\n\t */\n\tnew_head = next_page;\n\trb_inc_page(cpu_buffer, &new_head);\n\n\tret = rb_head_page_set_head(cpu_buffer, new_head, next_page,\n\t\t\t\t    RB_PAGE_NORMAL);\n\n\t/*\n\t * Valid returns are:\n\t *  HEAD   - an interrupt came in and already set it.\n\t *  NORMAL - One of two things:\n\t *            1) We really set it.\n\t *            2) A bunch of interrupts came in and moved\n\t *               the page forward again.\n\t */\n\tswitch (ret) {\n\tcase RB_PAGE_HEAD:\n\tcase RB_PAGE_NORMAL:\n\t\t/* OK */\n\t\tbreak;\n\tdefault:\n\t\tRB_WARN_ON(cpu_buffer, 1);\n\t\treturn -1;\n\t}\n\n\t/*\n\t * It is possible that an interrupt came in,\n\t * set the head up, then more interrupts came in\n\t * and moved it again. When we get back here,\n\t * the page would have been set to NORMAL but we\n\t * just set it back to HEAD.\n\t *\n\t * How do you detect this? Well, if that happened\n\t * the tail page would have moved.\n\t */\n\tif (ret == RB_PAGE_NORMAL) {\n\t\tstruct buffer_page *buffer_tail_page;\n\n\t\tbuffer_tail_page = READ_ONCE(cpu_buffer->tail_page);\n\t\t/*\n\t\t * If the tail had moved passed next, then we need\n\t\t * to reset the pointer.\n\t\t */\n\t\tif (buffer_tail_page != tail_page &&\n\t\t    buffer_tail_page != next_page)\n\t\t\trb_head_page_set_normal(cpu_buffer, new_head,\n\t\t\t\t\t\tnext_page,\n\t\t\t\t\t\tRB_PAGE_HEAD);\n\t}\n\n\t/*\n\t * If this was the outer most commit (the one that\n\t * changed the original pointer from HEAD to UPDATE),\n\t * then it is up to us to reset it to NORMAL.\n\t */\n\tif (type == RB_PAGE_HEAD) {\n\t\tret = rb_head_page_set_normal(cpu_buffer, next_page,\n\t\t\t\t\t      tail_page,\n\t\t\t\t\t      RB_PAGE_UPDATE);\n\t\tif (RB_WARN_ON(cpu_buffer,\n\t\t\t       ret != RB_PAGE_UPDATE))\n\t\t\treturn -1;\n\t}\n\n\treturn 0;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_PAGE_MOVED\t\t4UL",
            "#define RB_PAGE_UPDATE\t\t2UL",
            "#define RB_PAGE_HEAD\t\t1UL",
            "#define RB_PAGE_NORMAL\t\t0UL",
            "#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_PAGE_MOVED\t\t4UL\n#define RB_PAGE_UPDATE\t\t2UL\n#define RB_PAGE_HEAD\t\t1UL\n#define RB_PAGE_NORMAL\t\t0UL\n#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int\nrb_handle_head_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t    struct buffer_page *tail_page,\n\t\t    struct buffer_page *next_page)\n{\n\tstruct buffer_page *new_head;\n\tint entries;\n\tint type;\n\tint ret;\n\n\tentries = rb_page_entries(next_page);\n\n\t/*\n\t * The hard part is here. We need to move the head\n\t * forward, and protect against both readers on\n\t * other CPUs and writers coming in via interrupts.\n\t */\n\ttype = rb_head_page_set_update(cpu_buffer, next_page, tail_page,\n\t\t\t\t       RB_PAGE_HEAD);\n\n\t/*\n\t * type can be one of four:\n\t *  NORMAL - an interrupt already moved it for us\n\t *  HEAD   - we are the first to get here.\n\t *  UPDATE - we are the interrupt interrupting\n\t *           a current move.\n\t *  MOVED  - a reader on another CPU moved the next\n\t *           pointer to its reader page. Give up\n\t *           and try again.\n\t */\n\n\tswitch (type) {\n\tcase RB_PAGE_HEAD:\n\t\t/*\n\t\t * We changed the head to UPDATE, thus\n\t\t * it is our responsibility to update\n\t\t * the counters.\n\t\t */\n\t\tlocal_add(entries, &cpu_buffer->overrun);\n\t\tlocal_sub(BUF_PAGE_SIZE, &cpu_buffer->entries_bytes);\n\n\t\t/*\n\t\t * The entries will be zeroed out when we move the\n\t\t * tail page.\n\t\t */\n\n\t\t/* still more to do */\n\t\tbreak;\n\n\tcase RB_PAGE_UPDATE:\n\t\t/*\n\t\t * This is an interrupt that interrupt the\n\t\t * previous update. Still more to do.\n\t\t */\n\t\tbreak;\n\tcase RB_PAGE_NORMAL:\n\t\t/*\n\t\t * An interrupt came in before the update\n\t\t * and processed this for us.\n\t\t * Nothing left to do.\n\t\t */\n\t\treturn 1;\n\tcase RB_PAGE_MOVED:\n\t\t/*\n\t\t * The reader is on another CPU and just did\n\t\t * a swap with our next_page.\n\t\t * Try again.\n\t\t */\n\t\treturn 1;\n\tdefault:\n\t\tRB_WARN_ON(cpu_buffer, 1); /* WTF??? */\n\t\treturn -1;\n\t}\n\n\t/*\n\t * Now that we are here, the old head pointer is\n\t * set to UPDATE. This will keep the reader from\n\t * swapping the head page with the reader page.\n\t * The reader (on another CPU) will spin till\n\t * we are finished.\n\t *\n\t * We just need to protect against interrupts\n\t * doing the job. We will set the next pointer\n\t * to HEAD. After that, we set the old pointer\n\t * to NORMAL, but only if it was HEAD before.\n\t * otherwise we are an interrupt, and only\n\t * want the outer most commit to reset it.\n\t */\n\tnew_head = next_page;\n\trb_inc_page(cpu_buffer, &new_head);\n\n\tret = rb_head_page_set_head(cpu_buffer, new_head, next_page,\n\t\t\t\t    RB_PAGE_NORMAL);\n\n\t/*\n\t * Valid returns are:\n\t *  HEAD   - an interrupt came in and already set it.\n\t *  NORMAL - One of two things:\n\t *            1) We really set it.\n\t *            2) A bunch of interrupts came in and moved\n\t *               the page forward again.\n\t */\n\tswitch (ret) {\n\tcase RB_PAGE_HEAD:\n\tcase RB_PAGE_NORMAL:\n\t\t/* OK */\n\t\tbreak;\n\tdefault:\n\t\tRB_WARN_ON(cpu_buffer, 1);\n\t\treturn -1;\n\t}\n\n\t/*\n\t * It is possible that an interrupt came in,\n\t * set the head up, then more interrupts came in\n\t * and moved it again. When we get back here,\n\t * the page would have been set to NORMAL but we\n\t * just set it back to HEAD.\n\t *\n\t * How do you detect this? Well, if that happened\n\t * the tail page would have moved.\n\t */\n\tif (ret == RB_PAGE_NORMAL) {\n\t\tstruct buffer_page *buffer_tail_page;\n\n\t\tbuffer_tail_page = READ_ONCE(cpu_buffer->tail_page);\n\t\t/*\n\t\t * If the tail had moved passed next, then we need\n\t\t * to reset the pointer.\n\t\t */\n\t\tif (buffer_tail_page != tail_page &&\n\t\t    buffer_tail_page != next_page)\n\t\t\trb_head_page_set_normal(cpu_buffer, new_head,\n\t\t\t\t\t\tnext_page,\n\t\t\t\t\t\tRB_PAGE_HEAD);\n\t}\n\n\t/*\n\t * If this was the outer most commit (the one that\n\t * changed the original pointer from HEAD to UPDATE),\n\t * then it is up to us to reset it to NORMAL.\n\t */\n\tif (type == RB_PAGE_HEAD) {\n\t\tret = rb_head_page_set_normal(cpu_buffer, next_page,\n\t\t\t\t\t      tail_page,\n\t\t\t\t\t      RB_PAGE_UPDATE);\n\t\tif (RB_WARN_ON(cpu_buffer,\n\t\t\t       ret != RB_PAGE_UPDATE))\n\t\t\treturn -1;\n\t}\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_inc",
          "args": [
            "&cpu_buffer->dropped_events"
          ],
          "line": 2228
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_is_reader_page",
          "args": [
            "cpu_buffer->commit_page"
          ],
          "line": 2222
        },
        "resolved": true,
        "details": {
          "function_name": "rb_is_reader_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "865-870",
          "snippet": "static bool rb_is_reader_page(struct buffer_page *page)\n{\n\tstruct list_head *list = page->list.prev;\n\n\treturn rb_list_head(list->next) != &page->list;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic bool rb_is_reader_page(struct buffer_page *page)\n{\n\tstruct list_head *list = page->list.prev;\n\n\treturn rb_list_head(list->next) != &page->list;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_is_head_page",
          "args": [
            "cpu_buffer",
            "next_page",
            "&tail_page->list"
          ],
          "line": 2216
        },
        "resolved": true,
        "details": {
          "function_name": "rb_is_head_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "844-856",
          "snippet": "static inline int\nrb_is_head_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\tstruct buffer_page *page, struct list_head *list)\n{\n\tunsigned long val;\n\n\tval = (unsigned long)list->next;\n\n\tif ((val & ~RB_FLAG_MASK) != (unsigned long)&page->list)\n\t\treturn RB_PAGE_MOVED;\n\n\treturn val & RB_FLAG_MASK;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_PAGE_MOVED\t\t4UL",
            "#define RB_FLAG_MASK\t\t3UL"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_PAGE_MOVED\t\t4UL\n#define RB_FLAG_MASK\t\t3UL\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline int\nrb_is_head_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\tstruct buffer_page *page, struct list_head *list)\n{\n\tunsigned long val;\n\n\tval = (unsigned long)list->next;\n\n\tif ((val & ~RB_FLAG_MASK) != (unsigned long)&page->list)\n\t\treturn RB_PAGE_MOVED;\n\n\treturn val & RB_FLAG_MASK;\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_inc",
          "args": [
            "&cpu_buffer->commit_overrun"
          ],
          "line": 2198
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "next_page == commit_page"
          ],
          "line": 2197
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_inc_page",
          "args": [
            "cpu_buffer",
            "&next_page"
          ],
          "line": 2190
        },
        "resolved": true,
        "details": {
          "function_name": "rb_inc_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "974-980",
          "snippet": "static inline void rb_inc_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t       struct buffer_page **bpage)\n{\n\tstruct list_head *p = rb_list_head((*bpage)->list.next);\n\n\t*bpage = list_entry(p, struct buffer_page, list);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline void rb_inc_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t       struct buffer_page **bpage)\n{\n\tstruct list_head *p = rb_list_head((*bpage)->list.next);\n\n\t*bpage = list_entry(p, struct buffer_page, list);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nring_buffer_event *\nrb_move_tail(struct ring_buffer_per_cpu *cpu_buffer,\n\t     unsigned long tail, struct rb_event_info *info)\n{\n\tstruct buffer_page *tail_page = info->tail_page;\n\tstruct buffer_page *commit_page = cpu_buffer->commit_page;\n\tstruct ring_buffer *buffer = cpu_buffer->buffer;\n\tstruct buffer_page *next_page;\n\tint ret;\n\n\tnext_page = tail_page;\n\n\trb_inc_page(cpu_buffer, &next_page);\n\n\t/*\n\t * If for some reason, we had an interrupt storm that made\n\t * it all the way around the buffer, bail, and warn\n\t * about it.\n\t */\n\tif (unlikely(next_page == commit_page)) {\n\t\tlocal_inc(&cpu_buffer->commit_overrun);\n\t\tgoto out_reset;\n\t}\n\n\t/*\n\t * This is where the fun begins!\n\t *\n\t * We are fighting against races between a reader that\n\t * could be on another CPU trying to swap its reader\n\t * page with the buffer head.\n\t *\n\t * We are also fighting against interrupts coming in and\n\t * moving the head or tail on us as well.\n\t *\n\t * If the next page is the head page then we have filled\n\t * the buffer, unless the commit page is still on the\n\t * reader page.\n\t */\n\tif (rb_is_head_page(cpu_buffer, next_page, &tail_page->list)) {\n\n\t\t/*\n\t\t * If the commit is not on the reader page, then\n\t\t * move the header page.\n\t\t */\n\t\tif (!rb_is_reader_page(cpu_buffer->commit_page)) {\n\t\t\t/*\n\t\t\t * If we are not in overwrite mode,\n\t\t\t * this is easy, just stop here.\n\t\t\t */\n\t\t\tif (!(buffer->flags & RB_FL_OVERWRITE)) {\n\t\t\t\tlocal_inc(&cpu_buffer->dropped_events);\n\t\t\t\tgoto out_reset;\n\t\t\t}\n\n\t\t\tret = rb_handle_head_page(cpu_buffer,\n\t\t\t\t\t\t  tail_page,\n\t\t\t\t\t\t  next_page);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out_reset;\n\t\t\tif (ret)\n\t\t\t\tgoto out_again;\n\t\t} else {\n\t\t\t/*\n\t\t\t * We need to be careful here too. The\n\t\t\t * commit page could still be on the reader\n\t\t\t * page. We could have a small buffer, and\n\t\t\t * have filled up the buffer with events\n\t\t\t * from interrupts and such, and wrapped.\n\t\t\t *\n\t\t\t * Note, if the tail page is also the on the\n\t\t\t * reader_page, we let it move out.\n\t\t\t */\n\t\t\tif (unlikely((cpu_buffer->commit_page !=\n\t\t\t\t      cpu_buffer->tail_page) &&\n\t\t\t\t     (cpu_buffer->commit_page ==\n\t\t\t\t      cpu_buffer->reader_page))) {\n\t\t\t\tlocal_inc(&cpu_buffer->commit_overrun);\n\t\t\t\tgoto out_reset;\n\t\t\t}\n\t\t}\n\t}\n\n\trb_tail_page_update(cpu_buffer, tail_page, next_page);\n\n out_again:\n\n\trb_reset_tail(cpu_buffer, tail, info);\n\n\t/* Commit what we have for now. */\n\trb_end_commit(cpu_buffer);\n\t/* rb_end_commit() decs committing */\n\tlocal_inc(&cpu_buffer->committing);\n\n\t/* fail and let the caller try again */\n\treturn ERR_PTR(-EAGAIN);\n\n out_reset:\n\t/* reset write */\n\trb_reset_tail(cpu_buffer, tail, info);\n\n\treturn NULL;\n}"
  },
  {
    "function_name": "rb_reset_tail",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "2103-2171",
    "snippet": "static inline void\nrb_reset_tail(struct ring_buffer_per_cpu *cpu_buffer,\n\t      unsigned long tail, struct rb_event_info *info)\n{\n\tstruct buffer_page *tail_page = info->tail_page;\n\tstruct ring_buffer_event *event;\n\tunsigned long length = info->length;\n\n\t/*\n\t * Only the event that crossed the page boundary\n\t * must fill the old tail_page with padding.\n\t */\n\tif (tail >= BUF_PAGE_SIZE) {\n\t\t/*\n\t\t * If the page was filled, then we still need\n\t\t * to update the real_end. Reset it to zero\n\t\t * and the reader will ignore it.\n\t\t */\n\t\tif (tail == BUF_PAGE_SIZE)\n\t\t\ttail_page->real_end = 0;\n\n\t\tlocal_sub(length, &tail_page->write);\n\t\treturn;\n\t}\n\n\tevent = __rb_page_index(tail_page, tail);\n\n\t/* account for padding bytes */\n\tlocal_add(BUF_PAGE_SIZE - tail, &cpu_buffer->entries_bytes);\n\n\t/*\n\t * Save the original length to the meta data.\n\t * This will be used by the reader to add lost event\n\t * counter.\n\t */\n\ttail_page->real_end = tail;\n\n\t/*\n\t * If this event is bigger than the minimum size, then\n\t * we need to be careful that we don't subtract the\n\t * write counter enough to allow another writer to slip\n\t * in on this page.\n\t * We put in a discarded commit instead, to make sure\n\t * that this space is not used again.\n\t *\n\t * If we are less than the minimum size, we don't need to\n\t * worry about it.\n\t */\n\tif (tail > (BUF_PAGE_SIZE - RB_EVNT_MIN_SIZE)) {\n\t\t/* No room for any events */\n\n\t\t/* Mark the rest of the page with padding */\n\t\trb_event_set_padding(event);\n\n\t\t/* Set the write back to the previous setting */\n\t\tlocal_sub(length, &tail_page->write);\n\t\treturn;\n\t}\n\n\t/* Put in a discarded event */\n\tevent->array[0] = (BUF_PAGE_SIZE - tail) - RB_EVNT_HDR_SIZE;\n\tevent->type_len = RINGBUF_TYPE_PADDING;\n\t/* time delta must be non zero */\n\tevent->time_delta = 1;\n\n\t/* Set write to end of buffer */\n\tlength = (tail + length) - BUF_PAGE_SIZE;\n\tlocal_sub(length, &tail_page->write);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)",
      "#define RB_EVNT_MIN_SIZE\t8U\t/* two 32bit words */",
      "#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))"
    ],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_sub",
          "args": [
            "length",
            "&tail_page->write"
          ],
          "line": 2170
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_sub",
          "args": [
            "length",
            "&tail_page->write"
          ],
          "line": 2158
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_event_set_padding",
          "args": [
            "event"
          ],
          "line": 2155
        },
        "resolved": true,
        "details": {
          "function_name": "rb_event_set_padding",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "161-166",
          "snippet": "static void rb_event_set_padding(struct ring_buffer_event *event)\n{\n\t/* padding has a NULL time_delta */\n\tevent->type_len = RINGBUF_TYPE_PADDING;\n\tevent->time_delta = 0;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic void rb_event_set_padding(struct ring_buffer_event *event)\n{\n\t/* padding has a NULL time_delta */\n\tevent->type_len = RINGBUF_TYPE_PADDING;\n\tevent->time_delta = 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_add",
          "args": [
            "BUF_PAGE_SIZE - tail",
            "&cpu_buffer->entries_bytes"
          ],
          "line": 2131
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__rb_page_index",
          "args": [
            "tail_page",
            "tail"
          ],
          "line": 2128
        },
        "resolved": true,
        "details": {
          "function_name": "__rb_page_index",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1880-1883",
          "snippet": "static __always_inline void *__rb_page_index(struct buffer_page *bpage, unsigned index)\n{\n\treturn bpage->page->data + index;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline void *__rb_page_index(struct buffer_page *bpage, unsigned index)\n{\n\treturn bpage->page->data + index;\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_sub",
          "args": [
            "length",
            "&tail_page->write"
          ],
          "line": 2124
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)\n#define RB_EVNT_MIN_SIZE\t8U\t/* two 32bit words */\n#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic inline void\nrb_reset_tail(struct ring_buffer_per_cpu *cpu_buffer,\n\t      unsigned long tail, struct rb_event_info *info)\n{\n\tstruct buffer_page *tail_page = info->tail_page;\n\tstruct ring_buffer_event *event;\n\tunsigned long length = info->length;\n\n\t/*\n\t * Only the event that crossed the page boundary\n\t * must fill the old tail_page with padding.\n\t */\n\tif (tail >= BUF_PAGE_SIZE) {\n\t\t/*\n\t\t * If the page was filled, then we still need\n\t\t * to update the real_end. Reset it to zero\n\t\t * and the reader will ignore it.\n\t\t */\n\t\tif (tail == BUF_PAGE_SIZE)\n\t\t\ttail_page->real_end = 0;\n\n\t\tlocal_sub(length, &tail_page->write);\n\t\treturn;\n\t}\n\n\tevent = __rb_page_index(tail_page, tail);\n\n\t/* account for padding bytes */\n\tlocal_add(BUF_PAGE_SIZE - tail, &cpu_buffer->entries_bytes);\n\n\t/*\n\t * Save the original length to the meta data.\n\t * This will be used by the reader to add lost event\n\t * counter.\n\t */\n\ttail_page->real_end = tail;\n\n\t/*\n\t * If this event is bigger than the minimum size, then\n\t * we need to be careful that we don't subtract the\n\t * write counter enough to allow another writer to slip\n\t * in on this page.\n\t * We put in a discarded commit instead, to make sure\n\t * that this space is not used again.\n\t *\n\t * If we are less than the minimum size, we don't need to\n\t * worry about it.\n\t */\n\tif (tail > (BUF_PAGE_SIZE - RB_EVNT_MIN_SIZE)) {\n\t\t/* No room for any events */\n\n\t\t/* Mark the rest of the page with padding */\n\t\trb_event_set_padding(event);\n\n\t\t/* Set the write back to the previous setting */\n\t\tlocal_sub(length, &tail_page->write);\n\t\treturn;\n\t}\n\n\t/* Put in a discarded event */\n\tevent->array[0] = (BUF_PAGE_SIZE - tail) - RB_EVNT_HDR_SIZE;\n\tevent->type_len = RINGBUF_TYPE_PADDING;\n\t/* time delta must be non zero */\n\tevent->time_delta = 1;\n\n\t/* Set write to end of buffer */\n\tlength = (tail + length) - BUF_PAGE_SIZE;\n\tlocal_sub(length, &tail_page->write);\n}"
  },
  {
    "function_name": "rb_handle_head_page",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1949-2101",
    "snippet": "static int\nrb_handle_head_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t    struct buffer_page *tail_page,\n\t\t    struct buffer_page *next_page)\n{\n\tstruct buffer_page *new_head;\n\tint entries;\n\tint type;\n\tint ret;\n\n\tentries = rb_page_entries(next_page);\n\n\t/*\n\t * The hard part is here. We need to move the head\n\t * forward, and protect against both readers on\n\t * other CPUs and writers coming in via interrupts.\n\t */\n\ttype = rb_head_page_set_update(cpu_buffer, next_page, tail_page,\n\t\t\t\t       RB_PAGE_HEAD);\n\n\t/*\n\t * type can be one of four:\n\t *  NORMAL - an interrupt already moved it for us\n\t *  HEAD   - we are the first to get here.\n\t *  UPDATE - we are the interrupt interrupting\n\t *           a current move.\n\t *  MOVED  - a reader on another CPU moved the next\n\t *           pointer to its reader page. Give up\n\t *           and try again.\n\t */\n\n\tswitch (type) {\n\tcase RB_PAGE_HEAD:\n\t\t/*\n\t\t * We changed the head to UPDATE, thus\n\t\t * it is our responsibility to update\n\t\t * the counters.\n\t\t */\n\t\tlocal_add(entries, &cpu_buffer->overrun);\n\t\tlocal_sub(BUF_PAGE_SIZE, &cpu_buffer->entries_bytes);\n\n\t\t/*\n\t\t * The entries will be zeroed out when we move the\n\t\t * tail page.\n\t\t */\n\n\t\t/* still more to do */\n\t\tbreak;\n\n\tcase RB_PAGE_UPDATE:\n\t\t/*\n\t\t * This is an interrupt that interrupt the\n\t\t * previous update. Still more to do.\n\t\t */\n\t\tbreak;\n\tcase RB_PAGE_NORMAL:\n\t\t/*\n\t\t * An interrupt came in before the update\n\t\t * and processed this for us.\n\t\t * Nothing left to do.\n\t\t */\n\t\treturn 1;\n\tcase RB_PAGE_MOVED:\n\t\t/*\n\t\t * The reader is on another CPU and just did\n\t\t * a swap with our next_page.\n\t\t * Try again.\n\t\t */\n\t\treturn 1;\n\tdefault:\n\t\tRB_WARN_ON(cpu_buffer, 1); /* WTF??? */\n\t\treturn -1;\n\t}\n\n\t/*\n\t * Now that we are here, the old head pointer is\n\t * set to UPDATE. This will keep the reader from\n\t * swapping the head page with the reader page.\n\t * The reader (on another CPU) will spin till\n\t * we are finished.\n\t *\n\t * We just need to protect against interrupts\n\t * doing the job. We will set the next pointer\n\t * to HEAD. After that, we set the old pointer\n\t * to NORMAL, but only if it was HEAD before.\n\t * otherwise we are an interrupt, and only\n\t * want the outer most commit to reset it.\n\t */\n\tnew_head = next_page;\n\trb_inc_page(cpu_buffer, &new_head);\n\n\tret = rb_head_page_set_head(cpu_buffer, new_head, next_page,\n\t\t\t\t    RB_PAGE_NORMAL);\n\n\t/*\n\t * Valid returns are:\n\t *  HEAD   - an interrupt came in and already set it.\n\t *  NORMAL - One of two things:\n\t *            1) We really set it.\n\t *            2) A bunch of interrupts came in and moved\n\t *               the page forward again.\n\t */\n\tswitch (ret) {\n\tcase RB_PAGE_HEAD:\n\tcase RB_PAGE_NORMAL:\n\t\t/* OK */\n\t\tbreak;\n\tdefault:\n\t\tRB_WARN_ON(cpu_buffer, 1);\n\t\treturn -1;\n\t}\n\n\t/*\n\t * It is possible that an interrupt came in,\n\t * set the head up, then more interrupts came in\n\t * and moved it again. When we get back here,\n\t * the page would have been set to NORMAL but we\n\t * just set it back to HEAD.\n\t *\n\t * How do you detect this? Well, if that happened\n\t * the tail page would have moved.\n\t */\n\tif (ret == RB_PAGE_NORMAL) {\n\t\tstruct buffer_page *buffer_tail_page;\n\n\t\tbuffer_tail_page = READ_ONCE(cpu_buffer->tail_page);\n\t\t/*\n\t\t * If the tail had moved passed next, then we need\n\t\t * to reset the pointer.\n\t\t */\n\t\tif (buffer_tail_page != tail_page &&\n\t\t    buffer_tail_page != next_page)\n\t\t\trb_head_page_set_normal(cpu_buffer, new_head,\n\t\t\t\t\t\tnext_page,\n\t\t\t\t\t\tRB_PAGE_HEAD);\n\t}\n\n\t/*\n\t * If this was the outer most commit (the one that\n\t * changed the original pointer from HEAD to UPDATE),\n\t * then it is up to us to reset it to NORMAL.\n\t */\n\tif (type == RB_PAGE_HEAD) {\n\t\tret = rb_head_page_set_normal(cpu_buffer, next_page,\n\t\t\t\t\t      tail_page,\n\t\t\t\t\t      RB_PAGE_UPDATE);\n\t\tif (RB_WARN_ON(cpu_buffer,\n\t\t\t       ret != RB_PAGE_UPDATE))\n\t\t\treturn -1;\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_PAGE_MOVED\t\t4UL",
      "#define RB_PAGE_UPDATE\t\t2UL",
      "#define RB_PAGE_HEAD\t\t1UL",
      "#define RB_PAGE_NORMAL\t\t0UL",
      "#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)"
    ],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "ret != RB_PAGE_UPDATE"
          ],
          "line": 2095
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_head_page_set_normal",
          "args": [
            "cpu_buffer",
            "next_page",
            "tail_page",
            "RB_PAGE_UPDATE"
          ],
          "line": 2092
        },
        "resolved": true,
        "details": {
          "function_name": "rb_head_page_set_normal",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "965-972",
          "snippet": "static int rb_head_page_set_normal(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t   struct buffer_page *head,\n\t\t\t\t   struct buffer_page *prev,\n\t\t\t\t   int old_flag)\n{\n\treturn rb_head_page_set(cpu_buffer, head, prev,\n\t\t\t\told_flag, RB_PAGE_NORMAL);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_PAGE_NORMAL\t\t0UL"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_PAGE_NORMAL\t\t0UL\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int rb_head_page_set_normal(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t   struct buffer_page *head,\n\t\t\t\t   struct buffer_page *prev,\n\t\t\t\t   int old_flag)\n{\n\treturn rb_head_page_set(cpu_buffer, head, prev,\n\t\t\t\told_flag, RB_PAGE_NORMAL);\n}"
        }
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "cpu_buffer->tail_page"
          ],
          "line": 2074
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "1"
          ],
          "line": 2057
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_head_page_set_head",
          "args": [
            "cpu_buffer",
            "new_head",
            "next_page",
            "RB_PAGE_NORMAL"
          ],
          "line": 2040
        },
        "resolved": true,
        "details": {
          "function_name": "rb_head_page_set_head",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "956-963",
          "snippet": "static int rb_head_page_set_head(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t struct buffer_page *head,\n\t\t\t\t struct buffer_page *prev,\n\t\t\t\t int old_flag)\n{\n\treturn rb_head_page_set(cpu_buffer, head, prev,\n\t\t\t\told_flag, RB_PAGE_HEAD);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_PAGE_HEAD\t\t1UL"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_PAGE_HEAD\t\t1UL\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int rb_head_page_set_head(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t struct buffer_page *head,\n\t\t\t\t struct buffer_page *prev,\n\t\t\t\t int old_flag)\n{\n\treturn rb_head_page_set(cpu_buffer, head, prev,\n\t\t\t\told_flag, RB_PAGE_HEAD);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_inc_page",
          "args": [
            "cpu_buffer",
            "&new_head"
          ],
          "line": 2038
        },
        "resolved": true,
        "details": {
          "function_name": "rb_inc_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "974-980",
          "snippet": "static inline void rb_inc_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t       struct buffer_page **bpage)\n{\n\tstruct list_head *p = rb_list_head((*bpage)->list.next);\n\n\t*bpage = list_entry(p, struct buffer_page, list);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline void rb_inc_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t       struct buffer_page **bpage)\n{\n\tstruct list_head *p = rb_list_head((*bpage)->list.next);\n\n\t*bpage = list_entry(p, struct buffer_page, list);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "1"
          ],
          "line": 2019
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_sub",
          "args": [
            "BUF_PAGE_SIZE",
            "&cpu_buffer->entries_bytes"
          ],
          "line": 1988
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_add",
          "args": [
            "entries",
            "&cpu_buffer->overrun"
          ],
          "line": 1987
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_head_page_set_update",
          "args": [
            "cpu_buffer",
            "next_page",
            "tail_page",
            "RB_PAGE_HEAD"
          ],
          "line": 1966
        },
        "resolved": true,
        "details": {
          "function_name": "rb_head_page_set_update",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "947-954",
          "snippet": "static int rb_head_page_set_update(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t   struct buffer_page *head,\n\t\t\t\t   struct buffer_page *prev,\n\t\t\t\t   int old_flag)\n{\n\treturn rb_head_page_set(cpu_buffer, head, prev,\n\t\t\t\told_flag, RB_PAGE_UPDATE);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_PAGE_UPDATE\t\t2UL"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_PAGE_UPDATE\t\t2UL\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int rb_head_page_set_update(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t   struct buffer_page *head,\n\t\t\t\t   struct buffer_page *prev,\n\t\t\t\t   int old_flag)\n{\n\treturn rb_head_page_set(cpu_buffer, head, prev,\n\t\t\t\told_flag, RB_PAGE_UPDATE);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_page_entries",
          "args": [
            "next_page"
          ],
          "line": 1959
        },
        "resolved": true,
        "details": {
          "function_name": "rb_page_entries",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1459-1462",
          "snippet": "static inline unsigned long rb_page_entries(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->entries) & RB_WRITE_MASK;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_WRITE_MASK\t\t0xfffff"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_WRITE_MASK\t\t0xfffff\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline unsigned long rb_page_entries(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->entries) & RB_WRITE_MASK;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_PAGE_MOVED\t\t4UL\n#define RB_PAGE_UPDATE\t\t2UL\n#define RB_PAGE_HEAD\t\t1UL\n#define RB_PAGE_NORMAL\t\t0UL\n#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int\nrb_handle_head_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t    struct buffer_page *tail_page,\n\t\t    struct buffer_page *next_page)\n{\n\tstruct buffer_page *new_head;\n\tint entries;\n\tint type;\n\tint ret;\n\n\tentries = rb_page_entries(next_page);\n\n\t/*\n\t * The hard part is here. We need to move the head\n\t * forward, and protect against both readers on\n\t * other CPUs and writers coming in via interrupts.\n\t */\n\ttype = rb_head_page_set_update(cpu_buffer, next_page, tail_page,\n\t\t\t\t       RB_PAGE_HEAD);\n\n\t/*\n\t * type can be one of four:\n\t *  NORMAL - an interrupt already moved it for us\n\t *  HEAD   - we are the first to get here.\n\t *  UPDATE - we are the interrupt interrupting\n\t *           a current move.\n\t *  MOVED  - a reader on another CPU moved the next\n\t *           pointer to its reader page. Give up\n\t *           and try again.\n\t */\n\n\tswitch (type) {\n\tcase RB_PAGE_HEAD:\n\t\t/*\n\t\t * We changed the head to UPDATE, thus\n\t\t * it is our responsibility to update\n\t\t * the counters.\n\t\t */\n\t\tlocal_add(entries, &cpu_buffer->overrun);\n\t\tlocal_sub(BUF_PAGE_SIZE, &cpu_buffer->entries_bytes);\n\n\t\t/*\n\t\t * The entries will be zeroed out when we move the\n\t\t * tail page.\n\t\t */\n\n\t\t/* still more to do */\n\t\tbreak;\n\n\tcase RB_PAGE_UPDATE:\n\t\t/*\n\t\t * This is an interrupt that interrupt the\n\t\t * previous update. Still more to do.\n\t\t */\n\t\tbreak;\n\tcase RB_PAGE_NORMAL:\n\t\t/*\n\t\t * An interrupt came in before the update\n\t\t * and processed this for us.\n\t\t * Nothing left to do.\n\t\t */\n\t\treturn 1;\n\tcase RB_PAGE_MOVED:\n\t\t/*\n\t\t * The reader is on another CPU and just did\n\t\t * a swap with our next_page.\n\t\t * Try again.\n\t\t */\n\t\treturn 1;\n\tdefault:\n\t\tRB_WARN_ON(cpu_buffer, 1); /* WTF??? */\n\t\treturn -1;\n\t}\n\n\t/*\n\t * Now that we are here, the old head pointer is\n\t * set to UPDATE. This will keep the reader from\n\t * swapping the head page with the reader page.\n\t * The reader (on another CPU) will spin till\n\t * we are finished.\n\t *\n\t * We just need to protect against interrupts\n\t * doing the job. We will set the next pointer\n\t * to HEAD. After that, we set the old pointer\n\t * to NORMAL, but only if it was HEAD before.\n\t * otherwise we are an interrupt, and only\n\t * want the outer most commit to reset it.\n\t */\n\tnew_head = next_page;\n\trb_inc_page(cpu_buffer, &new_head);\n\n\tret = rb_head_page_set_head(cpu_buffer, new_head, next_page,\n\t\t\t\t    RB_PAGE_NORMAL);\n\n\t/*\n\t * Valid returns are:\n\t *  HEAD   - an interrupt came in and already set it.\n\t *  NORMAL - One of two things:\n\t *            1) We really set it.\n\t *            2) A bunch of interrupts came in and moved\n\t *               the page forward again.\n\t */\n\tswitch (ret) {\n\tcase RB_PAGE_HEAD:\n\tcase RB_PAGE_NORMAL:\n\t\t/* OK */\n\t\tbreak;\n\tdefault:\n\t\tRB_WARN_ON(cpu_buffer, 1);\n\t\treturn -1;\n\t}\n\n\t/*\n\t * It is possible that an interrupt came in,\n\t * set the head up, then more interrupts came in\n\t * and moved it again. When we get back here,\n\t * the page would have been set to NORMAL but we\n\t * just set it back to HEAD.\n\t *\n\t * How do you detect this? Well, if that happened\n\t * the tail page would have moved.\n\t */\n\tif (ret == RB_PAGE_NORMAL) {\n\t\tstruct buffer_page *buffer_tail_page;\n\n\t\tbuffer_tail_page = READ_ONCE(cpu_buffer->tail_page);\n\t\t/*\n\t\t * If the tail had moved passed next, then we need\n\t\t * to reset the pointer.\n\t\t */\n\t\tif (buffer_tail_page != tail_page &&\n\t\t    buffer_tail_page != next_page)\n\t\t\trb_head_page_set_normal(cpu_buffer, new_head,\n\t\t\t\t\t\tnext_page,\n\t\t\t\t\t\tRB_PAGE_HEAD);\n\t}\n\n\t/*\n\t * If this was the outer most commit (the one that\n\t * changed the original pointer from HEAD to UPDATE),\n\t * then it is up to us to reset it to NORMAL.\n\t */\n\tif (type == RB_PAGE_HEAD) {\n\t\tret = rb_head_page_set_normal(cpu_buffer, next_page,\n\t\t\t\t\t      tail_page,\n\t\t\t\t\t      RB_PAGE_UPDATE);\n\t\tif (RB_WARN_ON(cpu_buffer,\n\t\t\t       ret != RB_PAGE_UPDATE))\n\t\t\treturn -1;\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "rb_inc_iter",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1923-1940",
    "snippet": "static void rb_inc_iter(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = iter->cpu_buffer;\n\n\t/*\n\t * The iterator could be on the reader page (it starts there).\n\t * But the head could have moved, since the reader was\n\t * found. Check for this case and assign the iterator\n\t * to the head page instead of next.\n\t */\n\tif (iter->head_page == cpu_buffer->reader_page)\n\t\titer->head_page = rb_set_head_page(cpu_buffer);\n\telse\n\t\trb_inc_page(cpu_buffer, &iter->head_page);\n\n\titer->read_stamp = iter->head_page->page->time_stamp;\n\titer->head = 0;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_inc_page",
          "args": [
            "cpu_buffer",
            "&iter->head_page"
          ],
          "line": 1936
        },
        "resolved": true,
        "details": {
          "function_name": "rb_inc_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "974-980",
          "snippet": "static inline void rb_inc_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t       struct buffer_page **bpage)\n{\n\tstruct list_head *p = rb_list_head((*bpage)->list.next);\n\n\t*bpage = list_entry(p, struct buffer_page, list);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline void rb_inc_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t       struct buffer_page **bpage)\n{\n\tstruct list_head *p = rb_list_head((*bpage)->list.next);\n\n\t*bpage = list_entry(p, struct buffer_page, list);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_set_head_page",
          "args": [
            "cpu_buffer"
          ],
          "line": 1934
        },
        "resolved": true,
        "details": {
          "function_name": "rb_set_head_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "982-1018",
          "snippet": "static struct buffer_page *\nrb_set_head_page(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *head;\n\tstruct buffer_page *page;\n\tstruct list_head *list;\n\tint i;\n\n\tif (RB_WARN_ON(cpu_buffer, !cpu_buffer->head_page))\n\t\treturn NULL;\n\n\t/* sanity check */\n\tlist = cpu_buffer->pages;\n\tif (RB_WARN_ON(cpu_buffer, rb_list_head(list->prev->next) != list))\n\t\treturn NULL;\n\n\tpage = head = cpu_buffer->head_page;\n\t/*\n\t * It is possible that the writer moves the header behind\n\t * where we started, and we miss in one loop.\n\t * A second loop should grab the header, but we'll do\n\t * three loops just because I'm paranoid.\n\t */\n\tfor (i = 0; i < 3; i++) {\n\t\tdo {\n\t\t\tif (rb_is_head_page(cpu_buffer, page, page->list.prev)) {\n\t\t\t\tcpu_buffer->head_page = page;\n\t\t\t\treturn page;\n\t\t\t}\n\t\t\trb_inc_page(cpu_buffer, &page);\n\t\t} while (page != head);\n\t}\n\n\tRB_WARN_ON(cpu_buffer, 1);\n\n\treturn NULL;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic struct buffer_page *\nrb_set_head_page(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *head;\n\tstruct buffer_page *page;\n\tstruct list_head *list;\n\tint i;\n\n\tif (RB_WARN_ON(cpu_buffer, !cpu_buffer->head_page))\n\t\treturn NULL;\n\n\t/* sanity check */\n\tlist = cpu_buffer->pages;\n\tif (RB_WARN_ON(cpu_buffer, rb_list_head(list->prev->next) != list))\n\t\treturn NULL;\n\n\tpage = head = cpu_buffer->head_page;\n\t/*\n\t * It is possible that the writer moves the header behind\n\t * where we started, and we miss in one loop.\n\t * A second loop should grab the header, but we'll do\n\t * three loops just because I'm paranoid.\n\t */\n\tfor (i = 0; i < 3; i++) {\n\t\tdo {\n\t\t\tif (rb_is_head_page(cpu_buffer, page, page->list.prev)) {\n\t\t\t\tcpu_buffer->head_page = page;\n\t\t\t\treturn page;\n\t\t\t}\n\t\t\trb_inc_page(cpu_buffer, &page);\n\t\t} while (page != head);\n\t}\n\n\tRB_WARN_ON(cpu_buffer, 1);\n\n\treturn NULL;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_inc_iter(struct ring_buffer_iter *iter)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = iter->cpu_buffer;\n\n\t/*\n\t * The iterator could be on the reader page (it starts there).\n\t * But the head could have moved, since the reader was\n\t * found. Check for this case and assign the iterator\n\t * to the head page instead of next.\n\t */\n\tif (iter->head_page == cpu_buffer->reader_page)\n\t\titer->head_page = rb_set_head_page(cpu_buffer);\n\telse\n\t\trb_inc_page(cpu_buffer, &iter->head_page);\n\n\titer->read_stamp = iter->head_page->page->time_stamp;\n\titer->head = 0;\n}"
  },
  {
    "function_name": "rb_event_index",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1915-1921",
    "snippet": "static __always_inline unsigned\nrb_event_index(struct ring_buffer_event *event)\n{\n\tunsigned long addr = (unsigned long)event;\n\n\treturn (addr & ~PAGE_MASK) - BUF_PAGE_HDR_SIZE;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define BUF_PAGE_HDR_SIZE offsetof(struct buffer_data_page, data)"
    ],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define BUF_PAGE_HDR_SIZE offsetof(struct buffer_data_page, data)\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic __always_inline unsigned\nrb_event_index(struct ring_buffer_event *event)\n{\n\tunsigned long addr = (unsigned long)event;\n\n\treturn (addr & ~PAGE_MASK) - BUF_PAGE_HDR_SIZE;\n}"
  },
  {
    "function_name": "rb_commit_index",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1909-1913",
    "snippet": "static __always_inline unsigned\nrb_commit_index(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn rb_page_commit(cpu_buffer->commit_page);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_page_commit",
          "args": [
            "cpu_buffer->commit_page"
          ],
          "line": 1912
        },
        "resolved": true,
        "details": {
          "function_name": "rb_page_commit",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1898-1901",
          "snippet": "static __always_inline unsigned rb_page_commit(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->page->commit);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline unsigned rb_page_commit(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->page->commit);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline unsigned\nrb_commit_index(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn rb_page_commit(cpu_buffer->commit_page);\n}"
  },
  {
    "function_name": "rb_page_size",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1904-1907",
    "snippet": "static __always_inline unsigned rb_page_size(struct buffer_page *bpage)\n{\n\treturn rb_page_commit(bpage);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_page_commit",
          "args": [
            "bpage"
          ],
          "line": 1906
        },
        "resolved": true,
        "details": {
          "function_name": "rb_page_commit",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1898-1901",
          "snippet": "static __always_inline unsigned rb_page_commit(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->page->commit);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline unsigned rb_page_commit(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->page->commit);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline unsigned rb_page_size(struct buffer_page *bpage)\n{\n\treturn rb_page_commit(bpage);\n}"
  },
  {
    "function_name": "rb_page_commit",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1898-1901",
    "snippet": "static __always_inline unsigned rb_page_commit(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->page->commit);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_read",
          "args": [
            "&bpage->page->commit"
          ],
          "line": 1900
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline unsigned rb_page_commit(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->page->commit);\n}"
  },
  {
    "function_name": "rb_iter_head_event",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1892-1896",
    "snippet": "ring_buffer_event *\nrb_iter_head_event(struct ring_buffer_iter *iter)\n{\n\treturn __rb_page_index(iter->head_page, iter->head);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "__rb_page_index",
          "args": [
            "iter->head_page",
            "iter->head"
          ],
          "line": 1895
        },
        "resolved": true,
        "details": {
          "function_name": "__rb_page_index",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1880-1883",
          "snippet": "static __always_inline void *__rb_page_index(struct buffer_page *bpage, unsigned index)\n{\n\treturn bpage->page->data + index;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline void *__rb_page_index(struct buffer_page *bpage, unsigned index)\n{\n\treturn bpage->page->data + index;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nring_buffer_event *\nrb_iter_head_event(struct ring_buffer_iter *iter)\n{\n\treturn __rb_page_index(iter->head_page, iter->head);\n}"
  },
  {
    "function_name": "rb_reader_event",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1885-1890",
    "snippet": "ring_buffer_event *\nrb_reader_event(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn __rb_page_index(cpu_buffer->reader_page,\n\t\t\t       cpu_buffer->reader_page->read);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "__rb_page_index",
          "args": [
            "cpu_buffer->reader_page",
            "cpu_buffer->reader_page->read"
          ],
          "line": 1888
        },
        "resolved": true,
        "details": {
          "function_name": "__rb_page_index",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1880-1883",
          "snippet": "static __always_inline void *__rb_page_index(struct buffer_page *bpage, unsigned index)\n{\n\treturn bpage->page->data + index;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline void *__rb_page_index(struct buffer_page *bpage, unsigned index)\n{\n\treturn bpage->page->data + index;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nring_buffer_event *\nrb_reader_event(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\treturn __rb_page_index(cpu_buffer->reader_page,\n\t\t\t       cpu_buffer->reader_page->read);\n}"
  },
  {
    "function_name": "__rb_page_index",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1880-1883",
    "snippet": "static __always_inline void *__rb_page_index(struct buffer_page *bpage, unsigned index)\n{\n\treturn bpage->page->data + index;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic __always_inline void *__rb_page_index(struct buffer_page *bpage, unsigned index)\n{\n\treturn bpage->page->data + index;\n}"
  },
  {
    "function_name": "ring_buffer_change_overwrite",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1869-1877",
    "snippet": "void ring_buffer_change_overwrite(struct ring_buffer *buffer, int val)\n{\n\tmutex_lock(&buffer->mutex);\n\tif (val)\n\t\tbuffer->flags |= RB_FL_OVERWRITE;\n\telse\n\t\tbuffer->flags &= ~RB_FL_OVERWRITE;\n\tmutex_unlock(&buffer->mutex);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&buffer->mutex"
          ],
          "line": 1876
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/rtmutex.c",
          "lines": "1602-1606",
          "snippet": "void __sched rt_mutex_unlock(struct rt_mutex *lock)\n{\n\tmutex_release(&lock->dep_map, 1, _RET_IP_);\n\trt_mutex_fastunlock(lock, rt_mutex_slowunlock);\n}",
          "includes": [
            "#include \"rtmutex_common.h\"",
            "#include <linux/timer.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex_common.h\"\n#include <linux/timer.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched rt_mutex_unlock(struct rt_mutex *lock)\n{\n\tmutex_release(&lock->dep_map, 1, _RET_IP_);\n\trt_mutex_fastunlock(lock, rt_mutex_slowunlock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "&buffer->mutex"
          ],
          "line": 1871
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_lock_interruptible",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/rtmutex.c",
          "lines": "1512-1524",
          "snippet": "int __sched rt_mutex_lock_interruptible(struct rt_mutex *lock)\n{\n\tint ret;\n\n\tmight_sleep();\n\n\tmutex_acquire(&lock->dep_map, 0, 0, _RET_IP_);\n\tret = rt_mutex_fastlock(lock, TASK_INTERRUPTIBLE, rt_mutex_slowlock);\n\tif (ret)\n\t\tmutex_release(&lock->dep_map, 1, _RET_IP_);\n\n\treturn ret;\n}",
          "includes": [
            "#include \"rtmutex_common.h\"",
            "#include <linux/timer.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex_common.h\"\n#include <linux/timer.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nint __sched rt_mutex_lock_interruptible(struct rt_mutex *lock)\n{\n\tint ret;\n\n\tmight_sleep();\n\n\tmutex_acquire(&lock->dep_map, 0, 0, _RET_IP_);\n\tret = rt_mutex_fastlock(lock, TASK_INTERRUPTIBLE, rt_mutex_slowlock);\n\tif (ret)\n\t\tmutex_release(&lock->dep_map, 1, _RET_IP_);\n\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid ring_buffer_change_overwrite(struct ring_buffer *buffer, int val)\n{\n\tmutex_lock(&buffer->mutex);\n\tif (val)\n\t\tbuffer->flags |= RB_FL_OVERWRITE;\n\telse\n\t\tbuffer->flags &= ~RB_FL_OVERWRITE;\n\tmutex_unlock(&buffer->mutex);\n}"
  },
  {
    "function_name": "ring_buffer_resize",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1690-1866",
    "snippet": "int ring_buffer_resize(struct ring_buffer *buffer, unsigned long size,\n\t\t\tint cpu_id)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long nr_pages;\n\tint cpu, err = 0;\n\n\t/*\n\t * Always succeed at resizing a non-existent buffer:\n\t */\n\tif (!buffer)\n\t\treturn size;\n\n\t/* Make sure the requested buffer exists */\n\tif (cpu_id != RING_BUFFER_ALL_CPUS &&\n\t    !cpumask_test_cpu(cpu_id, buffer->cpumask))\n\t\treturn size;\n\n\tnr_pages = DIV_ROUND_UP(size, BUF_PAGE_SIZE);\n\n\t/* we need a minimum of two pages */\n\tif (nr_pages < 2)\n\t\tnr_pages = 2;\n\n\tsize = nr_pages * BUF_PAGE_SIZE;\n\n\t/*\n\t * Don't succeed if resizing is disabled, as a reader might be\n\t * manipulating the ring buffer and is expecting a sane state while\n\t * this is true.\n\t */\n\tif (atomic_read(&buffer->resize_disabled))\n\t\treturn -EBUSY;\n\n\t/* prevent another thread from changing buffer sizes */\n\tmutex_lock(&buffer->mutex);\n\n\tif (cpu_id == RING_BUFFER_ALL_CPUS) {\n\t\t/* calculate the pages to update */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\n\t\t\tcpu_buffer->nr_pages_to_update = nr_pages -\n\t\t\t\t\t\t\tcpu_buffer->nr_pages;\n\t\t\t/*\n\t\t\t * nothing more to do for removing pages or no update\n\t\t\t */\n\t\t\tif (cpu_buffer->nr_pages_to_update <= 0)\n\t\t\t\tcontinue;\n\t\t\t/*\n\t\t\t * to add pages, make sure all new pages can be\n\t\t\t * allocated without receiving ENOMEM\n\t\t\t */\n\t\t\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\t\t\tif (__rb_allocate_pages(cpu_buffer->nr_pages_to_update,\n\t\t\t\t\t\t&cpu_buffer->new_pages, cpu)) {\n\t\t\t\t/* not enough memory for new pages */\n\t\t\t\terr = -ENOMEM;\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t}\n\n\t\tget_online_cpus();\n\t\t/*\n\t\t * Fire off all the required work handlers\n\t\t * We can't schedule on offline CPUs, but it's not necessary\n\t\t * since we can change their buffer sizes without any race.\n\t\t */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\tif (!cpu_buffer->nr_pages_to_update)\n\t\t\t\tcontinue;\n\n\t\t\t/* Can't run something on an offline CPU. */\n\t\t\tif (!cpu_online(cpu)) {\n\t\t\t\trb_update_pages(cpu_buffer);\n\t\t\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\t\t} else {\n\t\t\t\tschedule_work_on(cpu,\n\t\t\t\t\t\t&cpu_buffer->update_pages_work);\n\t\t\t}\n\t\t}\n\n\t\t/* wait for all the updates to complete */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\tif (!cpu_buffer->nr_pages_to_update)\n\t\t\t\tcontinue;\n\n\t\t\tif (cpu_online(cpu))\n\t\t\t\twait_for_completion(&cpu_buffer->update_done);\n\t\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\t}\n\n\t\tput_online_cpus();\n\t} else {\n\t\t/* Make sure this CPU has been initialized */\n\t\tif (!cpumask_test_cpu(cpu_id, buffer->cpumask))\n\t\t\tgoto out;\n\n\t\tcpu_buffer = buffer->buffers[cpu_id];\n\n\t\tif (nr_pages == cpu_buffer->nr_pages)\n\t\t\tgoto out;\n\n\t\tcpu_buffer->nr_pages_to_update = nr_pages -\n\t\t\t\t\t\tcpu_buffer->nr_pages;\n\n\t\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\t\tif (cpu_buffer->nr_pages_to_update > 0 &&\n\t\t\t__rb_allocate_pages(cpu_buffer->nr_pages_to_update,\n\t\t\t\t\t    &cpu_buffer->new_pages, cpu_id)) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tget_online_cpus();\n\n\t\t/* Can't run something on an offline CPU. */\n\t\tif (!cpu_online(cpu_id))\n\t\t\trb_update_pages(cpu_buffer);\n\t\telse {\n\t\t\tschedule_work_on(cpu_id,\n\t\t\t\t\t &cpu_buffer->update_pages_work);\n\t\t\twait_for_completion(&cpu_buffer->update_done);\n\t\t}\n\n\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\tput_online_cpus();\n\t}\n\n out:\n\t/*\n\t * The ring buffer resize can happen with the ring buffer\n\t * enabled, so that the update disturbs the tracing as little\n\t * as possible. But if the buffer is disabled, we do not need\n\t * to worry about that, and we can take the time to verify\n\t * that the buffer is not corrupt.\n\t */\n\tif (atomic_read(&buffer->record_disabled)) {\n\t\tatomic_inc(&buffer->record_disabled);\n\t\t/*\n\t\t * Even though the buffer was disabled, we must make sure\n\t\t * that it is truly disabled before calling rb_check_pages.\n\t\t * There could have been a race between checking\n\t\t * record_disable and incrementing it.\n\t\t */\n\t\tsynchronize_sched();\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\trb_check_pages(cpu_buffer);\n\t\t}\n\t\tatomic_dec(&buffer->record_disabled);\n\t}\n\n\tmutex_unlock(&buffer->mutex);\n\treturn size;\n\n out_err:\n\tfor_each_buffer_cpu(buffer, cpu) {\n\t\tstruct buffer_page *bpage, *tmp;\n\n\t\tcpu_buffer = buffer->buffers[cpu];\n\t\tcpu_buffer->nr_pages_to_update = 0;\n\n\t\tif (list_empty(&cpu_buffer->new_pages))\n\t\t\tcontinue;\n\n\t\tlist_for_each_entry_safe(bpage, tmp, &cpu_buffer->new_pages,\n\t\t\t\t\tlist) {\n\t\t\tlist_del_init(&bpage->list);\n\t\t\tfree_buffer_page(bpage);\n\t\t}\n\t}\n\tmutex_unlock(&buffer->mutex);\n\treturn err;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)"
    ],
    "globals_used": [
      "static void update_pages_handler(struct work_struct *work);",
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&buffer->mutex"
          ],
          "line": 1864
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/rtmutex.c",
          "lines": "1602-1606",
          "snippet": "void __sched rt_mutex_unlock(struct rt_mutex *lock)\n{\n\tmutex_release(&lock->dep_map, 1, _RET_IP_);\n\trt_mutex_fastunlock(lock, rt_mutex_slowunlock);\n}",
          "includes": [
            "#include \"rtmutex_common.h\"",
            "#include <linux/timer.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex_common.h\"\n#include <linux/timer.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched rt_mutex_unlock(struct rt_mutex *lock)\n{\n\tmutex_release(&lock->dep_map, 1, _RET_IP_);\n\trt_mutex_fastunlock(lock, rt_mutex_slowunlock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_buffer_page",
          "args": [
            "bpage"
          ],
          "line": 1861
        },
        "resolved": true,
        "details": {
          "function_name": "free_buffer_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "374-378",
          "snippet": "static void free_buffer_page(struct buffer_page *bpage)\n{\n\tfree_page((unsigned long)bpage->page);\n\tkfree(bpage);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void free_buffer_page(struct buffer_page *bpage)\n{\n\tfree_page((unsigned long)bpage->page);\n\tkfree(bpage);\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_del_init",
          "args": [
            "&bpage->list"
          ],
          "line": 1860
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_for_each_entry_safe",
          "args": [
            "bpage",
            "tmp",
            "&cpu_buffer->new_pages",
            "list"
          ],
          "line": 1858
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "&cpu_buffer->new_pages"
          ],
          "line": 1855
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "50-53",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !rsclp->head;\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !rsclp->head;\n}"
        }
      },
      {
        "call_info": {
          "callee": "for_each_buffer_cpu",
          "args": [
            "buffer",
            "cpu"
          ],
          "line": 1849
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_dec",
          "args": [
            "&buffer->record_disabled"
          ],
          "line": 1842
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_check_pages",
          "args": [
            "cpu_buffer"
          ],
          "line": 1840
        },
        "resolved": true,
        "details": {
          "function_name": "rb_check_pages",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1129-1162",
          "snippet": "static int rb_check_pages(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *head = cpu_buffer->pages;\n\tstruct buffer_page *bpage, *tmp;\n\n\t/* Reset the head page if it exists */\n\tif (cpu_buffer->head_page)\n\t\trb_set_head_page(cpu_buffer);\n\n\trb_head_page_deactivate(cpu_buffer);\n\n\tif (RB_WARN_ON(cpu_buffer, head->next->prev != head))\n\t\treturn -1;\n\tif (RB_WARN_ON(cpu_buffer, head->prev->next != head))\n\t\treturn -1;\n\n\tif (rb_check_list(cpu_buffer, head))\n\t\treturn -1;\n\n\tlist_for_each_entry_safe(bpage, tmp, head, list) {\n\t\tif (RB_WARN_ON(cpu_buffer,\n\t\t\t       bpage->list.next->prev != &bpage->list))\n\t\t\treturn -1;\n\t\tif (RB_WARN_ON(cpu_buffer,\n\t\t\t       bpage->list.prev->next != &bpage->list))\n\t\t\treturn -1;\n\t\tif (rb_check_list(cpu_buffer, &bpage->list))\n\t\t\treturn -1;\n\t}\n\n\trb_head_page_activate(cpu_buffer);\n\n\treturn 0;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int rb_check_pages(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *head = cpu_buffer->pages;\n\tstruct buffer_page *bpage, *tmp;\n\n\t/* Reset the head page if it exists */\n\tif (cpu_buffer->head_page)\n\t\trb_set_head_page(cpu_buffer);\n\n\trb_head_page_deactivate(cpu_buffer);\n\n\tif (RB_WARN_ON(cpu_buffer, head->next->prev != head))\n\t\treturn -1;\n\tif (RB_WARN_ON(cpu_buffer, head->prev->next != head))\n\t\treturn -1;\n\n\tif (rb_check_list(cpu_buffer, head))\n\t\treturn -1;\n\n\tlist_for_each_entry_safe(bpage, tmp, head, list) {\n\t\tif (RB_WARN_ON(cpu_buffer,\n\t\t\t       bpage->list.next->prev != &bpage->list))\n\t\t\treturn -1;\n\t\tif (RB_WARN_ON(cpu_buffer,\n\t\t\t       bpage->list.prev->next != &bpage->list))\n\t\t\treturn -1;\n\t\tif (rb_check_list(cpu_buffer, &bpage->list))\n\t\t\treturn -1;\n\t}\n\n\trb_head_page_activate(cpu_buffer);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "for_each_buffer_cpu",
          "args": [
            "buffer",
            "cpu"
          ],
          "line": 1838
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "synchronize_sched",
          "args": [],
          "line": 1837
        },
        "resolved": true,
        "details": {
          "function_name": "synchronize_sched_expedited_wait",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/tree_exp.h",
          "lines": "468-540",
          "snippet": "static void synchronize_sched_expedited_wait(void)\n{\n\tint cpu;\n\tunsigned long jiffies_stall;\n\tunsigned long jiffies_start;\n\tunsigned long mask;\n\tint ndetected;\n\tstruct rcu_node *rnp;\n\tstruct rcu_node *rnp_root = rcu_get_root();\n\tint ret;\n\n\ttrace_rcu_exp_grace_period(rcu_state.name, rcu_exp_gp_seq_endval(), TPS(\"startwait\"));\n\tjiffies_stall = rcu_jiffies_till_stall_check();\n\tjiffies_start = jiffies;\n\n\tfor (;;) {\n\t\tret = swait_event_timeout_exclusive(\n\t\t\t\trcu_state.expedited_wq,\n\t\t\t\tsync_rcu_preempt_exp_done_unlocked(rnp_root),\n\t\t\t\tjiffies_stall);\n\t\tif (ret > 0 || sync_rcu_preempt_exp_done_unlocked(rnp_root))\n\t\t\treturn;\n\t\tWARN_ON(ret < 0);  /* workqueues should not be signaled. */\n\t\tif (rcu_cpu_stall_suppress)\n\t\t\tcontinue;\n\t\tpanic_on_rcu_stall();\n\t\tpr_err(\"INFO: %s detected expedited stalls on CPUs/tasks: {\",\n\t\t       rcu_state.name);\n\t\tndetected = 0;\n\t\trcu_for_each_leaf_node(rnp) {\n\t\t\tndetected += rcu_print_task_exp_stall(rnp);\n\t\t\tfor_each_leaf_node_possible_cpu(rnp, cpu) {\n\t\t\t\tstruct rcu_data *rdp;\n\n\t\t\t\tmask = leaf_node_cpu_bit(rnp, cpu);\n\t\t\t\tif (!(rnp->expmask & mask))\n\t\t\t\t\tcontinue;\n\t\t\t\tndetected++;\n\t\t\t\trdp = per_cpu_ptr(&rcu_data, cpu);\n\t\t\t\tpr_cont(\" %d-%c%c%c\", cpu,\n\t\t\t\t\t\"O.\"[!!cpu_online(cpu)],\n\t\t\t\t\t\"o.\"[!!(rdp->grpmask & rnp->expmaskinit)],\n\t\t\t\t\t\"N.\"[!!(rdp->grpmask & rnp->expmaskinitnext)]);\n\t\t\t}\n\t\t}\n\t\tpr_cont(\" } %lu jiffies s: %lu root: %#lx/%c\\n\",\n\t\t\tjiffies - jiffies_start, rcu_state.expedited_sequence,\n\t\t\trnp_root->expmask, \".T\"[!!rnp_root->exp_tasks]);\n\t\tif (ndetected) {\n\t\t\tpr_err(\"blocking rcu_node structures:\");\n\t\t\trcu_for_each_node_breadth_first(rnp) {\n\t\t\t\tif (rnp == rnp_root)\n\t\t\t\t\tcontinue; /* printed unconditionally */\n\t\t\t\tif (sync_rcu_preempt_exp_done_unlocked(rnp))\n\t\t\t\t\tcontinue;\n\t\t\t\tpr_cont(\" l=%u:%d-%d:%#lx/%c\",\n\t\t\t\t\trnp->level, rnp->grplo, rnp->grphi,\n\t\t\t\t\trnp->expmask,\n\t\t\t\t\t\".T\"[!!rnp->exp_tasks]);\n\t\t\t}\n\t\t\tpr_cont(\"\\n\");\n\t\t}\n\t\trcu_for_each_leaf_node(rnp) {\n\t\t\tfor_each_leaf_node_possible_cpu(rnp, cpu) {\n\t\t\t\tmask = leaf_node_cpu_bit(rnp, cpu);\n\t\t\t\tif (!(rnp->expmask & mask))\n\t\t\t\t\tcontinue;\n\t\t\t\tdump_cpu_task(cpu);\n\t\t\t}\n\t\t}\n\t\tjiffies_stall = 3 * rcu_jiffies_till_stall_check() + 3;\n\t}\n}",
          "includes": [
            "#include <linux/lockdep.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/lockdep.h>\n\nstatic void synchronize_sched_expedited_wait(void)\n{\n\tint cpu;\n\tunsigned long jiffies_stall;\n\tunsigned long jiffies_start;\n\tunsigned long mask;\n\tint ndetected;\n\tstruct rcu_node *rnp;\n\tstruct rcu_node *rnp_root = rcu_get_root();\n\tint ret;\n\n\ttrace_rcu_exp_grace_period(rcu_state.name, rcu_exp_gp_seq_endval(), TPS(\"startwait\"));\n\tjiffies_stall = rcu_jiffies_till_stall_check();\n\tjiffies_start = jiffies;\n\n\tfor (;;) {\n\t\tret = swait_event_timeout_exclusive(\n\t\t\t\trcu_state.expedited_wq,\n\t\t\t\tsync_rcu_preempt_exp_done_unlocked(rnp_root),\n\t\t\t\tjiffies_stall);\n\t\tif (ret > 0 || sync_rcu_preempt_exp_done_unlocked(rnp_root))\n\t\t\treturn;\n\t\tWARN_ON(ret < 0);  /* workqueues should not be signaled. */\n\t\tif (rcu_cpu_stall_suppress)\n\t\t\tcontinue;\n\t\tpanic_on_rcu_stall();\n\t\tpr_err(\"INFO: %s detected expedited stalls on CPUs/tasks: {\",\n\t\t       rcu_state.name);\n\t\tndetected = 0;\n\t\trcu_for_each_leaf_node(rnp) {\n\t\t\tndetected += rcu_print_task_exp_stall(rnp);\n\t\t\tfor_each_leaf_node_possible_cpu(rnp, cpu) {\n\t\t\t\tstruct rcu_data *rdp;\n\n\t\t\t\tmask = leaf_node_cpu_bit(rnp, cpu);\n\t\t\t\tif (!(rnp->expmask & mask))\n\t\t\t\t\tcontinue;\n\t\t\t\tndetected++;\n\t\t\t\trdp = per_cpu_ptr(&rcu_data, cpu);\n\t\t\t\tpr_cont(\" %d-%c%c%c\", cpu,\n\t\t\t\t\t\"O.\"[!!cpu_online(cpu)],\n\t\t\t\t\t\"o.\"[!!(rdp->grpmask & rnp->expmaskinit)],\n\t\t\t\t\t\"N.\"[!!(rdp->grpmask & rnp->expmaskinitnext)]);\n\t\t\t}\n\t\t}\n\t\tpr_cont(\" } %lu jiffies s: %lu root: %#lx/%c\\n\",\n\t\t\tjiffies - jiffies_start, rcu_state.expedited_sequence,\n\t\t\trnp_root->expmask, \".T\"[!!rnp_root->exp_tasks]);\n\t\tif (ndetected) {\n\t\t\tpr_err(\"blocking rcu_node structures:\");\n\t\t\trcu_for_each_node_breadth_first(rnp) {\n\t\t\t\tif (rnp == rnp_root)\n\t\t\t\t\tcontinue; /* printed unconditionally */\n\t\t\t\tif (sync_rcu_preempt_exp_done_unlocked(rnp))\n\t\t\t\t\tcontinue;\n\t\t\t\tpr_cont(\" l=%u:%d-%d:%#lx/%c\",\n\t\t\t\t\trnp->level, rnp->grplo, rnp->grphi,\n\t\t\t\t\trnp->expmask,\n\t\t\t\t\t\".T\"[!!rnp->exp_tasks]);\n\t\t\t}\n\t\t\tpr_cont(\"\\n\");\n\t\t}\n\t\trcu_for_each_leaf_node(rnp) {\n\t\t\tfor_each_leaf_node_possible_cpu(rnp, cpu) {\n\t\t\t\tmask = leaf_node_cpu_bit(rnp, cpu);\n\t\t\t\tif (!(rnp->expmask & mask))\n\t\t\t\t\tcontinue;\n\t\t\t\tdump_cpu_task(cpu);\n\t\t\t}\n\t\t}\n\t\tjiffies_stall = 3 * rcu_jiffies_till_stall_check() + 3;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_inc",
          "args": [
            "&buffer->record_disabled"
          ],
          "line": 1830
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&buffer->record_disabled"
          ],
          "line": 1829
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "put_online_cpus",
          "args": [],
          "line": 1818
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "wait_for_completion",
          "args": [
            "&cpu_buffer->update_done"
          ],
          "line": 1814
        },
        "resolved": true,
        "details": {
          "function_name": "try_wait_for_completion",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/completion.c",
          "lines": "280-301",
          "snippet": "bool try_wait_for_completion(struct completion *x)\n{\n\tunsigned long flags;\n\tbool ret = true;\n\n\t/*\n\t * Since x->done will need to be locked only\n\t * in the non-blocking case, we check x->done\n\t * first without taking the lock so we can\n\t * return early in the blocking case.\n\t */\n\tif (!READ_ONCE(x->done))\n\t\treturn false;\n\n\tspin_lock_irqsave(&x->wait.lock, flags);\n\tif (!x->done)\n\t\tret = false;\n\telse if (x->done != UINT_MAX)\n\t\tx->done--;\n\tspin_unlock_irqrestore(&x->wait.lock, flags);\n\treturn ret;\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nbool try_wait_for_completion(struct completion *x)\n{\n\tunsigned long flags;\n\tbool ret = true;\n\n\t/*\n\t * Since x->done will need to be locked only\n\t * in the non-blocking case, we check x->done\n\t * first without taking the lock so we can\n\t * return early in the blocking case.\n\t */\n\tif (!READ_ONCE(x->done))\n\t\treturn false;\n\n\tspin_lock_irqsave(&x->wait.lock, flags);\n\tif (!x->done)\n\t\tret = false;\n\telse if (x->done != UINT_MAX)\n\t\tx->done--;\n\tspin_unlock_irqrestore(&x->wait.lock, flags);\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "schedule_work_on",
          "args": [
            "cpu_id",
            "&cpu_buffer->update_pages_work"
          ],
          "line": 1812
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_update_pages",
          "args": [
            "cpu_buffer"
          ],
          "line": 1810
        },
        "resolved": true,
        "details": {
          "function_name": "rb_update_pages",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1658-1670",
          "snippet": "static void rb_update_pages(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tint success;\n\n\tif (cpu_buffer->nr_pages_to_update > 0)\n\t\tsuccess = rb_insert_pages(cpu_buffer);\n\telse\n\t\tsuccess = rb_remove_pages(cpu_buffer,\n\t\t\t\t\t-cpu_buffer->nr_pages_to_update);\n\n\tif (success)\n\t\tcpu_buffer->nr_pages += cpu_buffer->nr_pages_to_update;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_update_pages(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tint success;\n\n\tif (cpu_buffer->nr_pages_to_update > 0)\n\t\tsuccess = rb_insert_pages(cpu_buffer);\n\telse\n\t\tsuccess = rb_remove_pages(cpu_buffer,\n\t\t\t\t\t-cpu_buffer->nr_pages_to_update);\n\n\tif (success)\n\t\tcpu_buffer->nr_pages += cpu_buffer->nr_pages_to_update;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpu_online",
          "args": [
            "cpu_id"
          ],
          "line": 1809
        },
        "resolved": true,
        "details": {
          "function_name": "init_cpu_online",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/cpu.c",
          "lines": "2274-2277",
          "snippet": "void init_cpu_online(const struct cpumask *src)\n{\n\tcpumask_copy(&__cpu_online_mask, src);\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <trace/events/cpuhp.h>",
            "#include <trace/events/power.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/slab.h>",
            "#include <linux/relay.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/nmi.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/suspend.h>",
            "#include <linux/gfp.h>",
            "#include <linux/mutex.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/kthread.h>",
            "#include <linux/bug.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/unistd.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/notifier.h>",
            "#include <linux/init.h>",
            "#include <linux/smp.h>",
            "#include <linux/proc_fs.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "struct cpumask __cpu_online_mask"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <trace/events/cpuhp.h>\n#include <trace/events/power.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/slab.h>\n#include <linux/relay.h>\n#include <linux/smpboot.h>\n#include <linux/nmi.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/lockdep.h>\n#include <linux/suspend.h>\n#include <linux/gfp.h>\n#include <linux/mutex.h>\n#include <linux/stop_machine.h>\n#include <linux/kthread.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/unistd.h>\n#include <linux/sched/task.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/signal.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/smp.h>\n#include <linux/proc_fs.h>\n\nstruct cpumask __cpu_online_mask;\n\nvoid init_cpu_online(const struct cpumask *src)\n{\n\tcpumask_copy(&__cpu_online_mask, src);\n}"
        }
      },
      {
        "call_info": {
          "callee": "get_online_cpus",
          "args": [],
          "line": 1806
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__rb_allocate_pages",
          "args": [
            "cpu_buffer->nr_pages_to_update",
            "&cpu_buffer->new_pages",
            "cpu_id"
          ],
          "line": 1800
        },
        "resolved": true,
        "details": {
          "function_name": "__rb_allocate_pages",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1164-1233",
          "snippet": "static int __rb_allocate_pages(long nr_pages, struct list_head *pages, int cpu)\n{\n\tstruct buffer_page *bpage, *tmp;\n\tbool user_thread = current->mm != NULL;\n\tgfp_t mflags;\n\tlong i;\n\n\t/*\n\t * Check if the available memory is there first.\n\t * Note, si_mem_available() only gives us a rough estimate of available\n\t * memory. It may not be accurate. But we don't care, we just want\n\t * to prevent doing any allocation when it is obvious that it is\n\t * not going to succeed.\n\t */\n\ti = si_mem_available();\n\tif (i < nr_pages)\n\t\treturn -ENOMEM;\n\n\t/*\n\t * __GFP_RETRY_MAYFAIL flag makes sure that the allocation fails\n\t * gracefully without invoking oom-killer and the system is not\n\t * destabilized.\n\t */\n\tmflags = GFP_KERNEL | __GFP_RETRY_MAYFAIL;\n\n\t/*\n\t * If a user thread allocates too much, and si_mem_available()\n\t * reports there's enough memory, even though there is not.\n\t * Make sure the OOM killer kills this thread. This can happen\n\t * even with RETRY_MAYFAIL because another task may be doing\n\t * an allocation after this task has taken all memory.\n\t * This is the task the OOM killer needs to take out during this\n\t * loop, even if it was triggered by an allocation somewhere else.\n\t */\n\tif (user_thread)\n\t\tset_current_oom_origin();\n\tfor (i = 0; i < nr_pages; i++) {\n\t\tstruct page *page;\n\n\t\tbpage = kzalloc_node(ALIGN(sizeof(*bpage), cache_line_size()),\n\t\t\t\t    mflags, cpu_to_node(cpu));\n\t\tif (!bpage)\n\t\t\tgoto free_pages;\n\n\t\tlist_add(&bpage->list, pages);\n\n\t\tpage = alloc_pages_node(cpu_to_node(cpu), mflags, 0);\n\t\tif (!page)\n\t\t\tgoto free_pages;\n\t\tbpage->page = page_address(page);\n\t\trb_init_page(bpage->page);\n\n\t\tif (user_thread && fatal_signal_pending(current))\n\t\t\tgoto free_pages;\n\t}\n\tif (user_thread)\n\t\tclear_current_oom_origin();\n\n\treturn 0;\n\nfree_pages:\n\tlist_for_each_entry_safe(bpage, tmp, pages, list) {\n\t\tlist_del_init(&bpage->list);\n\t\tfree_buffer_page(bpage);\n\t}\n\tif (user_thread)\n\t\tclear_current_oom_origin();\n\n\treturn -ENOMEM;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int __rb_allocate_pages(long nr_pages, struct list_head *pages, int cpu)\n{\n\tstruct buffer_page *bpage, *tmp;\n\tbool user_thread = current->mm != NULL;\n\tgfp_t mflags;\n\tlong i;\n\n\t/*\n\t * Check if the available memory is there first.\n\t * Note, si_mem_available() only gives us a rough estimate of available\n\t * memory. It may not be accurate. But we don't care, we just want\n\t * to prevent doing any allocation when it is obvious that it is\n\t * not going to succeed.\n\t */\n\ti = si_mem_available();\n\tif (i < nr_pages)\n\t\treturn -ENOMEM;\n\n\t/*\n\t * __GFP_RETRY_MAYFAIL flag makes sure that the allocation fails\n\t * gracefully without invoking oom-killer and the system is not\n\t * destabilized.\n\t */\n\tmflags = GFP_KERNEL | __GFP_RETRY_MAYFAIL;\n\n\t/*\n\t * If a user thread allocates too much, and si_mem_available()\n\t * reports there's enough memory, even though there is not.\n\t * Make sure the OOM killer kills this thread. This can happen\n\t * even with RETRY_MAYFAIL because another task may be doing\n\t * an allocation after this task has taken all memory.\n\t * This is the task the OOM killer needs to take out during this\n\t * loop, even if it was triggered by an allocation somewhere else.\n\t */\n\tif (user_thread)\n\t\tset_current_oom_origin();\n\tfor (i = 0; i < nr_pages; i++) {\n\t\tstruct page *page;\n\n\t\tbpage = kzalloc_node(ALIGN(sizeof(*bpage), cache_line_size()),\n\t\t\t\t    mflags, cpu_to_node(cpu));\n\t\tif (!bpage)\n\t\t\tgoto free_pages;\n\n\t\tlist_add(&bpage->list, pages);\n\n\t\tpage = alloc_pages_node(cpu_to_node(cpu), mflags, 0);\n\t\tif (!page)\n\t\t\tgoto free_pages;\n\t\tbpage->page = page_address(page);\n\t\trb_init_page(bpage->page);\n\n\t\tif (user_thread && fatal_signal_pending(current))\n\t\t\tgoto free_pages;\n\t}\n\tif (user_thread)\n\t\tclear_current_oom_origin();\n\n\treturn 0;\n\nfree_pages:\n\tlist_for_each_entry_safe(bpage, tmp, pages, list) {\n\t\tlist_del_init(&bpage->list);\n\t\tfree_buffer_page(bpage);\n\t}\n\tif (user_thread)\n\t\tclear_current_oom_origin();\n\n\treturn -ENOMEM;\n}"
        }
      },
      {
        "call_info": {
          "callee": "INIT_LIST_HEAD",
          "args": [
            "&cpu_buffer->new_pages"
          ],
          "line": 1798
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu_id",
            "buffer->cpumask"
          ],
          "line": 1787
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "put_online_cpus",
          "args": [],
          "line": 1784
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "for_each_buffer_cpu",
          "args": [
            "buffer",
            "cpu"
          ],
          "line": 1774
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "schedule_work_on",
          "args": [
            "cpu",
            "&cpu_buffer->update_pages_work"
          ],
          "line": 1768
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "for_each_buffer_cpu",
          "args": [
            "buffer",
            "cpu"
          ],
          "line": 1758
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "get_online_cpus",
          "args": [],
          "line": 1752
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "INIT_LIST_HEAD",
          "args": [
            "&cpu_buffer->new_pages"
          ],
          "line": 1743
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "for_each_buffer_cpu",
          "args": [
            "buffer",
            "cpu"
          ],
          "line": 1729
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "&buffer->mutex"
          ],
          "line": 1725
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_lock_interruptible",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/rtmutex.c",
          "lines": "1512-1524",
          "snippet": "int __sched rt_mutex_lock_interruptible(struct rt_mutex *lock)\n{\n\tint ret;\n\n\tmight_sleep();\n\n\tmutex_acquire(&lock->dep_map, 0, 0, _RET_IP_);\n\tret = rt_mutex_fastlock(lock, TASK_INTERRUPTIBLE, rt_mutex_slowlock);\n\tif (ret)\n\t\tmutex_release(&lock->dep_map, 1, _RET_IP_);\n\n\treturn ret;\n}",
          "includes": [
            "#include \"rtmutex_common.h\"",
            "#include <linux/timer.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex_common.h\"\n#include <linux/timer.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nint __sched rt_mutex_lock_interruptible(struct rt_mutex *lock)\n{\n\tint ret;\n\n\tmight_sleep();\n\n\tmutex_acquire(&lock->dep_map, 0, 0, _RET_IP_);\n\tret = rt_mutex_fastlock(lock, TASK_INTERRUPTIBLE, rt_mutex_slowlock);\n\tif (ret)\n\t\tmutex_release(&lock->dep_map, 1, _RET_IP_);\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&buffer->resize_disabled"
          ],
          "line": 1721
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DIV_ROUND_UP",
          "args": [
            "size",
            "BUF_PAGE_SIZE"
          ],
          "line": 1708
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu_id",
            "buffer->cpumask"
          ],
          "line": 1705
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)\n\nstatic void update_pages_handler(struct work_struct *work);\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nint ring_buffer_resize(struct ring_buffer *buffer, unsigned long size,\n\t\t\tint cpu_id)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long nr_pages;\n\tint cpu, err = 0;\n\n\t/*\n\t * Always succeed at resizing a non-existent buffer:\n\t */\n\tif (!buffer)\n\t\treturn size;\n\n\t/* Make sure the requested buffer exists */\n\tif (cpu_id != RING_BUFFER_ALL_CPUS &&\n\t    !cpumask_test_cpu(cpu_id, buffer->cpumask))\n\t\treturn size;\n\n\tnr_pages = DIV_ROUND_UP(size, BUF_PAGE_SIZE);\n\n\t/* we need a minimum of two pages */\n\tif (nr_pages < 2)\n\t\tnr_pages = 2;\n\n\tsize = nr_pages * BUF_PAGE_SIZE;\n\n\t/*\n\t * Don't succeed if resizing is disabled, as a reader might be\n\t * manipulating the ring buffer and is expecting a sane state while\n\t * this is true.\n\t */\n\tif (atomic_read(&buffer->resize_disabled))\n\t\treturn -EBUSY;\n\n\t/* prevent another thread from changing buffer sizes */\n\tmutex_lock(&buffer->mutex);\n\n\tif (cpu_id == RING_BUFFER_ALL_CPUS) {\n\t\t/* calculate the pages to update */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\n\t\t\tcpu_buffer->nr_pages_to_update = nr_pages -\n\t\t\t\t\t\t\tcpu_buffer->nr_pages;\n\t\t\t/*\n\t\t\t * nothing more to do for removing pages or no update\n\t\t\t */\n\t\t\tif (cpu_buffer->nr_pages_to_update <= 0)\n\t\t\t\tcontinue;\n\t\t\t/*\n\t\t\t * to add pages, make sure all new pages can be\n\t\t\t * allocated without receiving ENOMEM\n\t\t\t */\n\t\t\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\t\t\tif (__rb_allocate_pages(cpu_buffer->nr_pages_to_update,\n\t\t\t\t\t\t&cpu_buffer->new_pages, cpu)) {\n\t\t\t\t/* not enough memory for new pages */\n\t\t\t\terr = -ENOMEM;\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t}\n\n\t\tget_online_cpus();\n\t\t/*\n\t\t * Fire off all the required work handlers\n\t\t * We can't schedule on offline CPUs, but it's not necessary\n\t\t * since we can change their buffer sizes without any race.\n\t\t */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\tif (!cpu_buffer->nr_pages_to_update)\n\t\t\t\tcontinue;\n\n\t\t\t/* Can't run something on an offline CPU. */\n\t\t\tif (!cpu_online(cpu)) {\n\t\t\t\trb_update_pages(cpu_buffer);\n\t\t\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\t\t} else {\n\t\t\t\tschedule_work_on(cpu,\n\t\t\t\t\t\t&cpu_buffer->update_pages_work);\n\t\t\t}\n\t\t}\n\n\t\t/* wait for all the updates to complete */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\tif (!cpu_buffer->nr_pages_to_update)\n\t\t\t\tcontinue;\n\n\t\t\tif (cpu_online(cpu))\n\t\t\t\twait_for_completion(&cpu_buffer->update_done);\n\t\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\t}\n\n\t\tput_online_cpus();\n\t} else {\n\t\t/* Make sure this CPU has been initialized */\n\t\tif (!cpumask_test_cpu(cpu_id, buffer->cpumask))\n\t\t\tgoto out;\n\n\t\tcpu_buffer = buffer->buffers[cpu_id];\n\n\t\tif (nr_pages == cpu_buffer->nr_pages)\n\t\t\tgoto out;\n\n\t\tcpu_buffer->nr_pages_to_update = nr_pages -\n\t\t\t\t\t\tcpu_buffer->nr_pages;\n\n\t\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\t\tif (cpu_buffer->nr_pages_to_update > 0 &&\n\t\t\t__rb_allocate_pages(cpu_buffer->nr_pages_to_update,\n\t\t\t\t\t    &cpu_buffer->new_pages, cpu_id)) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tget_online_cpus();\n\n\t\t/* Can't run something on an offline CPU. */\n\t\tif (!cpu_online(cpu_id))\n\t\t\trb_update_pages(cpu_buffer);\n\t\telse {\n\t\t\tschedule_work_on(cpu_id,\n\t\t\t\t\t &cpu_buffer->update_pages_work);\n\t\t\twait_for_completion(&cpu_buffer->update_done);\n\t\t}\n\n\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\tput_online_cpus();\n\t}\n\n out:\n\t/*\n\t * The ring buffer resize can happen with the ring buffer\n\t * enabled, so that the update disturbs the tracing as little\n\t * as possible. But if the buffer is disabled, we do not need\n\t * to worry about that, and we can take the time to verify\n\t * that the buffer is not corrupt.\n\t */\n\tif (atomic_read(&buffer->record_disabled)) {\n\t\tatomic_inc(&buffer->record_disabled);\n\t\t/*\n\t\t * Even though the buffer was disabled, we must make sure\n\t\t * that it is truly disabled before calling rb_check_pages.\n\t\t * There could have been a race between checking\n\t\t * record_disable and incrementing it.\n\t\t */\n\t\tsynchronize_sched();\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\trb_check_pages(cpu_buffer);\n\t\t}\n\t\tatomic_dec(&buffer->record_disabled);\n\t}\n\n\tmutex_unlock(&buffer->mutex);\n\treturn size;\n\n out_err:\n\tfor_each_buffer_cpu(buffer, cpu) {\n\t\tstruct buffer_page *bpage, *tmp;\n\n\t\tcpu_buffer = buffer->buffers[cpu];\n\t\tcpu_buffer->nr_pages_to_update = 0;\n\n\t\tif (list_empty(&cpu_buffer->new_pages))\n\t\t\tcontinue;\n\n\t\tlist_for_each_entry_safe(bpage, tmp, &cpu_buffer->new_pages,\n\t\t\t\t\tlist) {\n\t\t\tlist_del_init(&bpage->list);\n\t\t\tfree_buffer_page(bpage);\n\t\t}\n\t}\n\tmutex_unlock(&buffer->mutex);\n\treturn err;\n}"
  },
  {
    "function_name": "update_pages_handler",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1672-1678",
    "snippet": "static void update_pages_handler(struct work_struct *work)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = container_of(work,\n\t\t\tstruct ring_buffer_per_cpu, update_pages_work);\n\trb_update_pages(cpu_buffer);\n\tcomplete(&cpu_buffer->update_done);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void update_pages_handler(struct work_struct *work);",
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "complete",
          "args": [
            "&cpu_buffer->update_done"
          ],
          "line": 1677
        },
        "resolved": true,
        "details": {
          "function_name": "complete_vfork_done",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/fork.c",
          "lines": "1205-1216",
          "snippet": "static void complete_vfork_done(struct task_struct *tsk)\n{\n\tstruct completion *vfork;\n\n\ttask_lock(tsk);\n\tvfork = tsk->vfork_done;\n\tif (likely(vfork)) {\n\t\ttsk->vfork_done = NULL;\n\t\tcomplete(vfork);\n\t}\n\ttask_unlock(tsk);\n}",
          "includes": [
            "#include <linux/init_task.h>",
            "#include <trace/events/task.h>",
            "#include <trace/events/sched.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/cacheflush.h>",
            "#include <asm/mmu_context.h>",
            "#include <linux/uaccess.h>",
            "#include <asm/pgalloc.h>",
            "#include <asm/pgtable.h>",
            "#include <linux/stackleak.h>",
            "#include <linux/thread_info.h>",
            "#include <linux/livepatch.h>",
            "#include <linux/kcov.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/compiler.h>",
            "#include <linux/aio.h>",
            "#include <linux/uprobes.h>",
            "#include <linux/signalfd.h>",
            "#include <linux/khugepaged.h>",
            "#include <linux/oom.h>",
            "#include <linux/user-return-notifier.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/magic.h>",
            "#include <linux/fs_struct.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/tty.h>",
            "#include <linux/random.h>",
            "#include <linux/taskstats_kern.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/freezer.h>",
            "#include <linux/cn_proc.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/acct.h>",
            "#include <linux/ksm.h>",
            "#include <linux/rmap.h>",
            "#include <linux/profile.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/memcontrol.h>",
            "#include <linux/audit.h>",
            "#include <linux/mount.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/task_io_accounting_ops.h>",
            "#include <linux/kthread.h>",
            "#include <linux/compat.h>",
            "#include <linux/futex.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swap.h>",
            "#include <linux/seccomp.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/security.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/cpu.h>",
            "#include <linux/capability.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/vmacache.h>",
            "#include <linux/mm.h>",
            "#include <linux/fs.h>",
            "#include <linux/hmm.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/mman.h>",
            "#include <linux/binfmts.h>",
            "#include <linux/key.h>",
            "#include <linux/iocontext.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/file.h>",
            "#include <linux/sem.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/personality.h>",
            "#include <linux/completion.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/module.h>",
            "#include <linux/unistd.h>",
            "#include <linux/init.h>",
            "#include <linux/rtmutex.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/slab.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __latent_entropy struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/init_task.h>\n#include <trace/events/task.h>\n#include <trace/events/sched.h>\n#include <asm/tlbflush.h>\n#include <asm/cacheflush.h>\n#include <asm/mmu_context.h>\n#include <linux/uaccess.h>\n#include <asm/pgalloc.h>\n#include <asm/pgtable.h>\n#include <linux/stackleak.h>\n#include <linux/thread_info.h>\n#include <linux/livepatch.h>\n#include <linux/kcov.h>\n#include <linux/sysctl.h>\n#include <linux/compiler.h>\n#include <linux/aio.h>\n#include <linux/uprobes.h>\n#include <linux/signalfd.h>\n#include <linux/khugepaged.h>\n#include <linux/oom.h>\n#include <linux/user-return-notifier.h>\n#include <linux/posix-timers.h>\n#include <linux/perf_event.h>\n#include <linux/sched/mm.h>\n#include <linux/magic.h>\n#include <linux/fs_struct.h>\n#include <linux/blkdev.h>\n#include <linux/tty.h>\n#include <linux/random.h>\n#include <linux/taskstats_kern.h>\n#include <linux/delayacct.h>\n#include <linux/freezer.h>\n#include <linux/cn_proc.h>\n#include <linux/tsacct_kern.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/acct.h>\n#include <linux/ksm.h>\n#include <linux/rmap.h>\n#include <linux/profile.h>\n#include <linux/proc_fs.h>\n#include <linux/ftrace.h>\n#include <linux/memcontrol.h>\n#include <linux/audit.h>\n#include <linux/mount.h>\n#include <linux/ptrace.h>\n#include <linux/rcupdate.h>\n#include <linux/task_io_accounting_ops.h>\n#include <linux/kthread.h>\n#include <linux/compat.h>\n#include <linux/futex.h>\n#include <linux/jiffies.h>\n#include <linux/syscalls.h>\n#include <linux/swap.h>\n#include <linux/seccomp.h>\n#include <linux/hugetlb.h>\n#include <linux/security.h>\n#include <linux/cgroup.h>\n#include <linux/cpu.h>\n#include <linux/capability.h>\n#include <linux/nsproxy.h>\n#include <linux/vmacache.h>\n#include <linux/mm.h>\n#include <linux/fs.h>\n#include <linux/hmm.h>\n#include <linux/mmu_notifier.h>\n#include <linux/mman.h>\n#include <linux/binfmts.h>\n#include <linux/key.h>\n#include <linux/iocontext.h>\n#include <linux/fdtable.h>\n#include <linux/file.h>\n#include <linux/sem.h>\n#include <linux/mempolicy.h>\n#include <linux/personality.h>\n#include <linux/completion.h>\n#include <linux/vmalloc.h>\n#include <linux/module.h>\n#include <linux/unistd.h>\n#include <linux/init.h>\n#include <linux/rtmutex.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/user.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/autogroup.h>\n#include <linux/slab.h>\n\nstatic __latent_entropy struct;\n\nstatic void complete_vfork_done(struct task_struct *tsk)\n{\n\tstruct completion *vfork;\n\n\ttask_lock(tsk);\n\tvfork = tsk->vfork_done;\n\tif (likely(vfork)) {\n\t\ttsk->vfork_done = NULL;\n\t\tcomplete(vfork);\n\t}\n\ttask_unlock(tsk);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_update_pages",
          "args": [
            "cpu_buffer"
          ],
          "line": 1676
        },
        "resolved": true,
        "details": {
          "function_name": "rb_update_pages",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1658-1670",
          "snippet": "static void rb_update_pages(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tint success;\n\n\tif (cpu_buffer->nr_pages_to_update > 0)\n\t\tsuccess = rb_insert_pages(cpu_buffer);\n\telse\n\t\tsuccess = rb_remove_pages(cpu_buffer,\n\t\t\t\t\t-cpu_buffer->nr_pages_to_update);\n\n\tif (success)\n\t\tcpu_buffer->nr_pages += cpu_buffer->nr_pages_to_update;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_update_pages(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tint success;\n\n\tif (cpu_buffer->nr_pages_to_update > 0)\n\t\tsuccess = rb_insert_pages(cpu_buffer);\n\telse\n\t\tsuccess = rb_remove_pages(cpu_buffer,\n\t\t\t\t\t-cpu_buffer->nr_pages_to_update);\n\n\tif (success)\n\t\tcpu_buffer->nr_pages += cpu_buffer->nr_pages_to_update;\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "work",
            "structring_buffer_per_cpu",
            "update_pages_work"
          ],
          "line": 1674
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void update_pages_handler(struct work_struct *work);\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void update_pages_handler(struct work_struct *work)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer = container_of(work,\n\t\t\tstruct ring_buffer_per_cpu, update_pages_work);\n\trb_update_pages(cpu_buffer);\n\tcomplete(&cpu_buffer->update_done);\n}"
  },
  {
    "function_name": "rb_update_pages",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1658-1670",
    "snippet": "static void rb_update_pages(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tint success;\n\n\tif (cpu_buffer->nr_pages_to_update > 0)\n\t\tsuccess = rb_insert_pages(cpu_buffer);\n\telse\n\t\tsuccess = rb_remove_pages(cpu_buffer,\n\t\t\t\t\t-cpu_buffer->nr_pages_to_update);\n\n\tif (success)\n\t\tcpu_buffer->nr_pages += cpu_buffer->nr_pages_to_update;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_remove_pages",
          "args": [
            "cpu_buffer",
            "-cpu_buffer->nr_pages_to_update"
          ],
          "line": 1665
        },
        "resolved": true,
        "details": {
          "function_name": "rb_remove_pages",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1469-1579",
          "snippet": "static int\nrb_remove_pages(struct ring_buffer_per_cpu *cpu_buffer, unsigned long nr_pages)\n{\n\tstruct list_head *tail_page, *to_remove, *next_page;\n\tstruct buffer_page *to_remove_page, *tmp_iter_page;\n\tstruct buffer_page *last_page, *first_page;\n\tunsigned long nr_removed;\n\tunsigned long head_bit;\n\tint page_entries;\n\n\thead_bit = 0;\n\n\traw_spin_lock_irq(&cpu_buffer->reader_lock);\n\tatomic_inc(&cpu_buffer->record_disabled);\n\t/*\n\t * We don't race with the readers since we have acquired the reader\n\t * lock. We also don't race with writers after disabling recording.\n\t * This makes it easy to figure out the first and the last page to be\n\t * removed from the list. We unlink all the pages in between including\n\t * the first and last pages. This is done in a busy loop so that we\n\t * lose the least number of traces.\n\t * The pages are freed after we restart recording and unlock readers.\n\t */\n\ttail_page = &cpu_buffer->tail_page->list;\n\n\t/*\n\t * tail page might be on reader page, we remove the next page\n\t * from the ring buffer\n\t */\n\tif (cpu_buffer->tail_page == cpu_buffer->reader_page)\n\t\ttail_page = rb_list_head(tail_page->next);\n\tto_remove = tail_page;\n\n\t/* start of pages to remove */\n\tfirst_page = list_entry(rb_list_head(to_remove->next),\n\t\t\t\tstruct buffer_page, list);\n\n\tfor (nr_removed = 0; nr_removed < nr_pages; nr_removed++) {\n\t\tto_remove = rb_list_head(to_remove)->next;\n\t\thead_bit |= (unsigned long)to_remove & RB_PAGE_HEAD;\n\t}\n\n\tnext_page = rb_list_head(to_remove)->next;\n\n\t/*\n\t * Now we remove all pages between tail_page and next_page.\n\t * Make sure that we have head_bit value preserved for the\n\t * next page\n\t */\n\ttail_page->next = (struct list_head *)((unsigned long)next_page |\n\t\t\t\t\t\thead_bit);\n\tnext_page = rb_list_head(next_page);\n\tnext_page->prev = tail_page;\n\n\t/* make sure pages points to a valid page in the ring buffer */\n\tcpu_buffer->pages = next_page;\n\n\t/* update head page */\n\tif (head_bit)\n\t\tcpu_buffer->head_page = list_entry(next_page,\n\t\t\t\t\t\tstruct buffer_page, list);\n\n\t/*\n\t * change read pointer to make sure any read iterators reset\n\t * themselves\n\t */\n\tcpu_buffer->read = 0;\n\n\t/* pages are removed, resume tracing and then free the pages */\n\tatomic_dec(&cpu_buffer->record_disabled);\n\traw_spin_unlock_irq(&cpu_buffer->reader_lock);\n\n\tRB_WARN_ON(cpu_buffer, list_empty(cpu_buffer->pages));\n\n\t/* last buffer page to remove */\n\tlast_page = list_entry(rb_list_head(to_remove), struct buffer_page,\n\t\t\t\tlist);\n\ttmp_iter_page = first_page;\n\n\tdo {\n\t\tcond_resched();\n\n\t\tto_remove_page = tmp_iter_page;\n\t\trb_inc_page(cpu_buffer, &tmp_iter_page);\n\n\t\t/* update the counters */\n\t\tpage_entries = rb_page_entries(to_remove_page);\n\t\tif (page_entries) {\n\t\t\t/*\n\t\t\t * If something was added to this page, it was full\n\t\t\t * since it is not the tail page. So we deduct the\n\t\t\t * bytes consumed in ring buffer from here.\n\t\t\t * Increment overrun to account for the lost events.\n\t\t\t */\n\t\t\tlocal_add(page_entries, &cpu_buffer->overrun);\n\t\t\tlocal_sub(BUF_PAGE_SIZE, &cpu_buffer->entries_bytes);\n\t\t}\n\n\t\t/*\n\t\t * We have already removed references to this list item, just\n\t\t * free up the buffer_page and its page\n\t\t */\n\t\tfree_buffer_page(to_remove_page);\n\t\tnr_removed--;\n\n\t} while (to_remove_page != last_page);\n\n\tRB_WARN_ON(cpu_buffer, nr_removed);\n\n\treturn nr_removed == 0;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_PAGE_HEAD\t\t1UL",
            "#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_PAGE_HEAD\t\t1UL\n#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int\nrb_remove_pages(struct ring_buffer_per_cpu *cpu_buffer, unsigned long nr_pages)\n{\n\tstruct list_head *tail_page, *to_remove, *next_page;\n\tstruct buffer_page *to_remove_page, *tmp_iter_page;\n\tstruct buffer_page *last_page, *first_page;\n\tunsigned long nr_removed;\n\tunsigned long head_bit;\n\tint page_entries;\n\n\thead_bit = 0;\n\n\traw_spin_lock_irq(&cpu_buffer->reader_lock);\n\tatomic_inc(&cpu_buffer->record_disabled);\n\t/*\n\t * We don't race with the readers since we have acquired the reader\n\t * lock. We also don't race with writers after disabling recording.\n\t * This makes it easy to figure out the first and the last page to be\n\t * removed from the list. We unlink all the pages in between including\n\t * the first and last pages. This is done in a busy loop so that we\n\t * lose the least number of traces.\n\t * The pages are freed after we restart recording and unlock readers.\n\t */\n\ttail_page = &cpu_buffer->tail_page->list;\n\n\t/*\n\t * tail page might be on reader page, we remove the next page\n\t * from the ring buffer\n\t */\n\tif (cpu_buffer->tail_page == cpu_buffer->reader_page)\n\t\ttail_page = rb_list_head(tail_page->next);\n\tto_remove = tail_page;\n\n\t/* start of pages to remove */\n\tfirst_page = list_entry(rb_list_head(to_remove->next),\n\t\t\t\tstruct buffer_page, list);\n\n\tfor (nr_removed = 0; nr_removed < nr_pages; nr_removed++) {\n\t\tto_remove = rb_list_head(to_remove)->next;\n\t\thead_bit |= (unsigned long)to_remove & RB_PAGE_HEAD;\n\t}\n\n\tnext_page = rb_list_head(to_remove)->next;\n\n\t/*\n\t * Now we remove all pages between tail_page and next_page.\n\t * Make sure that we have head_bit value preserved for the\n\t * next page\n\t */\n\ttail_page->next = (struct list_head *)((unsigned long)next_page |\n\t\t\t\t\t\thead_bit);\n\tnext_page = rb_list_head(next_page);\n\tnext_page->prev = tail_page;\n\n\t/* make sure pages points to a valid page in the ring buffer */\n\tcpu_buffer->pages = next_page;\n\n\t/* update head page */\n\tif (head_bit)\n\t\tcpu_buffer->head_page = list_entry(next_page,\n\t\t\t\t\t\tstruct buffer_page, list);\n\n\t/*\n\t * change read pointer to make sure any read iterators reset\n\t * themselves\n\t */\n\tcpu_buffer->read = 0;\n\n\t/* pages are removed, resume tracing and then free the pages */\n\tatomic_dec(&cpu_buffer->record_disabled);\n\traw_spin_unlock_irq(&cpu_buffer->reader_lock);\n\n\tRB_WARN_ON(cpu_buffer, list_empty(cpu_buffer->pages));\n\n\t/* last buffer page to remove */\n\tlast_page = list_entry(rb_list_head(to_remove), struct buffer_page,\n\t\t\t\tlist);\n\ttmp_iter_page = first_page;\n\n\tdo {\n\t\tcond_resched();\n\n\t\tto_remove_page = tmp_iter_page;\n\t\trb_inc_page(cpu_buffer, &tmp_iter_page);\n\n\t\t/* update the counters */\n\t\tpage_entries = rb_page_entries(to_remove_page);\n\t\tif (page_entries) {\n\t\t\t/*\n\t\t\t * If something was added to this page, it was full\n\t\t\t * since it is not the tail page. So we deduct the\n\t\t\t * bytes consumed in ring buffer from here.\n\t\t\t * Increment overrun to account for the lost events.\n\t\t\t */\n\t\t\tlocal_add(page_entries, &cpu_buffer->overrun);\n\t\t\tlocal_sub(BUF_PAGE_SIZE, &cpu_buffer->entries_bytes);\n\t\t}\n\n\t\t/*\n\t\t * We have already removed references to this list item, just\n\t\t * free up the buffer_page and its page\n\t\t */\n\t\tfree_buffer_page(to_remove_page);\n\t\tnr_removed--;\n\n\t} while (to_remove_page != last_page);\n\n\tRB_WARN_ON(cpu_buffer, nr_removed);\n\n\treturn nr_removed == 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_insert_pages",
          "args": [
            "cpu_buffer"
          ],
          "line": 1663
        },
        "resolved": true,
        "details": {
          "function_name": "rb_insert_pages",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1581-1656",
          "snippet": "static int\nrb_insert_pages(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *pages = &cpu_buffer->new_pages;\n\tint retries, success;\n\n\traw_spin_lock_irq(&cpu_buffer->reader_lock);\n\t/*\n\t * We are holding the reader lock, so the reader page won't be swapped\n\t * in the ring buffer. Now we are racing with the writer trying to\n\t * move head page and the tail page.\n\t * We are going to adapt the reader page update process where:\n\t * 1. We first splice the start and end of list of new pages between\n\t *    the head page and its previous page.\n\t * 2. We cmpxchg the prev_page->next to point from head page to the\n\t *    start of new pages list.\n\t * 3. Finally, we update the head->prev to the end of new list.\n\t *\n\t * We will try this process 10 times, to make sure that we don't keep\n\t * spinning.\n\t */\n\tretries = 10;\n\tsuccess = 0;\n\twhile (retries--) {\n\t\tstruct list_head *head_page, *prev_page, *r;\n\t\tstruct list_head *last_page, *first_page;\n\t\tstruct list_head *head_page_with_bit;\n\n\t\thead_page = &rb_set_head_page(cpu_buffer)->list;\n\t\tif (!head_page)\n\t\t\tbreak;\n\t\tprev_page = head_page->prev;\n\n\t\tfirst_page = pages->next;\n\t\tlast_page  = pages->prev;\n\n\t\thead_page_with_bit = (struct list_head *)\n\t\t\t\t     ((unsigned long)head_page | RB_PAGE_HEAD);\n\n\t\tlast_page->next = head_page_with_bit;\n\t\tfirst_page->prev = prev_page;\n\n\t\tr = cmpxchg(&prev_page->next, head_page_with_bit, first_page);\n\n\t\tif (r == head_page_with_bit) {\n\t\t\t/*\n\t\t\t * yay, we replaced the page pointer to our new list,\n\t\t\t * now, we just have to update to head page's prev\n\t\t\t * pointer to point to end of list\n\t\t\t */\n\t\t\thead_page->prev = last_page;\n\t\t\tsuccess = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (success)\n\t\tINIT_LIST_HEAD(pages);\n\t/*\n\t * If we weren't successful in adding in new pages, warn and stop\n\t * tracing\n\t */\n\tRB_WARN_ON(cpu_buffer, !success);\n\traw_spin_unlock_irq(&cpu_buffer->reader_lock);\n\n\t/* free pages if they weren't inserted */\n\tif (!success) {\n\t\tstruct buffer_page *bpage, *tmp;\n\t\tlist_for_each_entry_safe(bpage, tmp, &cpu_buffer->new_pages,\n\t\t\t\t\t list) {\n\t\t\tlist_del_init(&bpage->list);\n\t\t\tfree_buffer_page(bpage);\n\t\t}\n\t}\n\treturn success;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_PAGE_HEAD\t\t1UL"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_PAGE_HEAD\t\t1UL\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int\nrb_insert_pages(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *pages = &cpu_buffer->new_pages;\n\tint retries, success;\n\n\traw_spin_lock_irq(&cpu_buffer->reader_lock);\n\t/*\n\t * We are holding the reader lock, so the reader page won't be swapped\n\t * in the ring buffer. Now we are racing with the writer trying to\n\t * move head page and the tail page.\n\t * We are going to adapt the reader page update process where:\n\t * 1. We first splice the start and end of list of new pages between\n\t *    the head page and its previous page.\n\t * 2. We cmpxchg the prev_page->next to point from head page to the\n\t *    start of new pages list.\n\t * 3. Finally, we update the head->prev to the end of new list.\n\t *\n\t * We will try this process 10 times, to make sure that we don't keep\n\t * spinning.\n\t */\n\tretries = 10;\n\tsuccess = 0;\n\twhile (retries--) {\n\t\tstruct list_head *head_page, *prev_page, *r;\n\t\tstruct list_head *last_page, *first_page;\n\t\tstruct list_head *head_page_with_bit;\n\n\t\thead_page = &rb_set_head_page(cpu_buffer)->list;\n\t\tif (!head_page)\n\t\t\tbreak;\n\t\tprev_page = head_page->prev;\n\n\t\tfirst_page = pages->next;\n\t\tlast_page  = pages->prev;\n\n\t\thead_page_with_bit = (struct list_head *)\n\t\t\t\t     ((unsigned long)head_page | RB_PAGE_HEAD);\n\n\t\tlast_page->next = head_page_with_bit;\n\t\tfirst_page->prev = prev_page;\n\n\t\tr = cmpxchg(&prev_page->next, head_page_with_bit, first_page);\n\n\t\tif (r == head_page_with_bit) {\n\t\t\t/*\n\t\t\t * yay, we replaced the page pointer to our new list,\n\t\t\t * now, we just have to update to head page's prev\n\t\t\t * pointer to point to end of list\n\t\t\t */\n\t\t\thead_page->prev = last_page;\n\t\t\tsuccess = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (success)\n\t\tINIT_LIST_HEAD(pages);\n\t/*\n\t * If we weren't successful in adding in new pages, warn and stop\n\t * tracing\n\t */\n\tRB_WARN_ON(cpu_buffer, !success);\n\traw_spin_unlock_irq(&cpu_buffer->reader_lock);\n\n\t/* free pages if they weren't inserted */\n\tif (!success) {\n\t\tstruct buffer_page *bpage, *tmp;\n\t\tlist_for_each_entry_safe(bpage, tmp, &cpu_buffer->new_pages,\n\t\t\t\t\t list) {\n\t\t\tlist_del_init(&bpage->list);\n\t\t\tfree_buffer_page(bpage);\n\t\t}\n\t}\n\treturn success;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_update_pages(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tint success;\n\n\tif (cpu_buffer->nr_pages_to_update > 0)\n\t\tsuccess = rb_insert_pages(cpu_buffer);\n\telse\n\t\tsuccess = rb_remove_pages(cpu_buffer,\n\t\t\t\t\t-cpu_buffer->nr_pages_to_update);\n\n\tif (success)\n\t\tcpu_buffer->nr_pages += cpu_buffer->nr_pages_to_update;\n}"
  },
  {
    "function_name": "rb_insert_pages",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1581-1656",
    "snippet": "static int\nrb_insert_pages(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *pages = &cpu_buffer->new_pages;\n\tint retries, success;\n\n\traw_spin_lock_irq(&cpu_buffer->reader_lock);\n\t/*\n\t * We are holding the reader lock, so the reader page won't be swapped\n\t * in the ring buffer. Now we are racing with the writer trying to\n\t * move head page and the tail page.\n\t * We are going to adapt the reader page update process where:\n\t * 1. We first splice the start and end of list of new pages between\n\t *    the head page and its previous page.\n\t * 2. We cmpxchg the prev_page->next to point from head page to the\n\t *    start of new pages list.\n\t * 3. Finally, we update the head->prev to the end of new list.\n\t *\n\t * We will try this process 10 times, to make sure that we don't keep\n\t * spinning.\n\t */\n\tretries = 10;\n\tsuccess = 0;\n\twhile (retries--) {\n\t\tstruct list_head *head_page, *prev_page, *r;\n\t\tstruct list_head *last_page, *first_page;\n\t\tstruct list_head *head_page_with_bit;\n\n\t\thead_page = &rb_set_head_page(cpu_buffer)->list;\n\t\tif (!head_page)\n\t\t\tbreak;\n\t\tprev_page = head_page->prev;\n\n\t\tfirst_page = pages->next;\n\t\tlast_page  = pages->prev;\n\n\t\thead_page_with_bit = (struct list_head *)\n\t\t\t\t     ((unsigned long)head_page | RB_PAGE_HEAD);\n\n\t\tlast_page->next = head_page_with_bit;\n\t\tfirst_page->prev = prev_page;\n\n\t\tr = cmpxchg(&prev_page->next, head_page_with_bit, first_page);\n\n\t\tif (r == head_page_with_bit) {\n\t\t\t/*\n\t\t\t * yay, we replaced the page pointer to our new list,\n\t\t\t * now, we just have to update to head page's prev\n\t\t\t * pointer to point to end of list\n\t\t\t */\n\t\t\thead_page->prev = last_page;\n\t\t\tsuccess = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (success)\n\t\tINIT_LIST_HEAD(pages);\n\t/*\n\t * If we weren't successful in adding in new pages, warn and stop\n\t * tracing\n\t */\n\tRB_WARN_ON(cpu_buffer, !success);\n\traw_spin_unlock_irq(&cpu_buffer->reader_lock);\n\n\t/* free pages if they weren't inserted */\n\tif (!success) {\n\t\tstruct buffer_page *bpage, *tmp;\n\t\tlist_for_each_entry_safe(bpage, tmp, &cpu_buffer->new_pages,\n\t\t\t\t\t list) {\n\t\t\tlist_del_init(&bpage->list);\n\t\t\tfree_buffer_page(bpage);\n\t\t}\n\t}\n\treturn success;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_PAGE_HEAD\t\t1UL"
    ],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "free_buffer_page",
          "args": [
            "bpage"
          ],
          "line": 1652
        },
        "resolved": true,
        "details": {
          "function_name": "free_buffer_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "374-378",
          "snippet": "static void free_buffer_page(struct buffer_page *bpage)\n{\n\tfree_page((unsigned long)bpage->page);\n\tkfree(bpage);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void free_buffer_page(struct buffer_page *bpage)\n{\n\tfree_page((unsigned long)bpage->page);\n\tkfree(bpage);\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_del_init",
          "args": [
            "&bpage->list"
          ],
          "line": 1651
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_for_each_entry_safe",
          "args": [
            "bpage",
            "tmp",
            "&cpu_buffer->new_pages",
            "list"
          ],
          "line": 1649
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_irq",
          "args": [
            "&cpu_buffer->reader_lock"
          ],
          "line": 1644
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_irq",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "190-193",
          "snippet": "void __lockfunc _raw_spin_unlock_irq(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_irq(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_irq(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_irq(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "!success"
          ],
          "line": 1643
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "INIT_LIST_HEAD",
          "args": [
            "pages"
          ],
          "line": 1638
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cmpxchg",
          "args": [
            "&prev_page->next",
            "head_page_with_bit",
            "first_page"
          ],
          "line": 1623
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_set_head_page",
          "args": [
            "cpu_buffer"
          ],
          "line": 1609
        },
        "resolved": true,
        "details": {
          "function_name": "rb_set_head_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "982-1018",
          "snippet": "static struct buffer_page *\nrb_set_head_page(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *head;\n\tstruct buffer_page *page;\n\tstruct list_head *list;\n\tint i;\n\n\tif (RB_WARN_ON(cpu_buffer, !cpu_buffer->head_page))\n\t\treturn NULL;\n\n\t/* sanity check */\n\tlist = cpu_buffer->pages;\n\tif (RB_WARN_ON(cpu_buffer, rb_list_head(list->prev->next) != list))\n\t\treturn NULL;\n\n\tpage = head = cpu_buffer->head_page;\n\t/*\n\t * It is possible that the writer moves the header behind\n\t * where we started, and we miss in one loop.\n\t * A second loop should grab the header, but we'll do\n\t * three loops just because I'm paranoid.\n\t */\n\tfor (i = 0; i < 3; i++) {\n\t\tdo {\n\t\t\tif (rb_is_head_page(cpu_buffer, page, page->list.prev)) {\n\t\t\t\tcpu_buffer->head_page = page;\n\t\t\t\treturn page;\n\t\t\t}\n\t\t\trb_inc_page(cpu_buffer, &page);\n\t\t} while (page != head);\n\t}\n\n\tRB_WARN_ON(cpu_buffer, 1);\n\n\treturn NULL;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic struct buffer_page *\nrb_set_head_page(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *head;\n\tstruct buffer_page *page;\n\tstruct list_head *list;\n\tint i;\n\n\tif (RB_WARN_ON(cpu_buffer, !cpu_buffer->head_page))\n\t\treturn NULL;\n\n\t/* sanity check */\n\tlist = cpu_buffer->pages;\n\tif (RB_WARN_ON(cpu_buffer, rb_list_head(list->prev->next) != list))\n\t\treturn NULL;\n\n\tpage = head = cpu_buffer->head_page;\n\t/*\n\t * It is possible that the writer moves the header behind\n\t * where we started, and we miss in one loop.\n\t * A second loop should grab the header, but we'll do\n\t * three loops just because I'm paranoid.\n\t */\n\tfor (i = 0; i < 3; i++) {\n\t\tdo {\n\t\t\tif (rb_is_head_page(cpu_buffer, page, page->list.prev)) {\n\t\t\t\tcpu_buffer->head_page = page;\n\t\t\t\treturn page;\n\t\t\t}\n\t\t\trb_inc_page(cpu_buffer, &page);\n\t\t} while (page != head);\n\t}\n\n\tRB_WARN_ON(cpu_buffer, 1);\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irq",
          "args": [
            "&cpu_buffer->reader_lock"
          ],
          "line": 1587
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_irq",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "158-161",
          "snippet": "void __lockfunc _raw_spin_lock_irq(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_irq(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_irq(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_irq(lock);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_PAGE_HEAD\t\t1UL\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int\nrb_insert_pages(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *pages = &cpu_buffer->new_pages;\n\tint retries, success;\n\n\traw_spin_lock_irq(&cpu_buffer->reader_lock);\n\t/*\n\t * We are holding the reader lock, so the reader page won't be swapped\n\t * in the ring buffer. Now we are racing with the writer trying to\n\t * move head page and the tail page.\n\t * We are going to adapt the reader page update process where:\n\t * 1. We first splice the start and end of list of new pages between\n\t *    the head page and its previous page.\n\t * 2. We cmpxchg the prev_page->next to point from head page to the\n\t *    start of new pages list.\n\t * 3. Finally, we update the head->prev to the end of new list.\n\t *\n\t * We will try this process 10 times, to make sure that we don't keep\n\t * spinning.\n\t */\n\tretries = 10;\n\tsuccess = 0;\n\twhile (retries--) {\n\t\tstruct list_head *head_page, *prev_page, *r;\n\t\tstruct list_head *last_page, *first_page;\n\t\tstruct list_head *head_page_with_bit;\n\n\t\thead_page = &rb_set_head_page(cpu_buffer)->list;\n\t\tif (!head_page)\n\t\t\tbreak;\n\t\tprev_page = head_page->prev;\n\n\t\tfirst_page = pages->next;\n\t\tlast_page  = pages->prev;\n\n\t\thead_page_with_bit = (struct list_head *)\n\t\t\t\t     ((unsigned long)head_page | RB_PAGE_HEAD);\n\n\t\tlast_page->next = head_page_with_bit;\n\t\tfirst_page->prev = prev_page;\n\n\t\tr = cmpxchg(&prev_page->next, head_page_with_bit, first_page);\n\n\t\tif (r == head_page_with_bit) {\n\t\t\t/*\n\t\t\t * yay, we replaced the page pointer to our new list,\n\t\t\t * now, we just have to update to head page's prev\n\t\t\t * pointer to point to end of list\n\t\t\t */\n\t\t\thead_page->prev = last_page;\n\t\t\tsuccess = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (success)\n\t\tINIT_LIST_HEAD(pages);\n\t/*\n\t * If we weren't successful in adding in new pages, warn and stop\n\t * tracing\n\t */\n\tRB_WARN_ON(cpu_buffer, !success);\n\traw_spin_unlock_irq(&cpu_buffer->reader_lock);\n\n\t/* free pages if they weren't inserted */\n\tif (!success) {\n\t\tstruct buffer_page *bpage, *tmp;\n\t\tlist_for_each_entry_safe(bpage, tmp, &cpu_buffer->new_pages,\n\t\t\t\t\t list) {\n\t\t\tlist_del_init(&bpage->list);\n\t\t\tfree_buffer_page(bpage);\n\t\t}\n\t}\n\treturn success;\n}"
  },
  {
    "function_name": "rb_remove_pages",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1469-1579",
    "snippet": "static int\nrb_remove_pages(struct ring_buffer_per_cpu *cpu_buffer, unsigned long nr_pages)\n{\n\tstruct list_head *tail_page, *to_remove, *next_page;\n\tstruct buffer_page *to_remove_page, *tmp_iter_page;\n\tstruct buffer_page *last_page, *first_page;\n\tunsigned long nr_removed;\n\tunsigned long head_bit;\n\tint page_entries;\n\n\thead_bit = 0;\n\n\traw_spin_lock_irq(&cpu_buffer->reader_lock);\n\tatomic_inc(&cpu_buffer->record_disabled);\n\t/*\n\t * We don't race with the readers since we have acquired the reader\n\t * lock. We also don't race with writers after disabling recording.\n\t * This makes it easy to figure out the first and the last page to be\n\t * removed from the list. We unlink all the pages in between including\n\t * the first and last pages. This is done in a busy loop so that we\n\t * lose the least number of traces.\n\t * The pages are freed after we restart recording and unlock readers.\n\t */\n\ttail_page = &cpu_buffer->tail_page->list;\n\n\t/*\n\t * tail page might be on reader page, we remove the next page\n\t * from the ring buffer\n\t */\n\tif (cpu_buffer->tail_page == cpu_buffer->reader_page)\n\t\ttail_page = rb_list_head(tail_page->next);\n\tto_remove = tail_page;\n\n\t/* start of pages to remove */\n\tfirst_page = list_entry(rb_list_head(to_remove->next),\n\t\t\t\tstruct buffer_page, list);\n\n\tfor (nr_removed = 0; nr_removed < nr_pages; nr_removed++) {\n\t\tto_remove = rb_list_head(to_remove)->next;\n\t\thead_bit |= (unsigned long)to_remove & RB_PAGE_HEAD;\n\t}\n\n\tnext_page = rb_list_head(to_remove)->next;\n\n\t/*\n\t * Now we remove all pages between tail_page and next_page.\n\t * Make sure that we have head_bit value preserved for the\n\t * next page\n\t */\n\ttail_page->next = (struct list_head *)((unsigned long)next_page |\n\t\t\t\t\t\thead_bit);\n\tnext_page = rb_list_head(next_page);\n\tnext_page->prev = tail_page;\n\n\t/* make sure pages points to a valid page in the ring buffer */\n\tcpu_buffer->pages = next_page;\n\n\t/* update head page */\n\tif (head_bit)\n\t\tcpu_buffer->head_page = list_entry(next_page,\n\t\t\t\t\t\tstruct buffer_page, list);\n\n\t/*\n\t * change read pointer to make sure any read iterators reset\n\t * themselves\n\t */\n\tcpu_buffer->read = 0;\n\n\t/* pages are removed, resume tracing and then free the pages */\n\tatomic_dec(&cpu_buffer->record_disabled);\n\traw_spin_unlock_irq(&cpu_buffer->reader_lock);\n\n\tRB_WARN_ON(cpu_buffer, list_empty(cpu_buffer->pages));\n\n\t/* last buffer page to remove */\n\tlast_page = list_entry(rb_list_head(to_remove), struct buffer_page,\n\t\t\t\tlist);\n\ttmp_iter_page = first_page;\n\n\tdo {\n\t\tcond_resched();\n\n\t\tto_remove_page = tmp_iter_page;\n\t\trb_inc_page(cpu_buffer, &tmp_iter_page);\n\n\t\t/* update the counters */\n\t\tpage_entries = rb_page_entries(to_remove_page);\n\t\tif (page_entries) {\n\t\t\t/*\n\t\t\t * If something was added to this page, it was full\n\t\t\t * since it is not the tail page. So we deduct the\n\t\t\t * bytes consumed in ring buffer from here.\n\t\t\t * Increment overrun to account for the lost events.\n\t\t\t */\n\t\t\tlocal_add(page_entries, &cpu_buffer->overrun);\n\t\t\tlocal_sub(BUF_PAGE_SIZE, &cpu_buffer->entries_bytes);\n\t\t}\n\n\t\t/*\n\t\t * We have already removed references to this list item, just\n\t\t * free up the buffer_page and its page\n\t\t */\n\t\tfree_buffer_page(to_remove_page);\n\t\tnr_removed--;\n\n\t} while (to_remove_page != last_page);\n\n\tRB_WARN_ON(cpu_buffer, nr_removed);\n\n\treturn nr_removed == 0;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_PAGE_HEAD\t\t1UL",
      "#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)"
    ],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "nr_removed"
          ],
          "line": 1576
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "free_buffer_page",
          "args": [
            "to_remove_page"
          ],
          "line": 1571
        },
        "resolved": true,
        "details": {
          "function_name": "free_buffer_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "374-378",
          "snippet": "static void free_buffer_page(struct buffer_page *bpage)\n{\n\tfree_page((unsigned long)bpage->page);\n\tkfree(bpage);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void free_buffer_page(struct buffer_page *bpage)\n{\n\tfree_page((unsigned long)bpage->page);\n\tkfree(bpage);\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_sub",
          "args": [
            "BUF_PAGE_SIZE",
            "&cpu_buffer->entries_bytes"
          ],
          "line": 1564
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_add",
          "args": [
            "page_entries",
            "&cpu_buffer->overrun"
          ],
          "line": 1563
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_page_entries",
          "args": [
            "to_remove_page"
          ],
          "line": 1555
        },
        "resolved": true,
        "details": {
          "function_name": "rb_page_entries",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1459-1462",
          "snippet": "static inline unsigned long rb_page_entries(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->entries) & RB_WRITE_MASK;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_WRITE_MASK\t\t0xfffff"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_WRITE_MASK\t\t0xfffff\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline unsigned long rb_page_entries(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->entries) & RB_WRITE_MASK;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_inc_page",
          "args": [
            "cpu_buffer",
            "&tmp_iter_page"
          ],
          "line": 1552
        },
        "resolved": true,
        "details": {
          "function_name": "rb_inc_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "974-980",
          "snippet": "static inline void rb_inc_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t       struct buffer_page **bpage)\n{\n\tstruct list_head *p = rb_list_head((*bpage)->list.next);\n\n\t*bpage = list_entry(p, struct buffer_page, list);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline void rb_inc_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t       struct buffer_page **bpage)\n{\n\tstruct list_head *p = rb_list_head((*bpage)->list.next);\n\n\t*bpage = list_entry(p, struct buffer_page, list);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cond_resched",
          "args": [],
          "line": 1549
        },
        "resolved": true,
        "details": {
          "function_name": "_cond_resched",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/core.c",
          "lines": "4957-4965",
          "snippet": "int __sched _cond_resched(void)\n{\n\tif (should_resched(0)) {\n\t\tpreempt_schedule_common();\n\t\treturn 1;\n\t}\n\trcu_all_qs();\n\treturn 0;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include <trace/events/sched.h>",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/kcov.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include <trace/events/sched.h>\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/kcov.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n\nstatic void __sched;\nstatic void __sched;\n\nint __sched _cond_resched(void)\n{\n\tif (should_resched(0)) {\n\t\tpreempt_schedule_common();\n\t\treturn 1;\n\t}\n\trcu_all_qs();\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_entry",
          "args": [
            "rb_list_head(to_remove)",
            "structbuffer_page",
            "list"
          ],
          "line": 1544
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_list_head",
          "args": [
            "to_remove"
          ],
          "line": 1544
        },
        "resolved": true,
        "details": {
          "function_name": "rb_list_head_clear",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "902-907",
          "snippet": "static void rb_list_head_clear(struct list_head *list)\n{\n\tunsigned long *ptr = (unsigned long *)&list->next;\n\n\t*ptr &= ~RB_FLAG_MASK;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_FLAG_MASK\t\t3UL"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_FLAG_MASK\t\t3UL\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_list_head_clear(struct list_head *list)\n{\n\tunsigned long *ptr = (unsigned long *)&list->next;\n\n\t*ptr &= ~RB_FLAG_MASK;\n}"
        }
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "list_empty(cpu_buffer->pages)"
          ],
          "line": 1541
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "cpu_buffer->pages"
          ],
          "line": 1541
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "50-53",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !rsclp->head;\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !rsclp->head;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_irq",
          "args": [
            "&cpu_buffer->reader_lock"
          ],
          "line": 1539
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_irq",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "190-193",
          "snippet": "void __lockfunc _raw_spin_unlock_irq(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_irq(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_irq(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_irq(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_dec",
          "args": [
            "&cpu_buffer->record_disabled"
          ],
          "line": 1538
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_entry",
          "args": [
            "next_page",
            "structbuffer_page",
            "list"
          ],
          "line": 1528
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_entry",
          "args": [
            "rb_list_head(to_remove->next)",
            "structbuffer_page",
            "list"
          ],
          "line": 1503
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_inc",
          "args": [
            "&cpu_buffer->record_disabled"
          ],
          "line": 1482
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irq",
          "args": [
            "&cpu_buffer->reader_lock"
          ],
          "line": 1481
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_irq",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "158-161",
          "snippet": "void __lockfunc _raw_spin_lock_irq(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_irq(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_irq(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_irq(lock);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_PAGE_HEAD\t\t1UL\n#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int\nrb_remove_pages(struct ring_buffer_per_cpu *cpu_buffer, unsigned long nr_pages)\n{\n\tstruct list_head *tail_page, *to_remove, *next_page;\n\tstruct buffer_page *to_remove_page, *tmp_iter_page;\n\tstruct buffer_page *last_page, *first_page;\n\tunsigned long nr_removed;\n\tunsigned long head_bit;\n\tint page_entries;\n\n\thead_bit = 0;\n\n\traw_spin_lock_irq(&cpu_buffer->reader_lock);\n\tatomic_inc(&cpu_buffer->record_disabled);\n\t/*\n\t * We don't race with the readers since we have acquired the reader\n\t * lock. We also don't race with writers after disabling recording.\n\t * This makes it easy to figure out the first and the last page to be\n\t * removed from the list. We unlink all the pages in between including\n\t * the first and last pages. This is done in a busy loop so that we\n\t * lose the least number of traces.\n\t * The pages are freed after we restart recording and unlock readers.\n\t */\n\ttail_page = &cpu_buffer->tail_page->list;\n\n\t/*\n\t * tail page might be on reader page, we remove the next page\n\t * from the ring buffer\n\t */\n\tif (cpu_buffer->tail_page == cpu_buffer->reader_page)\n\t\ttail_page = rb_list_head(tail_page->next);\n\tto_remove = tail_page;\n\n\t/* start of pages to remove */\n\tfirst_page = list_entry(rb_list_head(to_remove->next),\n\t\t\t\tstruct buffer_page, list);\n\n\tfor (nr_removed = 0; nr_removed < nr_pages; nr_removed++) {\n\t\tto_remove = rb_list_head(to_remove)->next;\n\t\thead_bit |= (unsigned long)to_remove & RB_PAGE_HEAD;\n\t}\n\n\tnext_page = rb_list_head(to_remove)->next;\n\n\t/*\n\t * Now we remove all pages between tail_page and next_page.\n\t * Make sure that we have head_bit value preserved for the\n\t * next page\n\t */\n\ttail_page->next = (struct list_head *)((unsigned long)next_page |\n\t\t\t\t\t\thead_bit);\n\tnext_page = rb_list_head(next_page);\n\tnext_page->prev = tail_page;\n\n\t/* make sure pages points to a valid page in the ring buffer */\n\tcpu_buffer->pages = next_page;\n\n\t/* update head page */\n\tif (head_bit)\n\t\tcpu_buffer->head_page = list_entry(next_page,\n\t\t\t\t\t\tstruct buffer_page, list);\n\n\t/*\n\t * change read pointer to make sure any read iterators reset\n\t * themselves\n\t */\n\tcpu_buffer->read = 0;\n\n\t/* pages are removed, resume tracing and then free the pages */\n\tatomic_dec(&cpu_buffer->record_disabled);\n\traw_spin_unlock_irq(&cpu_buffer->reader_lock);\n\n\tRB_WARN_ON(cpu_buffer, list_empty(cpu_buffer->pages));\n\n\t/* last buffer page to remove */\n\tlast_page = list_entry(rb_list_head(to_remove), struct buffer_page,\n\t\t\t\tlist);\n\ttmp_iter_page = first_page;\n\n\tdo {\n\t\tcond_resched();\n\n\t\tto_remove_page = tmp_iter_page;\n\t\trb_inc_page(cpu_buffer, &tmp_iter_page);\n\n\t\t/* update the counters */\n\t\tpage_entries = rb_page_entries(to_remove_page);\n\t\tif (page_entries) {\n\t\t\t/*\n\t\t\t * If something was added to this page, it was full\n\t\t\t * since it is not the tail page. So we deduct the\n\t\t\t * bytes consumed in ring buffer from here.\n\t\t\t * Increment overrun to account for the lost events.\n\t\t\t */\n\t\t\tlocal_add(page_entries, &cpu_buffer->overrun);\n\t\t\tlocal_sub(BUF_PAGE_SIZE, &cpu_buffer->entries_bytes);\n\t\t}\n\n\t\t/*\n\t\t * We have already removed references to this list item, just\n\t\t * free up the buffer_page and its page\n\t\t */\n\t\tfree_buffer_page(to_remove_page);\n\t\tnr_removed--;\n\n\t} while (to_remove_page != last_page);\n\n\tRB_WARN_ON(cpu_buffer, nr_removed);\n\n\treturn nr_removed == 0;\n}"
  },
  {
    "function_name": "rb_page_write",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1464-1467",
    "snippet": "static inline unsigned long rb_page_write(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->write) & RB_WRITE_MASK;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_WRITE_MASK\t\t0xfffff"
    ],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_read",
          "args": [
            "&bpage->write"
          ],
          "line": 1466
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_WRITE_MASK\t\t0xfffff\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline unsigned long rb_page_write(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->write) & RB_WRITE_MASK;\n}"
  },
  {
    "function_name": "rb_page_entries",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1459-1462",
    "snippet": "static inline unsigned long rb_page_entries(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->entries) & RB_WRITE_MASK;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_WRITE_MASK\t\t0xfffff"
    ],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_read",
          "args": [
            "&bpage->entries"
          ],
          "line": 1461
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_WRITE_MASK\t\t0xfffff\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline unsigned long rb_page_entries(struct buffer_page *bpage)\n{\n\treturn local_read(&bpage->entries) & RB_WRITE_MASK;\n}"
  },
  {
    "function_name": "ring_buffer_time_stamp_abs",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1452-1455",
    "snippet": "bool ring_buffer_time_stamp_abs(struct ring_buffer *buffer)\n{\n\treturn buffer->time_stamp_abs;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nbool ring_buffer_time_stamp_abs(struct ring_buffer *buffer)\n{\n\treturn buffer->time_stamp_abs;\n}"
  },
  {
    "function_name": "ring_buffer_set_time_stamp_abs",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1447-1450",
    "snippet": "void ring_buffer_set_time_stamp_abs(struct ring_buffer *buffer, bool abs)\n{\n\tbuffer->time_stamp_abs = abs;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid ring_buffer_set_time_stamp_abs(struct ring_buffer *buffer, bool abs)\n{\n\tbuffer->time_stamp_abs = abs;\n}"
  },
  {
    "function_name": "ring_buffer_set_clock",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1441-1445",
    "snippet": "void ring_buffer_set_clock(struct ring_buffer *buffer,\n\t\t\t   u64 (*clock)(void))\n{\n\tbuffer->clock = clock;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid ring_buffer_set_clock(struct ring_buffer *buffer,\n\t\t\t   u64 (*clock)(void))\n{\n\tbuffer->clock = clock;\n}"
  },
  {
    "function_name": "ring_buffer_free",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1424-1438",
    "snippet": "void\nring_buffer_free(struct ring_buffer *buffer)\n{\n\tint cpu;\n\n\tcpuhp_state_remove_instance(CPUHP_TRACE_RB_PREPARE, &buffer->node);\n\n\tfor_each_buffer_cpu(buffer, cpu)\n\t\trb_free_cpu_buffer(buffer->buffers[cpu]);\n\n\tkfree(buffer->buffers);\n\tfree_cpumask_var(buffer->cpumask);\n\n\tkfree(buffer);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "buffer"
          ],
          "line": 1437
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/params.c",
          "lines": "73-86",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_cpumask_var",
          "args": [
            "buffer->cpumask"
          ],
          "line": 1435
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_free_cpu_buffer",
          "args": [
            "buffer->buffers[cpu]"
          ],
          "line": 1432
        },
        "resolved": true,
        "details": {
          "function_name": "rb_free_cpu_buffer",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1321-1340",
          "snippet": "static void rb_free_cpu_buffer(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *head = cpu_buffer->pages;\n\tstruct buffer_page *bpage, *tmp;\n\n\tfree_buffer_page(cpu_buffer->reader_page);\n\n\trb_head_page_deactivate(cpu_buffer);\n\n\tif (head) {\n\t\tlist_for_each_entry_safe(bpage, tmp, head, list) {\n\t\t\tlist_del_init(&bpage->list);\n\t\t\tfree_buffer_page(bpage);\n\t\t}\n\t\tbpage = list_entry(head, struct buffer_page, list);\n\t\tfree_buffer_page(bpage);\n\t}\n\n\tkfree(cpu_buffer);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_free_cpu_buffer(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *head = cpu_buffer->pages;\n\tstruct buffer_page *bpage, *tmp;\n\n\tfree_buffer_page(cpu_buffer->reader_page);\n\n\trb_head_page_deactivate(cpu_buffer);\n\n\tif (head) {\n\t\tlist_for_each_entry_safe(bpage, tmp, head, list) {\n\t\t\tlist_del_init(&bpage->list);\n\t\t\tfree_buffer_page(bpage);\n\t\t}\n\t\tbpage = list_entry(head, struct buffer_page, list);\n\t\tfree_buffer_page(bpage);\n\t}\n\n\tkfree(cpu_buffer);\n}"
        }
      },
      {
        "call_info": {
          "callee": "for_each_buffer_cpu",
          "args": [
            "buffer",
            "cpu"
          ],
          "line": 1431
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpuhp_state_remove_instance",
          "args": [
            "CPUHP_TRACE_RB_PREPARE",
            "&buffer->node"
          ],
          "line": 1429
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid\nring_buffer_free(struct ring_buffer *buffer)\n{\n\tint cpu;\n\n\tcpuhp_state_remove_instance(CPUHP_TRACE_RB_PREPARE, &buffer->node);\n\n\tfor_each_buffer_cpu(buffer, cpu)\n\t\trb_free_cpu_buffer(buffer->buffers[cpu]);\n\n\tkfree(buffer->buffers);\n\tfree_cpumask_var(buffer->cpumask);\n\n\tkfree(buffer);\n}"
  },
  {
    "function_name": "__ring_buffer_alloc",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1352-1417",
    "snippet": "struct ring_buffer *__ring_buffer_alloc(unsigned long size, unsigned flags,\n\t\t\t\t\tstruct lock_class_key *key)\n{\n\tstruct ring_buffer *buffer;\n\tlong nr_pages;\n\tint bsize;\n\tint cpu;\n\tint ret;\n\n\t/* keep it in its own cache line */\n\tbuffer = kzalloc(ALIGN(sizeof(*buffer), cache_line_size()),\n\t\t\t GFP_KERNEL);\n\tif (!buffer)\n\t\treturn NULL;\n\n\tif (!zalloc_cpumask_var(&buffer->cpumask, GFP_KERNEL))\n\t\tgoto fail_free_buffer;\n\n\tnr_pages = DIV_ROUND_UP(size, BUF_PAGE_SIZE);\n\tbuffer->flags = flags;\n\tbuffer->clock = trace_clock_local;\n\tbuffer->reader_lock_key = key;\n\n\tinit_irq_work(&buffer->irq_work.work, rb_wake_up_waiters);\n\tinit_waitqueue_head(&buffer->irq_work.waiters);\n\n\t/* need at least two pages */\n\tif (nr_pages < 2)\n\t\tnr_pages = 2;\n\n\tbuffer->cpus = nr_cpu_ids;\n\n\tbsize = sizeof(void *) * nr_cpu_ids;\n\tbuffer->buffers = kzalloc(ALIGN(bsize, cache_line_size()),\n\t\t\t\t  GFP_KERNEL);\n\tif (!buffer->buffers)\n\t\tgoto fail_free_cpumask;\n\n\tcpu = raw_smp_processor_id();\n\tcpumask_set_cpu(cpu, buffer->cpumask);\n\tbuffer->buffers[cpu] = rb_allocate_cpu_buffer(buffer, nr_pages, cpu);\n\tif (!buffer->buffers[cpu])\n\t\tgoto fail_free_buffers;\n\n\tret = cpuhp_state_add_instance(CPUHP_TRACE_RB_PREPARE, &buffer->node);\n\tif (ret < 0)\n\t\tgoto fail_free_buffers;\n\n\tmutex_init(&buffer->mutex);\n\n\treturn buffer;\n\n fail_free_buffers:\n\tfor_each_buffer_cpu(buffer, cpu) {\n\t\tif (buffer->buffers[cpu])\n\t\t\trb_free_cpu_buffer(buffer->buffers[cpu]);\n\t}\n\tkfree(buffer->buffers);\n\n fail_free_cpumask:\n\tfree_cpumask_var(buffer->cpumask);\n\n fail_free_buffer:\n\tkfree(buffer);\n\treturn NULL;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)"
    ],
    "globals_used": [
      "static void update_pages_handler(struct work_struct *work);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "buffer"
          ],
          "line": 1415
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/params.c",
          "lines": "73-86",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_cpumask_var",
          "args": [
            "buffer->cpumask"
          ],
          "line": 1412
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_free_cpu_buffer",
          "args": [
            "buffer->buffers[cpu]"
          ],
          "line": 1407
        },
        "resolved": true,
        "details": {
          "function_name": "rb_free_cpu_buffer",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1321-1340",
          "snippet": "static void rb_free_cpu_buffer(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *head = cpu_buffer->pages;\n\tstruct buffer_page *bpage, *tmp;\n\n\tfree_buffer_page(cpu_buffer->reader_page);\n\n\trb_head_page_deactivate(cpu_buffer);\n\n\tif (head) {\n\t\tlist_for_each_entry_safe(bpage, tmp, head, list) {\n\t\t\tlist_del_init(&bpage->list);\n\t\t\tfree_buffer_page(bpage);\n\t\t}\n\t\tbpage = list_entry(head, struct buffer_page, list);\n\t\tfree_buffer_page(bpage);\n\t}\n\n\tkfree(cpu_buffer);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_free_cpu_buffer(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *head = cpu_buffer->pages;\n\tstruct buffer_page *bpage, *tmp;\n\n\tfree_buffer_page(cpu_buffer->reader_page);\n\n\trb_head_page_deactivate(cpu_buffer);\n\n\tif (head) {\n\t\tlist_for_each_entry_safe(bpage, tmp, head, list) {\n\t\t\tlist_del_init(&bpage->list);\n\t\t\tfree_buffer_page(bpage);\n\t\t}\n\t\tbpage = list_entry(head, struct buffer_page, list);\n\t\tfree_buffer_page(bpage);\n\t}\n\n\tkfree(cpu_buffer);\n}"
        }
      },
      {
        "call_info": {
          "callee": "for_each_buffer_cpu",
          "args": [
            "buffer",
            "cpu"
          ],
          "line": 1405
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_init",
          "args": [
            "&buffer->mutex"
          ],
          "line": 1400
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_init_task",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/fork.c",
          "lines": "1604-1612",
          "snippet": "static void rt_mutex_init_task(struct task_struct *p)\n{\n\traw_spin_lock_init(&p->pi_lock);\n#ifdef CONFIG_RT_MUTEXES\n\tp->pi_waiters = RB_ROOT_CACHED;\n\tp->pi_top_task = NULL;\n\tp->pi_blocked_on = NULL;\n#endif\n}",
          "includes": [
            "#include <linux/init_task.h>",
            "#include <trace/events/task.h>",
            "#include <trace/events/sched.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/cacheflush.h>",
            "#include <asm/mmu_context.h>",
            "#include <linux/uaccess.h>",
            "#include <asm/pgalloc.h>",
            "#include <asm/pgtable.h>",
            "#include <linux/stackleak.h>",
            "#include <linux/thread_info.h>",
            "#include <linux/livepatch.h>",
            "#include <linux/kcov.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/compiler.h>",
            "#include <linux/aio.h>",
            "#include <linux/uprobes.h>",
            "#include <linux/signalfd.h>",
            "#include <linux/khugepaged.h>",
            "#include <linux/oom.h>",
            "#include <linux/user-return-notifier.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/magic.h>",
            "#include <linux/fs_struct.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/tty.h>",
            "#include <linux/random.h>",
            "#include <linux/taskstats_kern.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/freezer.h>",
            "#include <linux/cn_proc.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/acct.h>",
            "#include <linux/ksm.h>",
            "#include <linux/rmap.h>",
            "#include <linux/profile.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/memcontrol.h>",
            "#include <linux/audit.h>",
            "#include <linux/mount.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/task_io_accounting_ops.h>",
            "#include <linux/kthread.h>",
            "#include <linux/compat.h>",
            "#include <linux/futex.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swap.h>",
            "#include <linux/seccomp.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/security.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/cpu.h>",
            "#include <linux/capability.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/vmacache.h>",
            "#include <linux/mm.h>",
            "#include <linux/fs.h>",
            "#include <linux/hmm.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/mman.h>",
            "#include <linux/binfmts.h>",
            "#include <linux/key.h>",
            "#include <linux/iocontext.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/file.h>",
            "#include <linux/sem.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/personality.h>",
            "#include <linux/completion.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/module.h>",
            "#include <linux/unistd.h>",
            "#include <linux/init.h>",
            "#include <linux/rtmutex.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/slab.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __latent_entropy struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/init_task.h>\n#include <trace/events/task.h>\n#include <trace/events/sched.h>\n#include <asm/tlbflush.h>\n#include <asm/cacheflush.h>\n#include <asm/mmu_context.h>\n#include <linux/uaccess.h>\n#include <asm/pgalloc.h>\n#include <asm/pgtable.h>\n#include <linux/stackleak.h>\n#include <linux/thread_info.h>\n#include <linux/livepatch.h>\n#include <linux/kcov.h>\n#include <linux/sysctl.h>\n#include <linux/compiler.h>\n#include <linux/aio.h>\n#include <linux/uprobes.h>\n#include <linux/signalfd.h>\n#include <linux/khugepaged.h>\n#include <linux/oom.h>\n#include <linux/user-return-notifier.h>\n#include <linux/posix-timers.h>\n#include <linux/perf_event.h>\n#include <linux/sched/mm.h>\n#include <linux/magic.h>\n#include <linux/fs_struct.h>\n#include <linux/blkdev.h>\n#include <linux/tty.h>\n#include <linux/random.h>\n#include <linux/taskstats_kern.h>\n#include <linux/delayacct.h>\n#include <linux/freezer.h>\n#include <linux/cn_proc.h>\n#include <linux/tsacct_kern.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/acct.h>\n#include <linux/ksm.h>\n#include <linux/rmap.h>\n#include <linux/profile.h>\n#include <linux/proc_fs.h>\n#include <linux/ftrace.h>\n#include <linux/memcontrol.h>\n#include <linux/audit.h>\n#include <linux/mount.h>\n#include <linux/ptrace.h>\n#include <linux/rcupdate.h>\n#include <linux/task_io_accounting_ops.h>\n#include <linux/kthread.h>\n#include <linux/compat.h>\n#include <linux/futex.h>\n#include <linux/jiffies.h>\n#include <linux/syscalls.h>\n#include <linux/swap.h>\n#include <linux/seccomp.h>\n#include <linux/hugetlb.h>\n#include <linux/security.h>\n#include <linux/cgroup.h>\n#include <linux/cpu.h>\n#include <linux/capability.h>\n#include <linux/nsproxy.h>\n#include <linux/vmacache.h>\n#include <linux/mm.h>\n#include <linux/fs.h>\n#include <linux/hmm.h>\n#include <linux/mmu_notifier.h>\n#include <linux/mman.h>\n#include <linux/binfmts.h>\n#include <linux/key.h>\n#include <linux/iocontext.h>\n#include <linux/fdtable.h>\n#include <linux/file.h>\n#include <linux/sem.h>\n#include <linux/mempolicy.h>\n#include <linux/personality.h>\n#include <linux/completion.h>\n#include <linux/vmalloc.h>\n#include <linux/module.h>\n#include <linux/unistd.h>\n#include <linux/init.h>\n#include <linux/rtmutex.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/user.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/autogroup.h>\n#include <linux/slab.h>\n\nstatic __latent_entropy struct;\n\nstatic void rt_mutex_init_task(struct task_struct *p)\n{\n\traw_spin_lock_init(&p->pi_lock);\n#ifdef CONFIG_RT_MUTEXES\n\tp->pi_waiters = RB_ROOT_CACHED;\n\tp->pi_top_task = NULL;\n\tp->pi_blocked_on = NULL;\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpuhp_state_add_instance",
          "args": [
            "CPUHP_TRACE_RB_PREPARE",
            "&buffer->node"
          ],
          "line": 1396
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_allocate_cpu_buffer",
          "args": [
            "buffer",
            "nr_pages",
            "cpu"
          ],
          "line": 1392
        },
        "resolved": true,
        "details": {
          "function_name": "rb_allocate_cpu_buffer",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1260-1319",
          "snippet": "static struct ring_buffer_per_cpu *\nrb_allocate_cpu_buffer(struct ring_buffer *buffer, long nr_pages, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct buffer_page *bpage;\n\tstruct page *page;\n\tint ret;\n\n\tcpu_buffer = kzalloc_node(ALIGN(sizeof(*cpu_buffer), cache_line_size()),\n\t\t\t\t  GFP_KERNEL, cpu_to_node(cpu));\n\tif (!cpu_buffer)\n\t\treturn NULL;\n\n\tcpu_buffer->cpu = cpu;\n\tcpu_buffer->buffer = buffer;\n\traw_spin_lock_init(&cpu_buffer->reader_lock);\n\tlockdep_set_class(&cpu_buffer->reader_lock, buffer->reader_lock_key);\n\tcpu_buffer->lock = (arch_spinlock_t)__ARCH_SPIN_LOCK_UNLOCKED;\n\tINIT_WORK(&cpu_buffer->update_pages_work, update_pages_handler);\n\tinit_completion(&cpu_buffer->update_done);\n\tinit_irq_work(&cpu_buffer->irq_work.work, rb_wake_up_waiters);\n\tinit_waitqueue_head(&cpu_buffer->irq_work.waiters);\n\tinit_waitqueue_head(&cpu_buffer->irq_work.full_waiters);\n\n\tbpage = kzalloc_node(ALIGN(sizeof(*bpage), cache_line_size()),\n\t\t\t    GFP_KERNEL, cpu_to_node(cpu));\n\tif (!bpage)\n\t\tgoto fail_free_buffer;\n\n\trb_check_bpage(cpu_buffer, bpage);\n\n\tcpu_buffer->reader_page = bpage;\n\tpage = alloc_pages_node(cpu_to_node(cpu), GFP_KERNEL, 0);\n\tif (!page)\n\t\tgoto fail_free_reader;\n\tbpage->page = page_address(page);\n\trb_init_page(bpage->page);\n\n\tINIT_LIST_HEAD(&cpu_buffer->reader_page->list);\n\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\n\tret = rb_allocate_pages(cpu_buffer, nr_pages);\n\tif (ret < 0)\n\t\tgoto fail_free_reader;\n\n\tcpu_buffer->head_page\n\t\t= list_entry(cpu_buffer->pages, struct buffer_page, list);\n\tcpu_buffer->tail_page = cpu_buffer->commit_page = cpu_buffer->head_page;\n\n\trb_head_page_activate(cpu_buffer);\n\n\treturn cpu_buffer;\n\n fail_free_reader:\n\tfree_buffer_page(cpu_buffer->reader_page);\n\n fail_free_buffer:\n\tkfree(cpu_buffer);\n\treturn NULL;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void update_pages_handler(struct work_struct *work);",
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void update_pages_handler(struct work_struct *work);\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic struct ring_buffer_per_cpu *\nrb_allocate_cpu_buffer(struct ring_buffer *buffer, long nr_pages, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct buffer_page *bpage;\n\tstruct page *page;\n\tint ret;\n\n\tcpu_buffer = kzalloc_node(ALIGN(sizeof(*cpu_buffer), cache_line_size()),\n\t\t\t\t  GFP_KERNEL, cpu_to_node(cpu));\n\tif (!cpu_buffer)\n\t\treturn NULL;\n\n\tcpu_buffer->cpu = cpu;\n\tcpu_buffer->buffer = buffer;\n\traw_spin_lock_init(&cpu_buffer->reader_lock);\n\tlockdep_set_class(&cpu_buffer->reader_lock, buffer->reader_lock_key);\n\tcpu_buffer->lock = (arch_spinlock_t)__ARCH_SPIN_LOCK_UNLOCKED;\n\tINIT_WORK(&cpu_buffer->update_pages_work, update_pages_handler);\n\tinit_completion(&cpu_buffer->update_done);\n\tinit_irq_work(&cpu_buffer->irq_work.work, rb_wake_up_waiters);\n\tinit_waitqueue_head(&cpu_buffer->irq_work.waiters);\n\tinit_waitqueue_head(&cpu_buffer->irq_work.full_waiters);\n\n\tbpage = kzalloc_node(ALIGN(sizeof(*bpage), cache_line_size()),\n\t\t\t    GFP_KERNEL, cpu_to_node(cpu));\n\tif (!bpage)\n\t\tgoto fail_free_buffer;\n\n\trb_check_bpage(cpu_buffer, bpage);\n\n\tcpu_buffer->reader_page = bpage;\n\tpage = alloc_pages_node(cpu_to_node(cpu), GFP_KERNEL, 0);\n\tif (!page)\n\t\tgoto fail_free_reader;\n\tbpage->page = page_address(page);\n\trb_init_page(bpage->page);\n\n\tINIT_LIST_HEAD(&cpu_buffer->reader_page->list);\n\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\n\tret = rb_allocate_pages(cpu_buffer, nr_pages);\n\tif (ret < 0)\n\t\tgoto fail_free_reader;\n\n\tcpu_buffer->head_page\n\t\t= list_entry(cpu_buffer->pages, struct buffer_page, list);\n\tcpu_buffer->tail_page = cpu_buffer->commit_page = cpu_buffer->head_page;\n\n\trb_head_page_activate(cpu_buffer);\n\n\treturn cpu_buffer;\n\n fail_free_reader:\n\tfree_buffer_page(cpu_buffer->reader_page);\n\n fail_free_buffer:\n\tkfree(cpu_buffer);\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpumask_set_cpu",
          "args": [
            "cpu",
            "buffer->cpumask"
          ],
          "line": 1391
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_smp_processor_id",
          "args": [],
          "line": 1390
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kzalloc",
          "args": [
            "ALIGN(bsize, cache_line_size())",
            "GFP_KERNEL"
          ],
          "line": 1385
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ALIGN",
          "args": [
            "bsize",
            "cache_line_size()"
          ],
          "line": 1385
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cache_line_size",
          "args": [],
          "line": 1385
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "init_waitqueue_head",
          "args": [
            "&buffer->irq_work.waiters"
          ],
          "line": 1376
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "init_irq_work",
          "args": [
            "&buffer->irq_work.work",
            "rb_wake_up_waiters"
          ],
          "line": 1375
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DIV_ROUND_UP",
          "args": [
            "size",
            "BUF_PAGE_SIZE"
          ],
          "line": 1370
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "zalloc_cpumask_var",
          "args": [
            "&buffer->cpumask",
            "GFP_KERNEL"
          ],
          "line": 1367
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kzalloc",
          "args": [
            "ALIGN(sizeof(*buffer), cache_line_size())",
            "GFP_KERNEL"
          ],
          "line": 1362
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ALIGN",
          "args": [
            "sizeof(*buffer)",
            "cache_line_size()"
          ],
          "line": 1362
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cache_line_size",
          "args": [],
          "line": 1362
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)\n\nstatic void update_pages_handler(struct work_struct *work);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstruct ring_buffer *__ring_buffer_alloc(unsigned long size, unsigned flags,\n\t\t\t\t\tstruct lock_class_key *key)\n{\n\tstruct ring_buffer *buffer;\n\tlong nr_pages;\n\tint bsize;\n\tint cpu;\n\tint ret;\n\n\t/* keep it in its own cache line */\n\tbuffer = kzalloc(ALIGN(sizeof(*buffer), cache_line_size()),\n\t\t\t GFP_KERNEL);\n\tif (!buffer)\n\t\treturn NULL;\n\n\tif (!zalloc_cpumask_var(&buffer->cpumask, GFP_KERNEL))\n\t\tgoto fail_free_buffer;\n\n\tnr_pages = DIV_ROUND_UP(size, BUF_PAGE_SIZE);\n\tbuffer->flags = flags;\n\tbuffer->clock = trace_clock_local;\n\tbuffer->reader_lock_key = key;\n\n\tinit_irq_work(&buffer->irq_work.work, rb_wake_up_waiters);\n\tinit_waitqueue_head(&buffer->irq_work.waiters);\n\n\t/* need at least two pages */\n\tif (nr_pages < 2)\n\t\tnr_pages = 2;\n\n\tbuffer->cpus = nr_cpu_ids;\n\n\tbsize = sizeof(void *) * nr_cpu_ids;\n\tbuffer->buffers = kzalloc(ALIGN(bsize, cache_line_size()),\n\t\t\t\t  GFP_KERNEL);\n\tif (!buffer->buffers)\n\t\tgoto fail_free_cpumask;\n\n\tcpu = raw_smp_processor_id();\n\tcpumask_set_cpu(cpu, buffer->cpumask);\n\tbuffer->buffers[cpu] = rb_allocate_cpu_buffer(buffer, nr_pages, cpu);\n\tif (!buffer->buffers[cpu])\n\t\tgoto fail_free_buffers;\n\n\tret = cpuhp_state_add_instance(CPUHP_TRACE_RB_PREPARE, &buffer->node);\n\tif (ret < 0)\n\t\tgoto fail_free_buffers;\n\n\tmutex_init(&buffer->mutex);\n\n\treturn buffer;\n\n fail_free_buffers:\n\tfor_each_buffer_cpu(buffer, cpu) {\n\t\tif (buffer->buffers[cpu])\n\t\t\trb_free_cpu_buffer(buffer->buffers[cpu]);\n\t}\n\tkfree(buffer->buffers);\n\n fail_free_cpumask:\n\tfree_cpumask_var(buffer->cpumask);\n\n fail_free_buffer:\n\tkfree(buffer);\n\treturn NULL;\n}"
  },
  {
    "function_name": "rb_free_cpu_buffer",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1321-1340",
    "snippet": "static void rb_free_cpu_buffer(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *head = cpu_buffer->pages;\n\tstruct buffer_page *bpage, *tmp;\n\n\tfree_buffer_page(cpu_buffer->reader_page);\n\n\trb_head_page_deactivate(cpu_buffer);\n\n\tif (head) {\n\t\tlist_for_each_entry_safe(bpage, tmp, head, list) {\n\t\t\tlist_del_init(&bpage->list);\n\t\t\tfree_buffer_page(bpage);\n\t\t}\n\t\tbpage = list_entry(head, struct buffer_page, list);\n\t\tfree_buffer_page(bpage);\n\t}\n\n\tkfree(cpu_buffer);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "cpu_buffer"
          ],
          "line": 1339
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/params.c",
          "lines": "73-86",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_buffer_page",
          "args": [
            "bpage"
          ],
          "line": 1336
        },
        "resolved": true,
        "details": {
          "function_name": "free_buffer_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "374-378",
          "snippet": "static void free_buffer_page(struct buffer_page *bpage)\n{\n\tfree_page((unsigned long)bpage->page);\n\tkfree(bpage);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void free_buffer_page(struct buffer_page *bpage)\n{\n\tfree_page((unsigned long)bpage->page);\n\tkfree(bpage);\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_entry",
          "args": [
            "head",
            "structbuffer_page",
            "list"
          ],
          "line": 1335
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_del_init",
          "args": [
            "&bpage->list"
          ],
          "line": 1332
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_for_each_entry_safe",
          "args": [
            "bpage",
            "tmp",
            "head",
            "list"
          ],
          "line": 1331
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_head_page_deactivate",
          "args": [
            "cpu_buffer"
          ],
          "line": 1328
        },
        "resolved": true,
        "details": {
          "function_name": "rb_head_page_deactivate",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "912-922",
          "snippet": "static void\nrb_head_page_deactivate(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *hd;\n\n\t/* Go through the whole list and clear any pointers found. */\n\trb_list_head_clear(cpu_buffer->pages);\n\n\tlist_for_each(hd, cpu_buffer->pages)\n\t\trb_list_head_clear(hd);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void\nrb_head_page_deactivate(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *hd;\n\n\t/* Go through the whole list and clear any pointers found. */\n\trb_list_head_clear(cpu_buffer->pages);\n\n\tlist_for_each(hd, cpu_buffer->pages)\n\t\trb_list_head_clear(hd);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_free_cpu_buffer(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *head = cpu_buffer->pages;\n\tstruct buffer_page *bpage, *tmp;\n\n\tfree_buffer_page(cpu_buffer->reader_page);\n\n\trb_head_page_deactivate(cpu_buffer);\n\n\tif (head) {\n\t\tlist_for_each_entry_safe(bpage, tmp, head, list) {\n\t\t\tlist_del_init(&bpage->list);\n\t\t\tfree_buffer_page(bpage);\n\t\t}\n\t\tbpage = list_entry(head, struct buffer_page, list);\n\t\tfree_buffer_page(bpage);\n\t}\n\n\tkfree(cpu_buffer);\n}"
  },
  {
    "function_name": "rb_allocate_cpu_buffer",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1260-1319",
    "snippet": "static struct ring_buffer_per_cpu *\nrb_allocate_cpu_buffer(struct ring_buffer *buffer, long nr_pages, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct buffer_page *bpage;\n\tstruct page *page;\n\tint ret;\n\n\tcpu_buffer = kzalloc_node(ALIGN(sizeof(*cpu_buffer), cache_line_size()),\n\t\t\t\t  GFP_KERNEL, cpu_to_node(cpu));\n\tif (!cpu_buffer)\n\t\treturn NULL;\n\n\tcpu_buffer->cpu = cpu;\n\tcpu_buffer->buffer = buffer;\n\traw_spin_lock_init(&cpu_buffer->reader_lock);\n\tlockdep_set_class(&cpu_buffer->reader_lock, buffer->reader_lock_key);\n\tcpu_buffer->lock = (arch_spinlock_t)__ARCH_SPIN_LOCK_UNLOCKED;\n\tINIT_WORK(&cpu_buffer->update_pages_work, update_pages_handler);\n\tinit_completion(&cpu_buffer->update_done);\n\tinit_irq_work(&cpu_buffer->irq_work.work, rb_wake_up_waiters);\n\tinit_waitqueue_head(&cpu_buffer->irq_work.waiters);\n\tinit_waitqueue_head(&cpu_buffer->irq_work.full_waiters);\n\n\tbpage = kzalloc_node(ALIGN(sizeof(*bpage), cache_line_size()),\n\t\t\t    GFP_KERNEL, cpu_to_node(cpu));\n\tif (!bpage)\n\t\tgoto fail_free_buffer;\n\n\trb_check_bpage(cpu_buffer, bpage);\n\n\tcpu_buffer->reader_page = bpage;\n\tpage = alloc_pages_node(cpu_to_node(cpu), GFP_KERNEL, 0);\n\tif (!page)\n\t\tgoto fail_free_reader;\n\tbpage->page = page_address(page);\n\trb_init_page(bpage->page);\n\n\tINIT_LIST_HEAD(&cpu_buffer->reader_page->list);\n\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\n\tret = rb_allocate_pages(cpu_buffer, nr_pages);\n\tif (ret < 0)\n\t\tgoto fail_free_reader;\n\n\tcpu_buffer->head_page\n\t\t= list_entry(cpu_buffer->pages, struct buffer_page, list);\n\tcpu_buffer->tail_page = cpu_buffer->commit_page = cpu_buffer->head_page;\n\n\trb_head_page_activate(cpu_buffer);\n\n\treturn cpu_buffer;\n\n fail_free_reader:\n\tfree_buffer_page(cpu_buffer->reader_page);\n\n fail_free_buffer:\n\tkfree(cpu_buffer);\n\treturn NULL;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void update_pages_handler(struct work_struct *work);",
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "cpu_buffer"
          ],
          "line": 1317
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/params.c",
          "lines": "73-86",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_buffer_page",
          "args": [
            "cpu_buffer->reader_page"
          ],
          "line": 1314
        },
        "resolved": true,
        "details": {
          "function_name": "free_buffer_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "374-378",
          "snippet": "static void free_buffer_page(struct buffer_page *bpage)\n{\n\tfree_page((unsigned long)bpage->page);\n\tkfree(bpage);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void free_buffer_page(struct buffer_page *bpage)\n{\n\tfree_page((unsigned long)bpage->page);\n\tkfree(bpage);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_head_page_activate",
          "args": [
            "cpu_buffer"
          ],
          "line": 1309
        },
        "resolved": true,
        "details": {
          "function_name": "rb_head_page_activate",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "888-900",
          "snippet": "static void rb_head_page_activate(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *head;\n\n\thead = cpu_buffer->head_page;\n\tif (!head)\n\t\treturn;\n\n\t/*\n\t * Set the previous list pointer to have the HEAD flag.\n\t */\n\trb_set_list_to_head(cpu_buffer, head->list.prev);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_head_page_activate(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *head;\n\n\thead = cpu_buffer->head_page;\n\tif (!head)\n\t\treturn;\n\n\t/*\n\t * Set the previous list pointer to have the HEAD flag.\n\t */\n\trb_set_list_to_head(cpu_buffer, head->list.prev);\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_entry",
          "args": [
            "cpu_buffer->pages",
            "structbuffer_page",
            "list"
          ],
          "line": 1306
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_allocate_pages",
          "args": [
            "cpu_buffer",
            "nr_pages"
          ],
          "line": 1301
        },
        "resolved": true,
        "details": {
          "function_name": "rb_allocate_pages",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1235-1258",
          "snippet": "static int rb_allocate_pages(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t     unsigned long nr_pages)\n{\n\tLIST_HEAD(pages);\n\n\tWARN_ON(!nr_pages);\n\n\tif (__rb_allocate_pages(nr_pages, &pages, cpu_buffer->cpu))\n\t\treturn -ENOMEM;\n\n\t/*\n\t * The ring buffer page list is a circular list that does not\n\t * start and end with a list head. All page list items point to\n\t * other pages.\n\t */\n\tcpu_buffer->pages = pages.next;\n\tlist_del(&pages);\n\n\tcpu_buffer->nr_pages = nr_pages;\n\n\trb_check_pages(cpu_buffer);\n\n\treturn 0;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int rb_allocate_pages(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t     unsigned long nr_pages)\n{\n\tLIST_HEAD(pages);\n\n\tWARN_ON(!nr_pages);\n\n\tif (__rb_allocate_pages(nr_pages, &pages, cpu_buffer->cpu))\n\t\treturn -ENOMEM;\n\n\t/*\n\t * The ring buffer page list is a circular list that does not\n\t * start and end with a list head. All page list items point to\n\t * other pages.\n\t */\n\tcpu_buffer->pages = pages.next;\n\tlist_del(&pages);\n\n\tcpu_buffer->nr_pages = nr_pages;\n\n\trb_check_pages(cpu_buffer);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "INIT_LIST_HEAD",
          "args": [
            "&cpu_buffer->new_pages"
          ],
          "line": 1299
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "INIT_LIST_HEAD",
          "args": [
            "&cpu_buffer->reader_page->list"
          ],
          "line": 1298
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_init_page",
          "args": [
            "bpage->page"
          ],
          "line": 1296
        },
        "resolved": true,
        "details": {
          "function_name": "rb_init_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "351-354",
          "snippet": "static void rb_init_page(struct buffer_data_page *bpage)\n{\n\tlocal_set(&bpage->commit, 0);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_init_page(struct buffer_data_page *bpage)\n{\n\tlocal_set(&bpage->commit, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "page_address",
          "args": [
            "page"
          ],
          "line": 1295
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "alloc_pages_node",
          "args": [
            "cpu_to_node(cpu)",
            "GFP_KERNEL",
            "0"
          ],
          "line": 1292
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_to_node",
          "args": [
            "cpu"
          ],
          "line": 1292
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_check_bpage",
          "args": [
            "cpu_buffer",
            "bpage"
          ],
          "line": 1289
        },
        "resolved": true,
        "details": {
          "function_name": "rb_check_bpage",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1098-1107",
          "snippet": "static int rb_check_bpage(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t  struct buffer_page *bpage)\n{\n\tunsigned long val = (unsigned long)bpage;\n\n\tif (RB_WARN_ON(cpu_buffer, val & RB_FLAG_MASK))\n\t\treturn 1;\n\n\treturn 0;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_FLAG_MASK\t\t3UL"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_FLAG_MASK\t\t3UL\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int rb_check_bpage(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t  struct buffer_page *bpage)\n{\n\tunsigned long val = (unsigned long)bpage;\n\n\tif (RB_WARN_ON(cpu_buffer, val & RB_FLAG_MASK))\n\t\treturn 1;\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kzalloc_node",
          "args": [
            "ALIGN(sizeof(*bpage), cache_line_size())",
            "GFP_KERNEL",
            "cpu_to_node(cpu)"
          ],
          "line": 1284
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_to_node",
          "args": [
            "cpu"
          ],
          "line": 1285
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ALIGN",
          "args": [
            "sizeof(*bpage)",
            "cache_line_size()"
          ],
          "line": 1284
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cache_line_size",
          "args": [],
          "line": 1284
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "init_waitqueue_head",
          "args": [
            "&cpu_buffer->irq_work.full_waiters"
          ],
          "line": 1282
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "init_waitqueue_head",
          "args": [
            "&cpu_buffer->irq_work.waiters"
          ],
          "line": 1281
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "init_irq_work",
          "args": [
            "&cpu_buffer->irq_work.work",
            "rb_wake_up_waiters"
          ],
          "line": 1280
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "init_completion",
          "args": [
            "&cpu_buffer->update_done"
          ],
          "line": 1279
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "INIT_WORK",
          "args": [
            "&cpu_buffer->update_pages_work",
            "update_pages_handler"
          ],
          "line": 1278
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lockdep_set_class",
          "args": [
            "&cpu_buffer->reader_lock",
            "buffer->reader_lock_key"
          ],
          "line": 1276
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_init",
          "args": [
            "&cpu_buffer->reader_lock"
          ],
          "line": 1275
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kzalloc_node",
          "args": [
            "ALIGN(sizeof(*cpu_buffer), cache_line_size())",
            "GFP_KERNEL",
            "cpu_to_node(cpu)"
          ],
          "line": 1268
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_to_node",
          "args": [
            "cpu"
          ],
          "line": 1269
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ALIGN",
          "args": [
            "sizeof(*cpu_buffer)",
            "cache_line_size()"
          ],
          "line": 1268
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cache_line_size",
          "args": [],
          "line": 1268
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void update_pages_handler(struct work_struct *work);\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic struct ring_buffer_per_cpu *\nrb_allocate_cpu_buffer(struct ring_buffer *buffer, long nr_pages, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct buffer_page *bpage;\n\tstruct page *page;\n\tint ret;\n\n\tcpu_buffer = kzalloc_node(ALIGN(sizeof(*cpu_buffer), cache_line_size()),\n\t\t\t\t  GFP_KERNEL, cpu_to_node(cpu));\n\tif (!cpu_buffer)\n\t\treturn NULL;\n\n\tcpu_buffer->cpu = cpu;\n\tcpu_buffer->buffer = buffer;\n\traw_spin_lock_init(&cpu_buffer->reader_lock);\n\tlockdep_set_class(&cpu_buffer->reader_lock, buffer->reader_lock_key);\n\tcpu_buffer->lock = (arch_spinlock_t)__ARCH_SPIN_LOCK_UNLOCKED;\n\tINIT_WORK(&cpu_buffer->update_pages_work, update_pages_handler);\n\tinit_completion(&cpu_buffer->update_done);\n\tinit_irq_work(&cpu_buffer->irq_work.work, rb_wake_up_waiters);\n\tinit_waitqueue_head(&cpu_buffer->irq_work.waiters);\n\tinit_waitqueue_head(&cpu_buffer->irq_work.full_waiters);\n\n\tbpage = kzalloc_node(ALIGN(sizeof(*bpage), cache_line_size()),\n\t\t\t    GFP_KERNEL, cpu_to_node(cpu));\n\tif (!bpage)\n\t\tgoto fail_free_buffer;\n\n\trb_check_bpage(cpu_buffer, bpage);\n\n\tcpu_buffer->reader_page = bpage;\n\tpage = alloc_pages_node(cpu_to_node(cpu), GFP_KERNEL, 0);\n\tif (!page)\n\t\tgoto fail_free_reader;\n\tbpage->page = page_address(page);\n\trb_init_page(bpage->page);\n\n\tINIT_LIST_HEAD(&cpu_buffer->reader_page->list);\n\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\n\tret = rb_allocate_pages(cpu_buffer, nr_pages);\n\tif (ret < 0)\n\t\tgoto fail_free_reader;\n\n\tcpu_buffer->head_page\n\t\t= list_entry(cpu_buffer->pages, struct buffer_page, list);\n\tcpu_buffer->tail_page = cpu_buffer->commit_page = cpu_buffer->head_page;\n\n\trb_head_page_activate(cpu_buffer);\n\n\treturn cpu_buffer;\n\n fail_free_reader:\n\tfree_buffer_page(cpu_buffer->reader_page);\n\n fail_free_buffer:\n\tkfree(cpu_buffer);\n\treturn NULL;\n}"
  },
  {
    "function_name": "rb_allocate_pages",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1235-1258",
    "snippet": "static int rb_allocate_pages(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t     unsigned long nr_pages)\n{\n\tLIST_HEAD(pages);\n\n\tWARN_ON(!nr_pages);\n\n\tif (__rb_allocate_pages(nr_pages, &pages, cpu_buffer->cpu))\n\t\treturn -ENOMEM;\n\n\t/*\n\t * The ring buffer page list is a circular list that does not\n\t * start and end with a list head. All page list items point to\n\t * other pages.\n\t */\n\tcpu_buffer->pages = pages.next;\n\tlist_del(&pages);\n\n\tcpu_buffer->nr_pages = nr_pages;\n\n\trb_check_pages(cpu_buffer);\n\n\treturn 0;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_check_pages",
          "args": [
            "cpu_buffer"
          ],
          "line": 1255
        },
        "resolved": true,
        "details": {
          "function_name": "rb_check_pages",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1129-1162",
          "snippet": "static int rb_check_pages(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *head = cpu_buffer->pages;\n\tstruct buffer_page *bpage, *tmp;\n\n\t/* Reset the head page if it exists */\n\tif (cpu_buffer->head_page)\n\t\trb_set_head_page(cpu_buffer);\n\n\trb_head_page_deactivate(cpu_buffer);\n\n\tif (RB_WARN_ON(cpu_buffer, head->next->prev != head))\n\t\treturn -1;\n\tif (RB_WARN_ON(cpu_buffer, head->prev->next != head))\n\t\treturn -1;\n\n\tif (rb_check_list(cpu_buffer, head))\n\t\treturn -1;\n\n\tlist_for_each_entry_safe(bpage, tmp, head, list) {\n\t\tif (RB_WARN_ON(cpu_buffer,\n\t\t\t       bpage->list.next->prev != &bpage->list))\n\t\t\treturn -1;\n\t\tif (RB_WARN_ON(cpu_buffer,\n\t\t\t       bpage->list.prev->next != &bpage->list))\n\t\t\treturn -1;\n\t\tif (rb_check_list(cpu_buffer, &bpage->list))\n\t\t\treturn -1;\n\t}\n\n\trb_head_page_activate(cpu_buffer);\n\n\treturn 0;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int rb_check_pages(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *head = cpu_buffer->pages;\n\tstruct buffer_page *bpage, *tmp;\n\n\t/* Reset the head page if it exists */\n\tif (cpu_buffer->head_page)\n\t\trb_set_head_page(cpu_buffer);\n\n\trb_head_page_deactivate(cpu_buffer);\n\n\tif (RB_WARN_ON(cpu_buffer, head->next->prev != head))\n\t\treturn -1;\n\tif (RB_WARN_ON(cpu_buffer, head->prev->next != head))\n\t\treturn -1;\n\n\tif (rb_check_list(cpu_buffer, head))\n\t\treturn -1;\n\n\tlist_for_each_entry_safe(bpage, tmp, head, list) {\n\t\tif (RB_WARN_ON(cpu_buffer,\n\t\t\t       bpage->list.next->prev != &bpage->list))\n\t\t\treturn -1;\n\t\tif (RB_WARN_ON(cpu_buffer,\n\t\t\t       bpage->list.prev->next != &bpage->list))\n\t\t\treturn -1;\n\t\tif (rb_check_list(cpu_buffer, &bpage->list))\n\t\t\treturn -1;\n\t}\n\n\trb_head_page_activate(cpu_buffer);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_del",
          "args": [
            "&pages"
          ],
          "line": 1251
        },
        "resolved": true,
        "details": {
          "function_name": "list_del_leaf_cfs_rq",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/fair.c",
          "lines": "446-448",
          "snippet": "static inline void list_del_leaf_cfs_rq(struct cfs_rq *cfs_rq)\n{\n}",
          "includes": [
            "#include \"sched-pelt.h\"",
            "#include \"pelt.h\"",
            "#include <trace/events/sched.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void check_enqueue_throttle(struct cfs_rq *cfs_rq);",
            "static __always_inline void return_cfs_rq_runtime(struct cfs_rq *cfs_rq);",
            "static bool check_cfs_rq_runtime(struct cfs_rq *cfs_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"sched-pelt.h\"\n#include \"pelt.h\"\n#include <trace/events/sched.h>\n#include \"sched.h\"\n\nstatic void check_enqueue_throttle(struct cfs_rq *cfs_rq);\nstatic __always_inline void return_cfs_rq_runtime(struct cfs_rq *cfs_rq);\nstatic bool check_cfs_rq_runtime(struct cfs_rq *cfs_rq);\n\nstatic inline void list_del_leaf_cfs_rq(struct cfs_rq *cfs_rq)\n{\n}"
        }
      },
      {
        "call_info": {
          "callee": "__rb_allocate_pages",
          "args": [
            "nr_pages",
            "&pages",
            "cpu_buffer->cpu"
          ],
          "line": 1242
        },
        "resolved": true,
        "details": {
          "function_name": "__rb_allocate_pages",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1164-1233",
          "snippet": "static int __rb_allocate_pages(long nr_pages, struct list_head *pages, int cpu)\n{\n\tstruct buffer_page *bpage, *tmp;\n\tbool user_thread = current->mm != NULL;\n\tgfp_t mflags;\n\tlong i;\n\n\t/*\n\t * Check if the available memory is there first.\n\t * Note, si_mem_available() only gives us a rough estimate of available\n\t * memory. It may not be accurate. But we don't care, we just want\n\t * to prevent doing any allocation when it is obvious that it is\n\t * not going to succeed.\n\t */\n\ti = si_mem_available();\n\tif (i < nr_pages)\n\t\treturn -ENOMEM;\n\n\t/*\n\t * __GFP_RETRY_MAYFAIL flag makes sure that the allocation fails\n\t * gracefully without invoking oom-killer and the system is not\n\t * destabilized.\n\t */\n\tmflags = GFP_KERNEL | __GFP_RETRY_MAYFAIL;\n\n\t/*\n\t * If a user thread allocates too much, and si_mem_available()\n\t * reports there's enough memory, even though there is not.\n\t * Make sure the OOM killer kills this thread. This can happen\n\t * even with RETRY_MAYFAIL because another task may be doing\n\t * an allocation after this task has taken all memory.\n\t * This is the task the OOM killer needs to take out during this\n\t * loop, even if it was triggered by an allocation somewhere else.\n\t */\n\tif (user_thread)\n\t\tset_current_oom_origin();\n\tfor (i = 0; i < nr_pages; i++) {\n\t\tstruct page *page;\n\n\t\tbpage = kzalloc_node(ALIGN(sizeof(*bpage), cache_line_size()),\n\t\t\t\t    mflags, cpu_to_node(cpu));\n\t\tif (!bpage)\n\t\t\tgoto free_pages;\n\n\t\tlist_add(&bpage->list, pages);\n\n\t\tpage = alloc_pages_node(cpu_to_node(cpu), mflags, 0);\n\t\tif (!page)\n\t\t\tgoto free_pages;\n\t\tbpage->page = page_address(page);\n\t\trb_init_page(bpage->page);\n\n\t\tif (user_thread && fatal_signal_pending(current))\n\t\t\tgoto free_pages;\n\t}\n\tif (user_thread)\n\t\tclear_current_oom_origin();\n\n\treturn 0;\n\nfree_pages:\n\tlist_for_each_entry_safe(bpage, tmp, pages, list) {\n\t\tlist_del_init(&bpage->list);\n\t\tfree_buffer_page(bpage);\n\t}\n\tif (user_thread)\n\t\tclear_current_oom_origin();\n\n\treturn -ENOMEM;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int __rb_allocate_pages(long nr_pages, struct list_head *pages, int cpu)\n{\n\tstruct buffer_page *bpage, *tmp;\n\tbool user_thread = current->mm != NULL;\n\tgfp_t mflags;\n\tlong i;\n\n\t/*\n\t * Check if the available memory is there first.\n\t * Note, si_mem_available() only gives us a rough estimate of available\n\t * memory. It may not be accurate. But we don't care, we just want\n\t * to prevent doing any allocation when it is obvious that it is\n\t * not going to succeed.\n\t */\n\ti = si_mem_available();\n\tif (i < nr_pages)\n\t\treturn -ENOMEM;\n\n\t/*\n\t * __GFP_RETRY_MAYFAIL flag makes sure that the allocation fails\n\t * gracefully without invoking oom-killer and the system is not\n\t * destabilized.\n\t */\n\tmflags = GFP_KERNEL | __GFP_RETRY_MAYFAIL;\n\n\t/*\n\t * If a user thread allocates too much, and si_mem_available()\n\t * reports there's enough memory, even though there is not.\n\t * Make sure the OOM killer kills this thread. This can happen\n\t * even with RETRY_MAYFAIL because another task may be doing\n\t * an allocation after this task has taken all memory.\n\t * This is the task the OOM killer needs to take out during this\n\t * loop, even if it was triggered by an allocation somewhere else.\n\t */\n\tif (user_thread)\n\t\tset_current_oom_origin();\n\tfor (i = 0; i < nr_pages; i++) {\n\t\tstruct page *page;\n\n\t\tbpage = kzalloc_node(ALIGN(sizeof(*bpage), cache_line_size()),\n\t\t\t\t    mflags, cpu_to_node(cpu));\n\t\tif (!bpage)\n\t\t\tgoto free_pages;\n\n\t\tlist_add(&bpage->list, pages);\n\n\t\tpage = alloc_pages_node(cpu_to_node(cpu), mflags, 0);\n\t\tif (!page)\n\t\t\tgoto free_pages;\n\t\tbpage->page = page_address(page);\n\t\trb_init_page(bpage->page);\n\n\t\tif (user_thread && fatal_signal_pending(current))\n\t\t\tgoto free_pages;\n\t}\n\tif (user_thread)\n\t\tclear_current_oom_origin();\n\n\treturn 0;\n\nfree_pages:\n\tlist_for_each_entry_safe(bpage, tmp, pages, list) {\n\t\tlist_del_init(&bpage->list);\n\t\tfree_buffer_page(bpage);\n\t}\n\tif (user_thread)\n\t\tclear_current_oom_origin();\n\n\treturn -ENOMEM;\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "!nr_pages"
          ],
          "line": 1240
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "LIST_HEAD",
          "args": [
            "pages"
          ],
          "line": 1238
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int rb_allocate_pages(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t     unsigned long nr_pages)\n{\n\tLIST_HEAD(pages);\n\n\tWARN_ON(!nr_pages);\n\n\tif (__rb_allocate_pages(nr_pages, &pages, cpu_buffer->cpu))\n\t\treturn -ENOMEM;\n\n\t/*\n\t * The ring buffer page list is a circular list that does not\n\t * start and end with a list head. All page list items point to\n\t * other pages.\n\t */\n\tcpu_buffer->pages = pages.next;\n\tlist_del(&pages);\n\n\tcpu_buffer->nr_pages = nr_pages;\n\n\trb_check_pages(cpu_buffer);\n\n\treturn 0;\n}"
  },
  {
    "function_name": "__rb_allocate_pages",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1164-1233",
    "snippet": "static int __rb_allocate_pages(long nr_pages, struct list_head *pages, int cpu)\n{\n\tstruct buffer_page *bpage, *tmp;\n\tbool user_thread = current->mm != NULL;\n\tgfp_t mflags;\n\tlong i;\n\n\t/*\n\t * Check if the available memory is there first.\n\t * Note, si_mem_available() only gives us a rough estimate of available\n\t * memory. It may not be accurate. But we don't care, we just want\n\t * to prevent doing any allocation when it is obvious that it is\n\t * not going to succeed.\n\t */\n\ti = si_mem_available();\n\tif (i < nr_pages)\n\t\treturn -ENOMEM;\n\n\t/*\n\t * __GFP_RETRY_MAYFAIL flag makes sure that the allocation fails\n\t * gracefully without invoking oom-killer and the system is not\n\t * destabilized.\n\t */\n\tmflags = GFP_KERNEL | __GFP_RETRY_MAYFAIL;\n\n\t/*\n\t * If a user thread allocates too much, and si_mem_available()\n\t * reports there's enough memory, even though there is not.\n\t * Make sure the OOM killer kills this thread. This can happen\n\t * even with RETRY_MAYFAIL because another task may be doing\n\t * an allocation after this task has taken all memory.\n\t * This is the task the OOM killer needs to take out during this\n\t * loop, even if it was triggered by an allocation somewhere else.\n\t */\n\tif (user_thread)\n\t\tset_current_oom_origin();\n\tfor (i = 0; i < nr_pages; i++) {\n\t\tstruct page *page;\n\n\t\tbpage = kzalloc_node(ALIGN(sizeof(*bpage), cache_line_size()),\n\t\t\t\t    mflags, cpu_to_node(cpu));\n\t\tif (!bpage)\n\t\t\tgoto free_pages;\n\n\t\tlist_add(&bpage->list, pages);\n\n\t\tpage = alloc_pages_node(cpu_to_node(cpu), mflags, 0);\n\t\tif (!page)\n\t\t\tgoto free_pages;\n\t\tbpage->page = page_address(page);\n\t\trb_init_page(bpage->page);\n\n\t\tif (user_thread && fatal_signal_pending(current))\n\t\t\tgoto free_pages;\n\t}\n\tif (user_thread)\n\t\tclear_current_oom_origin();\n\n\treturn 0;\n\nfree_pages:\n\tlist_for_each_entry_safe(bpage, tmp, pages, list) {\n\t\tlist_del_init(&bpage->list);\n\t\tfree_buffer_page(bpage);\n\t}\n\tif (user_thread)\n\t\tclear_current_oom_origin();\n\n\treturn -ENOMEM;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "clear_current_oom_origin",
          "args": [],
          "line": 1230
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "free_buffer_page",
          "args": [
            "bpage"
          ],
          "line": 1227
        },
        "resolved": true,
        "details": {
          "function_name": "free_buffer_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "374-378",
          "snippet": "static void free_buffer_page(struct buffer_page *bpage)\n{\n\tfree_page((unsigned long)bpage->page);\n\tkfree(bpage);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void free_buffer_page(struct buffer_page *bpage)\n{\n\tfree_page((unsigned long)bpage->page);\n\tkfree(bpage);\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_del_init",
          "args": [
            "&bpage->list"
          ],
          "line": 1226
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_for_each_entry_safe",
          "args": [
            "bpage",
            "tmp",
            "pages",
            "list"
          ],
          "line": 1225
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "clear_current_oom_origin",
          "args": [],
          "line": 1220
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "fatal_signal_pending",
          "args": [
            "current"
          ],
          "line": 1216
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_init_page",
          "args": [
            "bpage->page"
          ],
          "line": 1214
        },
        "resolved": true,
        "details": {
          "function_name": "rb_init_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "351-354",
          "snippet": "static void rb_init_page(struct buffer_data_page *bpage)\n{\n\tlocal_set(&bpage->commit, 0);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_init_page(struct buffer_data_page *bpage)\n{\n\tlocal_set(&bpage->commit, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "page_address",
          "args": [
            "page"
          ],
          "line": 1213
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "alloc_pages_node",
          "args": [
            "cpu_to_node(cpu)",
            "mflags",
            "0"
          ],
          "line": 1210
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_to_node",
          "args": [
            "cpu"
          ],
          "line": 1210
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_add",
          "args": [
            "&bpage->list",
            "pages"
          ],
          "line": 1208
        },
        "resolved": true,
        "details": {
          "function_name": "list_add_event",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/events/core.c",
          "lines": "1662-1690",
          "snippet": "static void\nlist_add_event(struct perf_event *event, struct perf_event_context *ctx)\n{\n\tlockdep_assert_held(&ctx->lock);\n\n\tWARN_ON_ONCE(event->attach_state & PERF_ATTACH_CONTEXT);\n\tevent->attach_state |= PERF_ATTACH_CONTEXT;\n\n\tevent->tstamp = perf_event_time(event);\n\n\t/*\n\t * If we're a stand alone event or group leader, we go to the context\n\t * list, group events are kept attached to the group so that\n\t * perf_group_detach can, at all times, locate all siblings.\n\t */\n\tif (event->group_leader == event) {\n\t\tevent->group_caps = event->event_caps;\n\t\tadd_event_to_groups(event, ctx);\n\t}\n\n\tlist_update_cgroup_event(event, ctx, true);\n\n\tlist_add_rcu(&event->event_entry, &ctx->event_list);\n\tctx->nr_events++;\n\tif (event->attr.inherit_stat)\n\t\tctx->nr_stat++;\n\n\tctx->generation++;\n}",
          "includes": [
            "#include <asm/irq_regs.h>",
            "#include \"internal.h\"",
            "#include <linux/mount.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/parser.h>",
            "#include <linux/namei.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/compat.h>",
            "#include <linux/mman.h>",
            "#include <linux/module.h>",
            "#include <linux/mm_types.h>",
            "#include <linux/hw_breakpoint.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/rculist.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/device.h>",
            "#include <linux/vmstat.h>",
            "#include <linux/reboot.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/percpu.h>",
            "#include <linux/dcache.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/tick.h>",
            "#include <linux/hash.h>",
            "#include <linux/slab.h>",
            "#include <linux/poll.h>",
            "#include <linux/file.h>",
            "#include <linux/idr.h>",
            "#include <linux/smp.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/fs.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void update_context_time(struct perf_event_context *ctx);",
            "static u64 perf_event_time(struct perf_event *event);",
            "static __must_check struct",
            "static void perf_log_itrace_start(struct perf_event *event);",
            "static void perf_event_free_filter(struct perf_event *event);",
            "static void perf_event_free_bpf_prog(struct perf_event *event);",
            "static int perf_copy_attr(struct perf_event_attr __user *uattr,\n\t\t\t  struct perf_event_attr *attr);",
            "static void perf_pmu_output_stop(struct perf_event *event);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/irq_regs.h>\n#include \"internal.h\"\n#include <linux/mount.h>\n#include <linux/proc_ns.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/clock.h>\n#include <linux/parser.h>\n#include <linux/namei.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/compat.h>\n#include <linux/mman.h>\n#include <linux/module.h>\n#include <linux/mm_types.h>\n#include <linux/hw_breakpoint.h>\n#include <linux/trace_events.h>\n#include <linux/perf_event.h>\n#include <linux/cgroup.h>\n#include <linux/kernel_stat.h>\n#include <linux/anon_inodes.h>\n#include <linux/syscalls.h>\n#include <linux/uaccess.h>\n#include <linux/rculist.h>\n#include <linux/hardirq.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/device.h>\n#include <linux/vmstat.h>\n#include <linux/reboot.h>\n#include <linux/ptrace.h>\n#include <linux/percpu.h>\n#include <linux/dcache.h>\n#include <linux/sysfs.h>\n#include <linux/tick.h>\n#include <linux/hash.h>\n#include <linux/slab.h>\n#include <linux/poll.h>\n#include <linux/file.h>\n#include <linux/idr.h>\n#include <linux/smp.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/fs.h>\n\nstatic void update_context_time(struct perf_event_context *ctx);\nstatic u64 perf_event_time(struct perf_event *event);\nstatic __must_check struct;\nstatic void perf_log_itrace_start(struct perf_event *event);\nstatic void perf_event_free_filter(struct perf_event *event);\nstatic void perf_event_free_bpf_prog(struct perf_event *event);\nstatic int perf_copy_attr(struct perf_event_attr __user *uattr,\n\t\t\t  struct perf_event_attr *attr);\nstatic void perf_pmu_output_stop(struct perf_event *event);\n\nstatic void\nlist_add_event(struct perf_event *event, struct perf_event_context *ctx)\n{\n\tlockdep_assert_held(&ctx->lock);\n\n\tWARN_ON_ONCE(event->attach_state & PERF_ATTACH_CONTEXT);\n\tevent->attach_state |= PERF_ATTACH_CONTEXT;\n\n\tevent->tstamp = perf_event_time(event);\n\n\t/*\n\t * If we're a stand alone event or group leader, we go to the context\n\t * list, group events are kept attached to the group so that\n\t * perf_group_detach can, at all times, locate all siblings.\n\t */\n\tif (event->group_leader == event) {\n\t\tevent->group_caps = event->event_caps;\n\t\tadd_event_to_groups(event, ctx);\n\t}\n\n\tlist_update_cgroup_event(event, ctx, true);\n\n\tlist_add_rcu(&event->event_entry, &ctx->event_list);\n\tctx->nr_events++;\n\tif (event->attr.inherit_stat)\n\t\tctx->nr_stat++;\n\n\tctx->generation++;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kzalloc_node",
          "args": [
            "ALIGN(sizeof(*bpage), cache_line_size())",
            "mflags",
            "cpu_to_node(cpu)"
          ],
          "line": 1203
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_to_node",
          "args": [
            "cpu"
          ],
          "line": 1204
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ALIGN",
          "args": [
            "sizeof(*bpage)",
            "cache_line_size()"
          ],
          "line": 1203
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cache_line_size",
          "args": [],
          "line": 1203
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "set_current_oom_origin",
          "args": [],
          "line": 1199
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "si_mem_available",
          "args": [],
          "line": 1178
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int __rb_allocate_pages(long nr_pages, struct list_head *pages, int cpu)\n{\n\tstruct buffer_page *bpage, *tmp;\n\tbool user_thread = current->mm != NULL;\n\tgfp_t mflags;\n\tlong i;\n\n\t/*\n\t * Check if the available memory is there first.\n\t * Note, si_mem_available() only gives us a rough estimate of available\n\t * memory. It may not be accurate. But we don't care, we just want\n\t * to prevent doing any allocation when it is obvious that it is\n\t * not going to succeed.\n\t */\n\ti = si_mem_available();\n\tif (i < nr_pages)\n\t\treturn -ENOMEM;\n\n\t/*\n\t * __GFP_RETRY_MAYFAIL flag makes sure that the allocation fails\n\t * gracefully without invoking oom-killer and the system is not\n\t * destabilized.\n\t */\n\tmflags = GFP_KERNEL | __GFP_RETRY_MAYFAIL;\n\n\t/*\n\t * If a user thread allocates too much, and si_mem_available()\n\t * reports there's enough memory, even though there is not.\n\t * Make sure the OOM killer kills this thread. This can happen\n\t * even with RETRY_MAYFAIL because another task may be doing\n\t * an allocation after this task has taken all memory.\n\t * This is the task the OOM killer needs to take out during this\n\t * loop, even if it was triggered by an allocation somewhere else.\n\t */\n\tif (user_thread)\n\t\tset_current_oom_origin();\n\tfor (i = 0; i < nr_pages; i++) {\n\t\tstruct page *page;\n\n\t\tbpage = kzalloc_node(ALIGN(sizeof(*bpage), cache_line_size()),\n\t\t\t\t    mflags, cpu_to_node(cpu));\n\t\tif (!bpage)\n\t\t\tgoto free_pages;\n\n\t\tlist_add(&bpage->list, pages);\n\n\t\tpage = alloc_pages_node(cpu_to_node(cpu), mflags, 0);\n\t\tif (!page)\n\t\t\tgoto free_pages;\n\t\tbpage->page = page_address(page);\n\t\trb_init_page(bpage->page);\n\n\t\tif (user_thread && fatal_signal_pending(current))\n\t\t\tgoto free_pages;\n\t}\n\tif (user_thread)\n\t\tclear_current_oom_origin();\n\n\treturn 0;\n\nfree_pages:\n\tlist_for_each_entry_safe(bpage, tmp, pages, list) {\n\t\tlist_del_init(&bpage->list);\n\t\tfree_buffer_page(bpage);\n\t}\n\tif (user_thread)\n\t\tclear_current_oom_origin();\n\n\treturn -ENOMEM;\n}"
  },
  {
    "function_name": "rb_check_pages",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1129-1162",
    "snippet": "static int rb_check_pages(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *head = cpu_buffer->pages;\n\tstruct buffer_page *bpage, *tmp;\n\n\t/* Reset the head page if it exists */\n\tif (cpu_buffer->head_page)\n\t\trb_set_head_page(cpu_buffer);\n\n\trb_head_page_deactivate(cpu_buffer);\n\n\tif (RB_WARN_ON(cpu_buffer, head->next->prev != head))\n\t\treturn -1;\n\tif (RB_WARN_ON(cpu_buffer, head->prev->next != head))\n\t\treturn -1;\n\n\tif (rb_check_list(cpu_buffer, head))\n\t\treturn -1;\n\n\tlist_for_each_entry_safe(bpage, tmp, head, list) {\n\t\tif (RB_WARN_ON(cpu_buffer,\n\t\t\t       bpage->list.next->prev != &bpage->list))\n\t\t\treturn -1;\n\t\tif (RB_WARN_ON(cpu_buffer,\n\t\t\t       bpage->list.prev->next != &bpage->list))\n\t\t\treturn -1;\n\t\tif (rb_check_list(cpu_buffer, &bpage->list))\n\t\t\treturn -1;\n\t}\n\n\trb_head_page_activate(cpu_buffer);\n\n\treturn 0;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_head_page_activate",
          "args": [
            "cpu_buffer"
          ],
          "line": 1159
        },
        "resolved": true,
        "details": {
          "function_name": "rb_head_page_activate",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "888-900",
          "snippet": "static void rb_head_page_activate(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *head;\n\n\thead = cpu_buffer->head_page;\n\tif (!head)\n\t\treturn;\n\n\t/*\n\t * Set the previous list pointer to have the HEAD flag.\n\t */\n\trb_set_list_to_head(cpu_buffer, head->list.prev);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_head_page_activate(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *head;\n\n\thead = cpu_buffer->head_page;\n\tif (!head)\n\t\treturn;\n\n\t/*\n\t * Set the previous list pointer to have the HEAD flag.\n\t */\n\trb_set_list_to_head(cpu_buffer, head->list.prev);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_check_list",
          "args": [
            "cpu_buffer",
            "&bpage->list"
          ],
          "line": 1155
        },
        "resolved": true,
        "details": {
          "function_name": "rb_check_list",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "1112-1120",
          "snippet": "static int rb_check_list(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t struct list_head *list)\n{\n\tif (RB_WARN_ON(cpu_buffer, rb_list_head(list->prev) != list->prev))\n\t\treturn 1;\n\tif (RB_WARN_ON(cpu_buffer, rb_list_head(list->next) != list->next))\n\t\treturn 1;\n\treturn 0;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int rb_check_list(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t struct list_head *list)\n{\n\tif (RB_WARN_ON(cpu_buffer, rb_list_head(list->prev) != list->prev))\n\t\treturn 1;\n\tif (RB_WARN_ON(cpu_buffer, rb_list_head(list->next) != list->next))\n\t\treturn 1;\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "bpage->list.prev->next != &bpage->list"
          ],
          "line": 1152
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "bpage->list.next->prev != &bpage->list"
          ],
          "line": 1149
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_for_each_entry_safe",
          "args": [
            "bpage",
            "tmp",
            "head",
            "list"
          ],
          "line": 1148
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "head->prev->next != head"
          ],
          "line": 1142
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "head->next->prev != head"
          ],
          "line": 1140
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_head_page_deactivate",
          "args": [
            "cpu_buffer"
          ],
          "line": 1138
        },
        "resolved": true,
        "details": {
          "function_name": "rb_head_page_deactivate",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "912-922",
          "snippet": "static void\nrb_head_page_deactivate(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *hd;\n\n\t/* Go through the whole list and clear any pointers found. */\n\trb_list_head_clear(cpu_buffer->pages);\n\n\tlist_for_each(hd, cpu_buffer->pages)\n\t\trb_list_head_clear(hd);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void\nrb_head_page_deactivate(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *hd;\n\n\t/* Go through the whole list and clear any pointers found. */\n\trb_list_head_clear(cpu_buffer->pages);\n\n\tlist_for_each(hd, cpu_buffer->pages)\n\t\trb_list_head_clear(hd);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_set_head_page",
          "args": [
            "cpu_buffer"
          ],
          "line": 1136
        },
        "resolved": true,
        "details": {
          "function_name": "rb_set_head_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "982-1018",
          "snippet": "static struct buffer_page *\nrb_set_head_page(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *head;\n\tstruct buffer_page *page;\n\tstruct list_head *list;\n\tint i;\n\n\tif (RB_WARN_ON(cpu_buffer, !cpu_buffer->head_page))\n\t\treturn NULL;\n\n\t/* sanity check */\n\tlist = cpu_buffer->pages;\n\tif (RB_WARN_ON(cpu_buffer, rb_list_head(list->prev->next) != list))\n\t\treturn NULL;\n\n\tpage = head = cpu_buffer->head_page;\n\t/*\n\t * It is possible that the writer moves the header behind\n\t * where we started, and we miss in one loop.\n\t * A second loop should grab the header, but we'll do\n\t * three loops just because I'm paranoid.\n\t */\n\tfor (i = 0; i < 3; i++) {\n\t\tdo {\n\t\t\tif (rb_is_head_page(cpu_buffer, page, page->list.prev)) {\n\t\t\t\tcpu_buffer->head_page = page;\n\t\t\t\treturn page;\n\t\t\t}\n\t\t\trb_inc_page(cpu_buffer, &page);\n\t\t} while (page != head);\n\t}\n\n\tRB_WARN_ON(cpu_buffer, 1);\n\n\treturn NULL;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic struct buffer_page *\nrb_set_head_page(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *head;\n\tstruct buffer_page *page;\n\tstruct list_head *list;\n\tint i;\n\n\tif (RB_WARN_ON(cpu_buffer, !cpu_buffer->head_page))\n\t\treturn NULL;\n\n\t/* sanity check */\n\tlist = cpu_buffer->pages;\n\tif (RB_WARN_ON(cpu_buffer, rb_list_head(list->prev->next) != list))\n\t\treturn NULL;\n\n\tpage = head = cpu_buffer->head_page;\n\t/*\n\t * It is possible that the writer moves the header behind\n\t * where we started, and we miss in one loop.\n\t * A second loop should grab the header, but we'll do\n\t * three loops just because I'm paranoid.\n\t */\n\tfor (i = 0; i < 3; i++) {\n\t\tdo {\n\t\t\tif (rb_is_head_page(cpu_buffer, page, page->list.prev)) {\n\t\t\t\tcpu_buffer->head_page = page;\n\t\t\t\treturn page;\n\t\t\t}\n\t\t\trb_inc_page(cpu_buffer, &page);\n\t\t} while (page != head);\n\t}\n\n\tRB_WARN_ON(cpu_buffer, 1);\n\n\treturn NULL;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int rb_check_pages(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *head = cpu_buffer->pages;\n\tstruct buffer_page *bpage, *tmp;\n\n\t/* Reset the head page if it exists */\n\tif (cpu_buffer->head_page)\n\t\trb_set_head_page(cpu_buffer);\n\n\trb_head_page_deactivate(cpu_buffer);\n\n\tif (RB_WARN_ON(cpu_buffer, head->next->prev != head))\n\t\treturn -1;\n\tif (RB_WARN_ON(cpu_buffer, head->prev->next != head))\n\t\treturn -1;\n\n\tif (rb_check_list(cpu_buffer, head))\n\t\treturn -1;\n\n\tlist_for_each_entry_safe(bpage, tmp, head, list) {\n\t\tif (RB_WARN_ON(cpu_buffer,\n\t\t\t       bpage->list.next->prev != &bpage->list))\n\t\t\treturn -1;\n\t\tif (RB_WARN_ON(cpu_buffer,\n\t\t\t       bpage->list.prev->next != &bpage->list))\n\t\t\treturn -1;\n\t\tif (rb_check_list(cpu_buffer, &bpage->list))\n\t\t\treturn -1;\n\t}\n\n\trb_head_page_activate(cpu_buffer);\n\n\treturn 0;\n}"
  },
  {
    "function_name": "rb_check_list",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1112-1120",
    "snippet": "static int rb_check_list(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t struct list_head *list)\n{\n\tif (RB_WARN_ON(cpu_buffer, rb_list_head(list->prev) != list->prev))\n\t\treturn 1;\n\tif (RB_WARN_ON(cpu_buffer, rb_list_head(list->next) != list->next))\n\t\treturn 1;\n\treturn 0;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "rb_list_head(list->next) != list->next"
          ],
          "line": 1117
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_list_head",
          "args": [
            "list->next"
          ],
          "line": 1117
        },
        "resolved": true,
        "details": {
          "function_name": "rb_list_head_clear",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "902-907",
          "snippet": "static void rb_list_head_clear(struct list_head *list)\n{\n\tunsigned long *ptr = (unsigned long *)&list->next;\n\n\t*ptr &= ~RB_FLAG_MASK;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_FLAG_MASK\t\t3UL"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_FLAG_MASK\t\t3UL\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_list_head_clear(struct list_head *list)\n{\n\tunsigned long *ptr = (unsigned long *)&list->next;\n\n\t*ptr &= ~RB_FLAG_MASK;\n}"
        }
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "rb_list_head(list->prev) != list->prev"
          ],
          "line": 1115
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int rb_check_list(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t struct list_head *list)\n{\n\tif (RB_WARN_ON(cpu_buffer, rb_list_head(list->prev) != list->prev))\n\t\treturn 1;\n\tif (RB_WARN_ON(cpu_buffer, rb_list_head(list->next) != list->next))\n\t\treturn 1;\n\treturn 0;\n}"
  },
  {
    "function_name": "rb_check_bpage",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1098-1107",
    "snippet": "static int rb_check_bpage(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t  struct buffer_page *bpage)\n{\n\tunsigned long val = (unsigned long)bpage;\n\n\tif (RB_WARN_ON(cpu_buffer, val & RB_FLAG_MASK))\n\t\treturn 1;\n\n\treturn 0;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_FLAG_MASK\t\t3UL"
    ],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "val & RB_FLAG_MASK"
          ],
          "line": 1103
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_FLAG_MASK\t\t3UL\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int rb_check_bpage(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t  struct buffer_page *bpage)\n{\n\tunsigned long val = (unsigned long)bpage;\n\n\tif (RB_WARN_ON(cpu_buffer, val & RB_FLAG_MASK))\n\t\treturn 1;\n\n\treturn 0;\n}"
  },
  {
    "function_name": "rb_tail_page_update",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1038-1096",
    "snippet": "static void rb_tail_page_update(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t       struct buffer_page *tail_page,\n\t\t\t       struct buffer_page *next_page)\n{\n\tunsigned long old_entries;\n\tunsigned long old_write;\n\n\t/*\n\t * The tail page now needs to be moved forward.\n\t *\n\t * We need to reset the tail page, but without messing\n\t * with possible erasing of data brought in by interrupts\n\t * that have moved the tail page and are currently on it.\n\t *\n\t * We add a counter to the write field to denote this.\n\t */\n\told_write = local_add_return(RB_WRITE_INTCNT, &next_page->write);\n\told_entries = local_add_return(RB_WRITE_INTCNT, &next_page->entries);\n\n\t/*\n\t * Just make sure we have seen our old_write and synchronize\n\t * with any interrupts that come in.\n\t */\n\tbarrier();\n\n\t/*\n\t * If the tail page is still the same as what we think\n\t * it is, then it is up to us to update the tail\n\t * pointer.\n\t */\n\tif (tail_page == READ_ONCE(cpu_buffer->tail_page)) {\n\t\t/* Zero the write counter */\n\t\tunsigned long val = old_write & ~RB_WRITE_MASK;\n\t\tunsigned long eval = old_entries & ~RB_WRITE_MASK;\n\n\t\t/*\n\t\t * This will only succeed if an interrupt did\n\t\t * not come in and change it. In which case, we\n\t\t * do not want to modify it.\n\t\t *\n\t\t * We add (void) to let the compiler know that we do not care\n\t\t * about the return value of these functions. We use the\n\t\t * cmpxchg to only update if an interrupt did not already\n\t\t * do it for us. If the cmpxchg fails, we don't care.\n\t\t */\n\t\t(void)local_cmpxchg(&next_page->write, old_write, val);\n\t\t(void)local_cmpxchg(&next_page->entries, old_entries, eval);\n\n\t\t/*\n\t\t * No need to worry about races with clearing out the commit.\n\t\t * it only can increment when a commit takes place. But that\n\t\t * only happens in the outer most nested commit.\n\t\t */\n\t\tlocal_set(&next_page->page->commit, 0);\n\n\t\t/* Again, either we update tail_page or an interrupt does */\n\t\t(void)cmpxchg(&cpu_buffer->tail_page, tail_page, next_page);\n\t}\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_WRITE_INTCNT\t\t(1 << 20)",
      "#define RB_WRITE_MASK\t\t0xfffff"
    ],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "cmpxchg",
          "args": [
            "&cpu_buffer->tail_page",
            "tail_page",
            "next_page"
          ],
          "line": 1094
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_set",
          "args": [
            "&next_page->page->commit",
            "0"
          ],
          "line": 1091
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_cmpxchg",
          "args": [
            "&next_page->entries",
            "old_entries",
            "eval"
          ],
          "line": 1084
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_cmpxchg",
          "args": [
            "&next_page->write",
            "old_write",
            "val"
          ],
          "line": 1083
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "cpu_buffer->tail_page"
          ],
          "line": 1068
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "barrier",
          "args": [],
          "line": 1061
        },
        "resolved": true,
        "details": {
          "function_name": "membarrier_register_global_expedited",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/membarrier.c",
          "lines": "189-219",
          "snippet": "static int membarrier_register_global_expedited(void)\n{\n\tstruct task_struct *p = current;\n\tstruct mm_struct *mm = p->mm;\n\n\tif (atomic_read(&mm->membarrier_state) &\n\t    MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY)\n\t\treturn 0;\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED, &mm->membarrier_state);\n\tif (atomic_read(&mm->mm_users) == 1 && get_nr_threads(p) == 1) {\n\t\t/*\n\t\t * For single mm user, single threaded process, we can\n\t\t * simply issue a memory barrier after setting\n\t\t * MEMBARRIER_STATE_GLOBAL_EXPEDITED to guarantee that\n\t\t * no memory access following registration is reordered\n\t\t * before registration.\n\t\t */\n\t\tsmp_mb();\n\t} else {\n\t\t/*\n\t\t * For multi-mm user threads, we need to ensure all\n\t\t * future scheduler executions will observe the new\n\t\t * thread flag state for this mm.\n\t\t */\n\t\tsynchronize_sched();\n\t}\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY,\n\t\t  &mm->membarrier_state);\n\n\treturn 0;\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nstatic int membarrier_register_global_expedited(void)\n{\n\tstruct task_struct *p = current;\n\tstruct mm_struct *mm = p->mm;\n\n\tif (atomic_read(&mm->membarrier_state) &\n\t    MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY)\n\t\treturn 0;\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED, &mm->membarrier_state);\n\tif (atomic_read(&mm->mm_users) == 1 && get_nr_threads(p) == 1) {\n\t\t/*\n\t\t * For single mm user, single threaded process, we can\n\t\t * simply issue a memory barrier after setting\n\t\t * MEMBARRIER_STATE_GLOBAL_EXPEDITED to guarantee that\n\t\t * no memory access following registration is reordered\n\t\t * before registration.\n\t\t */\n\t\tsmp_mb();\n\t} else {\n\t\t/*\n\t\t * For multi-mm user threads, we need to ensure all\n\t\t * future scheduler executions will observe the new\n\t\t * thread flag state for this mm.\n\t\t */\n\t\tsynchronize_sched();\n\t}\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY,\n\t\t  &mm->membarrier_state);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_add_return",
          "args": [
            "RB_WRITE_INTCNT",
            "&next_page->entries"
          ],
          "line": 1055
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_add_return",
          "args": [
            "RB_WRITE_INTCNT",
            "&next_page->write"
          ],
          "line": 1054
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_WRITE_INTCNT\t\t(1 << 20)\n#define RB_WRITE_MASK\t\t0xfffff\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_tail_page_update(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t       struct buffer_page *tail_page,\n\t\t\t       struct buffer_page *next_page)\n{\n\tunsigned long old_entries;\n\tunsigned long old_write;\n\n\t/*\n\t * The tail page now needs to be moved forward.\n\t *\n\t * We need to reset the tail page, but without messing\n\t * with possible erasing of data brought in by interrupts\n\t * that have moved the tail page and are currently on it.\n\t *\n\t * We add a counter to the write field to denote this.\n\t */\n\told_write = local_add_return(RB_WRITE_INTCNT, &next_page->write);\n\told_entries = local_add_return(RB_WRITE_INTCNT, &next_page->entries);\n\n\t/*\n\t * Just make sure we have seen our old_write and synchronize\n\t * with any interrupts that come in.\n\t */\n\tbarrier();\n\n\t/*\n\t * If the tail page is still the same as what we think\n\t * it is, then it is up to us to update the tail\n\t * pointer.\n\t */\n\tif (tail_page == READ_ONCE(cpu_buffer->tail_page)) {\n\t\t/* Zero the write counter */\n\t\tunsigned long val = old_write & ~RB_WRITE_MASK;\n\t\tunsigned long eval = old_entries & ~RB_WRITE_MASK;\n\n\t\t/*\n\t\t * This will only succeed if an interrupt did\n\t\t * not come in and change it. In which case, we\n\t\t * do not want to modify it.\n\t\t *\n\t\t * We add (void) to let the compiler know that we do not care\n\t\t * about the return value of these functions. We use the\n\t\t * cmpxchg to only update if an interrupt did not already\n\t\t * do it for us. If the cmpxchg fails, we don't care.\n\t\t */\n\t\t(void)local_cmpxchg(&next_page->write, old_write, val);\n\t\t(void)local_cmpxchg(&next_page->entries, old_entries, eval);\n\n\t\t/*\n\t\t * No need to worry about races with clearing out the commit.\n\t\t * it only can increment when a commit takes place. But that\n\t\t * only happens in the outer most nested commit.\n\t\t */\n\t\tlocal_set(&next_page->page->commit, 0);\n\n\t\t/* Again, either we update tail_page or an interrupt does */\n\t\t(void)cmpxchg(&cpu_buffer->tail_page, tail_page, next_page);\n\t}\n}"
  },
  {
    "function_name": "rb_head_page_replace",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "1020-1033",
    "snippet": "static int rb_head_page_replace(struct buffer_page *old,\n\t\t\t\tstruct buffer_page *new)\n{\n\tunsigned long *ptr = (unsigned long *)&old->list.prev->next;\n\tunsigned long val;\n\tunsigned long ret;\n\n\tval = *ptr & ~RB_FLAG_MASK;\n\tval |= RB_PAGE_HEAD;\n\n\tret = cmpxchg(ptr, val, (unsigned long)&new->list);\n\n\treturn ret == val;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_FLAG_MASK\t\t3UL",
      "#define RB_PAGE_HEAD\t\t1UL"
    ],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "cmpxchg",
          "args": [
            "ptr",
            "val",
            "(unsigned long)&new->list"
          ],
          "line": 1030
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_FLAG_MASK\t\t3UL\n#define RB_PAGE_HEAD\t\t1UL\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int rb_head_page_replace(struct buffer_page *old,\n\t\t\t\tstruct buffer_page *new)\n{\n\tunsigned long *ptr = (unsigned long *)&old->list.prev->next;\n\tunsigned long val;\n\tunsigned long ret;\n\n\tval = *ptr & ~RB_FLAG_MASK;\n\tval |= RB_PAGE_HEAD;\n\n\tret = cmpxchg(ptr, val, (unsigned long)&new->list);\n\n\treturn ret == val;\n}"
  },
  {
    "function_name": "rb_set_head_page",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "982-1018",
    "snippet": "static struct buffer_page *\nrb_set_head_page(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *head;\n\tstruct buffer_page *page;\n\tstruct list_head *list;\n\tint i;\n\n\tif (RB_WARN_ON(cpu_buffer, !cpu_buffer->head_page))\n\t\treturn NULL;\n\n\t/* sanity check */\n\tlist = cpu_buffer->pages;\n\tif (RB_WARN_ON(cpu_buffer, rb_list_head(list->prev->next) != list))\n\t\treturn NULL;\n\n\tpage = head = cpu_buffer->head_page;\n\t/*\n\t * It is possible that the writer moves the header behind\n\t * where we started, and we miss in one loop.\n\t * A second loop should grab the header, but we'll do\n\t * three loops just because I'm paranoid.\n\t */\n\tfor (i = 0; i < 3; i++) {\n\t\tdo {\n\t\t\tif (rb_is_head_page(cpu_buffer, page, page->list.prev)) {\n\t\t\t\tcpu_buffer->head_page = page;\n\t\t\t\treturn page;\n\t\t\t}\n\t\t\trb_inc_page(cpu_buffer, &page);\n\t\t} while (page != head);\n\t}\n\n\tRB_WARN_ON(cpu_buffer, 1);\n\n\treturn NULL;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "1"
          ],
          "line": 1015
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_inc_page",
          "args": [
            "cpu_buffer",
            "&page"
          ],
          "line": 1011
        },
        "resolved": true,
        "details": {
          "function_name": "rb_inc_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "974-980",
          "snippet": "static inline void rb_inc_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t       struct buffer_page **bpage)\n{\n\tstruct list_head *p = rb_list_head((*bpage)->list.next);\n\n\t*bpage = list_entry(p, struct buffer_page, list);\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline void rb_inc_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t       struct buffer_page **bpage)\n{\n\tstruct list_head *p = rb_list_head((*bpage)->list.next);\n\n\t*bpage = list_entry(p, struct buffer_page, list);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_is_head_page",
          "args": [
            "cpu_buffer",
            "page",
            "page->list.prev"
          ],
          "line": 1007
        },
        "resolved": true,
        "details": {
          "function_name": "rb_is_head_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "844-856",
          "snippet": "static inline int\nrb_is_head_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\tstruct buffer_page *page, struct list_head *list)\n{\n\tunsigned long val;\n\n\tval = (unsigned long)list->next;\n\n\tif ((val & ~RB_FLAG_MASK) != (unsigned long)&page->list)\n\t\treturn RB_PAGE_MOVED;\n\n\treturn val & RB_FLAG_MASK;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_PAGE_MOVED\t\t4UL",
            "#define RB_FLAG_MASK\t\t3UL"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_PAGE_MOVED\t\t4UL\n#define RB_FLAG_MASK\t\t3UL\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline int\nrb_is_head_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\tstruct buffer_page *page, struct list_head *list)\n{\n\tunsigned long val;\n\n\tval = (unsigned long)list->next;\n\n\tif ((val & ~RB_FLAG_MASK) != (unsigned long)&page->list)\n\t\treturn RB_PAGE_MOVED;\n\n\treturn val & RB_FLAG_MASK;\n}"
        }
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "rb_list_head(list->prev->next) != list"
          ],
          "line": 995
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_list_head",
          "args": [
            "list->prev->next"
          ],
          "line": 995
        },
        "resolved": true,
        "details": {
          "function_name": "rb_list_head_clear",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "902-907",
          "snippet": "static void rb_list_head_clear(struct list_head *list)\n{\n\tunsigned long *ptr = (unsigned long *)&list->next;\n\n\t*ptr &= ~RB_FLAG_MASK;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_FLAG_MASK\t\t3UL"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_FLAG_MASK\t\t3UL\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_list_head_clear(struct list_head *list)\n{\n\tunsigned long *ptr = (unsigned long *)&list->next;\n\n\t*ptr &= ~RB_FLAG_MASK;\n}"
        }
      },
      {
        "call_info": {
          "callee": "RB_WARN_ON",
          "args": [
            "cpu_buffer",
            "!cpu_buffer->head_page"
          ],
          "line": 990
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic struct buffer_page *\nrb_set_head_page(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *head;\n\tstruct buffer_page *page;\n\tstruct list_head *list;\n\tint i;\n\n\tif (RB_WARN_ON(cpu_buffer, !cpu_buffer->head_page))\n\t\treturn NULL;\n\n\t/* sanity check */\n\tlist = cpu_buffer->pages;\n\tif (RB_WARN_ON(cpu_buffer, rb_list_head(list->prev->next) != list))\n\t\treturn NULL;\n\n\tpage = head = cpu_buffer->head_page;\n\t/*\n\t * It is possible that the writer moves the header behind\n\t * where we started, and we miss in one loop.\n\t * A second loop should grab the header, but we'll do\n\t * three loops just because I'm paranoid.\n\t */\n\tfor (i = 0; i < 3; i++) {\n\t\tdo {\n\t\t\tif (rb_is_head_page(cpu_buffer, page, page->list.prev)) {\n\t\t\t\tcpu_buffer->head_page = page;\n\t\t\t\treturn page;\n\t\t\t}\n\t\t\trb_inc_page(cpu_buffer, &page);\n\t\t} while (page != head);\n\t}\n\n\tRB_WARN_ON(cpu_buffer, 1);\n\n\treturn NULL;\n}"
  },
  {
    "function_name": "rb_inc_page",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "974-980",
    "snippet": "static inline void rb_inc_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t       struct buffer_page **bpage)\n{\n\tstruct list_head *p = rb_list_head((*bpage)->list.next);\n\n\t*bpage = list_entry(p, struct buffer_page, list);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "list_entry",
          "args": [
            "p",
            "structbuffer_page",
            "list"
          ],
          "line": 979
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_list_head",
          "args": [
            "(*bpage)->list.next"
          ],
          "line": 977
        },
        "resolved": true,
        "details": {
          "function_name": "rb_list_head_clear",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "902-907",
          "snippet": "static void rb_list_head_clear(struct list_head *list)\n{\n\tunsigned long *ptr = (unsigned long *)&list->next;\n\n\t*ptr &= ~RB_FLAG_MASK;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_FLAG_MASK\t\t3UL"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_FLAG_MASK\t\t3UL\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_list_head_clear(struct list_head *list)\n{\n\tunsigned long *ptr = (unsigned long *)&list->next;\n\n\t*ptr &= ~RB_FLAG_MASK;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline void rb_inc_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t       struct buffer_page **bpage)\n{\n\tstruct list_head *p = rb_list_head((*bpage)->list.next);\n\n\t*bpage = list_entry(p, struct buffer_page, list);\n}"
  },
  {
    "function_name": "rb_head_page_set_normal",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "965-972",
    "snippet": "static int rb_head_page_set_normal(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t   struct buffer_page *head,\n\t\t\t\t   struct buffer_page *prev,\n\t\t\t\t   int old_flag)\n{\n\treturn rb_head_page_set(cpu_buffer, head, prev,\n\t\t\t\told_flag, RB_PAGE_NORMAL);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_PAGE_NORMAL\t\t0UL"
    ],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_head_page_set",
          "args": [
            "cpu_buffer",
            "head",
            "prev",
            "old_flag",
            "RB_PAGE_NORMAL"
          ],
          "line": 970
        },
        "resolved": true,
        "details": {
          "function_name": "rb_head_page_set",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "924-945",
          "snippet": "static int rb_head_page_set(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t    struct buffer_page *head,\n\t\t\t    struct buffer_page *prev,\n\t\t\t    int old_flag, int new_flag)\n{\n\tstruct list_head *list;\n\tunsigned long val = (unsigned long)&head->list;\n\tunsigned long ret;\n\n\tlist = &prev->list;\n\n\tval &= ~RB_FLAG_MASK;\n\n\tret = cmpxchg((unsigned long *)&list->next,\n\t\t      val | old_flag, val | new_flag);\n\n\t/* check if the reader took the page */\n\tif ((ret & ~RB_FLAG_MASK) != val)\n\t\treturn RB_PAGE_MOVED;\n\n\treturn ret & RB_FLAG_MASK;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_PAGE_MOVED\t\t4UL",
            "#define RB_FLAG_MASK\t\t3UL"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_PAGE_MOVED\t\t4UL\n#define RB_FLAG_MASK\t\t3UL\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int rb_head_page_set(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t    struct buffer_page *head,\n\t\t\t    struct buffer_page *prev,\n\t\t\t    int old_flag, int new_flag)\n{\n\tstruct list_head *list;\n\tunsigned long val = (unsigned long)&head->list;\n\tunsigned long ret;\n\n\tlist = &prev->list;\n\n\tval &= ~RB_FLAG_MASK;\n\n\tret = cmpxchg((unsigned long *)&list->next,\n\t\t      val | old_flag, val | new_flag);\n\n\t/* check if the reader took the page */\n\tif ((ret & ~RB_FLAG_MASK) != val)\n\t\treturn RB_PAGE_MOVED;\n\n\treturn ret & RB_FLAG_MASK;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_PAGE_NORMAL\t\t0UL\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int rb_head_page_set_normal(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t   struct buffer_page *head,\n\t\t\t\t   struct buffer_page *prev,\n\t\t\t\t   int old_flag)\n{\n\treturn rb_head_page_set(cpu_buffer, head, prev,\n\t\t\t\told_flag, RB_PAGE_NORMAL);\n}"
  },
  {
    "function_name": "rb_head_page_set_head",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "956-963",
    "snippet": "static int rb_head_page_set_head(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t struct buffer_page *head,\n\t\t\t\t struct buffer_page *prev,\n\t\t\t\t int old_flag)\n{\n\treturn rb_head_page_set(cpu_buffer, head, prev,\n\t\t\t\told_flag, RB_PAGE_HEAD);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_PAGE_HEAD\t\t1UL"
    ],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_head_page_set",
          "args": [
            "cpu_buffer",
            "head",
            "prev",
            "old_flag",
            "RB_PAGE_HEAD"
          ],
          "line": 961
        },
        "resolved": true,
        "details": {
          "function_name": "rb_head_page_set",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "924-945",
          "snippet": "static int rb_head_page_set(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t    struct buffer_page *head,\n\t\t\t    struct buffer_page *prev,\n\t\t\t    int old_flag, int new_flag)\n{\n\tstruct list_head *list;\n\tunsigned long val = (unsigned long)&head->list;\n\tunsigned long ret;\n\n\tlist = &prev->list;\n\n\tval &= ~RB_FLAG_MASK;\n\n\tret = cmpxchg((unsigned long *)&list->next,\n\t\t      val | old_flag, val | new_flag);\n\n\t/* check if the reader took the page */\n\tif ((ret & ~RB_FLAG_MASK) != val)\n\t\treturn RB_PAGE_MOVED;\n\n\treturn ret & RB_FLAG_MASK;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_PAGE_MOVED\t\t4UL",
            "#define RB_FLAG_MASK\t\t3UL"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_PAGE_MOVED\t\t4UL\n#define RB_FLAG_MASK\t\t3UL\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int rb_head_page_set(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t    struct buffer_page *head,\n\t\t\t    struct buffer_page *prev,\n\t\t\t    int old_flag, int new_flag)\n{\n\tstruct list_head *list;\n\tunsigned long val = (unsigned long)&head->list;\n\tunsigned long ret;\n\n\tlist = &prev->list;\n\n\tval &= ~RB_FLAG_MASK;\n\n\tret = cmpxchg((unsigned long *)&list->next,\n\t\t      val | old_flag, val | new_flag);\n\n\t/* check if the reader took the page */\n\tif ((ret & ~RB_FLAG_MASK) != val)\n\t\treturn RB_PAGE_MOVED;\n\n\treturn ret & RB_FLAG_MASK;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_PAGE_HEAD\t\t1UL\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int rb_head_page_set_head(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t struct buffer_page *head,\n\t\t\t\t struct buffer_page *prev,\n\t\t\t\t int old_flag)\n{\n\treturn rb_head_page_set(cpu_buffer, head, prev,\n\t\t\t\told_flag, RB_PAGE_HEAD);\n}"
  },
  {
    "function_name": "rb_head_page_set_update",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "947-954",
    "snippet": "static int rb_head_page_set_update(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t   struct buffer_page *head,\n\t\t\t\t   struct buffer_page *prev,\n\t\t\t\t   int old_flag)\n{\n\treturn rb_head_page_set(cpu_buffer, head, prev,\n\t\t\t\told_flag, RB_PAGE_UPDATE);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_PAGE_UPDATE\t\t2UL"
    ],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_head_page_set",
          "args": [
            "cpu_buffer",
            "head",
            "prev",
            "old_flag",
            "RB_PAGE_UPDATE"
          ],
          "line": 952
        },
        "resolved": true,
        "details": {
          "function_name": "rb_head_page_set",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "924-945",
          "snippet": "static int rb_head_page_set(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t    struct buffer_page *head,\n\t\t\t    struct buffer_page *prev,\n\t\t\t    int old_flag, int new_flag)\n{\n\tstruct list_head *list;\n\tunsigned long val = (unsigned long)&head->list;\n\tunsigned long ret;\n\n\tlist = &prev->list;\n\n\tval &= ~RB_FLAG_MASK;\n\n\tret = cmpxchg((unsigned long *)&list->next,\n\t\t      val | old_flag, val | new_flag);\n\n\t/* check if the reader took the page */\n\tif ((ret & ~RB_FLAG_MASK) != val)\n\t\treturn RB_PAGE_MOVED;\n\n\treturn ret & RB_FLAG_MASK;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_PAGE_MOVED\t\t4UL",
            "#define RB_FLAG_MASK\t\t3UL"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_PAGE_MOVED\t\t4UL\n#define RB_FLAG_MASK\t\t3UL\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int rb_head_page_set(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t    struct buffer_page *head,\n\t\t\t    struct buffer_page *prev,\n\t\t\t    int old_flag, int new_flag)\n{\n\tstruct list_head *list;\n\tunsigned long val = (unsigned long)&head->list;\n\tunsigned long ret;\n\n\tlist = &prev->list;\n\n\tval &= ~RB_FLAG_MASK;\n\n\tret = cmpxchg((unsigned long *)&list->next,\n\t\t      val | old_flag, val | new_flag);\n\n\t/* check if the reader took the page */\n\tif ((ret & ~RB_FLAG_MASK) != val)\n\t\treturn RB_PAGE_MOVED;\n\n\treturn ret & RB_FLAG_MASK;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_PAGE_UPDATE\t\t2UL\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int rb_head_page_set_update(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t   struct buffer_page *head,\n\t\t\t\t   struct buffer_page *prev,\n\t\t\t\t   int old_flag)\n{\n\treturn rb_head_page_set(cpu_buffer, head, prev,\n\t\t\t\told_flag, RB_PAGE_UPDATE);\n}"
  },
  {
    "function_name": "rb_head_page_set",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "924-945",
    "snippet": "static int rb_head_page_set(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t    struct buffer_page *head,\n\t\t\t    struct buffer_page *prev,\n\t\t\t    int old_flag, int new_flag)\n{\n\tstruct list_head *list;\n\tunsigned long val = (unsigned long)&head->list;\n\tunsigned long ret;\n\n\tlist = &prev->list;\n\n\tval &= ~RB_FLAG_MASK;\n\n\tret = cmpxchg((unsigned long *)&list->next,\n\t\t      val | old_flag, val | new_flag);\n\n\t/* check if the reader took the page */\n\tif ((ret & ~RB_FLAG_MASK) != val)\n\t\treturn RB_PAGE_MOVED;\n\n\treturn ret & RB_FLAG_MASK;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_PAGE_MOVED\t\t4UL",
      "#define RB_FLAG_MASK\t\t3UL"
    ],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "cmpxchg",
          "args": [
            "(unsigned long *)&list->next",
            "val | old_flag",
            "val | new_flag"
          ],
          "line": 937
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_PAGE_MOVED\t\t4UL\n#define RB_FLAG_MASK\t\t3UL\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic int rb_head_page_set(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t    struct buffer_page *head,\n\t\t\t    struct buffer_page *prev,\n\t\t\t    int old_flag, int new_flag)\n{\n\tstruct list_head *list;\n\tunsigned long val = (unsigned long)&head->list;\n\tunsigned long ret;\n\n\tlist = &prev->list;\n\n\tval &= ~RB_FLAG_MASK;\n\n\tret = cmpxchg((unsigned long *)&list->next,\n\t\t      val | old_flag, val | new_flag);\n\n\t/* check if the reader took the page */\n\tif ((ret & ~RB_FLAG_MASK) != val)\n\t\treturn RB_PAGE_MOVED;\n\n\treturn ret & RB_FLAG_MASK;\n}"
  },
  {
    "function_name": "rb_head_page_deactivate",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "912-922",
    "snippet": "static void\nrb_head_page_deactivate(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *hd;\n\n\t/* Go through the whole list and clear any pointers found. */\n\trb_list_head_clear(cpu_buffer->pages);\n\n\tlist_for_each(hd, cpu_buffer->pages)\n\t\trb_list_head_clear(hd);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_list_head_clear",
          "args": [
            "hd"
          ],
          "line": 921
        },
        "resolved": true,
        "details": {
          "function_name": "rb_list_head_clear",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "902-907",
          "snippet": "static void rb_list_head_clear(struct list_head *list)\n{\n\tunsigned long *ptr = (unsigned long *)&list->next;\n\n\t*ptr &= ~RB_FLAG_MASK;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_FLAG_MASK\t\t3UL"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_FLAG_MASK\t\t3UL\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_list_head_clear(struct list_head *list)\n{\n\tunsigned long *ptr = (unsigned long *)&list->next;\n\n\t*ptr &= ~RB_FLAG_MASK;\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_for_each",
          "args": [
            "hd",
            "cpu_buffer->pages"
          ],
          "line": 920
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void\nrb_head_page_deactivate(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct list_head *hd;\n\n\t/* Go through the whole list and clear any pointers found. */\n\trb_list_head_clear(cpu_buffer->pages);\n\n\tlist_for_each(hd, cpu_buffer->pages)\n\t\trb_list_head_clear(hd);\n}"
  },
  {
    "function_name": "rb_list_head_clear",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "902-907",
    "snippet": "static void rb_list_head_clear(struct list_head *list)\n{\n\tunsigned long *ptr = (unsigned long *)&list->next;\n\n\t*ptr &= ~RB_FLAG_MASK;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_FLAG_MASK\t\t3UL"
    ],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_FLAG_MASK\t\t3UL\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_list_head_clear(struct list_head *list)\n{\n\tunsigned long *ptr = (unsigned long *)&list->next;\n\n\t*ptr &= ~RB_FLAG_MASK;\n}"
  },
  {
    "function_name": "rb_head_page_activate",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "888-900",
    "snippet": "static void rb_head_page_activate(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *head;\n\n\thead = cpu_buffer->head_page;\n\tif (!head)\n\t\treturn;\n\n\t/*\n\t * Set the previous list pointer to have the HEAD flag.\n\t */\n\trb_set_list_to_head(cpu_buffer, head->list.prev);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_set_list_to_head",
          "args": [
            "cpu_buffer",
            "head->list.prev"
          ],
          "line": 899
        },
        "resolved": true,
        "details": {
          "function_name": "rb_set_list_to_head",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "875-883",
          "snippet": "static void rb_set_list_to_head(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\tstruct list_head *list)\n{\n\tunsigned long *ptr;\n\n\tptr = (unsigned long *)&list->next;\n\t*ptr |= RB_PAGE_HEAD;\n\t*ptr &= ~RB_PAGE_UPDATE;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_PAGE_UPDATE\t\t2UL",
            "#define RB_PAGE_HEAD\t\t1UL"
          ],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_PAGE_UPDATE\t\t2UL\n#define RB_PAGE_HEAD\t\t1UL\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_set_list_to_head(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\tstruct list_head *list)\n{\n\tunsigned long *ptr;\n\n\tptr = (unsigned long *)&list->next;\n\t*ptr |= RB_PAGE_HEAD;\n\t*ptr &= ~RB_PAGE_UPDATE;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_head_page_activate(struct ring_buffer_per_cpu *cpu_buffer)\n{\n\tstruct buffer_page *head;\n\n\thead = cpu_buffer->head_page;\n\tif (!head)\n\t\treturn;\n\n\t/*\n\t * Set the previous list pointer to have the HEAD flag.\n\t */\n\trb_set_list_to_head(cpu_buffer, head->list.prev);\n}"
  },
  {
    "function_name": "rb_set_list_to_head",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "875-883",
    "snippet": "static void rb_set_list_to_head(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\tstruct list_head *list)\n{\n\tunsigned long *ptr;\n\n\tptr = (unsigned long *)&list->next;\n\t*ptr |= RB_PAGE_HEAD;\n\t*ptr &= ~RB_PAGE_UPDATE;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_PAGE_UPDATE\t\t2UL",
      "#define RB_PAGE_HEAD\t\t1UL"
    ],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_PAGE_UPDATE\t\t2UL\n#define RB_PAGE_HEAD\t\t1UL\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_set_list_to_head(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\tstruct list_head *list)\n{\n\tunsigned long *ptr;\n\n\tptr = (unsigned long *)&list->next;\n\t*ptr |= RB_PAGE_HEAD;\n\t*ptr &= ~RB_PAGE_UPDATE;\n}"
  },
  {
    "function_name": "rb_is_reader_page",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "865-870",
    "snippet": "static bool rb_is_reader_page(struct buffer_page *page)\n{\n\tstruct list_head *list = page->list.prev;\n\n\treturn rb_list_head(list->next) != &page->list;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_list_head",
          "args": [
            "list->next"
          ],
          "line": 869
        },
        "resolved": true,
        "details": {
          "function_name": "rb_list_head_clear",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "902-907",
          "snippet": "static void rb_list_head_clear(struct list_head *list)\n{\n\tunsigned long *ptr = (unsigned long *)&list->next;\n\n\t*ptr &= ~RB_FLAG_MASK;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_FLAG_MASK\t\t3UL"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_FLAG_MASK\t\t3UL\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_list_head_clear(struct list_head *list)\n{\n\tunsigned long *ptr = (unsigned long *)&list->next;\n\n\t*ptr &= ~RB_FLAG_MASK;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic bool rb_is_reader_page(struct buffer_page *page)\n{\n\tstruct list_head *list = page->list.prev;\n\n\treturn rb_list_head(list->next) != &page->list;\n}"
  },
  {
    "function_name": "rb_is_head_page",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "844-856",
    "snippet": "static inline int\nrb_is_head_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\tstruct buffer_page *page, struct list_head *list)\n{\n\tunsigned long val;\n\n\tval = (unsigned long)list->next;\n\n\tif ((val & ~RB_FLAG_MASK) != (unsigned long)&page->list)\n\t\treturn RB_PAGE_MOVED;\n\n\treturn val & RB_FLAG_MASK;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_PAGE_MOVED\t\t4UL",
      "#define RB_FLAG_MASK\t\t3UL"
    ],
    "globals_used": [
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_PAGE_MOVED\t\t4UL\n#define RB_FLAG_MASK\t\t3UL\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline int\nrb_is_head_page(struct ring_buffer_per_cpu *cpu_buffer,\n\t\tstruct buffer_page *page, struct list_head *list)\n{\n\tunsigned long val;\n\n\tval = (unsigned long)list->next;\n\n\tif ((val & ~RB_FLAG_MASK) != (unsigned long)&page->list)\n\t\treturn RB_PAGE_MOVED;\n\n\treturn val & RB_FLAG_MASK;\n}"
  },
  {
    "function_name": "rb_list_head",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "829-834",
    "snippet": "static struct list_head *rb_list_head(struct list_head *list)\n{\n\tunsigned long val = (unsigned long)list;\n\n\treturn (struct list_head *)(val & ~RB_FLAG_MASK);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_FLAG_MASK\t\t3UL"
    ],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_FLAG_MASK\t\t3UL\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic struct list_head *rb_list_head(struct list_head *list)\n{\n\tunsigned long val = (unsigned long)list;\n\n\treturn (struct list_head *)(val & ~RB_FLAG_MASK);\n}"
  },
  {
    "function_name": "ring_buffer_normalize_time_stamp",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "739-744",
    "snippet": "void ring_buffer_normalize_time_stamp(struct ring_buffer *buffer,\n\t\t\t\t      int cpu, u64 *ts)\n{\n\t/* Just stupid testing the normalize function and deltas */\n\t*ts >>= DEBUG_SHIFT;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define DEBUG_SHIFT 0"
    ],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define DEBUG_SHIFT 0\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nvoid ring_buffer_normalize_time_stamp(struct ring_buffer *buffer,\n\t\t\t\t      int cpu, u64 *ts)\n{\n\t/* Just stupid testing the normalize function and deltas */\n\t*ts >>= DEBUG_SHIFT;\n}"
  },
  {
    "function_name": "ring_buffer_time_stamp",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "727-736",
    "snippet": "u64 ring_buffer_time_stamp(struct ring_buffer *buffer, int cpu)\n{\n\tu64 time;\n\n\tpreempt_disable_notrace();\n\ttime = rb_time_stamp(buffer);\n\tpreempt_enable_no_resched_notrace();\n\n\treturn time;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "preempt_enable_no_resched_notrace",
          "args": [],
          "line": 733
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_time_stamp",
          "args": [
            "buffer"
          ],
          "line": 732
        },
        "resolved": true,
        "details": {
          "function_name": "rb_time_stamp",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "721-725",
          "snippet": "static inline u64 rb_time_stamp(struct ring_buffer *buffer)\n{\n\t/* shift to debug/test normalization and TIME_EXTENTS */\n\treturn buffer->clock() << DEBUG_SHIFT;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define DEBUG_SHIFT 0"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define DEBUG_SHIFT 0\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline u64 rb_time_stamp(struct ring_buffer *buffer)\n{\n\t/* shift to debug/test normalization and TIME_EXTENTS */\n\treturn buffer->clock() << DEBUG_SHIFT;\n}"
        }
      },
      {
        "call_info": {
          "callee": "preempt_disable_notrace",
          "args": [],
          "line": 731
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nu64 ring_buffer_time_stamp(struct ring_buffer *buffer, int cpu)\n{\n\tu64 time;\n\n\tpreempt_disable_notrace();\n\ttime = rb_time_stamp(buffer);\n\tpreempt_enable_no_resched_notrace();\n\n\treturn time;\n}"
  },
  {
    "function_name": "rb_time_stamp",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "721-725",
    "snippet": "static inline u64 rb_time_stamp(struct ring_buffer *buffer)\n{\n\t/* shift to debug/test normalization and TIME_EXTENTS */\n\treturn buffer->clock() << DEBUG_SHIFT;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define DEBUG_SHIFT 0"
    ],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "buffer->clock",
          "args": [],
          "line": 724
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define DEBUG_SHIFT 0\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic inline u64 rb_time_stamp(struct ring_buffer *buffer)\n{\n\t/* shift to debug/test normalization and TIME_EXTENTS */\n\treturn buffer->clock() << DEBUG_SHIFT;\n}"
  },
  {
    "function_name": "ring_buffer_poll_wait",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "663-700",
    "snippet": "__poll_t ring_buffer_poll_wait(struct ring_buffer *buffer, int cpu,\n\t\t\t  struct file *filp, poll_table *poll_table)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct rb_irq_work *work;\n\n\tif (cpu == RING_BUFFER_ALL_CPUS)\n\t\twork = &buffer->irq_work;\n\telse {\n\t\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\t\treturn -EINVAL;\n\n\t\tcpu_buffer = buffer->buffers[cpu];\n\t\twork = &cpu_buffer->irq_work;\n\t}\n\n\tpoll_wait(filp, &work->waiters, poll_table);\n\twork->waiters_pending = true;\n\t/*\n\t * There's a tight race between setting the waiters_pending and\n\t * checking if the ring buffer is empty.  Once the waiters_pending bit\n\t * is set, the next event will wake the task up, but we can get stuck\n\t * if there's only a single event in.\n\t *\n\t * FIXME: Ideally, we need a memory barrier on the writer side as well,\n\t * but adding a memory barrier to all events will cause too much of a\n\t * performance hit in the fast path.  We only need a memory barrier when\n\t * the buffer goes from empty to having content.  But as this race is\n\t * extremely small, and it's not a problem if another event comes in, we\n\t * will fix it later.\n\t */\n\tsmp_mb();\n\n\tif ((cpu == RING_BUFFER_ALL_CPUS && !ring_buffer_empty(buffer)) ||\n\t    (cpu != RING_BUFFER_ALL_CPUS && !ring_buffer_empty_cpu(buffer, cpu)))\n\t\treturn EPOLLIN | EPOLLRDNORM;\n\treturn 0;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void update_pages_handler(struct work_struct *work);",
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "ring_buffer_empty_cpu",
          "args": [
            "buffer",
            "cpu"
          ],
          "line": 697
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_empty_cpu",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "4434-4452",
          "snippet": "bool ring_buffer_empty_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long flags;\n\tbool dolock;\n\tint ret;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn true;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tlocal_irq_save(flags);\n\tdolock = rb_reader_lock(cpu_buffer);\n\tret = rb_per_cpu_empty(cpu_buffer);\n\trb_reader_unlock(cpu_buffer, dolock);\n\tlocal_irq_restore(flags);\n\n\treturn ret;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nbool ring_buffer_empty_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long flags;\n\tbool dolock;\n\tint ret;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn true;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tlocal_irq_save(flags);\n\tdolock = rb_reader_lock(cpu_buffer);\n\tret = rb_per_cpu_empty(cpu_buffer);\n\trb_reader_unlock(cpu_buffer, dolock);\n\tlocal_irq_restore(flags);\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ring_buffer_empty",
          "args": [
            "buffer"
          ],
          "line": 696
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_empty",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "4404-4426",
          "snippet": "bool ring_buffer_empty(struct ring_buffer *buffer)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long flags;\n\tbool dolock;\n\tint cpu;\n\tint ret;\n\n\t/* yes this is racy, but if you don't like the race, lock the buffer */\n\tfor_each_buffer_cpu(buffer, cpu) {\n\t\tcpu_buffer = buffer->buffers[cpu];\n\t\tlocal_irq_save(flags);\n\t\tdolock = rb_reader_lock(cpu_buffer);\n\t\tret = rb_per_cpu_empty(cpu_buffer);\n\t\trb_reader_unlock(cpu_buffer, dolock);\n\t\tlocal_irq_restore(flags);\n\n\t\tif (!ret)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nbool ring_buffer_empty(struct ring_buffer *buffer)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long flags;\n\tbool dolock;\n\tint cpu;\n\tint ret;\n\n\t/* yes this is racy, but if you don't like the race, lock the buffer */\n\tfor_each_buffer_cpu(buffer, cpu) {\n\t\tcpu_buffer = buffer->buffers[cpu];\n\t\tlocal_irq_save(flags);\n\t\tdolock = rb_reader_lock(cpu_buffer);\n\t\tret = rb_per_cpu_empty(cpu_buffer);\n\t\trb_reader_unlock(cpu_buffer, dolock);\n\t\tlocal_irq_restore(flags);\n\n\t\tif (!ret)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "smp_mb",
          "args": [],
          "line": 694
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "poll_wait",
          "args": [
            "filp",
            "&work->waiters",
            "poll_table"
          ],
          "line": 679
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "buffer->cpumask"
          ],
          "line": 672
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void update_pages_handler(struct work_struct *work);\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\n__poll_t ring_buffer_poll_wait(struct ring_buffer *buffer, int cpu,\n\t\t\t  struct file *filp, poll_table *poll_table)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tstruct rb_irq_work *work;\n\n\tif (cpu == RING_BUFFER_ALL_CPUS)\n\t\twork = &buffer->irq_work;\n\telse {\n\t\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\t\treturn -EINVAL;\n\n\t\tcpu_buffer = buffer->buffers[cpu];\n\t\twork = &cpu_buffer->irq_work;\n\t}\n\n\tpoll_wait(filp, &work->waiters, poll_table);\n\twork->waiters_pending = true;\n\t/*\n\t * There's a tight race between setting the waiters_pending and\n\t * checking if the ring buffer is empty.  Once the waiters_pending bit\n\t * is set, the next event will wake the task up, but we can get stuck\n\t * if there's only a single event in.\n\t *\n\t * FIXME: Ideally, we need a memory barrier on the writer side as well,\n\t * but adding a memory barrier to all events will cause too much of a\n\t * performance hit in the fast path.  We only need a memory barrier when\n\t * the buffer goes from empty to having content.  But as this race is\n\t * extremely small, and it's not a problem if another event comes in, we\n\t * will fix it later.\n\t */\n\tsmp_mb();\n\n\tif ((cpu == RING_BUFFER_ALL_CPUS && !ring_buffer_empty(buffer)) ||\n\t    (cpu != RING_BUFFER_ALL_CPUS && !ring_buffer_empty_cpu(buffer, cpu)))\n\t\treturn EPOLLIN | EPOLLRDNORM;\n\treturn 0;\n}"
  },
  {
    "function_name": "ring_buffer_wait",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "559-647",
    "snippet": "int ring_buffer_wait(struct ring_buffer *buffer, int cpu, bool full)\n{\n\tstruct ring_buffer_per_cpu *uninitialized_var(cpu_buffer);\n\tDEFINE_WAIT(wait);\n\tstruct rb_irq_work *work;\n\tint ret = 0;\n\n\t/*\n\t * Depending on what the caller is waiting for, either any\n\t * data in any cpu buffer, or a specific buffer, put the\n\t * caller on the appropriate wait queue.\n\t */\n\tif (cpu == RING_BUFFER_ALL_CPUS) {\n\t\twork = &buffer->irq_work;\n\t\t/* Full only makes sense on per cpu reads */\n\t\tfull = false;\n\t} else {\n\t\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\t\treturn -ENODEV;\n\t\tcpu_buffer = buffer->buffers[cpu];\n\t\twork = &cpu_buffer->irq_work;\n\t}\n\n\n\twhile (true) {\n\t\tif (full)\n\t\t\tprepare_to_wait(&work->full_waiters, &wait, TASK_INTERRUPTIBLE);\n\t\telse\n\t\t\tprepare_to_wait(&work->waiters, &wait, TASK_INTERRUPTIBLE);\n\n\t\t/*\n\t\t * The events can happen in critical sections where\n\t\t * checking a work queue can cause deadlocks.\n\t\t * After adding a task to the queue, this flag is set\n\t\t * only to notify events to try to wake up the queue\n\t\t * using irq_work.\n\t\t *\n\t\t * We don't clear it even if the buffer is no longer\n\t\t * empty. The flag only causes the next event to run\n\t\t * irq_work to do the work queue wake up. The worse\n\t\t * that can happen if we race with !trace_empty() is that\n\t\t * an event will cause an irq_work to try to wake up\n\t\t * an empty queue.\n\t\t *\n\t\t * There's no reason to protect this flag either, as\n\t\t * the work queue and irq_work logic will do the necessary\n\t\t * synchronization for the wake ups. The only thing\n\t\t * that is necessary is that the wake up happens after\n\t\t * a task has been queued. It's OK for spurious wake ups.\n\t\t */\n\t\tif (full)\n\t\t\twork->full_waiters_pending = true;\n\t\telse\n\t\t\twork->waiters_pending = true;\n\n\t\tif (signal_pending(current)) {\n\t\t\tret = -EINTR;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (cpu == RING_BUFFER_ALL_CPUS && !ring_buffer_empty(buffer))\n\t\t\tbreak;\n\n\t\tif (cpu != RING_BUFFER_ALL_CPUS &&\n\t\t    !ring_buffer_empty_cpu(buffer, cpu)) {\n\t\t\tunsigned long flags;\n\t\t\tbool pagebusy;\n\n\t\t\tif (!full)\n\t\t\t\tbreak;\n\n\t\t\traw_spin_lock_irqsave(&cpu_buffer->reader_lock, flags);\n\t\t\tpagebusy = cpu_buffer->reader_page == cpu_buffer->commit_page;\n\t\t\traw_spin_unlock_irqrestore(&cpu_buffer->reader_lock, flags);\n\n\t\t\tif (!pagebusy)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tschedule();\n\t}\n\n\tif (full)\n\t\tfinish_wait(&work->full_waiters, &wait);\n\telse\n\t\tfinish_wait(&work->waiters, &wait);\n\n\treturn ret;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void update_pages_handler(struct work_struct *work);",
      "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "finish_wait",
          "args": [
            "&work->waiters",
            "&wait"
          ],
          "line": 644
        },
        "resolved": true,
        "details": {
          "function_name": "finish_wait",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/wait.c",
          "lines": "347-370",
          "snippet": "void finish_wait(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)\n{\n\tunsigned long flags;\n\n\t__set_current_state(TASK_RUNNING);\n\t/*\n\t * We can check for list emptiness outside the lock\n\t * IFF:\n\t *  - we use the \"careful\" check that verifies both\n\t *    the next and prev pointers, so that there cannot\n\t *    be any half-pending updates in progress on other\n\t *    CPU's that we haven't seen yet (and that might\n\t *    still change the stack area.\n\t * and\n\t *  - all other users take the lock (ie we can only\n\t *    have _one_ other CPU that looks at or modifies\n\t *    the list).\n\t */\n\tif (!list_empty_careful(&wq_entry->entry)) {\n\t\tspin_lock_irqsave(&wq_head->lock, flags);\n\t\tlist_del_init(&wq_entry->entry);\n\t\tspin_unlock_irqrestore(&wq_head->lock, flags);\n\t}\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nvoid finish_wait(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)\n{\n\tunsigned long flags;\n\n\t__set_current_state(TASK_RUNNING);\n\t/*\n\t * We can check for list emptiness outside the lock\n\t * IFF:\n\t *  - we use the \"careful\" check that verifies both\n\t *    the next and prev pointers, so that there cannot\n\t *    be any half-pending updates in progress on other\n\t *    CPU's that we haven't seen yet (and that might\n\t *    still change the stack area.\n\t * and\n\t *  - all other users take the lock (ie we can only\n\t *    have _one_ other CPU that looks at or modifies\n\t *    the list).\n\t */\n\tif (!list_empty_careful(&wq_entry->entry)) {\n\t\tspin_lock_irqsave(&wq_head->lock, flags);\n\t\tlist_del_init(&wq_entry->entry);\n\t\tspin_unlock_irqrestore(&wq_head->lock, flags);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "schedule",
          "args": [],
          "line": 638
        },
        "resolved": true,
        "details": {
          "function_name": "audit_schedule_prune",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/audit_tree.c",
          "lines": "919-922",
          "snippet": "static void audit_schedule_prune(void)\n{\n\twake_up_process(prune_thread);\n}",
          "includes": [
            "#include <linux/slab.h>",
            "#include <linux/refcount.h>",
            "#include <linux/kthread.h>",
            "#include <linux/mount.h>",
            "#include <linux/namei.h>",
            "#include <linux/fsnotify_backend.h>",
            "#include \"audit.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static struct task_struct *prune_thread;",
            "static void audit_schedule_prune(void);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/slab.h>\n#include <linux/refcount.h>\n#include <linux/kthread.h>\n#include <linux/mount.h>\n#include <linux/namei.h>\n#include <linux/fsnotify_backend.h>\n#include \"audit.h\"\n\nstatic struct task_struct *prune_thread;\nstatic void audit_schedule_prune(void);\n\nstatic void audit_schedule_prune(void)\n{\n\twake_up_process(prune_thread);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore",
          "args": [
            "&cpu_buffer->reader_lock",
            "flags"
          ],
          "line": 632
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_irqrestore",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "182-185",
          "snippet": "void __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irqsave",
          "args": [
            "&cpu_buffer->reader_lock",
            "flags"
          ],
          "line": 630
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_irqsave_nested",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "359-370",
          "snippet": "unsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED_FLAGS(lock, do_raw_spin_trylock, do_raw_spin_lock,\n\t\t\t\tdo_raw_spin_lock_flags, &flags);\n\treturn flags;\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nunsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED_FLAGS(lock, do_raw_spin_trylock, do_raw_spin_lock,\n\t\t\t\tdo_raw_spin_lock_flags, &flags);\n\treturn flags;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ring_buffer_empty_cpu",
          "args": [
            "buffer",
            "cpu"
          ],
          "line": 623
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_empty_cpu",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "4434-4452",
          "snippet": "bool ring_buffer_empty_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long flags;\n\tbool dolock;\n\tint ret;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn true;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tlocal_irq_save(flags);\n\tdolock = rb_reader_lock(cpu_buffer);\n\tret = rb_per_cpu_empty(cpu_buffer);\n\trb_reader_unlock(cpu_buffer, dolock);\n\tlocal_irq_restore(flags);\n\n\treturn ret;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nbool ring_buffer_empty_cpu(struct ring_buffer *buffer, int cpu)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long flags;\n\tbool dolock;\n\tint ret;\n\n\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\treturn true;\n\n\tcpu_buffer = buffer->buffers[cpu];\n\tlocal_irq_save(flags);\n\tdolock = rb_reader_lock(cpu_buffer);\n\tret = rb_per_cpu_empty(cpu_buffer);\n\trb_reader_unlock(cpu_buffer, dolock);\n\tlocal_irq_restore(flags);\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ring_buffer_empty",
          "args": [
            "buffer"
          ],
          "line": 619
        },
        "resolved": true,
        "details": {
          "function_name": "ring_buffer_empty",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "4404-4426",
          "snippet": "bool ring_buffer_empty(struct ring_buffer *buffer)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long flags;\n\tbool dolock;\n\tint cpu;\n\tint ret;\n\n\t/* yes this is racy, but if you don't like the race, lock the buffer */\n\tfor_each_buffer_cpu(buffer, cpu) {\n\t\tcpu_buffer = buffer->buffers[cpu];\n\t\tlocal_irq_save(flags);\n\t\tdolock = rb_reader_lock(cpu_buffer);\n\t\tret = rb_per_cpu_empty(cpu_buffer);\n\t\trb_reader_unlock(cpu_buffer, dolock);\n\t\tlocal_irq_restore(flags);\n\n\t\tif (!ret)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);",
            "static __always_inline struct",
            "static __always_inline struct",
            "static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);",
            "static noinline struct",
            "static noinline struct",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nbool ring_buffer_empty(struct ring_buffer *buffer)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long flags;\n\tbool dolock;\n\tint cpu;\n\tint ret;\n\n\t/* yes this is racy, but if you don't like the race, lock the buffer */\n\tfor_each_buffer_cpu(buffer, cpu) {\n\t\tcpu_buffer = buffer->buffers[cpu];\n\t\tlocal_irq_save(flags);\n\t\tdolock = rb_reader_lock(cpu_buffer);\n\t\tret = rb_per_cpu_empty(cpu_buffer);\n\t\trb_reader_unlock(cpu_buffer, dolock);\n\t\tlocal_irq_restore(flags);\n\n\t\tif (!ret)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "signal_pending",
          "args": [
            "current"
          ],
          "line": 614
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "prepare_to_wait",
          "args": [
            "&work->waiters",
            "&wait",
            "TASK_INTERRUPTIBLE"
          ],
          "line": 587
        },
        "resolved": true,
        "details": {
          "function_name": "prepare_to_wait_event",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/wait.c",
          "lines": "261-294",
          "snippet": "long prepare_to_wait_event(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry, int state)\n{\n\tunsigned long flags;\n\tlong ret = 0;\n\n\tspin_lock_irqsave(&wq_head->lock, flags);\n\tif (unlikely(signal_pending_state(state, current))) {\n\t\t/*\n\t\t * Exclusive waiter must not fail if it was selected by wakeup,\n\t\t * it should \"consume\" the condition we were waiting for.\n\t\t *\n\t\t * The caller will recheck the condition and return success if\n\t\t * we were already woken up, we can not miss the event because\n\t\t * wakeup locks/unlocks the same wq_head->lock.\n\t\t *\n\t\t * But we need to ensure that set-condition + wakeup after that\n\t\t * can't see us, it should wake up another exclusive waiter if\n\t\t * we fail.\n\t\t */\n\t\tlist_del_init(&wq_entry->entry);\n\t\tret = -ERESTARTSYS;\n\t} else {\n\t\tif (list_empty(&wq_entry->entry)) {\n\t\t\tif (wq_entry->flags & WQ_FLAG_EXCLUSIVE)\n\t\t\t\t__add_wait_queue_entry_tail(wq_head, wq_entry);\n\t\t\telse\n\t\t\t\t__add_wait_queue(wq_head, wq_entry);\n\t\t}\n\t\tset_current_state(state);\n\t}\n\tspin_unlock_irqrestore(&wq_head->lock, flags);\n\n\treturn ret;\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nlong prepare_to_wait_event(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry, int state)\n{\n\tunsigned long flags;\n\tlong ret = 0;\n\n\tspin_lock_irqsave(&wq_head->lock, flags);\n\tif (unlikely(signal_pending_state(state, current))) {\n\t\t/*\n\t\t * Exclusive waiter must not fail if it was selected by wakeup,\n\t\t * it should \"consume\" the condition we were waiting for.\n\t\t *\n\t\t * The caller will recheck the condition and return success if\n\t\t * we were already woken up, we can not miss the event because\n\t\t * wakeup locks/unlocks the same wq_head->lock.\n\t\t *\n\t\t * But we need to ensure that set-condition + wakeup after that\n\t\t * can't see us, it should wake up another exclusive waiter if\n\t\t * we fail.\n\t\t */\n\t\tlist_del_init(&wq_entry->entry);\n\t\tret = -ERESTARTSYS;\n\t} else {\n\t\tif (list_empty(&wq_entry->entry)) {\n\t\t\tif (wq_entry->flags & WQ_FLAG_EXCLUSIVE)\n\t\t\t\t__add_wait_queue_entry_tail(wq_head, wq_entry);\n\t\t\telse\n\t\t\t\t__add_wait_queue(wq_head, wq_entry);\n\t\t}\n\t\tset_current_state(state);\n\t}\n\tspin_unlock_irqrestore(&wq_head->lock, flags);\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "buffer->cpumask"
          ],
          "line": 576
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DEFINE_WAIT",
          "args": [
            "wait"
          ],
          "line": 562
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void update_pages_handler(struct work_struct *work);\nstatic void rb_reset_cpu(struct ring_buffer_per_cpu *cpu_buffer);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer);\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nint ring_buffer_wait(struct ring_buffer *buffer, int cpu, bool full)\n{\n\tstruct ring_buffer_per_cpu *uninitialized_var(cpu_buffer);\n\tDEFINE_WAIT(wait);\n\tstruct rb_irq_work *work;\n\tint ret = 0;\n\n\t/*\n\t * Depending on what the caller is waiting for, either any\n\t * data in any cpu buffer, or a specific buffer, put the\n\t * caller on the appropriate wait queue.\n\t */\n\tif (cpu == RING_BUFFER_ALL_CPUS) {\n\t\twork = &buffer->irq_work;\n\t\t/* Full only makes sense on per cpu reads */\n\t\tfull = false;\n\t} else {\n\t\tif (!cpumask_test_cpu(cpu, buffer->cpumask))\n\t\t\treturn -ENODEV;\n\t\tcpu_buffer = buffer->buffers[cpu];\n\t\twork = &cpu_buffer->irq_work;\n\t}\n\n\n\twhile (true) {\n\t\tif (full)\n\t\t\tprepare_to_wait(&work->full_waiters, &wait, TASK_INTERRUPTIBLE);\n\t\telse\n\t\t\tprepare_to_wait(&work->waiters, &wait, TASK_INTERRUPTIBLE);\n\n\t\t/*\n\t\t * The events can happen in critical sections where\n\t\t * checking a work queue can cause deadlocks.\n\t\t * After adding a task to the queue, this flag is set\n\t\t * only to notify events to try to wake up the queue\n\t\t * using irq_work.\n\t\t *\n\t\t * We don't clear it even if the buffer is no longer\n\t\t * empty. The flag only causes the next event to run\n\t\t * irq_work to do the work queue wake up. The worse\n\t\t * that can happen if we race with !trace_empty() is that\n\t\t * an event will cause an irq_work to try to wake up\n\t\t * an empty queue.\n\t\t *\n\t\t * There's no reason to protect this flag either, as\n\t\t * the work queue and irq_work logic will do the necessary\n\t\t * synchronization for the wake ups. The only thing\n\t\t * that is necessary is that the wake up happens after\n\t\t * a task has been queued. It's OK for spurious wake ups.\n\t\t */\n\t\tif (full)\n\t\t\twork->full_waiters_pending = true;\n\t\telse\n\t\t\twork->waiters_pending = true;\n\n\t\tif (signal_pending(current)) {\n\t\t\tret = -EINTR;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (cpu == RING_BUFFER_ALL_CPUS && !ring_buffer_empty(buffer))\n\t\t\tbreak;\n\n\t\tif (cpu != RING_BUFFER_ALL_CPUS &&\n\t\t    !ring_buffer_empty_cpu(buffer, cpu)) {\n\t\t\tunsigned long flags;\n\t\t\tbool pagebusy;\n\n\t\t\tif (!full)\n\t\t\t\tbreak;\n\n\t\t\traw_spin_lock_irqsave(&cpu_buffer->reader_lock, flags);\n\t\t\tpagebusy = cpu_buffer->reader_page == cpu_buffer->commit_page;\n\t\t\traw_spin_unlock_irqrestore(&cpu_buffer->reader_lock, flags);\n\n\t\t\tif (!pagebusy)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tschedule();\n\t}\n\n\tif (full)\n\t\tfinish_wait(&work->full_waiters, &wait);\n\telse\n\t\tfinish_wait(&work->waiters, &wait);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "rb_wake_up_waiters",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "538-547",
    "snippet": "static void rb_wake_up_waiters(struct irq_work *work)\n{\n\tstruct rb_irq_work *rbwork = container_of(work, struct rb_irq_work, work);\n\n\twake_up_all(&rbwork->waiters);\n\tif (rbwork->wakeup_full) {\n\t\trbwork->wakeup_full = false;\n\t\twake_up_all(&rbwork->full_waiters);\n\t}\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static void update_pages_handler(struct work_struct *work);",
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "wake_up_all",
          "args": [
            "&rbwork->full_waiters"
          ],
          "line": 545
        },
        "resolved": true,
        "details": {
          "function_name": "swake_up_all",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/swait.c",
          "lines": "49-69",
          "snippet": "void swake_up_all(struct swait_queue_head *q)\n{\n\tstruct swait_queue *curr;\n\tLIST_HEAD(tmp);\n\n\traw_spin_lock_irq(&q->lock);\n\tlist_splice_init(&q->task_list, &tmp);\n\twhile (!list_empty(&tmp)) {\n\t\tcurr = list_first_entry(&tmp, typeof(*curr), task_list);\n\n\t\twake_up_state(curr->task, TASK_NORMAL);\n\t\tlist_del_init(&curr->task_list);\n\n\t\tif (list_empty(&tmp))\n\t\t\tbreak;\n\n\t\traw_spin_unlock_irq(&q->lock);\n\t\traw_spin_lock_irq(&q->lock);\n\t}\n\traw_spin_unlock_irq(&q->lock);\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nvoid swake_up_all(struct swait_queue_head *q)\n{\n\tstruct swait_queue *curr;\n\tLIST_HEAD(tmp);\n\n\traw_spin_lock_irq(&q->lock);\n\tlist_splice_init(&q->task_list, &tmp);\n\twhile (!list_empty(&tmp)) {\n\t\tcurr = list_first_entry(&tmp, typeof(*curr), task_list);\n\n\t\twake_up_state(curr->task, TASK_NORMAL);\n\t\tlist_del_init(&curr->task_list);\n\n\t\tif (list_empty(&tmp))\n\t\t\tbreak;\n\n\t\traw_spin_unlock_irq(&q->lock);\n\t\traw_spin_lock_irq(&q->lock);\n\t}\n\traw_spin_unlock_irq(&q->lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "work",
            "structrb_irq_work",
            "work"
          ],
          "line": 540
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic void update_pages_handler(struct work_struct *work);\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_wake_up_waiters(struct irq_work *work)\n{\n\tstruct rb_irq_work *rbwork = container_of(work, struct rb_irq_work, work);\n\n\twake_up_all(&rbwork->waiters);\n\tif (rbwork->wakeup_full) {\n\t\trbwork->wakeup_full = false;\n\t\twake_up_all(&rbwork->full_waiters);\n\t}\n}"
  },
  {
    "function_name": "ring_buffer_print_page_header",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "395-423",
    "snippet": "int ring_buffer_print_page_header(struct trace_seq *s)\n{\n\tstruct buffer_data_page field;\n\n\ttrace_seq_printf(s, \"\\tfield: u64 timestamp;\\t\"\n\t\t\t \"offset:0;\\tsize:%u;\\tsigned:%u;\\n\",\n\t\t\t (unsigned int)sizeof(field.time_stamp),\n\t\t\t (unsigned int)is_signed_type(u64));\n\n\ttrace_seq_printf(s, \"\\tfield: local_t commit;\\t\"\n\t\t\t \"offset:%u;\\tsize:%u;\\tsigned:%u;\\n\",\n\t\t\t (unsigned int)offsetof(typeof(field), commit),\n\t\t\t (unsigned int)sizeof(field.commit),\n\t\t\t (unsigned int)is_signed_type(long));\n\n\ttrace_seq_printf(s, \"\\tfield: int overwrite;\\t\"\n\t\t\t \"offset:%u;\\tsize:%u;\\tsigned:%u;\\n\",\n\t\t\t (unsigned int)offsetof(typeof(field), commit),\n\t\t\t 1,\n\t\t\t (unsigned int)is_signed_type(long));\n\n\ttrace_seq_printf(s, \"\\tfield: char data;\\t\"\n\t\t\t \"offset:%u;\\tsize:%u;\\tsigned:%u;\\n\",\n\t\t\t (unsigned int)offsetof(typeof(field), data),\n\t\t\t (unsigned int)BUF_PAGE_SIZE,\n\t\t\t (unsigned int)is_signed_type(char));\n\n\treturn !trace_seq_has_overflowed(s);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)"
    ],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "trace_seq_has_overflowed",
          "args": [
            "s"
          ],
          "line": 422
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_seq_printf",
          "args": [
            "s",
            "\"\\tfield: char data;\\t\"\n\t\t\t \"offset:%u;\\tsize:%u;\\tsigned:%u;\\n\"",
            "(unsigned int)offsetof(typeof(field), data)",
            "(unsigned int)BUF_PAGE_SIZE",
            "(unsigned int)is_signed_type(char)"
          ],
          "line": 416
        },
        "resolved": true,
        "details": {
          "function_name": "trace_seq_printf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/trace_seq.c",
          "lines": "84-103",
          "snippet": "void trace_seq_printf(struct trace_seq *s, const char *fmt, ...)\n{\n\tunsigned int save_len = s->seq.len;\n\tva_list ap;\n\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tva_start(ap, fmt);\n\tseq_buf_vprintf(&s->seq, fmt, ap);\n\tva_end(ap);\n\n\t/* If we can't write it all, don't bother writing anything */\n\tif (unlikely(seq_buf_has_overflowed(&s->seq))) {\n\t\ts->seq.len = save_len;\n\t\ts->full = 1;\n\t}\n}",
          "includes": [
            "#include <linux/trace_seq.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/uaccess.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/trace_seq.h>\n#include <linux/seq_file.h>\n#include <linux/uaccess.h>\n\nvoid trace_seq_printf(struct trace_seq *s, const char *fmt, ...)\n{\n\tunsigned int save_len = s->seq.len;\n\tva_list ap;\n\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tva_start(ap, fmt);\n\tseq_buf_vprintf(&s->seq, fmt, ap);\n\tva_end(ap);\n\n\t/* If we can't write it all, don't bother writing anything */\n\tif (unlikely(seq_buf_has_overflowed(&s->seq))) {\n\t\ts->seq.len = save_len;\n\t\ts->full = 1;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_signed_type",
          "args": [
            "char"
          ],
          "line": 420
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "is_signed_type",
          "args": [
            "long"
          ],
          "line": 414
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "is_signed_type",
          "args": [
            "long"
          ],
          "line": 408
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "is_signed_type",
          "args": [
            "u64"
          ],
          "line": 402
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define BUF_PAGE_SIZE (PAGE_SIZE - BUF_PAGE_HDR_SIZE)\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nint ring_buffer_print_page_header(struct trace_seq *s)\n{\n\tstruct buffer_data_page field;\n\n\ttrace_seq_printf(s, \"\\tfield: u64 timestamp;\\t\"\n\t\t\t \"offset:0;\\tsize:%u;\\tsigned:%u;\\n\",\n\t\t\t (unsigned int)sizeof(field.time_stamp),\n\t\t\t (unsigned int)is_signed_type(u64));\n\n\ttrace_seq_printf(s, \"\\tfield: local_t commit;\\t\"\n\t\t\t \"offset:%u;\\tsize:%u;\\tsigned:%u;\\n\",\n\t\t\t (unsigned int)offsetof(typeof(field), commit),\n\t\t\t (unsigned int)sizeof(field.commit),\n\t\t\t (unsigned int)is_signed_type(long));\n\n\ttrace_seq_printf(s, \"\\tfield: int overwrite;\\t\"\n\t\t\t \"offset:%u;\\tsize:%u;\\tsigned:%u;\\n\",\n\t\t\t (unsigned int)offsetof(typeof(field), commit),\n\t\t\t 1,\n\t\t\t (unsigned int)is_signed_type(long));\n\n\ttrace_seq_printf(s, \"\\tfield: char data;\\t\"\n\t\t\t \"offset:%u;\\tsize:%u;\\tsigned:%u;\\n\",\n\t\t\t (unsigned int)offsetof(typeof(field), data),\n\t\t\t (unsigned int)BUF_PAGE_SIZE,\n\t\t\t (unsigned int)is_signed_type(char));\n\n\treturn !trace_seq_has_overflowed(s);\n}"
  },
  {
    "function_name": "test_time_stamp",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "383-388",
    "snippet": "static inline int test_time_stamp(u64 delta)\n{\n\tif (delta & TS_DELTA_TEST)\n\t\treturn 1;\n\treturn 0;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define TS_DELTA_TEST\t(~TS_MASK)"
    ],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define TS_DELTA_TEST\t(~TS_MASK)\n\nstatic inline int test_time_stamp(u64 delta)\n{\n\tif (delta & TS_DELTA_TEST)\n\t\treturn 1;\n\treturn 0;\n}"
  },
  {
    "function_name": "free_buffer_page",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "374-378",
    "snippet": "static void free_buffer_page(struct buffer_page *bpage)\n{\n\tfree_page((unsigned long)bpage->page);\n\tkfree(bpage);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "bpage"
          ],
          "line": 377
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/params.c",
          "lines": "73-86",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_page",
          "args": [
            "(unsigned long)bpage->page"
          ],
          "line": 376
        },
        "resolved": true,
        "details": {
          "function_name": "perf_mmap_free_page",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/events/ring_buffer.c",
          "lines": "770-776",
          "snippet": "static void perf_mmap_free_page(unsigned long addr)\n{\n\tstruct page *page = virt_to_page((void *)addr);\n\n\tpage->mapping = NULL;\n\t__free_page(page);\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <linux/nospec.h>",
            "#include <linux/poll.h>",
            "#include <linux/circ_buf.h>",
            "#include <linux/slab.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/perf_event.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <linux/nospec.h>\n#include <linux/poll.h>\n#include <linux/circ_buf.h>\n#include <linux/slab.h>\n#include <linux/vmalloc.h>\n#include <linux/perf_event.h>\n\nstatic void perf_mmap_free_page(unsigned long addr)\n{\n\tstruct page *page = virt_to_page((void *)addr);\n\n\tpage->mapping = NULL;\n\t__free_page(page);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void free_buffer_page(struct buffer_page *bpage)\n{\n\tfree_page((unsigned long)bpage->page);\n\tkfree(bpage);\n}"
  },
  {
    "function_name": "ring_buffer_page_len",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "362-368",
    "snippet": "size_t ring_buffer_page_len(void *page)\n{\n\tstruct buffer_data_page *bpage = page;\n\n\treturn (local_read(&bpage->commit) & ~RB_MISSED_FLAGS)\n\t\t+ BUF_PAGE_HDR_SIZE;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_MISSED_FLAGS\t\t(RB_MISSED_EVENTS|RB_MISSED_STORED)",
      "#define BUF_PAGE_HDR_SIZE offsetof(struct buffer_data_page, data)"
    ],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_read",
          "args": [
            "&bpage->commit"
          ],
          "line": 366
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_MISSED_FLAGS\t\t(RB_MISSED_EVENTS|RB_MISSED_STORED)\n#define BUF_PAGE_HDR_SIZE offsetof(struct buffer_data_page, data)\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nsize_t ring_buffer_page_len(void *page)\n{\n\tstruct buffer_data_page *bpage = page;\n\n\treturn (local_read(&bpage->commit) & ~RB_MISSED_FLAGS)\n\t\t+ BUF_PAGE_HDR_SIZE;\n}"
  },
  {
    "function_name": "rb_init_page",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "351-354",
    "snippet": "static void rb_init_page(struct buffer_data_page *bpage)\n{\n\tlocal_set(&bpage->commit, 0);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_set",
          "args": [
            "&bpage->commit",
            "0"
          ],
          "line": 353
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nstatic void rb_init_page(struct buffer_data_page *bpage)\n{\n\tlocal_set(&bpage->commit, 0);\n}"
  },
  {
    "function_name": "ring_buffer_event_time_stamp",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "295-304",
    "snippet": "u64 ring_buffer_event_time_stamp(struct ring_buffer_event *event)\n{\n\tu64 ts;\n\n\tts = event->array[0];\n\tts <<= TS_SHIFT;\n\tts += event->time_delta;\n\n\treturn ts;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define TS_SHIFT\t27"
    ],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define TS_SHIFT\t27\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nu64 ring_buffer_event_time_stamp(struct ring_buffer_event *event)\n{\n\tu64 ts;\n\n\tts = event->array[0];\n\tts <<= TS_SHIFT;\n\tts += event->time_delta;\n\n\treturn ts;\n}"
  },
  {
    "function_name": "ring_buffer_event_data",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "272-275",
    "snippet": "void *ring_buffer_event_data(struct ring_buffer_event *event)\n{\n\treturn rb_event_data(event);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_event_data",
          "args": [
            "event"
          ],
          "line": 274
        },
        "resolved": true,
        "details": {
          "function_name": "rb_event_data",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "255-266",
          "snippet": "static __always_inline void *\nrb_event_data(struct ring_buffer_event *event)\n{\n\tif (extended_time(event))\n\t\tevent = skip_time_extend(event);\n\tBUG_ON(event->type_len > RINGBUF_TYPE_DATA_TYPE_LEN_MAX);\n\t/* If length is in len field, then array[0] has the data */\n\tif (event->type_len)\n\t\treturn (void *)&event->array[0];\n\t/* Otherwise length is in array[0] and array[1] has the data */\n\treturn (void *)&event->array[1];\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic __always_inline void *\nrb_event_data(struct ring_buffer_event *event)\n{\n\tif (extended_time(event))\n\t\tevent = skip_time_extend(event);\n\tBUG_ON(event->type_len > RINGBUF_TYPE_DATA_TYPE_LEN_MAX);\n\t/* If length is in len field, then array[0] has the data */\n\tif (event->type_len)\n\t\treturn (void *)&event->array[0];\n\t/* Otherwise length is in array[0] and array[1] has the data */\n\treturn (void *)&event->array[1];\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nvoid *ring_buffer_event_data(struct ring_buffer_event *event)\n{\n\treturn rb_event_data(event);\n}"
  },
  {
    "function_name": "rb_event_data",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "255-266",
    "snippet": "static __always_inline void *\nrb_event_data(struct ring_buffer_event *event)\n{\n\tif (extended_time(event))\n\t\tevent = skip_time_extend(event);\n\tBUG_ON(event->type_len > RINGBUF_TYPE_DATA_TYPE_LEN_MAX);\n\t/* If length is in len field, then array[0] has the data */\n\tif (event->type_len)\n\t\treturn (void *)&event->array[0];\n\t/* Otherwise length is in array[0] and array[1] has the data */\n\treturn (void *)&event->array[1];\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "event->type_len > RINGBUF_TYPE_DATA_TYPE_LEN_MAX"
          ],
          "line": 260
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "skip_time_extend",
          "args": [
            "event"
          ],
          "line": 259
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "extended_time",
          "args": [
            "event"
          ],
          "line": 258
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic __always_inline void *\nrb_event_data(struct ring_buffer_event *event)\n{\n\tif (extended_time(event))\n\t\tevent = skip_time_extend(event);\n\tBUG_ON(event->type_len > RINGBUF_TYPE_DATA_TYPE_LEN_MAX);\n\t/* If length is in len field, then array[0] has the data */\n\tif (event->type_len)\n\t\treturn (void *)&event->array[0];\n\t/* Otherwise length is in array[0] and array[1] has the data */\n\treturn (void *)&event->array[1];\n}"
  },
  {
    "function_name": "ring_buffer_event_length",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "237-251",
    "snippet": "unsigned ring_buffer_event_length(struct ring_buffer_event *event)\n{\n\tunsigned length;\n\n\tif (extended_time(event))\n\t\tevent = skip_time_extend(event);\n\n\tlength = rb_event_length(event);\n\tif (event->type_len > RINGBUF_TYPE_DATA_TYPE_LEN_MAX)\n\t\treturn length;\n\tlength -= RB_EVNT_HDR_SIZE;\n\tif (length > RB_MAX_SMALL_DATA + sizeof(event->array[0]))\n                length -= sizeof(event->array[0]);\n\treturn length;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_MAX_SMALL_DATA\t(RB_ALIGNMENT * RINGBUF_TYPE_DATA_TYPE_LEN_MAX)",
      "#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))"
    ],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_event_length",
          "args": [
            "event"
          ],
          "line": 244
        },
        "resolved": true,
        "details": {
          "function_name": "rb_event_length",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "185-208",
          "snippet": "static inline unsigned\nrb_event_length(struct ring_buffer_event *event)\n{\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event))\n\t\t\t/* undefined */\n\t\t\treturn -1;\n\t\treturn  event->array[0] + RB_EVNT_HDR_SIZE;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\treturn RB_LEN_TIME_EXTEND;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\treturn RB_LEN_TIME_STAMP;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\treturn rb_event_data_length(event);\n\tdefault:\n\t\tBUG();\n\t}\n\t/* not hit */\n\treturn 0;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX",
            "#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX\n#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic inline unsigned\nrb_event_length(struct ring_buffer_event *event)\n{\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event))\n\t\t\t/* undefined */\n\t\t\treturn -1;\n\t\treturn  event->array[0] + RB_EVNT_HDR_SIZE;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\treturn RB_LEN_TIME_EXTEND;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\treturn RB_LEN_TIME_STAMP;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\treturn rb_event_data_length(event);\n\tdefault:\n\t\tBUG();\n\t}\n\t/* not hit */\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "skip_time_extend",
          "args": [
            "event"
          ],
          "line": 242
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "extended_time",
          "args": [
            "event"
          ],
          "line": 241
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_MAX_SMALL_DATA\t(RB_ALIGNMENT * RINGBUF_TYPE_DATA_TYPE_LEN_MAX)\n#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nunsigned ring_buffer_event_length(struct ring_buffer_event *event)\n{\n\tunsigned length;\n\n\tif (extended_time(event))\n\t\tevent = skip_time_extend(event);\n\n\tlength = rb_event_length(event);\n\tif (event->type_len > RINGBUF_TYPE_DATA_TYPE_LEN_MAX)\n\t\treturn length;\n\tlength -= RB_EVNT_HDR_SIZE;\n\tif (length > RB_MAX_SMALL_DATA + sizeof(event->array[0]))\n                length -= sizeof(event->array[0]);\n\treturn length;\n}"
  },
  {
    "function_name": "rb_event_ts_length",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "214-225",
    "snippet": "static inline unsigned\nrb_event_ts_length(struct ring_buffer_event *event)\n{\n\tunsigned len = 0;\n\n\tif (extended_time(event)) {\n\t\t/* time extends include the data event after it */\n\t\tlen = RB_LEN_TIME_EXTEND;\n\t\tevent = skip_time_extend(event);\n\t}\n\treturn len + rb_event_length(event);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rb_event_length",
          "args": [
            "event"
          ],
          "line": 224
        },
        "resolved": true,
        "details": {
          "function_name": "rb_event_length",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "185-208",
          "snippet": "static inline unsigned\nrb_event_length(struct ring_buffer_event *event)\n{\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event))\n\t\t\t/* undefined */\n\t\t\treturn -1;\n\t\treturn  event->array[0] + RB_EVNT_HDR_SIZE;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\treturn RB_LEN_TIME_EXTEND;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\treturn RB_LEN_TIME_STAMP;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\treturn rb_event_data_length(event);\n\tdefault:\n\t\tBUG();\n\t}\n\t/* not hit */\n\treturn 0;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX",
            "#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX\n#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic inline unsigned\nrb_event_length(struct ring_buffer_event *event)\n{\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event))\n\t\t\t/* undefined */\n\t\t\treturn -1;\n\t\treturn  event->array[0] + RB_EVNT_HDR_SIZE;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\treturn RB_LEN_TIME_EXTEND;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\treturn RB_LEN_TIME_STAMP;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\treturn rb_event_data_length(event);\n\tdefault:\n\t\tBUG();\n\t}\n\t/* not hit */\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "skip_time_extend",
          "args": [
            "event"
          ],
          "line": 222
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "extended_time",
          "args": [
            "event"
          ],
          "line": 219
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic inline unsigned\nrb_event_ts_length(struct ring_buffer_event *event)\n{\n\tunsigned len = 0;\n\n\tif (extended_time(event)) {\n\t\t/* time extends include the data event after it */\n\t\tlen = RB_LEN_TIME_EXTEND;\n\t\tevent = skip_time_extend(event);\n\t}\n\treturn len + rb_event_length(event);\n}"
  },
  {
    "function_name": "rb_event_length",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "185-208",
    "snippet": "static inline unsigned\nrb_event_length(struct ring_buffer_event *event)\n{\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event))\n\t\t\t/* undefined */\n\t\t\treturn -1;\n\t\treturn  event->array[0] + RB_EVNT_HDR_SIZE;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\treturn RB_LEN_TIME_EXTEND;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\treturn RB_LEN_TIME_STAMP;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\treturn rb_event_data_length(event);\n\tdefault:\n\t\tBUG();\n\t}\n\t/* not hit */\n\treturn 0;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX",
      "#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))"
    ],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "BUG",
          "args": [],
          "line": 204
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rb_event_data_length",
          "args": [
            "event"
          ],
          "line": 202
        },
        "resolved": true,
        "details": {
          "function_name": "rb_event_data_length",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "168-178",
          "snippet": "static unsigned\nrb_event_data_length(struct ring_buffer_event *event)\n{\n\tunsigned length;\n\n\tif (event->type_len)\n\t\tlength = event->type_len * RB_ALIGNMENT;\n\telse\n\t\tlength = event->array[0];\n\treturn length + RB_EVNT_HDR_SIZE;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [
            "#define RB_ALIGNMENT\t\t4U",
            "#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))"
          ],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_ALIGNMENT\t\t4U\n#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic unsigned\nrb_event_data_length(struct ring_buffer_event *event)\n{\n\tunsigned length;\n\n\tif (event->type_len)\n\t\tlength = event->type_len * RB_ALIGNMENT;\n\telse\n\t\tlength = event->array[0];\n\treturn length + RB_EVNT_HDR_SIZE;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rb_null_event",
          "args": [
            "event"
          ],
          "line": 190
        },
        "resolved": true,
        "details": {
          "function_name": "rb_null_event",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
          "lines": "156-159",
          "snippet": "static inline int rb_null_event(struct ring_buffer_event *event)\n{\n\treturn event->type_len == RINGBUF_TYPE_PADDING && !event->time_delta;\n}",
          "includes": [
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static __always_inline struct",
            "static noinline struct",
            "static noinline struct",
            "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic inline int rb_null_event(struct ring_buffer_event *event)\n{\n\treturn event->type_len == RINGBUF_TYPE_PADDING && !event->time_delta;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RINGBUF_TYPE_DATA 0 ... RINGBUF_TYPE_DATA_TYPE_LEN_MAX\n#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic inline unsigned\nrb_event_length(struct ring_buffer_event *event)\n{\n\tswitch (event->type_len) {\n\tcase RINGBUF_TYPE_PADDING:\n\t\tif (rb_null_event(event))\n\t\t\t/* undefined */\n\t\t\treturn -1;\n\t\treturn  event->array[0] + RB_EVNT_HDR_SIZE;\n\n\tcase RINGBUF_TYPE_TIME_EXTEND:\n\t\treturn RB_LEN_TIME_EXTEND;\n\n\tcase RINGBUF_TYPE_TIME_STAMP:\n\t\treturn RB_LEN_TIME_STAMP;\n\n\tcase RINGBUF_TYPE_DATA:\n\t\treturn rb_event_data_length(event);\n\tdefault:\n\t\tBUG();\n\t}\n\t/* not hit */\n\treturn 0;\n}"
  },
  {
    "function_name": "rb_event_data_length",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "168-178",
    "snippet": "static unsigned\nrb_event_data_length(struct ring_buffer_event *event)\n{\n\tunsigned length;\n\n\tif (event->type_len)\n\t\tlength = event->type_len * RB_ALIGNMENT;\n\telse\n\t\tlength = event->array[0];\n\treturn length + RB_EVNT_HDR_SIZE;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [
      "#define RB_ALIGNMENT\t\t4U",
      "#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))"
    ],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\n#define RB_ALIGNMENT\t\t4U\n#define RB_EVNT_HDR_SIZE (offsetof(struct ring_buffer_event, array))\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic unsigned\nrb_event_data_length(struct ring_buffer_event *event)\n{\n\tunsigned length;\n\n\tif (event->type_len)\n\t\tlength = event->type_len * RB_ALIGNMENT;\n\telse\n\t\tlength = event->array[0];\n\treturn length + RB_EVNT_HDR_SIZE;\n}"
  },
  {
    "function_name": "rb_event_set_padding",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "161-166",
    "snippet": "static void rb_event_set_padding(struct ring_buffer_event *event)\n{\n\t/* padding has a NULL time_delta */\n\tevent->type_len = RINGBUF_TYPE_PADDING;\n\tevent->time_delta = 0;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic void rb_event_set_padding(struct ring_buffer_event *event)\n{\n\t/* padding has a NULL time_delta */\n\tevent->type_len = RINGBUF_TYPE_PADDING;\n\tevent->time_delta = 0;\n}"
  },
  {
    "function_name": "rb_null_event",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "156-159",
    "snippet": "static inline int rb_null_event(struct ring_buffer_event *event)\n{\n\treturn event->type_len == RINGBUF_TYPE_PADDING && !event->time_delta;\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);",
      "static __always_inline struct"
    ],
    "called_functions": [],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic inline bool rb_event_is_commit(struct ring_buffer_per_cpu *cpu_buffer,\n\t\t\t\t     struct ring_buffer_event *event);\nstatic __always_inline struct;\n\nstatic inline int rb_null_event(struct ring_buffer_event *event)\n{\n\treturn event->type_len == RINGBUF_TYPE_PADDING && !event->time_delta;\n}"
  },
  {
    "function_name": "ring_buffer_print_entry_header",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ring_buffer.c",
    "lines": "35-52",
    "snippet": "int ring_buffer_print_entry_header(struct trace_seq *s)\n{\n\ttrace_seq_puts(s, \"# compressed entry header\\n\");\n\ttrace_seq_puts(s, \"\\ttype_len    :    5 bits\\n\");\n\ttrace_seq_puts(s, \"\\ttime_delta  :   27 bits\\n\");\n\ttrace_seq_puts(s, \"\\tarray       :   32 bits\\n\");\n\ttrace_seq_putc(s, '\\n');\n\ttrace_seq_printf(s, \"\\tpadding     : type == %d\\n\",\n\t\t\t RINGBUF_TYPE_PADDING);\n\ttrace_seq_printf(s, \"\\ttime_extend : type == %d\\n\",\n\t\t\t RINGBUF_TYPE_TIME_EXTEND);\n\ttrace_seq_printf(s, \"\\ttime_stamp : type == %d\\n\",\n\t\t\t RINGBUF_TYPE_TIME_STAMP);\n\ttrace_seq_printf(s, \"\\tdata max type_len  == %d\\n\",\n\t\t\t RINGBUF_TYPE_DATA_TYPE_LEN_MAX);\n\n\treturn !trace_seq_has_overflowed(s);\n}",
    "includes": [
      "#include <asm/local.h>",
      "#include <linux/oom.h>",
      "#include <linux/cpu.h>",
      "#include <linux/list.h>",
      "#include <linux/hash.h>",
      "#include <linux/init.h>",
      "#include <linux/slab.h>",
      "#include <linux/delay.h>",
      "#include <linux/mutex.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/kthread.h>\t/* for self test */",
      "#include <linux/hardirq.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/irq_work.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/trace_seq.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/trace_clock.h>",
      "#include <linux/ring_buffer.h>",
      "#include <linux/trace_events.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline struct",
      "static __always_inline struct",
      "static noinline struct",
      "static noinline struct",
      "static __always_inline struct"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "trace_seq_has_overflowed",
          "args": [
            "s"
          ],
          "line": 51
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_seq_printf",
          "args": [
            "s",
            "\"\\tdata max type_len  == %d\\n\"",
            "RINGBUF_TYPE_DATA_TYPE_LEN_MAX"
          ],
          "line": 48
        },
        "resolved": true,
        "details": {
          "function_name": "trace_seq_printf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/trace_seq.c",
          "lines": "84-103",
          "snippet": "void trace_seq_printf(struct trace_seq *s, const char *fmt, ...)\n{\n\tunsigned int save_len = s->seq.len;\n\tva_list ap;\n\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tva_start(ap, fmt);\n\tseq_buf_vprintf(&s->seq, fmt, ap);\n\tva_end(ap);\n\n\t/* If we can't write it all, don't bother writing anything */\n\tif (unlikely(seq_buf_has_overflowed(&s->seq))) {\n\t\ts->seq.len = save_len;\n\t\ts->full = 1;\n\t}\n}",
          "includes": [
            "#include <linux/trace_seq.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/uaccess.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/trace_seq.h>\n#include <linux/seq_file.h>\n#include <linux/uaccess.h>\n\nvoid trace_seq_printf(struct trace_seq *s, const char *fmt, ...)\n{\n\tunsigned int save_len = s->seq.len;\n\tva_list ap;\n\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tva_start(ap, fmt);\n\tseq_buf_vprintf(&s->seq, fmt, ap);\n\tva_end(ap);\n\n\t/* If we can't write it all, don't bother writing anything */\n\tif (unlikely(seq_buf_has_overflowed(&s->seq))) {\n\t\ts->seq.len = save_len;\n\t\ts->full = 1;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "trace_seq_putc",
          "args": [
            "s",
            "'\\n'"
          ],
          "line": 41
        },
        "resolved": true,
        "details": {
          "function_name": "trace_seq_putc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/trace_seq.c",
          "lines": "236-249",
          "snippet": "void trace_seq_putc(struct trace_seq *s, unsigned char c)\n{\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tif (TRACE_SEQ_BUF_LEFT(s) < 1) {\n\t\ts->full = 1;\n\t\treturn;\n\t}\n\n\tseq_buf_putc(&s->seq, c);\n}",
          "includes": [
            "#include <linux/trace_seq.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/uaccess.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/trace_seq.h>\n#include <linux/seq_file.h>\n#include <linux/uaccess.h>\n\nvoid trace_seq_putc(struct trace_seq *s, unsigned char c)\n{\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tif (TRACE_SEQ_BUF_LEFT(s) < 1) {\n\t\ts->full = 1;\n\t\treturn;\n\t}\n\n\tseq_buf_putc(&s->seq, c);\n}"
        }
      },
      {
        "call_info": {
          "callee": "trace_seq_puts",
          "args": [
            "s",
            "\"\\tarray       :   32 bits\\n\""
          ],
          "line": 40
        },
        "resolved": true,
        "details": {
          "function_name": "trace_seq_puts",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/trace_seq.c",
          "lines": "208-223",
          "snippet": "void trace_seq_puts(struct trace_seq *s, const char *str)\n{\n\tunsigned int len = strlen(str);\n\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tif (len > TRACE_SEQ_BUF_LEFT(s)) {\n\t\ts->full = 1;\n\t\treturn;\n\t}\n\n\tseq_buf_putmem(&s->seq, str, len);\n}",
          "includes": [
            "#include <linux/trace_seq.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/uaccess.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/trace_seq.h>\n#include <linux/seq_file.h>\n#include <linux/uaccess.h>\n\nvoid trace_seq_puts(struct trace_seq *s, const char *str)\n{\n\tunsigned int len = strlen(str);\n\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tif (len > TRACE_SEQ_BUF_LEFT(s)) {\n\t\ts->full = 1;\n\t\treturn;\n\t}\n\n\tseq_buf_putmem(&s->seq, str, len);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n\nstatic __always_inline struct;\nstatic __always_inline struct;\nstatic noinline struct;\nstatic noinline struct;\nstatic __always_inline struct;\n\nint ring_buffer_print_entry_header(struct trace_seq *s)\n{\n\ttrace_seq_puts(s, \"# compressed entry header\\n\");\n\ttrace_seq_puts(s, \"\\ttype_len    :    5 bits\\n\");\n\ttrace_seq_puts(s, \"\\ttime_delta  :   27 bits\\n\");\n\ttrace_seq_puts(s, \"\\tarray       :   32 bits\\n\");\n\ttrace_seq_putc(s, '\\n');\n\ttrace_seq_printf(s, \"\\tpadding     : type == %d\\n\",\n\t\t\t RINGBUF_TYPE_PADDING);\n\ttrace_seq_printf(s, \"\\ttime_extend : type == %d\\n\",\n\t\t\t RINGBUF_TYPE_TIME_EXTEND);\n\ttrace_seq_printf(s, \"\\ttime_stamp : type == %d\\n\",\n\t\t\t RINGBUF_TYPE_TIME_STAMP);\n\ttrace_seq_printf(s, \"\\tdata max type_len  == %d\\n\",\n\t\t\t RINGBUF_TYPE_DATA_TYPE_LEN_MAX);\n\n\treturn !trace_seq_has_overflowed(s);\n}"
  }
]