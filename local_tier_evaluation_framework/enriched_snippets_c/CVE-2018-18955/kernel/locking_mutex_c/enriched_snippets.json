[
  {
    "function_name": "atomic_dec_and_mutex_lock",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "1430-1444",
    "snippet": "int atomic_dec_and_mutex_lock(atomic_t *cnt, struct mutex *lock)\n{\n\t/* dec if we can't possibly hit 0 */\n\tif (atomic_add_unless(cnt, -1, 1))\n\t\treturn 0;\n\t/* we might hit 0, so take the lock */\n\tmutex_lock(lock);\n\tif (!atomic_dec_and_test(cnt)) {\n\t\t/* when we actually did the dec, we didn't hit 0 */\n\t\tmutex_unlock(lock);\n\t\treturn 0;\n\t}\n\t/* we hit 0, and we hold the lock */\n\treturn 1;\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "lock"
          ],
          "line": 1439
        },
        "resolved": true,
        "details": {
          "function_name": "ww_mutex_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "728-744",
          "snippet": "void __sched ww_mutex_unlock(struct ww_mutex *lock)\n{\n\t/*\n\t * The unlocking fastpath is the 0->1 transition from 'locked'\n\t * into 'unlocked' state:\n\t */\n\tif (lock->ctx) {\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\tDEBUG_LOCKS_WARN_ON(!lock->ctx->acquired);\n#endif\n\t\tif (lock->ctx->acquired > 0)\n\t\t\tlock->ctx->acquired--;\n\t\tlock->ctx = NULL;\n\t}\n\n\tmutex_unlock(&lock->base);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nvoid __sched ww_mutex_unlock(struct ww_mutex *lock)\n{\n\t/*\n\t * The unlocking fastpath is the 0->1 transition from 'locked'\n\t * into 'unlocked' state:\n\t */\n\tif (lock->ctx) {\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\tDEBUG_LOCKS_WARN_ON(!lock->ctx->acquired);\n#endif\n\t\tif (lock->ctx->acquired > 0)\n\t\t\tlock->ctx->acquired--;\n\t\tlock->ctx = NULL;\n\t}\n\n\tmutex_unlock(&lock->base);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_dec_and_test",
          "args": [
            "cnt"
          ],
          "line": 1437
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "lock"
          ],
          "line": 1436
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock_interruptible_slowpath",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "1342-1346",
          "snippet": "__sched\n__mutex_lock_interruptible_slowpath(struct mutex *lock)\n{\n\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__mutex_lock_interruptible_slowpath(struct mutex *lock)\n{\n\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_add_unless",
          "args": [
            "cnt",
            "-1",
            "1"
          ],
          "line": 1433
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nint atomic_dec_and_mutex_lock(atomic_t *cnt, struct mutex *lock)\n{\n\t/* dec if we can't possibly hit 0 */\n\tif (atomic_add_unless(cnt, -1, 1))\n\t\treturn 0;\n\t/* we might hit 0, so take the lock */\n\tmutex_lock(lock);\n\tif (!atomic_dec_and_test(cnt)) {\n\t\t/* when we actually did the dec, we didn't hit 0 */\n\t\tmutex_unlock(lock);\n\t\treturn 0;\n\t}\n\t/* we hit 0, and we hold the lock */\n\treturn 1;\n}"
  },
  {
    "function_name": "ww_mutex_lock_interruptible",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "1406-1418",
    "snippet": "int __sched\nww_mutex_lock_interruptible(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tmight_sleep();\n\n\tif (__mutex_trylock_fast(&lock->base)) {\n\t\tif (ctx)\n\t\t\tww_mutex_set_context_fastpath(lock, ctx);\n\t\treturn 0;\n\t}\n\n\treturn __ww_mutex_lock_interruptible_slowpath(lock, ctx);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__ww_mutex_lock_interruptible_slowpath",
          "args": [
            "lock",
            "ctx"
          ],
          "line": 1417
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_lock_interruptible_slowpath",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "1355-1361",
          "snippet": "__sched\n__ww_mutex_lock_interruptible_slowpath(struct ww_mutex *lock,\n\t\t\t\t\t    struct ww_acquire_ctx *ctx)\n{\n\treturn __ww_mutex_lock(&lock->base, TASK_INTERRUPTIBLE, 0, NULL,\n\t\t\t       _RET_IP_, ctx);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__ww_mutex_lock_interruptible_slowpath(struct ww_mutex *lock,\n\t\t\t\t\t    struct ww_acquire_ctx *ctx)\n{\n\treturn __ww_mutex_lock(&lock->base, TASK_INTERRUPTIBLE, 0, NULL,\n\t\t\t       _RET_IP_, ctx);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ww_mutex_set_context_fastpath",
          "args": [
            "lock",
            "ctx"
          ],
          "line": 1413
        },
        "resolved": true,
        "details": {
          "function_name": "ww_mutex_set_context_fastpath",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "437-470",
          "snippet": "static __always_inline void\nww_mutex_set_context_fastpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tww_mutex_lock_acquired(lock, ctx);\n\n\t/*\n\t * The lock->ctx update should be visible on all cores before\n\t * the WAITERS check is done, otherwise contended waiters might be\n\t * missed. The contended waiters will either see ww_ctx == NULL\n\t * and keep spinning, or it will acquire wait_lock, add itself\n\t * to waiter list and sleep.\n\t */\n\tsmp_mb(); /* See comments above and below. */\n\n\t/*\n\t * [W] ww->ctx = ctx\t    [W] MUTEX_FLAG_WAITERS\n\t *     MB\t\t        MB\n\t * [R] MUTEX_FLAG_WAITERS   [R] ww->ctx\n\t *\n\t * The memory barrier above pairs with the memory barrier in\n\t * __ww_mutex_add_waiter() and makes sure we either observe ww->ctx\n\t * and/or !empty list.\n\t */\n\tif (likely(!(atomic_long_read(&lock->base.owner) & MUTEX_FLAG_WAITERS)))\n\t\treturn;\n\n\t/*\n\t * Uh oh, we raced in fastpath, check if any of the waiters need to\n\t * die or wound us.\n\t */\n\tspin_lock(&lock->base.wait_lock);\n\t__ww_mutex_check_waiters(&lock->base, ctx);\n\tspin_unlock(&lock->base.wait_lock);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAG_WAITERS\t0x01"
          ],
          "globals_used": [
            "static __always_inline int",
            "static __always_inline int"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAG_WAITERS\t0x01\n\nstatic __always_inline int;\nstatic __always_inline int;\n\nstatic __always_inline void\nww_mutex_set_context_fastpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tww_mutex_lock_acquired(lock, ctx);\n\n\t/*\n\t * The lock->ctx update should be visible on all cores before\n\t * the WAITERS check is done, otherwise contended waiters might be\n\t * missed. The contended waiters will either see ww_ctx == NULL\n\t * and keep spinning, or it will acquire wait_lock, add itself\n\t * to waiter list and sleep.\n\t */\n\tsmp_mb(); /* See comments above and below. */\n\n\t/*\n\t * [W] ww->ctx = ctx\t    [W] MUTEX_FLAG_WAITERS\n\t *     MB\t\t        MB\n\t * [R] MUTEX_FLAG_WAITERS   [R] ww->ctx\n\t *\n\t * The memory barrier above pairs with the memory barrier in\n\t * __ww_mutex_add_waiter() and makes sure we either observe ww->ctx\n\t * and/or !empty list.\n\t */\n\tif (likely(!(atomic_long_read(&lock->base.owner) & MUTEX_FLAG_WAITERS)))\n\t\treturn;\n\n\t/*\n\t * Uh oh, we raced in fastpath, check if any of the waiters need to\n\t * die or wound us.\n\t */\n\tspin_lock(&lock->base.wait_lock);\n\t__ww_mutex_check_waiters(&lock->base, ctx);\n\tspin_unlock(&lock->base.wait_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_trylock_fast",
          "args": [
            "&lock->base"
          ],
          "line": 1411
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_trylock_fast",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "139-148",
          "snippet": "static __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline int",
            "static __always_inline int"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline int;\nstatic __always_inline int;\n\nstatic __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 1409
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nint __sched\nww_mutex_lock_interruptible(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tmight_sleep();\n\n\tif (__mutex_trylock_fast(&lock->base)) {\n\t\tif (ctx)\n\t\t\tww_mutex_set_context_fastpath(lock, ctx);\n\t\treturn 0;\n\t}\n\n\treturn __ww_mutex_lock_interruptible_slowpath(lock, ctx);\n}"
  },
  {
    "function_name": "ww_mutex_lock",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "1391-1403",
    "snippet": "int __sched\nww_mutex_lock(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tmight_sleep();\n\n\tif (__mutex_trylock_fast(&lock->base)) {\n\t\tif (ctx)\n\t\t\tww_mutex_set_context_fastpath(lock, ctx);\n\t\treturn 0;\n\t}\n\n\treturn __ww_mutex_lock_slowpath(lock, ctx);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__ww_mutex_lock_slowpath",
          "args": [
            "lock",
            "ctx"
          ],
          "line": 1402
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_lock_slowpath",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "1348-1353",
          "snippet": "__sched\n__ww_mutex_lock_slowpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\treturn __ww_mutex_lock(&lock->base, TASK_UNINTERRUPTIBLE, 0, NULL,\n\t\t\t       _RET_IP_, ctx);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__ww_mutex_lock_slowpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\treturn __ww_mutex_lock(&lock->base, TASK_UNINTERRUPTIBLE, 0, NULL,\n\t\t\t       _RET_IP_, ctx);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ww_mutex_set_context_fastpath",
          "args": [
            "lock",
            "ctx"
          ],
          "line": 1398
        },
        "resolved": true,
        "details": {
          "function_name": "ww_mutex_set_context_fastpath",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "437-470",
          "snippet": "static __always_inline void\nww_mutex_set_context_fastpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tww_mutex_lock_acquired(lock, ctx);\n\n\t/*\n\t * The lock->ctx update should be visible on all cores before\n\t * the WAITERS check is done, otherwise contended waiters might be\n\t * missed. The contended waiters will either see ww_ctx == NULL\n\t * and keep spinning, or it will acquire wait_lock, add itself\n\t * to waiter list and sleep.\n\t */\n\tsmp_mb(); /* See comments above and below. */\n\n\t/*\n\t * [W] ww->ctx = ctx\t    [W] MUTEX_FLAG_WAITERS\n\t *     MB\t\t        MB\n\t * [R] MUTEX_FLAG_WAITERS   [R] ww->ctx\n\t *\n\t * The memory barrier above pairs with the memory barrier in\n\t * __ww_mutex_add_waiter() and makes sure we either observe ww->ctx\n\t * and/or !empty list.\n\t */\n\tif (likely(!(atomic_long_read(&lock->base.owner) & MUTEX_FLAG_WAITERS)))\n\t\treturn;\n\n\t/*\n\t * Uh oh, we raced in fastpath, check if any of the waiters need to\n\t * die or wound us.\n\t */\n\tspin_lock(&lock->base.wait_lock);\n\t__ww_mutex_check_waiters(&lock->base, ctx);\n\tspin_unlock(&lock->base.wait_lock);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAG_WAITERS\t0x01"
          ],
          "globals_used": [
            "static __always_inline int",
            "static __always_inline int"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAG_WAITERS\t0x01\n\nstatic __always_inline int;\nstatic __always_inline int;\n\nstatic __always_inline void\nww_mutex_set_context_fastpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tww_mutex_lock_acquired(lock, ctx);\n\n\t/*\n\t * The lock->ctx update should be visible on all cores before\n\t * the WAITERS check is done, otherwise contended waiters might be\n\t * missed. The contended waiters will either see ww_ctx == NULL\n\t * and keep spinning, or it will acquire wait_lock, add itself\n\t * to waiter list and sleep.\n\t */\n\tsmp_mb(); /* See comments above and below. */\n\n\t/*\n\t * [W] ww->ctx = ctx\t    [W] MUTEX_FLAG_WAITERS\n\t *     MB\t\t        MB\n\t * [R] MUTEX_FLAG_WAITERS   [R] ww->ctx\n\t *\n\t * The memory barrier above pairs with the memory barrier in\n\t * __ww_mutex_add_waiter() and makes sure we either observe ww->ctx\n\t * and/or !empty list.\n\t */\n\tif (likely(!(atomic_long_read(&lock->base.owner) & MUTEX_FLAG_WAITERS)))\n\t\treturn;\n\n\t/*\n\t * Uh oh, we raced in fastpath, check if any of the waiters need to\n\t * die or wound us.\n\t */\n\tspin_lock(&lock->base.wait_lock);\n\t__ww_mutex_check_waiters(&lock->base, ctx);\n\tspin_unlock(&lock->base.wait_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_trylock_fast",
          "args": [
            "&lock->base"
          ],
          "line": 1396
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_trylock_fast",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "139-148",
          "snippet": "static __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline int",
            "static __always_inline int"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline int;\nstatic __always_inline int;\n\nstatic __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 1394
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nint __sched\nww_mutex_lock(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tmight_sleep();\n\n\tif (__mutex_trylock_fast(&lock->base)) {\n\t\tif (ctx)\n\t\t\tww_mutex_set_context_fastpath(lock, ctx);\n\t\treturn 0;\n\t}\n\n\treturn __ww_mutex_lock_slowpath(lock, ctx);\n}"
  },
  {
    "function_name": "mutex_trylock",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "1379-1387",
    "snippet": "int __sched mutex_trylock(struct mutex *lock)\n{\n\tbool locked = __mutex_trylock(lock);\n\n\tif (locked)\n\t\tmutex_acquire(&lock->dep_map, 0, 1, _RET_IP_);\n\n\treturn locked;\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "mutex_acquire",
          "args": [
            "&lock->dep_map",
            "0",
            "1",
            "_RET_IP_"
          ],
          "line": 1384
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__mutex_trylock",
          "args": [
            "lock"
          ],
          "line": 1381
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_trylock_fast",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "139-148",
          "snippet": "static __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline int",
            "static __always_inline int"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline int;\nstatic __always_inline int;\n\nstatic __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}"
        }
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nint __sched mutex_trylock(struct mutex *lock)\n{\n\tbool locked = __mutex_trylock(lock);\n\n\tif (locked)\n\t\tmutex_acquire(&lock->dep_map, 0, 1, _RET_IP_);\n\n\treturn locked;\n}"
  },
  {
    "function_name": "__ww_mutex_lock_interruptible_slowpath",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "1355-1361",
    "snippet": "__sched\n__ww_mutex_lock_interruptible_slowpath(struct ww_mutex *lock,\n\t\t\t\t\t    struct ww_acquire_ctx *ctx)\n{\n\treturn __ww_mutex_lock(&lock->base, TASK_INTERRUPTIBLE, 0, NULL,\n\t\t\t       _RET_IP_, ctx);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__ww_mutex_lock",
          "args": [
            "&lock->base",
            "TASK_INTERRUPTIBLE",
            "0",
            "NULL",
            "_RET_IP_",
            "ctx"
          ],
          "line": 1359
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_lock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "1075-1081",
          "snippet": "static int __sched\n__ww_mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t\tstruct lockdep_map *nest_lock, unsigned long ip,\n\t\tstruct ww_acquire_ctx *ww_ctx)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, ww_ctx, true);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);\n\nstatic int __sched\n__ww_mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t\tstruct lockdep_map *nest_lock, unsigned long ip,\n\t\tstruct ww_acquire_ctx *ww_ctx)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, ww_ctx, true);\n}"
        }
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__ww_mutex_lock_interruptible_slowpath(struct ww_mutex *lock,\n\t\t\t\t\t    struct ww_acquire_ctx *ctx)\n{\n\treturn __ww_mutex_lock(&lock->base, TASK_INTERRUPTIBLE, 0, NULL,\n\t\t\t       _RET_IP_, ctx);\n}"
  },
  {
    "function_name": "__ww_mutex_lock_slowpath",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "1348-1353",
    "snippet": "__sched\n__ww_mutex_lock_slowpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\treturn __ww_mutex_lock(&lock->base, TASK_UNINTERRUPTIBLE, 0, NULL,\n\t\t\t       _RET_IP_, ctx);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__ww_mutex_lock",
          "args": [
            "&lock->base",
            "TASK_UNINTERRUPTIBLE",
            "0",
            "NULL",
            "_RET_IP_",
            "ctx"
          ],
          "line": 1351
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_lock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "1075-1081",
          "snippet": "static int __sched\n__ww_mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t\tstruct lockdep_map *nest_lock, unsigned long ip,\n\t\tstruct ww_acquire_ctx *ww_ctx)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, ww_ctx, true);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);\n\nstatic int __sched\n__ww_mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t\tstruct lockdep_map *nest_lock, unsigned long ip,\n\t\tstruct ww_acquire_ctx *ww_ctx)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, ww_ctx, true);\n}"
        }
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__ww_mutex_lock_slowpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\treturn __ww_mutex_lock(&lock->base, TASK_UNINTERRUPTIBLE, 0, NULL,\n\t\t\t       _RET_IP_, ctx);\n}"
  },
  {
    "function_name": "__mutex_lock_interruptible_slowpath",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "1342-1346",
    "snippet": "__sched\n__mutex_lock_interruptible_slowpath(struct mutex *lock)\n{\n\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_lock",
          "args": [
            "lock",
            "TASK_INTERRUPTIBLE",
            "0",
            "NULL",
            "_RET_IP_"
          ],
          "line": 1345
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "1068-1073",
          "snippet": "static int __sched\n__mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);\n\nstatic int __sched\n__mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}"
        }
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__mutex_lock_interruptible_slowpath(struct mutex *lock)\n{\n\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);\n}"
  },
  {
    "function_name": "__mutex_lock_killable_slowpath",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "1336-1340",
    "snippet": "__sched\n__mutex_lock_killable_slowpath(struct mutex *lock)\n{\n\treturn __mutex_lock(lock, TASK_KILLABLE, 0, NULL, _RET_IP_);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_lock",
          "args": [
            "lock",
            "TASK_KILLABLE",
            "0",
            "NULL",
            "_RET_IP_"
          ],
          "line": 1339
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "1068-1073",
          "snippet": "static int __sched\n__mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);\n\nstatic int __sched\n__mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}"
        }
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__mutex_lock_killable_slowpath(struct mutex *lock)\n{\n\treturn __mutex_lock(lock, TASK_KILLABLE, 0, NULL, _RET_IP_);\n}"
  },
  {
    "function_name": "__mutex_lock_slowpath",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "1330-1334",
    "snippet": "__sched\n__mutex_lock_slowpath(struct mutex *lock)\n{\n\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_lock",
          "args": [
            "lock",
            "TASK_UNINTERRUPTIBLE",
            "0",
            "NULL",
            "_RET_IP_"
          ],
          "line": 1333
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "1068-1073",
          "snippet": "static int __sched\n__mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);\n\nstatic int __sched\n__mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}"
        }
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__mutex_lock_slowpath(struct mutex *lock)\n{\n\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n}"
  },
  {
    "function_name": "mutex_lock_io",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "1320-1327",
    "snippet": "void __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token;\n\n\ttoken = io_schedule_prepare();\n\tmutex_lock(lock);\n\tio_schedule_finish(token);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "io_schedule_finish",
          "args": [
            "token"
          ],
          "line": 1326
        },
        "resolved": true,
        "details": {
          "function_name": "io_schedule_finish",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/core.c",
          "lines": "5110-5113",
          "snippet": "void io_schedule_finish(int token)\n{\n\tcurrent->in_iowait = token;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include <trace/events/sched.h>",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/kcov.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include <trace/events/sched.h>\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/kcov.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n\nvoid io_schedule_finish(int token)\n{\n\tcurrent->in_iowait = token;\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "lock"
          ],
          "line": 1325
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock_interruptible_slowpath",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "1342-1346",
          "snippet": "__sched\n__mutex_lock_interruptible_slowpath(struct mutex *lock)\n{\n\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__mutex_lock_interruptible_slowpath(struct mutex *lock)\n{\n\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);\n}"
        }
      },
      {
        "call_info": {
          "callee": "io_schedule_prepare",
          "args": [],
          "line": 1324
        },
        "resolved": true,
        "details": {
          "function_name": "io_schedule_prepare",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/core.c",
          "lines": "5100-5108",
          "snippet": "int io_schedule_prepare(void)\n{\n\tint old_iowait = current->in_iowait;\n\n\tcurrent->in_iowait = 1;\n\tblk_schedule_flush_plug(current);\n\n\treturn old_iowait;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include <trace/events/sched.h>",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/kcov.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include <trace/events/sched.h>\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/kcov.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n\nint io_schedule_prepare(void)\n{\n\tint old_iowait = current->in_iowait;\n\n\tcurrent->in_iowait = 1;\n\tblk_schedule_flush_plug(current);\n\n\treturn old_iowait;\n}"
        }
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nvoid __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token;\n\n\ttoken = io_schedule_prepare();\n\tmutex_lock(lock);\n\tio_schedule_finish(token);\n}"
  },
  {
    "function_name": "mutex_lock_killable",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "1299-1307",
    "snippet": "int __sched mutex_lock_killable(struct mutex *lock)\n{\n\tmight_sleep();\n\n\tif (__mutex_trylock_fast(lock))\n\t\treturn 0;\n\n\treturn __mutex_lock_killable_slowpath(lock);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_lock_killable_slowpath",
          "args": [
            "lock"
          ],
          "line": 1306
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock_killable_slowpath",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "1336-1340",
          "snippet": "__sched\n__mutex_lock_killable_slowpath(struct mutex *lock)\n{\n\treturn __mutex_lock(lock, TASK_KILLABLE, 0, NULL, _RET_IP_);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__mutex_lock_killable_slowpath(struct mutex *lock)\n{\n\treturn __mutex_lock(lock, TASK_KILLABLE, 0, NULL, _RET_IP_);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_trylock_fast",
          "args": [
            "lock"
          ],
          "line": 1303
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_trylock_fast",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "139-148",
          "snippet": "static __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline int",
            "static __always_inline int"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline int;\nstatic __always_inline int;\n\nstatic __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 1301
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nint __sched mutex_lock_killable(struct mutex *lock)\n{\n\tmight_sleep();\n\n\tif (__mutex_trylock_fast(lock))\n\t\treturn 0;\n\n\treturn __mutex_lock_killable_slowpath(lock);\n}"
  },
  {
    "function_name": "mutex_lock_interruptible",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "1275-1283",
    "snippet": "int __sched mutex_lock_interruptible(struct mutex *lock)\n{\n\tmight_sleep();\n\n\tif (__mutex_trylock_fast(lock))\n\t\treturn 0;\n\n\treturn __mutex_lock_interruptible_slowpath(lock);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_lock_interruptible_slowpath",
          "args": [
            "lock"
          ],
          "line": 1282
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock_interruptible_slowpath",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "1342-1346",
          "snippet": "__sched\n__mutex_lock_interruptible_slowpath(struct mutex *lock)\n{\n\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__mutex_lock_interruptible_slowpath(struct mutex *lock)\n{\n\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_trylock_fast",
          "args": [
            "lock"
          ],
          "line": 1279
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_trylock_fast",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "139-148",
          "snippet": "static __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline int",
            "static __always_inline int"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline int;\nstatic __always_inline int;\n\nstatic __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 1277
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nint __sched mutex_lock_interruptible(struct mutex *lock)\n{\n\tmight_sleep();\n\n\tif (__mutex_trylock_fast(lock))\n\t\treturn 0;\n\n\treturn __mutex_lock_interruptible_slowpath(lock);\n}"
  },
  {
    "function_name": "__mutex_unlock_slowpath",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "1191-1250",
    "snippet": "__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip)\n{\n\tstruct task_struct *next = NULL;\n\tDEFINE_WAKE_Q(wake_q);\n\tunsigned long owner;\n\n\tmutex_release(&lock->dep_map, 1, ip);\n\n\t/*\n\t * Release the lock before (potentially) taking the spinlock such that\n\t * other contenders can get on with things ASAP.\n\t *\n\t * Except when HANDOFF, in that case we must not clear the owner field,\n\t * but instead set it to the top waiter.\n\t */\n\towner = atomic_long_read(&lock->owner);\n\tfor (;;) {\n\t\tunsigned long old;\n\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\tDEBUG_LOCKS_WARN_ON(__owner_task(owner) != current);\n\t\tDEBUG_LOCKS_WARN_ON(owner & MUTEX_FLAG_PICKUP);\n#endif\n\n\t\tif (owner & MUTEX_FLAG_HANDOFF)\n\t\t\tbreak;\n\n\t\told = atomic_long_cmpxchg_release(&lock->owner, owner,\n\t\t\t\t\t\t  __owner_flags(owner));\n\t\tif (old == owner) {\n\t\t\tif (owner & MUTEX_FLAG_WAITERS)\n\t\t\t\tbreak;\n\n\t\t\treturn;\n\t\t}\n\n\t\towner = old;\n\t}\n\n\tspin_lock(&lock->wait_lock);\n\tdebug_mutex_unlock(lock);\n\tif (!list_empty(&lock->wait_list)) {\n\t\t/* get the first entry from the wait-list: */\n\t\tstruct mutex_waiter *waiter =\n\t\t\tlist_first_entry(&lock->wait_list,\n\t\t\t\t\t struct mutex_waiter, list);\n\n\t\tnext = waiter->task;\n\n\t\tdebug_mutex_wake_waiter(lock, waiter);\n\t\twake_q_add(&wake_q, next);\n\t}\n\n\tif (owner & MUTEX_FLAG_HANDOFF)\n\t\t__mutex_handoff(lock, next);\n\n\tspin_unlock(&lock->wait_lock);\n\n\twake_up_q(&wake_q);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [
      "#define MUTEX_FLAG_PICKUP\t0x04",
      "#define MUTEX_FLAG_HANDOFF\t0x02",
      "#define MUTEX_FLAG_WAITERS\t0x01"
    ],
    "globals_used": [
      "__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "wake_up_q",
          "args": [
            "&wake_q"
          ],
          "line": 1249
        },
        "resolved": true,
        "details": {
          "function_name": "wake_up_q",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/core.c",
          "lines": "423-443",
          "snippet": "void wake_up_q(struct wake_q_head *head)\n{\n\tstruct wake_q_node *node = head->first;\n\n\twhile (node != WAKE_Q_TAIL) {\n\t\tstruct task_struct *task;\n\n\t\ttask = container_of(node, struct task_struct, wake_q);\n\t\tBUG_ON(!task);\n\t\t/* Task can safely be re-inserted now: */\n\t\tnode = node->next;\n\t\ttask->wake_q.next = NULL;\n\n\t\t/*\n\t\t * wake_up_process() executes a full barrier, which pairs with\n\t\t * the queueing in wake_q_add() so as not to miss wakeups.\n\t\t */\n\t\twake_up_process(task);\n\t\tput_task_struct(task);\n\t}\n}",
          "includes": [
            "#include \"features.h\"",
            "#include <trace/events/sched.h>",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/kcov.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include <trace/events/sched.h>\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/kcov.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n\nstatic __always_inline struct;\n\nvoid wake_up_q(struct wake_q_head *head)\n{\n\tstruct wake_q_node *node = head->first;\n\n\twhile (node != WAKE_Q_TAIL) {\n\t\tstruct task_struct *task;\n\n\t\ttask = container_of(node, struct task_struct, wake_q);\n\t\tBUG_ON(!task);\n\t\t/* Task can safely be re-inserted now: */\n\t\tnode = node->next;\n\t\ttask->wake_q.next = NULL;\n\n\t\t/*\n\t\t * wake_up_process() executes a full barrier, which pairs with\n\t\t * the queueing in wake_q_add() so as not to miss wakeups.\n\t\t */\n\t\twake_up_process(task);\n\t\tput_task_struct(task);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "spin_unlock",
          "args": [
            "&lock->wait_lock"
          ],
          "line": 1247
        },
        "resolved": true,
        "details": {
          "function_name": "__pv_queued_spin_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/qspinlock_paravirt.h",
          "lines": "546-560",
          "snippet": "__visible void __pv_queued_spin_unlock(struct qspinlock *lock)\n{\n\tu8 locked;\n\n\t/*\n\t * We must not unlock if SLOW, because in that case we must first\n\t * unhash. Otherwise it would be possible to have multiple @lock\n\t * entries, which would be BAD.\n\t */\n\tlocked = cmpxchg_release(&lock->locked, _Q_LOCKED_VAL, 0);\n\tif (likely(locked == _Q_LOCKED_VAL))\n\t\treturn;\n\n\t__pv_queued_spin_unlock_slowpath(lock, locked);\n}",
          "includes": [
            "#include <asm/qspinlock_paravirt.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/memblock.h>",
            "#include <linux/hash.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/qspinlock_paravirt.h>\n#include <linux/debug_locks.h>\n#include <linux/memblock.h>\n#include <linux/hash.h>\n\n__visible void __pv_queued_spin_unlock(struct qspinlock *lock)\n{\n\tu8 locked;\n\n\t/*\n\t * We must not unlock if SLOW, because in that case we must first\n\t * unhash. Otherwise it would be possible to have multiple @lock\n\t * entries, which would be BAD.\n\t */\n\tlocked = cmpxchg_release(&lock->locked, _Q_LOCKED_VAL, 0);\n\tif (likely(locked == _Q_LOCKED_VAL))\n\t\treturn;\n\n\t__pv_queued_spin_unlock_slowpath(lock, locked);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_handoff",
          "args": [
            "lock",
            "next"
          ],
          "line": 1245
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_handoff",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "197-220",
          "snippet": "static void __mutex_handoff(struct mutex *lock, struct task_struct *task)\n{\n\tunsigned long owner = atomic_long_read(&lock->owner);\n\n\tfor (;;) {\n\t\tunsigned long old, new;\n\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\tDEBUG_LOCKS_WARN_ON(__owner_task(owner) != current);\n\t\tDEBUG_LOCKS_WARN_ON(owner & MUTEX_FLAG_PICKUP);\n#endif\n\n\t\tnew = (owner & MUTEX_FLAG_WAITERS);\n\t\tnew |= (unsigned long)task;\n\t\tif (task)\n\t\t\tnew |= MUTEX_FLAG_PICKUP;\n\n\t\told = atomic_long_cmpxchg_release(&lock->owner, owner, new);\n\t\tif (old == owner)\n\t\t\tbreak;\n\n\t\towner = old;\n\t}\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAG_PICKUP\t0x04",
            "#define MUTEX_FLAG_WAITERS\t0x01"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAG_PICKUP\t0x04\n#define MUTEX_FLAG_WAITERS\t0x01\n\nstatic void __mutex_handoff(struct mutex *lock, struct task_struct *task)\n{\n\tunsigned long owner = atomic_long_read(&lock->owner);\n\n\tfor (;;) {\n\t\tunsigned long old, new;\n\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\tDEBUG_LOCKS_WARN_ON(__owner_task(owner) != current);\n\t\tDEBUG_LOCKS_WARN_ON(owner & MUTEX_FLAG_PICKUP);\n#endif\n\n\t\tnew = (owner & MUTEX_FLAG_WAITERS);\n\t\tnew |= (unsigned long)task;\n\t\tif (task)\n\t\t\tnew |= MUTEX_FLAG_PICKUP;\n\n\t\told = atomic_long_cmpxchg_release(&lock->owner, owner, new);\n\t\tif (old == owner)\n\t\t\tbreak;\n\n\t\towner = old;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "wake_q_add",
          "args": [
            "&wake_q",
            "next"
          ],
          "line": 1241
        },
        "resolved": true,
        "details": {
          "function_name": "wake_q_add",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/core.c",
          "lines": "399-421",
          "snippet": "void wake_q_add(struct wake_q_head *head, struct task_struct *task)\n{\n\tstruct wake_q_node *node = &task->wake_q;\n\n\t/*\n\t * Atomically grab the task, if ->wake_q is !nil already it means\n\t * its already queued (either by us or someone else) and will get the\n\t * wakeup due to that.\n\t *\n\t * This cmpxchg() executes a full barrier, which pairs with the full\n\t * barrier executed by the wakeup in wake_up_q().\n\t */\n\tif (cmpxchg(&node->next, NULL, WAKE_Q_TAIL))\n\t\treturn;\n\n\tget_task_struct(task);\n\n\t/*\n\t * The head is context local, there can be no concurrency.\n\t */\n\t*head->lastp = node;\n\thead->lastp = &node->next;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include <trace/events/sched.h>",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/kcov.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include <trace/events/sched.h>\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/kcov.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n\nstatic __always_inline struct;\n\nvoid wake_q_add(struct wake_q_head *head, struct task_struct *task)\n{\n\tstruct wake_q_node *node = &task->wake_q;\n\n\t/*\n\t * Atomically grab the task, if ->wake_q is !nil already it means\n\t * its already queued (either by us or someone else) and will get the\n\t * wakeup due to that.\n\t *\n\t * This cmpxchg() executes a full barrier, which pairs with the full\n\t * barrier executed by the wakeup in wake_up_q().\n\t */\n\tif (cmpxchg(&node->next, NULL, WAKE_Q_TAIL))\n\t\treturn;\n\n\tget_task_struct(task);\n\n\t/*\n\t * The head is context local, there can be no concurrency.\n\t */\n\t*head->lastp = node;\n\thead->lastp = &node->next;\n}"
        }
      },
      {
        "call_info": {
          "callee": "debug_mutex_wake_waiter",
          "args": [
            "lock",
            "waiter"
          ],
          "line": 1240
        },
        "resolved": true,
        "details": {
          "function_name": "debug_mutex_wake_waiter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex-debug.c",
          "lines": "37-43",
          "snippet": "void debug_mutex_wake_waiter(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\tSMP_DEBUG_LOCKS_WARN_ON(!spin_is_locked(&lock->wait_lock));\n\tDEBUG_LOCKS_WARN_ON(list_empty(&lock->wait_list));\n\tDEBUG_LOCKS_WARN_ON(waiter->magic != waiter);\n\tDEBUG_LOCKS_WARN_ON(list_empty(&waiter->list));\n}",
          "includes": [
            "#include \"mutex-debug.h\"",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/poison.h>",
            "#include <linux/export.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"mutex-debug.h\"\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/sched.h>\n#include <linux/poison.h>\n#include <linux/export.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n\nvoid debug_mutex_wake_waiter(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\tSMP_DEBUG_LOCKS_WARN_ON(!spin_is_locked(&lock->wait_lock));\n\tDEBUG_LOCKS_WARN_ON(list_empty(&lock->wait_list));\n\tDEBUG_LOCKS_WARN_ON(waiter->magic != waiter);\n\tDEBUG_LOCKS_WARN_ON(list_empty(&waiter->list));\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_first_entry",
          "args": [
            "&lock->wait_list",
            "structmutex_waiter",
            "list"
          ],
          "line": 1235
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "&lock->wait_list"
          ],
          "line": 1232
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "50-53",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !rsclp->head;\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !rsclp->head;\n}"
        }
      },
      {
        "call_info": {
          "callee": "debug_mutex_unlock",
          "args": [
            "lock"
          ],
          "line": 1231
        },
        "resolved": true,
        "details": {
          "function_name": "debug_mutex_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex-debug.c",
          "lines": "72-78",
          "snippet": "void debug_mutex_unlock(struct mutex *lock)\n{\n\tif (likely(debug_locks)) {\n\t\tDEBUG_LOCKS_WARN_ON(lock->magic != lock);\n\t\tDEBUG_LOCKS_WARN_ON(!lock->wait_list.prev && !lock->wait_list.next);\n\t}\n}",
          "includes": [
            "#include \"mutex-debug.h\"",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/poison.h>",
            "#include <linux/export.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"mutex-debug.h\"\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/sched.h>\n#include <linux/poison.h>\n#include <linux/export.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n\nvoid debug_mutex_unlock(struct mutex *lock)\n{\n\tif (likely(debug_locks)) {\n\t\tDEBUG_LOCKS_WARN_ON(lock->magic != lock);\n\t\tDEBUG_LOCKS_WARN_ON(!lock->wait_list.prev && !lock->wait_list.next);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "spin_lock",
          "args": [
            "&lock->wait_lock"
          ],
          "line": 1230
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "166-169",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_cmpxchg_release",
          "args": [
            "&lock->owner",
            "owner",
            "__owner_flags(owner)"
          ],
          "line": 1218
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__owner_flags",
          "args": [
            "owner"
          ],
          "line": 1219
        },
        "resolved": true,
        "details": {
          "function_name": "__owner_flags",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "72-75",
          "snippet": "static inline unsigned long __owner_flags(unsigned long owner)\n{\n\treturn owner & MUTEX_FLAGS;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAGS\t\t0x07"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n\nstatic inline unsigned long __owner_flags(unsigned long owner)\n{\n\treturn owner & MUTEX_FLAGS;\n}"
        }
      },
      {
        "call_info": {
          "callee": "DEBUG_LOCKS_WARN_ON",
          "args": [
            "owner & MUTEX_FLAG_PICKUP"
          ],
          "line": 1212
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DEBUG_LOCKS_WARN_ON",
          "args": [
            "__owner_task(owner) != current"
          ],
          "line": 1211
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__owner_task",
          "args": [
            "owner"
          ],
          "line": 1211
        },
        "resolved": true,
        "details": {
          "function_name": "__owner_task",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "67-70",
          "snippet": "static inline struct task_struct *__owner_task(unsigned long owner)\n{\n\treturn (struct task_struct *)(owner & ~MUTEX_FLAGS);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAGS\t\t0x07"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n\nstatic inline struct task_struct *__owner_task(unsigned long owner)\n{\n\treturn (struct task_struct *)(owner & ~MUTEX_FLAGS);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&lock->owner"
          ],
          "line": 1206
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_release",
          "args": [
            "&lock->dep_map",
            "1",
            "ip"
          ],
          "line": 1197
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DEFINE_WAKE_Q",
          "args": [
            "wake_q"
          ],
          "line": 1194
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAG_PICKUP\t0x04\n#define MUTEX_FLAG_HANDOFF\t0x02\n#define MUTEX_FLAG_WAITERS\t0x01\n\n__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);\n\n__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip)\n{\n\tstruct task_struct *next = NULL;\n\tDEFINE_WAKE_Q(wake_q);\n\tunsigned long owner;\n\n\tmutex_release(&lock->dep_map, 1, ip);\n\n\t/*\n\t * Release the lock before (potentially) taking the spinlock such that\n\t * other contenders can get on with things ASAP.\n\t *\n\t * Except when HANDOFF, in that case we must not clear the owner field,\n\t * but instead set it to the top waiter.\n\t */\n\towner = atomic_long_read(&lock->owner);\n\tfor (;;) {\n\t\tunsigned long old;\n\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\tDEBUG_LOCKS_WARN_ON(__owner_task(owner) != current);\n\t\tDEBUG_LOCKS_WARN_ON(owner & MUTEX_FLAG_PICKUP);\n#endif\n\n\t\tif (owner & MUTEX_FLAG_HANDOFF)\n\t\t\tbreak;\n\n\t\told = atomic_long_cmpxchg_release(&lock->owner, owner,\n\t\t\t\t\t\t  __owner_flags(owner));\n\t\tif (old == owner) {\n\t\t\tif (owner & MUTEX_FLAG_WAITERS)\n\t\t\t\tbreak;\n\n\t\t\treturn;\n\t\t}\n\n\t\towner = old;\n\t}\n\n\tspin_lock(&lock->wait_lock);\n\tdebug_mutex_unlock(lock);\n\tif (!list_empty(&lock->wait_list)) {\n\t\t/* get the first entry from the wait-list: */\n\t\tstruct mutex_waiter *waiter =\n\t\t\tlist_first_entry(&lock->wait_list,\n\t\t\t\t\t struct mutex_waiter, list);\n\n\t\tnext = waiter->task;\n\n\t\tdebug_mutex_wake_waiter(lock, waiter);\n\t\twake_q_add(&wake_q, next);\n\t}\n\n\tif (owner & MUTEX_FLAG_HANDOFF)\n\t\t__mutex_handoff(lock, next);\n\n\tspin_unlock(&lock->wait_lock);\n\n\twake_up_q(&wake_q);\n}"
  },
  {
    "function_name": "ww_mutex_lock_interruptible",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "1169-1183",
    "snippet": "int __sched\nww_mutex_lock_interruptible(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tint ret;\n\n\tmight_sleep();\n\tret = __ww_mutex_lock(&lock->base, TASK_INTERRUPTIBLE,\n\t\t\t      0, ctx ? &ctx->dep_map : NULL, _RET_IP_,\n\t\t\t      ctx);\n\n\tif (!ret && ctx && ctx->acquired > 1)\n\t\treturn ww_mutex_deadlock_injection(lock, ctx);\n\n\treturn ret;\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "ww_mutex_deadlock_injection",
          "args": [
            "lock",
            "ctx"
          ],
          "line": 1180
        },
        "resolved": true,
        "details": {
          "function_name": "ww_mutex_deadlock_injection",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "1127-1151",
          "snippet": "static inline int\nww_mutex_deadlock_injection(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n#ifdef CONFIG_DEBUG_WW_MUTEX_SLOWPATH\n\tunsigned tmp;\n\n\tif (ctx->deadlock_inject_countdown-- == 0) {\n\t\ttmp = ctx->deadlock_inject_interval;\n\t\tif (tmp > UINT_MAX/4)\n\t\t\ttmp = UINT_MAX;\n\t\telse\n\t\t\ttmp = tmp*2 + tmp + tmp/2;\n\n\t\tctx->deadlock_inject_interval = tmp;\n\t\tctx->deadlock_inject_countdown = tmp;\n\t\tctx->contending_lock = lock;\n\n\t\tww_mutex_unlock(lock);\n\n\t\treturn -EDEADLK;\n\t}\n#endif\n\n\treturn 0;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline int\nww_mutex_deadlock_injection(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n#ifdef CONFIG_DEBUG_WW_MUTEX_SLOWPATH\n\tunsigned tmp;\n\n\tif (ctx->deadlock_inject_countdown-- == 0) {\n\t\ttmp = ctx->deadlock_inject_interval;\n\t\tif (tmp > UINT_MAX/4)\n\t\t\ttmp = UINT_MAX;\n\t\telse\n\t\t\ttmp = tmp*2 + tmp + tmp/2;\n\n\t\tctx->deadlock_inject_interval = tmp;\n\t\tctx->deadlock_inject_countdown = tmp;\n\t\tctx->contending_lock = lock;\n\n\t\tww_mutex_unlock(lock);\n\n\t\treturn -EDEADLK;\n\t}\n#endif\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__ww_mutex_lock",
          "args": [
            "&lock->base",
            "TASK_INTERRUPTIBLE",
            "0",
            "ctx ? &ctx->dep_map : NULL",
            "_RET_IP_",
            "ctx"
          ],
          "line": 1175
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_lock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "1075-1081",
          "snippet": "static int __sched\n__ww_mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t\tstruct lockdep_map *nest_lock, unsigned long ip,\n\t\tstruct ww_acquire_ctx *ww_ctx)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, ww_ctx, true);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);\n\nstatic int __sched\n__ww_mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t\tstruct lockdep_map *nest_lock, unsigned long ip,\n\t\tstruct ww_acquire_ctx *ww_ctx)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, ww_ctx, true);\n}"
        }
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 1174
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nint __sched\nww_mutex_lock_interruptible(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tint ret;\n\n\tmight_sleep();\n\tret = __ww_mutex_lock(&lock->base, TASK_INTERRUPTIBLE,\n\t\t\t      0, ctx ? &ctx->dep_map : NULL, _RET_IP_,\n\t\t\t      ctx);\n\n\tif (!ret && ctx && ctx->acquired > 1)\n\t\treturn ww_mutex_deadlock_injection(lock, ctx);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "ww_mutex_lock",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "1153-1166",
    "snippet": "int __sched\nww_mutex_lock(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tint ret;\n\n\tmight_sleep();\n\tret =  __ww_mutex_lock(&lock->base, TASK_UNINTERRUPTIBLE,\n\t\t\t       0, ctx ? &ctx->dep_map : NULL, _RET_IP_,\n\t\t\t       ctx);\n\tif (!ret && ctx && ctx->acquired > 1)\n\t\treturn ww_mutex_deadlock_injection(lock, ctx);\n\n\treturn ret;\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "ww_mutex_deadlock_injection",
          "args": [
            "lock",
            "ctx"
          ],
          "line": 1163
        },
        "resolved": true,
        "details": {
          "function_name": "ww_mutex_deadlock_injection",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "1127-1151",
          "snippet": "static inline int\nww_mutex_deadlock_injection(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n#ifdef CONFIG_DEBUG_WW_MUTEX_SLOWPATH\n\tunsigned tmp;\n\n\tif (ctx->deadlock_inject_countdown-- == 0) {\n\t\ttmp = ctx->deadlock_inject_interval;\n\t\tif (tmp > UINT_MAX/4)\n\t\t\ttmp = UINT_MAX;\n\t\telse\n\t\t\ttmp = tmp*2 + tmp + tmp/2;\n\n\t\tctx->deadlock_inject_interval = tmp;\n\t\tctx->deadlock_inject_countdown = tmp;\n\t\tctx->contending_lock = lock;\n\n\t\tww_mutex_unlock(lock);\n\n\t\treturn -EDEADLK;\n\t}\n#endif\n\n\treturn 0;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline int\nww_mutex_deadlock_injection(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n#ifdef CONFIG_DEBUG_WW_MUTEX_SLOWPATH\n\tunsigned tmp;\n\n\tif (ctx->deadlock_inject_countdown-- == 0) {\n\t\ttmp = ctx->deadlock_inject_interval;\n\t\tif (tmp > UINT_MAX/4)\n\t\t\ttmp = UINT_MAX;\n\t\telse\n\t\t\ttmp = tmp*2 + tmp + tmp/2;\n\n\t\tctx->deadlock_inject_interval = tmp;\n\t\tctx->deadlock_inject_countdown = tmp;\n\t\tctx->contending_lock = lock;\n\n\t\tww_mutex_unlock(lock);\n\n\t\treturn -EDEADLK;\n\t}\n#endif\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__ww_mutex_lock",
          "args": [
            "&lock->base",
            "TASK_UNINTERRUPTIBLE",
            "0",
            "ctx ? &ctx->dep_map : NULL",
            "_RET_IP_",
            "ctx"
          ],
          "line": 1159
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_lock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "1075-1081",
          "snippet": "static int __sched\n__ww_mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t\tstruct lockdep_map *nest_lock, unsigned long ip,\n\t\tstruct ww_acquire_ctx *ww_ctx)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, ww_ctx, true);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);\n\nstatic int __sched\n__ww_mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t\tstruct lockdep_map *nest_lock, unsigned long ip,\n\t\tstruct ww_acquire_ctx *ww_ctx)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, ww_ctx, true);\n}"
        }
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 1158
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nint __sched\nww_mutex_lock(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tint ret;\n\n\tmight_sleep();\n\tret =  __ww_mutex_lock(&lock->base, TASK_UNINTERRUPTIBLE,\n\t\t\t       0, ctx ? &ctx->dep_map : NULL, _RET_IP_,\n\t\t\t       ctx);\n\tif (!ret && ctx && ctx->acquired > 1)\n\t\treturn ww_mutex_deadlock_injection(lock, ctx);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "ww_mutex_deadlock_injection",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "1127-1151",
    "snippet": "static inline int\nww_mutex_deadlock_injection(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n#ifdef CONFIG_DEBUG_WW_MUTEX_SLOWPATH\n\tunsigned tmp;\n\n\tif (ctx->deadlock_inject_countdown-- == 0) {\n\t\ttmp = ctx->deadlock_inject_interval;\n\t\tif (tmp > UINT_MAX/4)\n\t\t\ttmp = UINT_MAX;\n\t\telse\n\t\t\ttmp = tmp*2 + tmp + tmp/2;\n\n\t\tctx->deadlock_inject_interval = tmp;\n\t\tctx->deadlock_inject_countdown = tmp;\n\t\tctx->contending_lock = lock;\n\n\t\tww_mutex_unlock(lock);\n\n\t\treturn -EDEADLK;\n\t}\n#endif\n\n\treturn 0;\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "ww_mutex_unlock",
          "args": [
            "lock"
          ],
          "line": 1144
        },
        "resolved": true,
        "details": {
          "function_name": "ww_mutex_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "728-744",
          "snippet": "void __sched ww_mutex_unlock(struct ww_mutex *lock)\n{\n\t/*\n\t * The unlocking fastpath is the 0->1 transition from 'locked'\n\t * into 'unlocked' state:\n\t */\n\tif (lock->ctx) {\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\tDEBUG_LOCKS_WARN_ON(!lock->ctx->acquired);\n#endif\n\t\tif (lock->ctx->acquired > 0)\n\t\t\tlock->ctx->acquired--;\n\t\tlock->ctx = NULL;\n\t}\n\n\tmutex_unlock(&lock->base);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nvoid __sched ww_mutex_unlock(struct ww_mutex *lock)\n{\n\t/*\n\t * The unlocking fastpath is the 0->1 transition from 'locked'\n\t * into 'unlocked' state:\n\t */\n\tif (lock->ctx) {\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\tDEBUG_LOCKS_WARN_ON(!lock->ctx->acquired);\n#endif\n\t\tif (lock->ctx->acquired > 0)\n\t\t\tlock->ctx->acquired--;\n\t\tlock->ctx = NULL;\n\t}\n\n\tmutex_unlock(&lock->base);\n}"
        }
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline int\nww_mutex_deadlock_injection(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n#ifdef CONFIG_DEBUG_WW_MUTEX_SLOWPATH\n\tunsigned tmp;\n\n\tif (ctx->deadlock_inject_countdown-- == 0) {\n\t\ttmp = ctx->deadlock_inject_interval;\n\t\tif (tmp > UINT_MAX/4)\n\t\t\ttmp = UINT_MAX;\n\t\telse\n\t\t\ttmp = tmp*2 + tmp + tmp/2;\n\n\t\tctx->deadlock_inject_interval = tmp;\n\t\tctx->deadlock_inject_countdown = tmp;\n\t\tctx->contending_lock = lock;\n\n\t\tww_mutex_unlock(lock);\n\n\t\treturn -EDEADLK;\n\t}\n#endif\n\n\treturn 0;\n}"
  },
  {
    "function_name": "mutex_lock_io_nested",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "1113-1124",
    "snippet": "void __sched\nmutex_lock_io_nested(struct mutex *lock, unsigned int subclass)\n{\n\tint token;\n\n\tmight_sleep();\n\n\ttoken = io_schedule_prepare();\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE,\n\t\t\t    subclass, NULL, _RET_IP_, NULL, 0);\n\tio_schedule_finish(token);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "io_schedule_finish",
          "args": [
            "token"
          ],
          "line": 1123
        },
        "resolved": true,
        "details": {
          "function_name": "io_schedule_finish",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/core.c",
          "lines": "5110-5113",
          "snippet": "void io_schedule_finish(int token)\n{\n\tcurrent->in_iowait = token;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include <trace/events/sched.h>",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/kcov.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include <trace/events/sched.h>\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/kcov.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n\nvoid io_schedule_finish(int token)\n{\n\tcurrent->in_iowait = token;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_lock_common",
          "args": [
            "lock",
            "TASK_UNINTERRUPTIBLE",
            "subclass",
            "NULL",
            "_RET_IP_",
            "NULL",
            "0"
          ],
          "line": 1121
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock_common",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "898-1066",
          "snippet": "__sched\n__mutex_lock_common(struct mutex *lock, long state, unsigned int subclass,\n\t\t    struct lockdep_map *nest_lock, unsigned long ip,\n\t\t    struct ww_acquire_ctx *ww_ctx, const bool use_ww_ctx)\n{\n\tstruct mutex_waiter waiter;\n\tbool first = false;\n\tstruct ww_mutex *ww;\n\tint ret;\n\n\tmight_sleep();\n\n\tww = container_of(lock, struct ww_mutex, base);\n\tif (use_ww_ctx && ww_ctx) {\n\t\tif (unlikely(ww_ctx == READ_ONCE(ww->ctx)))\n\t\t\treturn -EALREADY;\n\n\t\t/*\n\t\t * Reset the wounded flag after a kill. No other process can\n\t\t * race and wound us here since they can't have a valid owner\n\t\t * pointer if we don't have any locks held.\n\t\t */\n\t\tif (ww_ctx->acquired == 0)\n\t\t\tww_ctx->wounded = 0;\n\t}\n\n\tpreempt_disable();\n\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);\n\n\tif (__mutex_trylock(lock) ||\n\t    mutex_optimistic_spin(lock, ww_ctx, use_ww_ctx, NULL)) {\n\t\t/* got the lock, yay! */\n\t\tlock_acquired(&lock->dep_map, ip);\n\t\tif (use_ww_ctx && ww_ctx)\n\t\t\tww_mutex_set_context_fastpath(ww, ww_ctx);\n\t\tpreempt_enable();\n\t\treturn 0;\n\t}\n\n\tspin_lock(&lock->wait_lock);\n\t/*\n\t * After waiting to acquire the wait_lock, try again.\n\t */\n\tif (__mutex_trylock(lock)) {\n\t\tif (use_ww_ctx && ww_ctx)\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\n\t\tgoto skip_wait;\n\t}\n\n\tdebug_mutex_lock_common(lock, &waiter);\n\n\tlock_contended(&lock->dep_map, ip);\n\n\tif (!use_ww_ctx) {\n\t\t/* add waiting tasks to the end of the waitqueue (FIFO): */\n\t\t__mutex_add_waiter(lock, &waiter, &lock->wait_list);\n\n\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\twaiter.ww_ctx = MUTEX_POISON_WW_CTX;\n#endif\n\t} else {\n\t\t/*\n\t\t * Add in stamp order, waking up waiters that must kill\n\t\t * themselves.\n\t\t */\n\t\tret = __ww_mutex_add_waiter(&waiter, lock, ww_ctx);\n\t\tif (ret)\n\t\t\tgoto err_early_kill;\n\n\t\twaiter.ww_ctx = ww_ctx;\n\t}\n\n\twaiter.task = current;\n\n\tset_current_state(state);\n\tfor (;;) {\n\t\t/*\n\t\t * Once we hold wait_lock, we're serialized against\n\t\t * mutex_unlock() handing the lock off to us, do a trylock\n\t\t * before testing the error conditions to make sure we pick up\n\t\t * the handoff.\n\t\t */\n\t\tif (__mutex_trylock(lock))\n\t\t\tgoto acquired;\n\n\t\t/*\n\t\t * Check for signals and kill conditions while holding\n\t\t * wait_lock. This ensures the lock cancellation is ordered\n\t\t * against mutex_unlock() and wake-ups do not go missing.\n\t\t */\n\t\tif (unlikely(signal_pending_state(state, current))) {\n\t\t\tret = -EINTR;\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (use_ww_ctx && ww_ctx) {\n\t\t\tret = __ww_mutex_check_kill(lock, &waiter, ww_ctx);\n\t\t\tif (ret)\n\t\t\t\tgoto err;\n\t\t}\n\n\t\tspin_unlock(&lock->wait_lock);\n\t\tschedule_preempt_disabled();\n\n\t\t/*\n\t\t * ww_mutex needs to always recheck its position since its waiter\n\t\t * list is not FIFO ordered.\n\t\t */\n\t\tif ((use_ww_ctx && ww_ctx) || !first) {\n\t\t\tfirst = __mutex_waiter_is_first(lock, &waiter);\n\t\t\tif (first)\n\t\t\t\t__mutex_set_flag(lock, MUTEX_FLAG_HANDOFF);\n\t\t}\n\n\t\tset_current_state(state);\n\t\t/*\n\t\t * Here we order against unlock; we must either see it change\n\t\t * state back to RUNNING and fall through the next schedule(),\n\t\t * or we must see its unlock and acquire.\n\t\t */\n\t\tif (__mutex_trylock(lock) ||\n\t\t    (first && mutex_optimistic_spin(lock, ww_ctx, use_ww_ctx, &waiter)))\n\t\t\tbreak;\n\n\t\tspin_lock(&lock->wait_lock);\n\t}\n\tspin_lock(&lock->wait_lock);\nacquired:\n\t__set_current_state(TASK_RUNNING);\n\n\tif (use_ww_ctx && ww_ctx) {\n\t\t/*\n\t\t * Wound-Wait; we stole the lock (!first_waiter), check the\n\t\t * waiters as anyone might want to wound us.\n\t\t */\n\t\tif (!ww_ctx->is_wait_die &&\n\t\t    !__mutex_waiter_is_first(lock, &waiter))\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\t}\n\n\tmutex_remove_waiter(lock, &waiter, current);\n\tif (likely(list_empty(&lock->wait_list)))\n\t\t__mutex_clear_flag(lock, MUTEX_FLAGS);\n\n\tdebug_mutex_free_waiter(&waiter);\n\nskip_wait:\n\t/* got the lock - cleanup and rejoice! */\n\tlock_acquired(&lock->dep_map, ip);\n\n\tif (use_ww_ctx && ww_ctx)\n\t\tww_mutex_lock_acquired(ww, ww_ctx);\n\n\tspin_unlock(&lock->wait_lock);\n\tpreempt_enable();\n\treturn 0;\n\nerr:\n\t__set_current_state(TASK_RUNNING);\n\tmutex_remove_waiter(lock, &waiter, current);\nerr_early_kill:\n\tspin_unlock(&lock->wait_lock);\n\tdebug_mutex_free_waiter(&waiter);\n\tmutex_release(&lock->dep_map, 1, ip);\n\tpreempt_enable();\n\treturn ret;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAGS\t\t0x07",
            "#define MUTEX_FLAG_HANDOFF\t0x02"
          ],
          "globals_used": [
            "__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n#define MUTEX_FLAG_HANDOFF\t0x02\n\n__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);\n\n__sched\n__mutex_lock_common(struct mutex *lock, long state, unsigned int subclass,\n\t\t    struct lockdep_map *nest_lock, unsigned long ip,\n\t\t    struct ww_acquire_ctx *ww_ctx, const bool use_ww_ctx)\n{\n\tstruct mutex_waiter waiter;\n\tbool first = false;\n\tstruct ww_mutex *ww;\n\tint ret;\n\n\tmight_sleep();\n\n\tww = container_of(lock, struct ww_mutex, base);\n\tif (use_ww_ctx && ww_ctx) {\n\t\tif (unlikely(ww_ctx == READ_ONCE(ww->ctx)))\n\t\t\treturn -EALREADY;\n\n\t\t/*\n\t\t * Reset the wounded flag after a kill. No other process can\n\t\t * race and wound us here since they can't have a valid owner\n\t\t * pointer if we don't have any locks held.\n\t\t */\n\t\tif (ww_ctx->acquired == 0)\n\t\t\tww_ctx->wounded = 0;\n\t}\n\n\tpreempt_disable();\n\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);\n\n\tif (__mutex_trylock(lock) ||\n\t    mutex_optimistic_spin(lock, ww_ctx, use_ww_ctx, NULL)) {\n\t\t/* got the lock, yay! */\n\t\tlock_acquired(&lock->dep_map, ip);\n\t\tif (use_ww_ctx && ww_ctx)\n\t\t\tww_mutex_set_context_fastpath(ww, ww_ctx);\n\t\tpreempt_enable();\n\t\treturn 0;\n\t}\n\n\tspin_lock(&lock->wait_lock);\n\t/*\n\t * After waiting to acquire the wait_lock, try again.\n\t */\n\tif (__mutex_trylock(lock)) {\n\t\tif (use_ww_ctx && ww_ctx)\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\n\t\tgoto skip_wait;\n\t}\n\n\tdebug_mutex_lock_common(lock, &waiter);\n\n\tlock_contended(&lock->dep_map, ip);\n\n\tif (!use_ww_ctx) {\n\t\t/* add waiting tasks to the end of the waitqueue (FIFO): */\n\t\t__mutex_add_waiter(lock, &waiter, &lock->wait_list);\n\n\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\twaiter.ww_ctx = MUTEX_POISON_WW_CTX;\n#endif\n\t} else {\n\t\t/*\n\t\t * Add in stamp order, waking up waiters that must kill\n\t\t * themselves.\n\t\t */\n\t\tret = __ww_mutex_add_waiter(&waiter, lock, ww_ctx);\n\t\tif (ret)\n\t\t\tgoto err_early_kill;\n\n\t\twaiter.ww_ctx = ww_ctx;\n\t}\n\n\twaiter.task = current;\n\n\tset_current_state(state);\n\tfor (;;) {\n\t\t/*\n\t\t * Once we hold wait_lock, we're serialized against\n\t\t * mutex_unlock() handing the lock off to us, do a trylock\n\t\t * before testing the error conditions to make sure we pick up\n\t\t * the handoff.\n\t\t */\n\t\tif (__mutex_trylock(lock))\n\t\t\tgoto acquired;\n\n\t\t/*\n\t\t * Check for signals and kill conditions while holding\n\t\t * wait_lock. This ensures the lock cancellation is ordered\n\t\t * against mutex_unlock() and wake-ups do not go missing.\n\t\t */\n\t\tif (unlikely(signal_pending_state(state, current))) {\n\t\t\tret = -EINTR;\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (use_ww_ctx && ww_ctx) {\n\t\t\tret = __ww_mutex_check_kill(lock, &waiter, ww_ctx);\n\t\t\tif (ret)\n\t\t\t\tgoto err;\n\t\t}\n\n\t\tspin_unlock(&lock->wait_lock);\n\t\tschedule_preempt_disabled();\n\n\t\t/*\n\t\t * ww_mutex needs to always recheck its position since its waiter\n\t\t * list is not FIFO ordered.\n\t\t */\n\t\tif ((use_ww_ctx && ww_ctx) || !first) {\n\t\t\tfirst = __mutex_waiter_is_first(lock, &waiter);\n\t\t\tif (first)\n\t\t\t\t__mutex_set_flag(lock, MUTEX_FLAG_HANDOFF);\n\t\t}\n\n\t\tset_current_state(state);\n\t\t/*\n\t\t * Here we order against unlock; we must either see it change\n\t\t * state back to RUNNING and fall through the next schedule(),\n\t\t * or we must see its unlock and acquire.\n\t\t */\n\t\tif (__mutex_trylock(lock) ||\n\t\t    (first && mutex_optimistic_spin(lock, ww_ctx, use_ww_ctx, &waiter)))\n\t\t\tbreak;\n\n\t\tspin_lock(&lock->wait_lock);\n\t}\n\tspin_lock(&lock->wait_lock);\nacquired:\n\t__set_current_state(TASK_RUNNING);\n\n\tif (use_ww_ctx && ww_ctx) {\n\t\t/*\n\t\t * Wound-Wait; we stole the lock (!first_waiter), check the\n\t\t * waiters as anyone might want to wound us.\n\t\t */\n\t\tif (!ww_ctx->is_wait_die &&\n\t\t    !__mutex_waiter_is_first(lock, &waiter))\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\t}\n\n\tmutex_remove_waiter(lock, &waiter, current);\n\tif (likely(list_empty(&lock->wait_list)))\n\t\t__mutex_clear_flag(lock, MUTEX_FLAGS);\n\n\tdebug_mutex_free_waiter(&waiter);\n\nskip_wait:\n\t/* got the lock - cleanup and rejoice! */\n\tlock_acquired(&lock->dep_map, ip);\n\n\tif (use_ww_ctx && ww_ctx)\n\t\tww_mutex_lock_acquired(ww, ww_ctx);\n\n\tspin_unlock(&lock->wait_lock);\n\tpreempt_enable();\n\treturn 0;\n\nerr:\n\t__set_current_state(TASK_RUNNING);\n\tmutex_remove_waiter(lock, &waiter, current);\nerr_early_kill:\n\tspin_unlock(&lock->wait_lock);\n\tdebug_mutex_free_waiter(&waiter);\n\tmutex_release(&lock->dep_map, 1, ip);\n\tpreempt_enable();\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "io_schedule_prepare",
          "args": [],
          "line": 1120
        },
        "resolved": true,
        "details": {
          "function_name": "io_schedule_prepare",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/core.c",
          "lines": "5100-5108",
          "snippet": "int io_schedule_prepare(void)\n{\n\tint old_iowait = current->in_iowait;\n\n\tcurrent->in_iowait = 1;\n\tblk_schedule_flush_plug(current);\n\n\treturn old_iowait;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include <trace/events/sched.h>",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/kcov.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include <trace/events/sched.h>\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/kcov.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n\nint io_schedule_prepare(void)\n{\n\tint old_iowait = current->in_iowait;\n\n\tcurrent->in_iowait = 1;\n\tblk_schedule_flush_plug(current);\n\n\treturn old_iowait;\n}"
        }
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 1118
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nvoid __sched\nmutex_lock_io_nested(struct mutex *lock, unsigned int subclass)\n{\n\tint token;\n\n\tmight_sleep();\n\n\ttoken = io_schedule_prepare();\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE,\n\t\t\t    subclass, NULL, _RET_IP_, NULL, 0);\n\tio_schedule_finish(token);\n}"
  },
  {
    "function_name": "mutex_lock_interruptible_nested",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "1106-1110",
    "snippet": "int __sched\nmutex_lock_interruptible_nested(struct mutex *lock, unsigned int subclass)\n{\n\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, subclass, NULL, _RET_IP_);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_lock",
          "args": [
            "lock",
            "TASK_INTERRUPTIBLE",
            "subclass",
            "NULL",
            "_RET_IP_"
          ],
          "line": 1109
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "1068-1073",
          "snippet": "static int __sched\n__mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);\n\nstatic int __sched\n__mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}"
        }
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nint __sched\nmutex_lock_interruptible_nested(struct mutex *lock, unsigned int subclass)\n{\n\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, subclass, NULL, _RET_IP_);\n}"
  },
  {
    "function_name": "mutex_lock_killable_nested",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "1099-1103",
    "snippet": "int __sched\nmutex_lock_killable_nested(struct mutex *lock, unsigned int subclass)\n{\n\treturn __mutex_lock(lock, TASK_KILLABLE, subclass, NULL, _RET_IP_);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_lock",
          "args": [
            "lock",
            "TASK_KILLABLE",
            "subclass",
            "NULL",
            "_RET_IP_"
          ],
          "line": 1102
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "1068-1073",
          "snippet": "static int __sched\n__mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);\n\nstatic int __sched\n__mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}"
        }
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nint __sched\nmutex_lock_killable_nested(struct mutex *lock, unsigned int subclass)\n{\n\treturn __mutex_lock(lock, TASK_KILLABLE, subclass, NULL, _RET_IP_);\n}"
  },
  {
    "function_name": "_mutex_lock_nest_lock",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "1092-1096",
    "snippet": "void __sched\n_mutex_lock_nest_lock(struct mutex *lock, struct lockdep_map *nest)\n{\n\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, 0, nest, _RET_IP_);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_lock",
          "args": [
            "lock",
            "TASK_UNINTERRUPTIBLE",
            "0",
            "nest",
            "_RET_IP_"
          ],
          "line": 1095
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "1068-1073",
          "snippet": "static int __sched\n__mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);\n\nstatic int __sched\n__mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}"
        }
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nvoid __sched\n_mutex_lock_nest_lock(struct mutex *lock, struct lockdep_map *nest)\n{\n\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, 0, nest, _RET_IP_);\n}"
  },
  {
    "function_name": "mutex_lock_nested",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "1084-1088",
    "snippet": "void __sched\nmutex_lock_nested(struct mutex *lock, unsigned int subclass)\n{\n\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, subclass, NULL, _RET_IP_);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_lock",
          "args": [
            "lock",
            "TASK_UNINTERRUPTIBLE",
            "subclass",
            "NULL",
            "_RET_IP_"
          ],
          "line": 1087
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "1068-1073",
          "snippet": "static int __sched\n__mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);\n\nstatic int __sched\n__mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}"
        }
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nvoid __sched\nmutex_lock_nested(struct mutex *lock, unsigned int subclass)\n{\n\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, subclass, NULL, _RET_IP_);\n}"
  },
  {
    "function_name": "__ww_mutex_lock",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "1075-1081",
    "snippet": "static int __sched\n__ww_mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t\tstruct lockdep_map *nest_lock, unsigned long ip,\n\t\tstruct ww_acquire_ctx *ww_ctx)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, ww_ctx, true);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_lock_common",
          "args": [
            "lock",
            "state",
            "subclass",
            "nest_lock",
            "ip",
            "ww_ctx",
            "true"
          ],
          "line": 1080
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock_common",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "898-1066",
          "snippet": "__sched\n__mutex_lock_common(struct mutex *lock, long state, unsigned int subclass,\n\t\t    struct lockdep_map *nest_lock, unsigned long ip,\n\t\t    struct ww_acquire_ctx *ww_ctx, const bool use_ww_ctx)\n{\n\tstruct mutex_waiter waiter;\n\tbool first = false;\n\tstruct ww_mutex *ww;\n\tint ret;\n\n\tmight_sleep();\n\n\tww = container_of(lock, struct ww_mutex, base);\n\tif (use_ww_ctx && ww_ctx) {\n\t\tif (unlikely(ww_ctx == READ_ONCE(ww->ctx)))\n\t\t\treturn -EALREADY;\n\n\t\t/*\n\t\t * Reset the wounded flag after a kill. No other process can\n\t\t * race and wound us here since they can't have a valid owner\n\t\t * pointer if we don't have any locks held.\n\t\t */\n\t\tif (ww_ctx->acquired == 0)\n\t\t\tww_ctx->wounded = 0;\n\t}\n\n\tpreempt_disable();\n\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);\n\n\tif (__mutex_trylock(lock) ||\n\t    mutex_optimistic_spin(lock, ww_ctx, use_ww_ctx, NULL)) {\n\t\t/* got the lock, yay! */\n\t\tlock_acquired(&lock->dep_map, ip);\n\t\tif (use_ww_ctx && ww_ctx)\n\t\t\tww_mutex_set_context_fastpath(ww, ww_ctx);\n\t\tpreempt_enable();\n\t\treturn 0;\n\t}\n\n\tspin_lock(&lock->wait_lock);\n\t/*\n\t * After waiting to acquire the wait_lock, try again.\n\t */\n\tif (__mutex_trylock(lock)) {\n\t\tif (use_ww_ctx && ww_ctx)\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\n\t\tgoto skip_wait;\n\t}\n\n\tdebug_mutex_lock_common(lock, &waiter);\n\n\tlock_contended(&lock->dep_map, ip);\n\n\tif (!use_ww_ctx) {\n\t\t/* add waiting tasks to the end of the waitqueue (FIFO): */\n\t\t__mutex_add_waiter(lock, &waiter, &lock->wait_list);\n\n\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\twaiter.ww_ctx = MUTEX_POISON_WW_CTX;\n#endif\n\t} else {\n\t\t/*\n\t\t * Add in stamp order, waking up waiters that must kill\n\t\t * themselves.\n\t\t */\n\t\tret = __ww_mutex_add_waiter(&waiter, lock, ww_ctx);\n\t\tif (ret)\n\t\t\tgoto err_early_kill;\n\n\t\twaiter.ww_ctx = ww_ctx;\n\t}\n\n\twaiter.task = current;\n\n\tset_current_state(state);\n\tfor (;;) {\n\t\t/*\n\t\t * Once we hold wait_lock, we're serialized against\n\t\t * mutex_unlock() handing the lock off to us, do a trylock\n\t\t * before testing the error conditions to make sure we pick up\n\t\t * the handoff.\n\t\t */\n\t\tif (__mutex_trylock(lock))\n\t\t\tgoto acquired;\n\n\t\t/*\n\t\t * Check for signals and kill conditions while holding\n\t\t * wait_lock. This ensures the lock cancellation is ordered\n\t\t * against mutex_unlock() and wake-ups do not go missing.\n\t\t */\n\t\tif (unlikely(signal_pending_state(state, current))) {\n\t\t\tret = -EINTR;\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (use_ww_ctx && ww_ctx) {\n\t\t\tret = __ww_mutex_check_kill(lock, &waiter, ww_ctx);\n\t\t\tif (ret)\n\t\t\t\tgoto err;\n\t\t}\n\n\t\tspin_unlock(&lock->wait_lock);\n\t\tschedule_preempt_disabled();\n\n\t\t/*\n\t\t * ww_mutex needs to always recheck its position since its waiter\n\t\t * list is not FIFO ordered.\n\t\t */\n\t\tif ((use_ww_ctx && ww_ctx) || !first) {\n\t\t\tfirst = __mutex_waiter_is_first(lock, &waiter);\n\t\t\tif (first)\n\t\t\t\t__mutex_set_flag(lock, MUTEX_FLAG_HANDOFF);\n\t\t}\n\n\t\tset_current_state(state);\n\t\t/*\n\t\t * Here we order against unlock; we must either see it change\n\t\t * state back to RUNNING and fall through the next schedule(),\n\t\t * or we must see its unlock and acquire.\n\t\t */\n\t\tif (__mutex_trylock(lock) ||\n\t\t    (first && mutex_optimistic_spin(lock, ww_ctx, use_ww_ctx, &waiter)))\n\t\t\tbreak;\n\n\t\tspin_lock(&lock->wait_lock);\n\t}\n\tspin_lock(&lock->wait_lock);\nacquired:\n\t__set_current_state(TASK_RUNNING);\n\n\tif (use_ww_ctx && ww_ctx) {\n\t\t/*\n\t\t * Wound-Wait; we stole the lock (!first_waiter), check the\n\t\t * waiters as anyone might want to wound us.\n\t\t */\n\t\tif (!ww_ctx->is_wait_die &&\n\t\t    !__mutex_waiter_is_first(lock, &waiter))\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\t}\n\n\tmutex_remove_waiter(lock, &waiter, current);\n\tif (likely(list_empty(&lock->wait_list)))\n\t\t__mutex_clear_flag(lock, MUTEX_FLAGS);\n\n\tdebug_mutex_free_waiter(&waiter);\n\nskip_wait:\n\t/* got the lock - cleanup and rejoice! */\n\tlock_acquired(&lock->dep_map, ip);\n\n\tif (use_ww_ctx && ww_ctx)\n\t\tww_mutex_lock_acquired(ww, ww_ctx);\n\n\tspin_unlock(&lock->wait_lock);\n\tpreempt_enable();\n\treturn 0;\n\nerr:\n\t__set_current_state(TASK_RUNNING);\n\tmutex_remove_waiter(lock, &waiter, current);\nerr_early_kill:\n\tspin_unlock(&lock->wait_lock);\n\tdebug_mutex_free_waiter(&waiter);\n\tmutex_release(&lock->dep_map, 1, ip);\n\tpreempt_enable();\n\treturn ret;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAGS\t\t0x07",
            "#define MUTEX_FLAG_HANDOFF\t0x02"
          ],
          "globals_used": [
            "__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n#define MUTEX_FLAG_HANDOFF\t0x02\n\n__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);\n\n__sched\n__mutex_lock_common(struct mutex *lock, long state, unsigned int subclass,\n\t\t    struct lockdep_map *nest_lock, unsigned long ip,\n\t\t    struct ww_acquire_ctx *ww_ctx, const bool use_ww_ctx)\n{\n\tstruct mutex_waiter waiter;\n\tbool first = false;\n\tstruct ww_mutex *ww;\n\tint ret;\n\n\tmight_sleep();\n\n\tww = container_of(lock, struct ww_mutex, base);\n\tif (use_ww_ctx && ww_ctx) {\n\t\tif (unlikely(ww_ctx == READ_ONCE(ww->ctx)))\n\t\t\treturn -EALREADY;\n\n\t\t/*\n\t\t * Reset the wounded flag after a kill. No other process can\n\t\t * race and wound us here since they can't have a valid owner\n\t\t * pointer if we don't have any locks held.\n\t\t */\n\t\tif (ww_ctx->acquired == 0)\n\t\t\tww_ctx->wounded = 0;\n\t}\n\n\tpreempt_disable();\n\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);\n\n\tif (__mutex_trylock(lock) ||\n\t    mutex_optimistic_spin(lock, ww_ctx, use_ww_ctx, NULL)) {\n\t\t/* got the lock, yay! */\n\t\tlock_acquired(&lock->dep_map, ip);\n\t\tif (use_ww_ctx && ww_ctx)\n\t\t\tww_mutex_set_context_fastpath(ww, ww_ctx);\n\t\tpreempt_enable();\n\t\treturn 0;\n\t}\n\n\tspin_lock(&lock->wait_lock);\n\t/*\n\t * After waiting to acquire the wait_lock, try again.\n\t */\n\tif (__mutex_trylock(lock)) {\n\t\tif (use_ww_ctx && ww_ctx)\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\n\t\tgoto skip_wait;\n\t}\n\n\tdebug_mutex_lock_common(lock, &waiter);\n\n\tlock_contended(&lock->dep_map, ip);\n\n\tif (!use_ww_ctx) {\n\t\t/* add waiting tasks to the end of the waitqueue (FIFO): */\n\t\t__mutex_add_waiter(lock, &waiter, &lock->wait_list);\n\n\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\twaiter.ww_ctx = MUTEX_POISON_WW_CTX;\n#endif\n\t} else {\n\t\t/*\n\t\t * Add in stamp order, waking up waiters that must kill\n\t\t * themselves.\n\t\t */\n\t\tret = __ww_mutex_add_waiter(&waiter, lock, ww_ctx);\n\t\tif (ret)\n\t\t\tgoto err_early_kill;\n\n\t\twaiter.ww_ctx = ww_ctx;\n\t}\n\n\twaiter.task = current;\n\n\tset_current_state(state);\n\tfor (;;) {\n\t\t/*\n\t\t * Once we hold wait_lock, we're serialized against\n\t\t * mutex_unlock() handing the lock off to us, do a trylock\n\t\t * before testing the error conditions to make sure we pick up\n\t\t * the handoff.\n\t\t */\n\t\tif (__mutex_trylock(lock))\n\t\t\tgoto acquired;\n\n\t\t/*\n\t\t * Check for signals and kill conditions while holding\n\t\t * wait_lock. This ensures the lock cancellation is ordered\n\t\t * against mutex_unlock() and wake-ups do not go missing.\n\t\t */\n\t\tif (unlikely(signal_pending_state(state, current))) {\n\t\t\tret = -EINTR;\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (use_ww_ctx && ww_ctx) {\n\t\t\tret = __ww_mutex_check_kill(lock, &waiter, ww_ctx);\n\t\t\tif (ret)\n\t\t\t\tgoto err;\n\t\t}\n\n\t\tspin_unlock(&lock->wait_lock);\n\t\tschedule_preempt_disabled();\n\n\t\t/*\n\t\t * ww_mutex needs to always recheck its position since its waiter\n\t\t * list is not FIFO ordered.\n\t\t */\n\t\tif ((use_ww_ctx && ww_ctx) || !first) {\n\t\t\tfirst = __mutex_waiter_is_first(lock, &waiter);\n\t\t\tif (first)\n\t\t\t\t__mutex_set_flag(lock, MUTEX_FLAG_HANDOFF);\n\t\t}\n\n\t\tset_current_state(state);\n\t\t/*\n\t\t * Here we order against unlock; we must either see it change\n\t\t * state back to RUNNING and fall through the next schedule(),\n\t\t * or we must see its unlock and acquire.\n\t\t */\n\t\tif (__mutex_trylock(lock) ||\n\t\t    (first && mutex_optimistic_spin(lock, ww_ctx, use_ww_ctx, &waiter)))\n\t\t\tbreak;\n\n\t\tspin_lock(&lock->wait_lock);\n\t}\n\tspin_lock(&lock->wait_lock);\nacquired:\n\t__set_current_state(TASK_RUNNING);\n\n\tif (use_ww_ctx && ww_ctx) {\n\t\t/*\n\t\t * Wound-Wait; we stole the lock (!first_waiter), check the\n\t\t * waiters as anyone might want to wound us.\n\t\t */\n\t\tif (!ww_ctx->is_wait_die &&\n\t\t    !__mutex_waiter_is_first(lock, &waiter))\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\t}\n\n\tmutex_remove_waiter(lock, &waiter, current);\n\tif (likely(list_empty(&lock->wait_list)))\n\t\t__mutex_clear_flag(lock, MUTEX_FLAGS);\n\n\tdebug_mutex_free_waiter(&waiter);\n\nskip_wait:\n\t/* got the lock - cleanup and rejoice! */\n\tlock_acquired(&lock->dep_map, ip);\n\n\tif (use_ww_ctx && ww_ctx)\n\t\tww_mutex_lock_acquired(ww, ww_ctx);\n\n\tspin_unlock(&lock->wait_lock);\n\tpreempt_enable();\n\treturn 0;\n\nerr:\n\t__set_current_state(TASK_RUNNING);\n\tmutex_remove_waiter(lock, &waiter, current);\nerr_early_kill:\n\tspin_unlock(&lock->wait_lock);\n\tdebug_mutex_free_waiter(&waiter);\n\tmutex_release(&lock->dep_map, 1, ip);\n\tpreempt_enable();\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);\n\nstatic int __sched\n__ww_mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t\tstruct lockdep_map *nest_lock, unsigned long ip,\n\t\tstruct ww_acquire_ctx *ww_ctx)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, ww_ctx, true);\n}"
  },
  {
    "function_name": "__mutex_lock",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "1068-1073",
    "snippet": "static int __sched\n__mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_lock_common",
          "args": [
            "lock",
            "state",
            "subclass",
            "nest_lock",
            "ip",
            "NULL",
            "false"
          ],
          "line": 1072
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock_common",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "898-1066",
          "snippet": "__sched\n__mutex_lock_common(struct mutex *lock, long state, unsigned int subclass,\n\t\t    struct lockdep_map *nest_lock, unsigned long ip,\n\t\t    struct ww_acquire_ctx *ww_ctx, const bool use_ww_ctx)\n{\n\tstruct mutex_waiter waiter;\n\tbool first = false;\n\tstruct ww_mutex *ww;\n\tint ret;\n\n\tmight_sleep();\n\n\tww = container_of(lock, struct ww_mutex, base);\n\tif (use_ww_ctx && ww_ctx) {\n\t\tif (unlikely(ww_ctx == READ_ONCE(ww->ctx)))\n\t\t\treturn -EALREADY;\n\n\t\t/*\n\t\t * Reset the wounded flag after a kill. No other process can\n\t\t * race and wound us here since they can't have a valid owner\n\t\t * pointer if we don't have any locks held.\n\t\t */\n\t\tif (ww_ctx->acquired == 0)\n\t\t\tww_ctx->wounded = 0;\n\t}\n\n\tpreempt_disable();\n\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);\n\n\tif (__mutex_trylock(lock) ||\n\t    mutex_optimistic_spin(lock, ww_ctx, use_ww_ctx, NULL)) {\n\t\t/* got the lock, yay! */\n\t\tlock_acquired(&lock->dep_map, ip);\n\t\tif (use_ww_ctx && ww_ctx)\n\t\t\tww_mutex_set_context_fastpath(ww, ww_ctx);\n\t\tpreempt_enable();\n\t\treturn 0;\n\t}\n\n\tspin_lock(&lock->wait_lock);\n\t/*\n\t * After waiting to acquire the wait_lock, try again.\n\t */\n\tif (__mutex_trylock(lock)) {\n\t\tif (use_ww_ctx && ww_ctx)\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\n\t\tgoto skip_wait;\n\t}\n\n\tdebug_mutex_lock_common(lock, &waiter);\n\n\tlock_contended(&lock->dep_map, ip);\n\n\tif (!use_ww_ctx) {\n\t\t/* add waiting tasks to the end of the waitqueue (FIFO): */\n\t\t__mutex_add_waiter(lock, &waiter, &lock->wait_list);\n\n\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\twaiter.ww_ctx = MUTEX_POISON_WW_CTX;\n#endif\n\t} else {\n\t\t/*\n\t\t * Add in stamp order, waking up waiters that must kill\n\t\t * themselves.\n\t\t */\n\t\tret = __ww_mutex_add_waiter(&waiter, lock, ww_ctx);\n\t\tif (ret)\n\t\t\tgoto err_early_kill;\n\n\t\twaiter.ww_ctx = ww_ctx;\n\t}\n\n\twaiter.task = current;\n\n\tset_current_state(state);\n\tfor (;;) {\n\t\t/*\n\t\t * Once we hold wait_lock, we're serialized against\n\t\t * mutex_unlock() handing the lock off to us, do a trylock\n\t\t * before testing the error conditions to make sure we pick up\n\t\t * the handoff.\n\t\t */\n\t\tif (__mutex_trylock(lock))\n\t\t\tgoto acquired;\n\n\t\t/*\n\t\t * Check for signals and kill conditions while holding\n\t\t * wait_lock. This ensures the lock cancellation is ordered\n\t\t * against mutex_unlock() and wake-ups do not go missing.\n\t\t */\n\t\tif (unlikely(signal_pending_state(state, current))) {\n\t\t\tret = -EINTR;\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (use_ww_ctx && ww_ctx) {\n\t\t\tret = __ww_mutex_check_kill(lock, &waiter, ww_ctx);\n\t\t\tif (ret)\n\t\t\t\tgoto err;\n\t\t}\n\n\t\tspin_unlock(&lock->wait_lock);\n\t\tschedule_preempt_disabled();\n\n\t\t/*\n\t\t * ww_mutex needs to always recheck its position since its waiter\n\t\t * list is not FIFO ordered.\n\t\t */\n\t\tif ((use_ww_ctx && ww_ctx) || !first) {\n\t\t\tfirst = __mutex_waiter_is_first(lock, &waiter);\n\t\t\tif (first)\n\t\t\t\t__mutex_set_flag(lock, MUTEX_FLAG_HANDOFF);\n\t\t}\n\n\t\tset_current_state(state);\n\t\t/*\n\t\t * Here we order against unlock; we must either see it change\n\t\t * state back to RUNNING and fall through the next schedule(),\n\t\t * or we must see its unlock and acquire.\n\t\t */\n\t\tif (__mutex_trylock(lock) ||\n\t\t    (first && mutex_optimistic_spin(lock, ww_ctx, use_ww_ctx, &waiter)))\n\t\t\tbreak;\n\n\t\tspin_lock(&lock->wait_lock);\n\t}\n\tspin_lock(&lock->wait_lock);\nacquired:\n\t__set_current_state(TASK_RUNNING);\n\n\tif (use_ww_ctx && ww_ctx) {\n\t\t/*\n\t\t * Wound-Wait; we stole the lock (!first_waiter), check the\n\t\t * waiters as anyone might want to wound us.\n\t\t */\n\t\tif (!ww_ctx->is_wait_die &&\n\t\t    !__mutex_waiter_is_first(lock, &waiter))\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\t}\n\n\tmutex_remove_waiter(lock, &waiter, current);\n\tif (likely(list_empty(&lock->wait_list)))\n\t\t__mutex_clear_flag(lock, MUTEX_FLAGS);\n\n\tdebug_mutex_free_waiter(&waiter);\n\nskip_wait:\n\t/* got the lock - cleanup and rejoice! */\n\tlock_acquired(&lock->dep_map, ip);\n\n\tif (use_ww_ctx && ww_ctx)\n\t\tww_mutex_lock_acquired(ww, ww_ctx);\n\n\tspin_unlock(&lock->wait_lock);\n\tpreempt_enable();\n\treturn 0;\n\nerr:\n\t__set_current_state(TASK_RUNNING);\n\tmutex_remove_waiter(lock, &waiter, current);\nerr_early_kill:\n\tspin_unlock(&lock->wait_lock);\n\tdebug_mutex_free_waiter(&waiter);\n\tmutex_release(&lock->dep_map, 1, ip);\n\tpreempt_enable();\n\treturn ret;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAGS\t\t0x07",
            "#define MUTEX_FLAG_HANDOFF\t0x02"
          ],
          "globals_used": [
            "__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n#define MUTEX_FLAG_HANDOFF\t0x02\n\n__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);\n\n__sched\n__mutex_lock_common(struct mutex *lock, long state, unsigned int subclass,\n\t\t    struct lockdep_map *nest_lock, unsigned long ip,\n\t\t    struct ww_acquire_ctx *ww_ctx, const bool use_ww_ctx)\n{\n\tstruct mutex_waiter waiter;\n\tbool first = false;\n\tstruct ww_mutex *ww;\n\tint ret;\n\n\tmight_sleep();\n\n\tww = container_of(lock, struct ww_mutex, base);\n\tif (use_ww_ctx && ww_ctx) {\n\t\tif (unlikely(ww_ctx == READ_ONCE(ww->ctx)))\n\t\t\treturn -EALREADY;\n\n\t\t/*\n\t\t * Reset the wounded flag after a kill. No other process can\n\t\t * race and wound us here since they can't have a valid owner\n\t\t * pointer if we don't have any locks held.\n\t\t */\n\t\tif (ww_ctx->acquired == 0)\n\t\t\tww_ctx->wounded = 0;\n\t}\n\n\tpreempt_disable();\n\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);\n\n\tif (__mutex_trylock(lock) ||\n\t    mutex_optimistic_spin(lock, ww_ctx, use_ww_ctx, NULL)) {\n\t\t/* got the lock, yay! */\n\t\tlock_acquired(&lock->dep_map, ip);\n\t\tif (use_ww_ctx && ww_ctx)\n\t\t\tww_mutex_set_context_fastpath(ww, ww_ctx);\n\t\tpreempt_enable();\n\t\treturn 0;\n\t}\n\n\tspin_lock(&lock->wait_lock);\n\t/*\n\t * After waiting to acquire the wait_lock, try again.\n\t */\n\tif (__mutex_trylock(lock)) {\n\t\tif (use_ww_ctx && ww_ctx)\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\n\t\tgoto skip_wait;\n\t}\n\n\tdebug_mutex_lock_common(lock, &waiter);\n\n\tlock_contended(&lock->dep_map, ip);\n\n\tif (!use_ww_ctx) {\n\t\t/* add waiting tasks to the end of the waitqueue (FIFO): */\n\t\t__mutex_add_waiter(lock, &waiter, &lock->wait_list);\n\n\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\twaiter.ww_ctx = MUTEX_POISON_WW_CTX;\n#endif\n\t} else {\n\t\t/*\n\t\t * Add in stamp order, waking up waiters that must kill\n\t\t * themselves.\n\t\t */\n\t\tret = __ww_mutex_add_waiter(&waiter, lock, ww_ctx);\n\t\tif (ret)\n\t\t\tgoto err_early_kill;\n\n\t\twaiter.ww_ctx = ww_ctx;\n\t}\n\n\twaiter.task = current;\n\n\tset_current_state(state);\n\tfor (;;) {\n\t\t/*\n\t\t * Once we hold wait_lock, we're serialized against\n\t\t * mutex_unlock() handing the lock off to us, do a trylock\n\t\t * before testing the error conditions to make sure we pick up\n\t\t * the handoff.\n\t\t */\n\t\tif (__mutex_trylock(lock))\n\t\t\tgoto acquired;\n\n\t\t/*\n\t\t * Check for signals and kill conditions while holding\n\t\t * wait_lock. This ensures the lock cancellation is ordered\n\t\t * against mutex_unlock() and wake-ups do not go missing.\n\t\t */\n\t\tif (unlikely(signal_pending_state(state, current))) {\n\t\t\tret = -EINTR;\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (use_ww_ctx && ww_ctx) {\n\t\t\tret = __ww_mutex_check_kill(lock, &waiter, ww_ctx);\n\t\t\tif (ret)\n\t\t\t\tgoto err;\n\t\t}\n\n\t\tspin_unlock(&lock->wait_lock);\n\t\tschedule_preempt_disabled();\n\n\t\t/*\n\t\t * ww_mutex needs to always recheck its position since its waiter\n\t\t * list is not FIFO ordered.\n\t\t */\n\t\tif ((use_ww_ctx && ww_ctx) || !first) {\n\t\t\tfirst = __mutex_waiter_is_first(lock, &waiter);\n\t\t\tif (first)\n\t\t\t\t__mutex_set_flag(lock, MUTEX_FLAG_HANDOFF);\n\t\t}\n\n\t\tset_current_state(state);\n\t\t/*\n\t\t * Here we order against unlock; we must either see it change\n\t\t * state back to RUNNING and fall through the next schedule(),\n\t\t * or we must see its unlock and acquire.\n\t\t */\n\t\tif (__mutex_trylock(lock) ||\n\t\t    (first && mutex_optimistic_spin(lock, ww_ctx, use_ww_ctx, &waiter)))\n\t\t\tbreak;\n\n\t\tspin_lock(&lock->wait_lock);\n\t}\n\tspin_lock(&lock->wait_lock);\nacquired:\n\t__set_current_state(TASK_RUNNING);\n\n\tif (use_ww_ctx && ww_ctx) {\n\t\t/*\n\t\t * Wound-Wait; we stole the lock (!first_waiter), check the\n\t\t * waiters as anyone might want to wound us.\n\t\t */\n\t\tif (!ww_ctx->is_wait_die &&\n\t\t    !__mutex_waiter_is_first(lock, &waiter))\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\t}\n\n\tmutex_remove_waiter(lock, &waiter, current);\n\tif (likely(list_empty(&lock->wait_list)))\n\t\t__mutex_clear_flag(lock, MUTEX_FLAGS);\n\n\tdebug_mutex_free_waiter(&waiter);\n\nskip_wait:\n\t/* got the lock - cleanup and rejoice! */\n\tlock_acquired(&lock->dep_map, ip);\n\n\tif (use_ww_ctx && ww_ctx)\n\t\tww_mutex_lock_acquired(ww, ww_ctx);\n\n\tspin_unlock(&lock->wait_lock);\n\tpreempt_enable();\n\treturn 0;\n\nerr:\n\t__set_current_state(TASK_RUNNING);\n\tmutex_remove_waiter(lock, &waiter, current);\nerr_early_kill:\n\tspin_unlock(&lock->wait_lock);\n\tdebug_mutex_free_waiter(&waiter);\n\tmutex_release(&lock->dep_map, 1, ip);\n\tpreempt_enable();\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);\n\nstatic int __sched\n__mutex_lock(struct mutex *lock, long state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}"
  },
  {
    "function_name": "__mutex_lock_common",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "898-1066",
    "snippet": "__sched\n__mutex_lock_common(struct mutex *lock, long state, unsigned int subclass,\n\t\t    struct lockdep_map *nest_lock, unsigned long ip,\n\t\t    struct ww_acquire_ctx *ww_ctx, const bool use_ww_ctx)\n{\n\tstruct mutex_waiter waiter;\n\tbool first = false;\n\tstruct ww_mutex *ww;\n\tint ret;\n\n\tmight_sleep();\n\n\tww = container_of(lock, struct ww_mutex, base);\n\tif (use_ww_ctx && ww_ctx) {\n\t\tif (unlikely(ww_ctx == READ_ONCE(ww->ctx)))\n\t\t\treturn -EALREADY;\n\n\t\t/*\n\t\t * Reset the wounded flag after a kill. No other process can\n\t\t * race and wound us here since they can't have a valid owner\n\t\t * pointer if we don't have any locks held.\n\t\t */\n\t\tif (ww_ctx->acquired == 0)\n\t\t\tww_ctx->wounded = 0;\n\t}\n\n\tpreempt_disable();\n\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);\n\n\tif (__mutex_trylock(lock) ||\n\t    mutex_optimistic_spin(lock, ww_ctx, use_ww_ctx, NULL)) {\n\t\t/* got the lock, yay! */\n\t\tlock_acquired(&lock->dep_map, ip);\n\t\tif (use_ww_ctx && ww_ctx)\n\t\t\tww_mutex_set_context_fastpath(ww, ww_ctx);\n\t\tpreempt_enable();\n\t\treturn 0;\n\t}\n\n\tspin_lock(&lock->wait_lock);\n\t/*\n\t * After waiting to acquire the wait_lock, try again.\n\t */\n\tif (__mutex_trylock(lock)) {\n\t\tif (use_ww_ctx && ww_ctx)\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\n\t\tgoto skip_wait;\n\t}\n\n\tdebug_mutex_lock_common(lock, &waiter);\n\n\tlock_contended(&lock->dep_map, ip);\n\n\tif (!use_ww_ctx) {\n\t\t/* add waiting tasks to the end of the waitqueue (FIFO): */\n\t\t__mutex_add_waiter(lock, &waiter, &lock->wait_list);\n\n\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\twaiter.ww_ctx = MUTEX_POISON_WW_CTX;\n#endif\n\t} else {\n\t\t/*\n\t\t * Add in stamp order, waking up waiters that must kill\n\t\t * themselves.\n\t\t */\n\t\tret = __ww_mutex_add_waiter(&waiter, lock, ww_ctx);\n\t\tif (ret)\n\t\t\tgoto err_early_kill;\n\n\t\twaiter.ww_ctx = ww_ctx;\n\t}\n\n\twaiter.task = current;\n\n\tset_current_state(state);\n\tfor (;;) {\n\t\t/*\n\t\t * Once we hold wait_lock, we're serialized against\n\t\t * mutex_unlock() handing the lock off to us, do a trylock\n\t\t * before testing the error conditions to make sure we pick up\n\t\t * the handoff.\n\t\t */\n\t\tif (__mutex_trylock(lock))\n\t\t\tgoto acquired;\n\n\t\t/*\n\t\t * Check for signals and kill conditions while holding\n\t\t * wait_lock. This ensures the lock cancellation is ordered\n\t\t * against mutex_unlock() and wake-ups do not go missing.\n\t\t */\n\t\tif (unlikely(signal_pending_state(state, current))) {\n\t\t\tret = -EINTR;\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (use_ww_ctx && ww_ctx) {\n\t\t\tret = __ww_mutex_check_kill(lock, &waiter, ww_ctx);\n\t\t\tif (ret)\n\t\t\t\tgoto err;\n\t\t}\n\n\t\tspin_unlock(&lock->wait_lock);\n\t\tschedule_preempt_disabled();\n\n\t\t/*\n\t\t * ww_mutex needs to always recheck its position since its waiter\n\t\t * list is not FIFO ordered.\n\t\t */\n\t\tif ((use_ww_ctx && ww_ctx) || !first) {\n\t\t\tfirst = __mutex_waiter_is_first(lock, &waiter);\n\t\t\tif (first)\n\t\t\t\t__mutex_set_flag(lock, MUTEX_FLAG_HANDOFF);\n\t\t}\n\n\t\tset_current_state(state);\n\t\t/*\n\t\t * Here we order against unlock; we must either see it change\n\t\t * state back to RUNNING and fall through the next schedule(),\n\t\t * or we must see its unlock and acquire.\n\t\t */\n\t\tif (__mutex_trylock(lock) ||\n\t\t    (first && mutex_optimistic_spin(lock, ww_ctx, use_ww_ctx, &waiter)))\n\t\t\tbreak;\n\n\t\tspin_lock(&lock->wait_lock);\n\t}\n\tspin_lock(&lock->wait_lock);\nacquired:\n\t__set_current_state(TASK_RUNNING);\n\n\tif (use_ww_ctx && ww_ctx) {\n\t\t/*\n\t\t * Wound-Wait; we stole the lock (!first_waiter), check the\n\t\t * waiters as anyone might want to wound us.\n\t\t */\n\t\tif (!ww_ctx->is_wait_die &&\n\t\t    !__mutex_waiter_is_first(lock, &waiter))\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\t}\n\n\tmutex_remove_waiter(lock, &waiter, current);\n\tif (likely(list_empty(&lock->wait_list)))\n\t\t__mutex_clear_flag(lock, MUTEX_FLAGS);\n\n\tdebug_mutex_free_waiter(&waiter);\n\nskip_wait:\n\t/* got the lock - cleanup and rejoice! */\n\tlock_acquired(&lock->dep_map, ip);\n\n\tif (use_ww_ctx && ww_ctx)\n\t\tww_mutex_lock_acquired(ww, ww_ctx);\n\n\tspin_unlock(&lock->wait_lock);\n\tpreempt_enable();\n\treturn 0;\n\nerr:\n\t__set_current_state(TASK_RUNNING);\n\tmutex_remove_waiter(lock, &waiter, current);\nerr_early_kill:\n\tspin_unlock(&lock->wait_lock);\n\tdebug_mutex_free_waiter(&waiter);\n\tmutex_release(&lock->dep_map, 1, ip);\n\tpreempt_enable();\n\treturn ret;\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [
      "#define MUTEX_FLAGS\t\t0x07",
      "#define MUTEX_FLAG_HANDOFF\t0x02"
    ],
    "globals_used": [
      "__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "preempt_enable",
          "args": [],
          "line": 1064
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_release",
          "args": [
            "&lock->dep_map",
            "1",
            "ip"
          ],
          "line": 1063
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "debug_mutex_free_waiter",
          "args": [
            "&waiter"
          ],
          "line": 1062
        },
        "resolved": true,
        "details": {
          "function_name": "debug_mutex_free_waiter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex-debug.c",
          "lines": "45-49",
          "snippet": "void debug_mutex_free_waiter(struct mutex_waiter *waiter)\n{\n\tDEBUG_LOCKS_WARN_ON(!list_empty(&waiter->list));\n\tmemset(waiter, MUTEX_DEBUG_FREE, sizeof(*waiter));\n}",
          "includes": [
            "#include \"mutex-debug.h\"",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/poison.h>",
            "#include <linux/export.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"mutex-debug.h\"\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/sched.h>\n#include <linux/poison.h>\n#include <linux/export.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n\nvoid debug_mutex_free_waiter(struct mutex_waiter *waiter)\n{\n\tDEBUG_LOCKS_WARN_ON(!list_empty(&waiter->list));\n\tmemset(waiter, MUTEX_DEBUG_FREE, sizeof(*waiter));\n}"
        }
      },
      {
        "call_info": {
          "callee": "spin_unlock",
          "args": [
            "&lock->wait_lock"
          ],
          "line": 1061
        },
        "resolved": true,
        "details": {
          "function_name": "__pv_queued_spin_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/qspinlock_paravirt.h",
          "lines": "546-560",
          "snippet": "__visible void __pv_queued_spin_unlock(struct qspinlock *lock)\n{\n\tu8 locked;\n\n\t/*\n\t * We must not unlock if SLOW, because in that case we must first\n\t * unhash. Otherwise it would be possible to have multiple @lock\n\t * entries, which would be BAD.\n\t */\n\tlocked = cmpxchg_release(&lock->locked, _Q_LOCKED_VAL, 0);\n\tif (likely(locked == _Q_LOCKED_VAL))\n\t\treturn;\n\n\t__pv_queued_spin_unlock_slowpath(lock, locked);\n}",
          "includes": [
            "#include <asm/qspinlock_paravirt.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/memblock.h>",
            "#include <linux/hash.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/qspinlock_paravirt.h>\n#include <linux/debug_locks.h>\n#include <linux/memblock.h>\n#include <linux/hash.h>\n\n__visible void __pv_queued_spin_unlock(struct qspinlock *lock)\n{\n\tu8 locked;\n\n\t/*\n\t * We must not unlock if SLOW, because in that case we must first\n\t * unhash. Otherwise it would be possible to have multiple @lock\n\t * entries, which would be BAD.\n\t */\n\tlocked = cmpxchg_release(&lock->locked, _Q_LOCKED_VAL, 0);\n\tif (likely(locked == _Q_LOCKED_VAL))\n\t\treturn;\n\n\t__pv_queued_spin_unlock_slowpath(lock, locked);\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_remove_waiter",
          "args": [
            "lock",
            "&waiter",
            "current"
          ],
          "line": 1059
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_remove_waiter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex-debug.c",
          "lines": "60-70",
          "snippet": "void mutex_remove_waiter(struct mutex *lock, struct mutex_waiter *waiter,\n\t\t\t struct task_struct *task)\n{\n\tDEBUG_LOCKS_WARN_ON(list_empty(&waiter->list));\n\tDEBUG_LOCKS_WARN_ON(waiter->task != task);\n\tDEBUG_LOCKS_WARN_ON(task->blocked_on != waiter);\n\ttask->blocked_on = NULL;\n\n\tlist_del_init(&waiter->list);\n\twaiter->task = NULL;\n}",
          "includes": [
            "#include \"mutex-debug.h\"",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/poison.h>",
            "#include <linux/export.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"mutex-debug.h\"\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/sched.h>\n#include <linux/poison.h>\n#include <linux/export.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n\nvoid mutex_remove_waiter(struct mutex *lock, struct mutex_waiter *waiter,\n\t\t\t struct task_struct *task)\n{\n\tDEBUG_LOCKS_WARN_ON(list_empty(&waiter->list));\n\tDEBUG_LOCKS_WARN_ON(waiter->task != task);\n\tDEBUG_LOCKS_WARN_ON(task->blocked_on != waiter);\n\ttask->blocked_on = NULL;\n\n\tlist_del_init(&waiter->list);\n\twaiter->task = NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__set_current_state",
          "args": [
            "TASK_RUNNING"
          ],
          "line": 1058
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "preempt_enable",
          "args": [],
          "line": 1054
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ww_mutex_lock_acquired",
          "args": [
            "ww",
            "ww_ctx"
          ],
          "line": 1051
        },
        "resolved": true,
        "details": {
          "function_name": "ww_mutex_lock_acquired",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "278-317",
          "snippet": "static __always_inline void\nww_mutex_lock_acquired(struct ww_mutex *ww, struct ww_acquire_ctx *ww_ctx)\n{\n#ifdef CONFIG_DEBUG_MUTEXES\n\t/*\n\t * If this WARN_ON triggers, you used ww_mutex_lock to acquire,\n\t * but released with a normal mutex_unlock in this call.\n\t *\n\t * This should never happen, always use ww_mutex_unlock.\n\t */\n\tDEBUG_LOCKS_WARN_ON(ww->ctx);\n\n\t/*\n\t * Not quite done after calling ww_acquire_done() ?\n\t */\n\tDEBUG_LOCKS_WARN_ON(ww_ctx->done_acquire);\n\n\tif (ww_ctx->contending_lock) {\n\t\t/*\n\t\t * After -EDEADLK you tried to\n\t\t * acquire a different ww_mutex? Bad!\n\t\t */\n\t\tDEBUG_LOCKS_WARN_ON(ww_ctx->contending_lock != ww);\n\n\t\t/*\n\t\t * You called ww_mutex_lock after receiving -EDEADLK,\n\t\t * but 'forgot' to unlock everything else first?\n\t\t */\n\t\tDEBUG_LOCKS_WARN_ON(ww_ctx->acquired > 0);\n\t\tww_ctx->contending_lock = NULL;\n\t}\n\n\t/*\n\t * Naughty, using a different class will lead to undefined behavior!\n\t */\n\tDEBUG_LOCKS_WARN_ON(ww_ctx->ww_class != ww->ww_class);\n#endif\n\tww_ctx->acquired++;\n\tww->ctx = ww_ctx;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline int",
            "static __always_inline int"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline int;\nstatic __always_inline int;\n\nstatic __always_inline void\nww_mutex_lock_acquired(struct ww_mutex *ww, struct ww_acquire_ctx *ww_ctx)\n{\n#ifdef CONFIG_DEBUG_MUTEXES\n\t/*\n\t * If this WARN_ON triggers, you used ww_mutex_lock to acquire,\n\t * but released with a normal mutex_unlock in this call.\n\t *\n\t * This should never happen, always use ww_mutex_unlock.\n\t */\n\tDEBUG_LOCKS_WARN_ON(ww->ctx);\n\n\t/*\n\t * Not quite done after calling ww_acquire_done() ?\n\t */\n\tDEBUG_LOCKS_WARN_ON(ww_ctx->done_acquire);\n\n\tif (ww_ctx->contending_lock) {\n\t\t/*\n\t\t * After -EDEADLK you tried to\n\t\t * acquire a different ww_mutex? Bad!\n\t\t */\n\t\tDEBUG_LOCKS_WARN_ON(ww_ctx->contending_lock != ww);\n\n\t\t/*\n\t\t * You called ww_mutex_lock after receiving -EDEADLK,\n\t\t * but 'forgot' to unlock everything else first?\n\t\t */\n\t\tDEBUG_LOCKS_WARN_ON(ww_ctx->acquired > 0);\n\t\tww_ctx->contending_lock = NULL;\n\t}\n\n\t/*\n\t * Naughty, using a different class will lead to undefined behavior!\n\t */\n\tDEBUG_LOCKS_WARN_ON(ww_ctx->ww_class != ww->ww_class);\n#endif\n\tww_ctx->acquired++;\n\tww->ctx = ww_ctx;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_clear_flag",
          "args": [
            "lock",
            "MUTEX_FLAGS"
          ],
          "line": 1042
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_clear_flag",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "166-169",
          "snippet": "static inline void __mutex_clear_flag(struct mutex *lock, unsigned long flag)\n{\n\tatomic_long_andnot(flag, &lock->owner);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline void __mutex_clear_flag(struct mutex *lock, unsigned long flag)\n{\n\tatomic_long_andnot(flag, &lock->owner);\n}"
        }
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "list_empty(&lock->wait_list)"
          ],
          "line": 1041
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "&lock->wait_list"
          ],
          "line": 1041
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "50-53",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !rsclp->head;\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !rsclp->head;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__ww_mutex_check_waiters",
          "args": [
            "lock",
            "ww_ctx"
          ],
          "line": 1037
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_check_waiters",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "416-431",
          "snippet": "static void __sched\n__ww_mutex_check_waiters(struct mutex *lock, struct ww_acquire_ctx *ww_ctx)\n{\n\tstruct mutex_waiter *cur;\n\n\tlockdep_assert_held(&lock->wait_lock);\n\n\tlist_for_each_entry(cur, &lock->wait_list, list) {\n\t\tif (!cur->ww_ctx)\n\t\t\tcontinue;\n\n\t\tif (__ww_mutex_die(lock, cur, ww_ctx) ||\n\t\t    __ww_mutex_wound(lock, cur->ww_ctx, ww_ctx))\n\t\t\tbreak;\n\t}\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic void __sched\n__ww_mutex_check_waiters(struct mutex *lock, struct ww_acquire_ctx *ww_ctx)\n{\n\tstruct mutex_waiter *cur;\n\n\tlockdep_assert_held(&lock->wait_lock);\n\n\tlist_for_each_entry(cur, &lock->wait_list, list) {\n\t\tif (!cur->ww_ctx)\n\t\t\tcontinue;\n\n\t\tif (__ww_mutex_die(lock, cur, ww_ctx) ||\n\t\t    __ww_mutex_wound(lock, cur->ww_ctx, ww_ctx))\n\t\t\tbreak;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_waiter_is_first",
          "args": [
            "lock",
            "&waiter"
          ],
          "line": 1036
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_waiter_is_first",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "171-174",
          "snippet": "static inline bool __mutex_waiter_is_first(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\treturn list_first_entry(&lock->wait_list, struct mutex_waiter, list) == waiter;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline bool __mutex_waiter_is_first(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\treturn list_first_entry(&lock->wait_list, struct mutex_waiter, list) == waiter;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__set_current_state",
          "args": [
            "TASK_RUNNING"
          ],
          "line": 1028
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_lock",
          "args": [
            "&lock->wait_lock"
          ],
          "line": 1026
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "166-169",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_optimistic_spin",
          "args": [
            "lock",
            "ww_ctx",
            "use_ww_ctx",
            "&waiter"
          ],
          "line": 1021
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_optimistic_spin",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "686-691",
          "snippet": "static __always_inline bool\nmutex_optimistic_spin(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,\n\t\t      const bool use_ww_ctx, struct mutex_waiter *waiter)\n{\n\treturn false;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline int",
            "static __always_inline int"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline int;\nstatic __always_inline int;\n\nstatic __always_inline bool\nmutex_optimistic_spin(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,\n\t\t      const bool use_ww_ctx, struct mutex_waiter *waiter)\n{\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_trylock",
          "args": [
            "lock"
          ],
          "line": 1020
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_trylock_fast",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "139-148",
          "snippet": "static __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline int",
            "static __always_inline int"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline int;\nstatic __always_inline int;\n\nstatic __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "set_current_state",
          "args": [
            "state"
          ],
          "line": 1014
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__mutex_set_flag",
          "args": [
            "lock",
            "MUTEX_FLAG_HANDOFF"
          ],
          "line": 1011
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_set_flag",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "161-164",
          "snippet": "static inline void __mutex_set_flag(struct mutex *lock, unsigned long flag)\n{\n\tatomic_long_or(flag, &lock->owner);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline void __mutex_set_flag(struct mutex *lock, unsigned long flag)\n{\n\tatomic_long_or(flag, &lock->owner);\n}"
        }
      },
      {
        "call_info": {
          "callee": "schedule_preempt_disabled",
          "args": [],
          "line": 1002
        },
        "resolved": true,
        "details": {
          "function_name": "schedule_preempt_disabled",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/core.c",
          "lines": "3571-3576",
          "snippet": "void __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}",
          "includes": [
            "#include \"features.h\"",
            "#include <trace/events/sched.h>",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/kcov.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include <trace/events/sched.h>\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/kcov.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n\nstatic void __sched;\nstatic void __sched;\n\nvoid __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "__ww_mutex_check_kill",
          "args": [
            "lock",
            "&waiter",
            "ww_ctx"
          ],
          "line": 996
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_check_kill",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "777-811",
          "snippet": "static inline int __sched\n__ww_mutex_check_kill(struct mutex *lock, struct mutex_waiter *waiter,\n\t\t      struct ww_acquire_ctx *ctx)\n{\n\tstruct ww_mutex *ww = container_of(lock, struct ww_mutex, base);\n\tstruct ww_acquire_ctx *hold_ctx = READ_ONCE(ww->ctx);\n\tstruct mutex_waiter *cur;\n\n\tif (ctx->acquired == 0)\n\t\treturn 0;\n\n\tif (!ctx->is_wait_die) {\n\t\tif (ctx->wounded)\n\t\t\treturn __ww_mutex_kill(lock, ctx);\n\n\t\treturn 0;\n\t}\n\n\tif (hold_ctx && __ww_ctx_stamp_after(ctx, hold_ctx))\n\t\treturn __ww_mutex_kill(lock, ctx);\n\n\t/*\n\t * If there is a waiter in front of us that has a context, then its\n\t * stamp is earlier than ours and we must kill ourself.\n\t */\n\tcur = waiter;\n\tlist_for_each_entry_continue_reverse(cur, &lock->wait_list, list) {\n\t\tif (!cur->ww_ctx)\n\t\t\tcontinue;\n\n\t\treturn __ww_mutex_kill(lock, ctx);\n\t}\n\n\treturn 0;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline int __sched\n__ww_mutex_check_kill(struct mutex *lock, struct mutex_waiter *waiter,\n\t\t      struct ww_acquire_ctx *ctx)\n{\n\tstruct ww_mutex *ww = container_of(lock, struct ww_mutex, base);\n\tstruct ww_acquire_ctx *hold_ctx = READ_ONCE(ww->ctx);\n\tstruct mutex_waiter *cur;\n\n\tif (ctx->acquired == 0)\n\t\treturn 0;\n\n\tif (!ctx->is_wait_die) {\n\t\tif (ctx->wounded)\n\t\t\treturn __ww_mutex_kill(lock, ctx);\n\n\t\treturn 0;\n\t}\n\n\tif (hold_ctx && __ww_ctx_stamp_after(ctx, hold_ctx))\n\t\treturn __ww_mutex_kill(lock, ctx);\n\n\t/*\n\t * If there is a waiter in front of us that has a context, then its\n\t * stamp is earlier than ours and we must kill ourself.\n\t */\n\tcur = waiter;\n\tlist_for_each_entry_continue_reverse(cur, &lock->wait_list, list) {\n\t\tif (!cur->ww_ctx)\n\t\t\tcontinue;\n\n\t\treturn __ww_mutex_kill(lock, ctx);\n\t}\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "signal_pending_state(state, current)"
          ],
          "line": 990
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "signal_pending_state",
          "args": [
            "state",
            "current"
          ],
          "line": 990
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "set_current_state",
          "args": [
            "state"
          ],
          "line": 974
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__ww_mutex_add_waiter",
          "args": [
            "&waiter",
            "lock",
            "ww_ctx"
          ],
          "line": 965
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_add_waiter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "824-893",
          "snippet": "static inline int __sched\n__ww_mutex_add_waiter(struct mutex_waiter *waiter,\n\t\t      struct mutex *lock,\n\t\t      struct ww_acquire_ctx *ww_ctx)\n{\n\tstruct mutex_waiter *cur;\n\tstruct list_head *pos;\n\tbool is_wait_die;\n\n\tif (!ww_ctx) {\n\t\t__mutex_add_waiter(lock, waiter, &lock->wait_list);\n\t\treturn 0;\n\t}\n\n\tis_wait_die = ww_ctx->is_wait_die;\n\n\t/*\n\t * Add the waiter before the first waiter with a higher stamp.\n\t * Waiters without a context are skipped to avoid starving\n\t * them. Wait-Die waiters may die here. Wound-Wait waiters\n\t * never die here, but they are sorted in stamp order and\n\t * may wound the lock holder.\n\t */\n\tpos = &lock->wait_list;\n\tlist_for_each_entry_reverse(cur, &lock->wait_list, list) {\n\t\tif (!cur->ww_ctx)\n\t\t\tcontinue;\n\n\t\tif (__ww_ctx_stamp_after(ww_ctx, cur->ww_ctx)) {\n\t\t\t/*\n\t\t\t * Wait-Die: if we find an older context waiting, there\n\t\t\t * is no point in queueing behind it, as we'd have to\n\t\t\t * die the moment it would acquire the lock.\n\t\t\t */\n\t\t\tif (is_wait_die) {\n\t\t\t\tint ret = __ww_mutex_kill(lock, ww_ctx);\n\n\t\t\t\tif (ret)\n\t\t\t\t\treturn ret;\n\t\t\t}\n\n\t\t\tbreak;\n\t\t}\n\n\t\tpos = &cur->list;\n\n\t\t/* Wait-Die: ensure younger waiters die. */\n\t\t__ww_mutex_die(lock, cur, ww_ctx);\n\t}\n\n\t__mutex_add_waiter(lock, waiter, pos);\n\n\t/*\n\t * Wound-Wait: if we're blocking on a mutex owned by a younger context,\n\t * wound that such that we might proceed.\n\t */\n\tif (!is_wait_die) {\n\t\tstruct ww_mutex *ww = container_of(lock, struct ww_mutex, base);\n\n\t\t/*\n\t\t * See ww_mutex_set_context_fastpath(). Orders setting\n\t\t * MUTEX_FLAG_WAITERS vs the ww->ctx load,\n\t\t * such that either we or the fastpath will wound @ww->ctx.\n\t\t */\n\t\tsmp_mb();\n\t\t__ww_mutex_wound(lock, ww_ctx, ww->ctx);\n\t}\n\n\treturn 0;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAG_WAITERS\t0x01"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAG_WAITERS\t0x01\n\nstatic inline int __sched\n__ww_mutex_add_waiter(struct mutex_waiter *waiter,\n\t\t      struct mutex *lock,\n\t\t      struct ww_acquire_ctx *ww_ctx)\n{\n\tstruct mutex_waiter *cur;\n\tstruct list_head *pos;\n\tbool is_wait_die;\n\n\tif (!ww_ctx) {\n\t\t__mutex_add_waiter(lock, waiter, &lock->wait_list);\n\t\treturn 0;\n\t}\n\n\tis_wait_die = ww_ctx->is_wait_die;\n\n\t/*\n\t * Add the waiter before the first waiter with a higher stamp.\n\t * Waiters without a context are skipped to avoid starving\n\t * them. Wait-Die waiters may die here. Wound-Wait waiters\n\t * never die here, but they are sorted in stamp order and\n\t * may wound the lock holder.\n\t */\n\tpos = &lock->wait_list;\n\tlist_for_each_entry_reverse(cur, &lock->wait_list, list) {\n\t\tif (!cur->ww_ctx)\n\t\t\tcontinue;\n\n\t\tif (__ww_ctx_stamp_after(ww_ctx, cur->ww_ctx)) {\n\t\t\t/*\n\t\t\t * Wait-Die: if we find an older context waiting, there\n\t\t\t * is no point in queueing behind it, as we'd have to\n\t\t\t * die the moment it would acquire the lock.\n\t\t\t */\n\t\t\tif (is_wait_die) {\n\t\t\t\tint ret = __ww_mutex_kill(lock, ww_ctx);\n\n\t\t\t\tif (ret)\n\t\t\t\t\treturn ret;\n\t\t\t}\n\n\t\t\tbreak;\n\t\t}\n\n\t\tpos = &cur->list;\n\n\t\t/* Wait-Die: ensure younger waiters die. */\n\t\t__ww_mutex_die(lock, cur, ww_ctx);\n\t}\n\n\t__mutex_add_waiter(lock, waiter, pos);\n\n\t/*\n\t * Wound-Wait: if we're blocking on a mutex owned by a younger context,\n\t * wound that such that we might proceed.\n\t */\n\tif (!is_wait_die) {\n\t\tstruct ww_mutex *ww = container_of(lock, struct ww_mutex, base);\n\n\t\t/*\n\t\t * See ww_mutex_set_context_fastpath(). Orders setting\n\t\t * MUTEX_FLAG_WAITERS vs the ww->ctx load,\n\t\t * such that either we or the fastpath will wound @ww->ctx.\n\t\t */\n\t\tsmp_mb();\n\t\t__ww_mutex_wound(lock, ww_ctx, ww->ctx);\n\t}\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_add_waiter",
          "args": [
            "lock",
            "&waiter",
            "&lock->wait_list"
          ],
          "line": 954
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_add_waiter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "180-189",
          "snippet": "static void __sched\n__mutex_add_waiter(struct mutex *lock, struct mutex_waiter *waiter,\n\t\t   struct list_head *list)\n{\n\tdebug_mutex_add_waiter(lock, waiter, current);\n\n\tlist_add_tail(&waiter->list, list);\n\tif (__mutex_waiter_is_first(lock, waiter))\n\t\t__mutex_set_flag(lock, MUTEX_FLAG_WAITERS);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAG_WAITERS\t0x01"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAG_WAITERS\t0x01\n\nstatic void __sched\n__mutex_add_waiter(struct mutex *lock, struct mutex_waiter *waiter,\n\t\t   struct list_head *list)\n{\n\tdebug_mutex_add_waiter(lock, waiter, current);\n\n\tlist_add_tail(&waiter->list, list);\n\tif (__mutex_waiter_is_first(lock, waiter))\n\t\t__mutex_set_flag(lock, MUTEX_FLAG_WAITERS);\n}"
        }
      },
      {
        "call_info": {
          "callee": "lock_contended",
          "args": [
            "&lock->dep_map",
            "ip"
          ],
          "line": 950
        },
        "resolved": true,
        "details": {
          "function_name": "lock_contended",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/lockdep.c",
          "lines": "4065-4082",
          "snippet": "void lock_contended(struct lockdep_map *lock, unsigned long ip)\n{\n\tunsigned long flags;\n\n\tif (unlikely(!lock_stat || !debug_locks))\n\t\treturn;\n\n\tif (unlikely(current->lockdep_recursion))\n\t\treturn;\n\n\traw_local_irq_save(flags);\n\tcheck_flags(flags);\n\tcurrent->lockdep_recursion = 1;\n\ttrace_lock_contended(lock, ip);\n\t__lock_contended(lock, ip);\n\tcurrent->lockdep_recursion = 0;\n\traw_local_irq_restore(flags);\n}",
          "includes": [
            "#include \"lockdep_states.h\"",
            "#include \"lockdep_states.h\"",
            "#include \"lockdep_states.h\"",
            "#include \"lockdep_states.h\"",
            "#include <trace/events/lock.h>",
            "#include \"lockdep_internals.h\"",
            "#include <asm/sections.h>",
            "#include <linux/nmi.h>",
            "#include <linux/jhash.h>",
            "#include <linux/random.h>",
            "#include <linux/gfp.h>",
            "#include <linux/bitops.h>",
            "#include <linux/stringify.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/hash.h>",
            "#include <linux/utsname.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/stacktrace.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/module.h>",
            "#include <linux/delay.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define lock_stat 0"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"lockdep_states.h\"\n#include \"lockdep_states.h\"\n#include \"lockdep_states.h\"\n#include \"lockdep_states.h\"\n#include <trace/events/lock.h>\n#include \"lockdep_internals.h\"\n#include <asm/sections.h>\n#include <linux/nmi.h>\n#include <linux/jhash.h>\n#include <linux/random.h>\n#include <linux/gfp.h>\n#include <linux/bitops.h>\n#include <linux/stringify.h>\n#include <linux/ftrace.h>\n#include <linux/hash.h>\n#include <linux/utsname.h>\n#include <linux/irqflags.h>\n#include <linux/debug_locks.h>\n#include <linux/stacktrace.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/seq_file.h>\n#include <linux/proc_fs.h>\n#include <linux/module.h>\n#include <linux/delay.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/task.h>\n#include <linux/sched/clock.h>\n#include <linux/sched.h>\n#include <linux/mutex.h>\n\n#define lock_stat 0\n\nvoid lock_contended(struct lockdep_map *lock, unsigned long ip)\n{\n\tunsigned long flags;\n\n\tif (unlikely(!lock_stat || !debug_locks))\n\t\treturn;\n\n\tif (unlikely(current->lockdep_recursion))\n\t\treturn;\n\n\traw_local_irq_save(flags);\n\tcheck_flags(flags);\n\tcurrent->lockdep_recursion = 1;\n\ttrace_lock_contended(lock, ip);\n\t__lock_contended(lock, ip);\n\tcurrent->lockdep_recursion = 0;\n\traw_local_irq_restore(flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "debug_mutex_lock_common",
          "args": [
            "lock",
            "&waiter"
          ],
          "line": 948
        },
        "resolved": true,
        "details": {
          "function_name": "debug_mutex_lock_common",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.h",
          "lines": "22-25",
          "snippet": "static inline void\ndebug_mutex_lock_common(struct mutex *lock, struct mutex_waiter *waiter)\n{\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static inline void\ndebug_mutex_lock_common(struct mutex *lock, struct mutex_waiter *waiter)\n{\n}"
        }
      },
      {
        "call_info": {
          "callee": "preempt_enable",
          "args": [],
          "line": 933
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ww_mutex_set_context_fastpath",
          "args": [
            "ww",
            "ww_ctx"
          ],
          "line": 932
        },
        "resolved": true,
        "details": {
          "function_name": "ww_mutex_set_context_fastpath",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "437-470",
          "snippet": "static __always_inline void\nww_mutex_set_context_fastpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tww_mutex_lock_acquired(lock, ctx);\n\n\t/*\n\t * The lock->ctx update should be visible on all cores before\n\t * the WAITERS check is done, otherwise contended waiters might be\n\t * missed. The contended waiters will either see ww_ctx == NULL\n\t * and keep spinning, or it will acquire wait_lock, add itself\n\t * to waiter list and sleep.\n\t */\n\tsmp_mb(); /* See comments above and below. */\n\n\t/*\n\t * [W] ww->ctx = ctx\t    [W] MUTEX_FLAG_WAITERS\n\t *     MB\t\t        MB\n\t * [R] MUTEX_FLAG_WAITERS   [R] ww->ctx\n\t *\n\t * The memory barrier above pairs with the memory barrier in\n\t * __ww_mutex_add_waiter() and makes sure we either observe ww->ctx\n\t * and/or !empty list.\n\t */\n\tif (likely(!(atomic_long_read(&lock->base.owner) & MUTEX_FLAG_WAITERS)))\n\t\treturn;\n\n\t/*\n\t * Uh oh, we raced in fastpath, check if any of the waiters need to\n\t * die or wound us.\n\t */\n\tspin_lock(&lock->base.wait_lock);\n\t__ww_mutex_check_waiters(&lock->base, ctx);\n\tspin_unlock(&lock->base.wait_lock);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAG_WAITERS\t0x01"
          ],
          "globals_used": [
            "static __always_inline int",
            "static __always_inline int"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAG_WAITERS\t0x01\n\nstatic __always_inline int;\nstatic __always_inline int;\n\nstatic __always_inline void\nww_mutex_set_context_fastpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tww_mutex_lock_acquired(lock, ctx);\n\n\t/*\n\t * The lock->ctx update should be visible on all cores before\n\t * the WAITERS check is done, otherwise contended waiters might be\n\t * missed. The contended waiters will either see ww_ctx == NULL\n\t * and keep spinning, or it will acquire wait_lock, add itself\n\t * to waiter list and sleep.\n\t */\n\tsmp_mb(); /* See comments above and below. */\n\n\t/*\n\t * [W] ww->ctx = ctx\t    [W] MUTEX_FLAG_WAITERS\n\t *     MB\t\t        MB\n\t * [R] MUTEX_FLAG_WAITERS   [R] ww->ctx\n\t *\n\t * The memory barrier above pairs with the memory barrier in\n\t * __ww_mutex_add_waiter() and makes sure we either observe ww->ctx\n\t * and/or !empty list.\n\t */\n\tif (likely(!(atomic_long_read(&lock->base.owner) & MUTEX_FLAG_WAITERS)))\n\t\treturn;\n\n\t/*\n\t * Uh oh, we raced in fastpath, check if any of the waiters need to\n\t * die or wound us.\n\t */\n\tspin_lock(&lock->base.wait_lock);\n\t__ww_mutex_check_waiters(&lock->base, ctx);\n\tspin_unlock(&lock->base.wait_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_acquire_nest",
          "args": [
            "&lock->dep_map",
            "subclass",
            "0",
            "nest_lock",
            "ip"
          ],
          "line": 925
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "ww_ctx == READ_ONCE(ww->ctx)"
          ],
          "line": 912
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "ww->ctx"
          ],
          "line": 912
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "lock",
            "structww_mutex",
            "base"
          ],
          "line": 910
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 908
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n#define MUTEX_FLAG_HANDOFF\t0x02\n\n__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);\n\n__sched\n__mutex_lock_common(struct mutex *lock, long state, unsigned int subclass,\n\t\t    struct lockdep_map *nest_lock, unsigned long ip,\n\t\t    struct ww_acquire_ctx *ww_ctx, const bool use_ww_ctx)\n{\n\tstruct mutex_waiter waiter;\n\tbool first = false;\n\tstruct ww_mutex *ww;\n\tint ret;\n\n\tmight_sleep();\n\n\tww = container_of(lock, struct ww_mutex, base);\n\tif (use_ww_ctx && ww_ctx) {\n\t\tif (unlikely(ww_ctx == READ_ONCE(ww->ctx)))\n\t\t\treturn -EALREADY;\n\n\t\t/*\n\t\t * Reset the wounded flag after a kill. No other process can\n\t\t * race and wound us here since they can't have a valid owner\n\t\t * pointer if we don't have any locks held.\n\t\t */\n\t\tif (ww_ctx->acquired == 0)\n\t\t\tww_ctx->wounded = 0;\n\t}\n\n\tpreempt_disable();\n\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);\n\n\tif (__mutex_trylock(lock) ||\n\t    mutex_optimistic_spin(lock, ww_ctx, use_ww_ctx, NULL)) {\n\t\t/* got the lock, yay! */\n\t\tlock_acquired(&lock->dep_map, ip);\n\t\tif (use_ww_ctx && ww_ctx)\n\t\t\tww_mutex_set_context_fastpath(ww, ww_ctx);\n\t\tpreempt_enable();\n\t\treturn 0;\n\t}\n\n\tspin_lock(&lock->wait_lock);\n\t/*\n\t * After waiting to acquire the wait_lock, try again.\n\t */\n\tif (__mutex_trylock(lock)) {\n\t\tif (use_ww_ctx && ww_ctx)\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\n\t\tgoto skip_wait;\n\t}\n\n\tdebug_mutex_lock_common(lock, &waiter);\n\n\tlock_contended(&lock->dep_map, ip);\n\n\tif (!use_ww_ctx) {\n\t\t/* add waiting tasks to the end of the waitqueue (FIFO): */\n\t\t__mutex_add_waiter(lock, &waiter, &lock->wait_list);\n\n\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\twaiter.ww_ctx = MUTEX_POISON_WW_CTX;\n#endif\n\t} else {\n\t\t/*\n\t\t * Add in stamp order, waking up waiters that must kill\n\t\t * themselves.\n\t\t */\n\t\tret = __ww_mutex_add_waiter(&waiter, lock, ww_ctx);\n\t\tif (ret)\n\t\t\tgoto err_early_kill;\n\n\t\twaiter.ww_ctx = ww_ctx;\n\t}\n\n\twaiter.task = current;\n\n\tset_current_state(state);\n\tfor (;;) {\n\t\t/*\n\t\t * Once we hold wait_lock, we're serialized against\n\t\t * mutex_unlock() handing the lock off to us, do a trylock\n\t\t * before testing the error conditions to make sure we pick up\n\t\t * the handoff.\n\t\t */\n\t\tif (__mutex_trylock(lock))\n\t\t\tgoto acquired;\n\n\t\t/*\n\t\t * Check for signals and kill conditions while holding\n\t\t * wait_lock. This ensures the lock cancellation is ordered\n\t\t * against mutex_unlock() and wake-ups do not go missing.\n\t\t */\n\t\tif (unlikely(signal_pending_state(state, current))) {\n\t\t\tret = -EINTR;\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (use_ww_ctx && ww_ctx) {\n\t\t\tret = __ww_mutex_check_kill(lock, &waiter, ww_ctx);\n\t\t\tif (ret)\n\t\t\t\tgoto err;\n\t\t}\n\n\t\tspin_unlock(&lock->wait_lock);\n\t\tschedule_preempt_disabled();\n\n\t\t/*\n\t\t * ww_mutex needs to always recheck its position since its waiter\n\t\t * list is not FIFO ordered.\n\t\t */\n\t\tif ((use_ww_ctx && ww_ctx) || !first) {\n\t\t\tfirst = __mutex_waiter_is_first(lock, &waiter);\n\t\t\tif (first)\n\t\t\t\t__mutex_set_flag(lock, MUTEX_FLAG_HANDOFF);\n\t\t}\n\n\t\tset_current_state(state);\n\t\t/*\n\t\t * Here we order against unlock; we must either see it change\n\t\t * state back to RUNNING and fall through the next schedule(),\n\t\t * or we must see its unlock and acquire.\n\t\t */\n\t\tif (__mutex_trylock(lock) ||\n\t\t    (first && mutex_optimistic_spin(lock, ww_ctx, use_ww_ctx, &waiter)))\n\t\t\tbreak;\n\n\t\tspin_lock(&lock->wait_lock);\n\t}\n\tspin_lock(&lock->wait_lock);\nacquired:\n\t__set_current_state(TASK_RUNNING);\n\n\tif (use_ww_ctx && ww_ctx) {\n\t\t/*\n\t\t * Wound-Wait; we stole the lock (!first_waiter), check the\n\t\t * waiters as anyone might want to wound us.\n\t\t */\n\t\tif (!ww_ctx->is_wait_die &&\n\t\t    !__mutex_waiter_is_first(lock, &waiter))\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\t}\n\n\tmutex_remove_waiter(lock, &waiter, current);\n\tif (likely(list_empty(&lock->wait_list)))\n\t\t__mutex_clear_flag(lock, MUTEX_FLAGS);\n\n\tdebug_mutex_free_waiter(&waiter);\n\nskip_wait:\n\t/* got the lock - cleanup and rejoice! */\n\tlock_acquired(&lock->dep_map, ip);\n\n\tif (use_ww_ctx && ww_ctx)\n\t\tww_mutex_lock_acquired(ww, ww_ctx);\n\n\tspin_unlock(&lock->wait_lock);\n\tpreempt_enable();\n\treturn 0;\n\nerr:\n\t__set_current_state(TASK_RUNNING);\n\tmutex_remove_waiter(lock, &waiter, current);\nerr_early_kill:\n\tspin_unlock(&lock->wait_lock);\n\tdebug_mutex_free_waiter(&waiter);\n\tmutex_release(&lock->dep_map, 1, ip);\n\tpreempt_enable();\n\treturn ret;\n}"
  },
  {
    "function_name": "__ww_mutex_add_waiter",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "824-893",
    "snippet": "static inline int __sched\n__ww_mutex_add_waiter(struct mutex_waiter *waiter,\n\t\t      struct mutex *lock,\n\t\t      struct ww_acquire_ctx *ww_ctx)\n{\n\tstruct mutex_waiter *cur;\n\tstruct list_head *pos;\n\tbool is_wait_die;\n\n\tif (!ww_ctx) {\n\t\t__mutex_add_waiter(lock, waiter, &lock->wait_list);\n\t\treturn 0;\n\t}\n\n\tis_wait_die = ww_ctx->is_wait_die;\n\n\t/*\n\t * Add the waiter before the first waiter with a higher stamp.\n\t * Waiters without a context are skipped to avoid starving\n\t * them. Wait-Die waiters may die here. Wound-Wait waiters\n\t * never die here, but they are sorted in stamp order and\n\t * may wound the lock holder.\n\t */\n\tpos = &lock->wait_list;\n\tlist_for_each_entry_reverse(cur, &lock->wait_list, list) {\n\t\tif (!cur->ww_ctx)\n\t\t\tcontinue;\n\n\t\tif (__ww_ctx_stamp_after(ww_ctx, cur->ww_ctx)) {\n\t\t\t/*\n\t\t\t * Wait-Die: if we find an older context waiting, there\n\t\t\t * is no point in queueing behind it, as we'd have to\n\t\t\t * die the moment it would acquire the lock.\n\t\t\t */\n\t\t\tif (is_wait_die) {\n\t\t\t\tint ret = __ww_mutex_kill(lock, ww_ctx);\n\n\t\t\t\tif (ret)\n\t\t\t\t\treturn ret;\n\t\t\t}\n\n\t\t\tbreak;\n\t\t}\n\n\t\tpos = &cur->list;\n\n\t\t/* Wait-Die: ensure younger waiters die. */\n\t\t__ww_mutex_die(lock, cur, ww_ctx);\n\t}\n\n\t__mutex_add_waiter(lock, waiter, pos);\n\n\t/*\n\t * Wound-Wait: if we're blocking on a mutex owned by a younger context,\n\t * wound that such that we might proceed.\n\t */\n\tif (!is_wait_die) {\n\t\tstruct ww_mutex *ww = container_of(lock, struct ww_mutex, base);\n\n\t\t/*\n\t\t * See ww_mutex_set_context_fastpath(). Orders setting\n\t\t * MUTEX_FLAG_WAITERS vs the ww->ctx load,\n\t\t * such that either we or the fastpath will wound @ww->ctx.\n\t\t */\n\t\tsmp_mb();\n\t\t__ww_mutex_wound(lock, ww_ctx, ww->ctx);\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [
      "#define MUTEX_FLAG_WAITERS\t0x01"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__ww_mutex_wound",
          "args": [
            "lock",
            "ww_ctx",
            "ww->ctx"
          ],
          "line": 889
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_wound",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "362-402",
          "snippet": "static bool __ww_mutex_wound(struct mutex *lock,\n\t\t\t     struct ww_acquire_ctx *ww_ctx,\n\t\t\t     struct ww_acquire_ctx *hold_ctx)\n{\n\tstruct task_struct *owner = __mutex_owner(lock);\n\n\tlockdep_assert_held(&lock->wait_lock);\n\n\t/*\n\t * Possible through __ww_mutex_add_waiter() when we race with\n\t * ww_mutex_set_context_fastpath(). In that case we'll get here again\n\t * through __ww_mutex_check_waiters().\n\t */\n\tif (!hold_ctx)\n\t\treturn false;\n\n\t/*\n\t * Can have !owner because of __mutex_unlock_slowpath(), but if owner,\n\t * it cannot go away because we'll have FLAG_WAITERS set and hold\n\t * wait_lock.\n\t */\n\tif (!owner)\n\t\treturn false;\n\n\tif (ww_ctx->acquired > 0 && __ww_ctx_stamp_after(hold_ctx, ww_ctx)) {\n\t\thold_ctx->wounded = 1;\n\n\t\t/*\n\t\t * wake_up_process() paired with set_current_state()\n\t\t * inserts sufficient barriers to make sure @owner either sees\n\t\t * it's wounded in __ww_mutex_check_kill() or has a\n\t\t * wakeup pending to re-read the wounded state.\n\t\t */\n\t\tif (owner != current)\n\t\t\twake_up_process(owner);\n\n\t\treturn true;\n\t}\n\n\treturn false;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic bool __ww_mutex_wound(struct mutex *lock,\n\t\t\t     struct ww_acquire_ctx *ww_ctx,\n\t\t\t     struct ww_acquire_ctx *hold_ctx)\n{\n\tstruct task_struct *owner = __mutex_owner(lock);\n\n\tlockdep_assert_held(&lock->wait_lock);\n\n\t/*\n\t * Possible through __ww_mutex_add_waiter() when we race with\n\t * ww_mutex_set_context_fastpath(). In that case we'll get here again\n\t * through __ww_mutex_check_waiters().\n\t */\n\tif (!hold_ctx)\n\t\treturn false;\n\n\t/*\n\t * Can have !owner because of __mutex_unlock_slowpath(), but if owner,\n\t * it cannot go away because we'll have FLAG_WAITERS set and hold\n\t * wait_lock.\n\t */\n\tif (!owner)\n\t\treturn false;\n\n\tif (ww_ctx->acquired > 0 && __ww_ctx_stamp_after(hold_ctx, ww_ctx)) {\n\t\thold_ctx->wounded = 1;\n\n\t\t/*\n\t\t * wake_up_process() paired with set_current_state()\n\t\t * inserts sufficient barriers to make sure @owner either sees\n\t\t * it's wounded in __ww_mutex_check_kill() or has a\n\t\t * wakeup pending to re-read the wounded state.\n\t\t */\n\t\tif (owner != current)\n\t\t\twake_up_process(owner);\n\n\t\treturn true;\n\t}\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "smp_mb",
          "args": [],
          "line": 888
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "lock",
            "structww_mutex",
            "base"
          ],
          "line": 881
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__mutex_add_waiter",
          "args": [
            "lock",
            "waiter",
            "pos"
          ],
          "line": 874
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_add_waiter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "180-189",
          "snippet": "static void __sched\n__mutex_add_waiter(struct mutex *lock, struct mutex_waiter *waiter,\n\t\t   struct list_head *list)\n{\n\tdebug_mutex_add_waiter(lock, waiter, current);\n\n\tlist_add_tail(&waiter->list, list);\n\tif (__mutex_waiter_is_first(lock, waiter))\n\t\t__mutex_set_flag(lock, MUTEX_FLAG_WAITERS);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAG_WAITERS\t0x01"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAG_WAITERS\t0x01\n\nstatic void __sched\n__mutex_add_waiter(struct mutex *lock, struct mutex_waiter *waiter,\n\t\t   struct list_head *list)\n{\n\tdebug_mutex_add_waiter(lock, waiter, current);\n\n\tlist_add_tail(&waiter->list, list);\n\tif (__mutex_waiter_is_first(lock, waiter))\n\t\t__mutex_set_flag(lock, MUTEX_FLAG_WAITERS);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__ww_mutex_die",
          "args": [
            "lock",
            "cur",
            "ww_ctx"
          ],
          "line": 871
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_die",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "339-353",
          "snippet": "static bool __sched\n__ww_mutex_die(struct mutex *lock, struct mutex_waiter *waiter,\n\t       struct ww_acquire_ctx *ww_ctx)\n{\n\tif (!ww_ctx->is_wait_die)\n\t\treturn false;\n\n\tif (waiter->ww_ctx->acquired > 0 &&\n\t\t\t__ww_ctx_stamp_after(waiter->ww_ctx, ww_ctx)) {\n\t\tdebug_mutex_wake_waiter(lock, waiter);\n\t\twake_up_process(waiter->task);\n\t}\n\n\treturn true;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic bool __sched\n__ww_mutex_die(struct mutex *lock, struct mutex_waiter *waiter,\n\t       struct ww_acquire_ctx *ww_ctx)\n{\n\tif (!ww_ctx->is_wait_die)\n\t\treturn false;\n\n\tif (waiter->ww_ctx->acquired > 0 &&\n\t\t\t__ww_ctx_stamp_after(waiter->ww_ctx, ww_ctx)) {\n\t\tdebug_mutex_wake_waiter(lock, waiter);\n\t\twake_up_process(waiter->task);\n\t}\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__ww_mutex_kill",
          "args": [
            "lock",
            "ww_ctx"
          ],
          "line": 859
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_kill",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "748-763",
          "snippet": "__sched\n__ww_mutex_kill(struct mutex *lock, struct ww_acquire_ctx *ww_ctx)\n{\n\tif (ww_ctx->acquired > 0) {\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\tstruct ww_mutex *ww;\n\n\t\tww = container_of(lock, struct ww_mutex, base);\n\t\tDEBUG_LOCKS_WARN_ON(ww_ctx->contending_lock);\n\t\tww_ctx->contending_lock = ww;\n#endif\n\t\treturn -EDEADLK;\n\t}\n\n\treturn 0;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__ww_mutex_kill(struct mutex *lock, struct ww_acquire_ctx *ww_ctx)\n{\n\tif (ww_ctx->acquired > 0) {\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\tstruct ww_mutex *ww;\n\n\t\tww = container_of(lock, struct ww_mutex, base);\n\t\tDEBUG_LOCKS_WARN_ON(ww_ctx->contending_lock);\n\t\tww_ctx->contending_lock = ww;\n#endif\n\t\treturn -EDEADLK;\n\t}\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__ww_ctx_stamp_after",
          "args": [
            "ww_ctx",
            "cur->ww_ctx"
          ],
          "line": 852
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_ctx_stamp_after",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "324-329",
          "snippet": "static inline bool __sched\n__ww_ctx_stamp_after(struct ww_acquire_ctx *a, struct ww_acquire_ctx *b)\n{\n\n\treturn (signed long)(a->stamp - b->stamp) > 0;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline bool __sched\n__ww_ctx_stamp_after(struct ww_acquire_ctx *a, struct ww_acquire_ctx *b)\n{\n\n\treturn (signed long)(a->stamp - b->stamp) > 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_for_each_entry_reverse",
          "args": [
            "cur",
            "&lock->wait_list",
            "list"
          ],
          "line": 848
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAG_WAITERS\t0x01\n\nstatic inline int __sched\n__ww_mutex_add_waiter(struct mutex_waiter *waiter,\n\t\t      struct mutex *lock,\n\t\t      struct ww_acquire_ctx *ww_ctx)\n{\n\tstruct mutex_waiter *cur;\n\tstruct list_head *pos;\n\tbool is_wait_die;\n\n\tif (!ww_ctx) {\n\t\t__mutex_add_waiter(lock, waiter, &lock->wait_list);\n\t\treturn 0;\n\t}\n\n\tis_wait_die = ww_ctx->is_wait_die;\n\n\t/*\n\t * Add the waiter before the first waiter with a higher stamp.\n\t * Waiters without a context are skipped to avoid starving\n\t * them. Wait-Die waiters may die here. Wound-Wait waiters\n\t * never die here, but they are sorted in stamp order and\n\t * may wound the lock holder.\n\t */\n\tpos = &lock->wait_list;\n\tlist_for_each_entry_reverse(cur, &lock->wait_list, list) {\n\t\tif (!cur->ww_ctx)\n\t\t\tcontinue;\n\n\t\tif (__ww_ctx_stamp_after(ww_ctx, cur->ww_ctx)) {\n\t\t\t/*\n\t\t\t * Wait-Die: if we find an older context waiting, there\n\t\t\t * is no point in queueing behind it, as we'd have to\n\t\t\t * die the moment it would acquire the lock.\n\t\t\t */\n\t\t\tif (is_wait_die) {\n\t\t\t\tint ret = __ww_mutex_kill(lock, ww_ctx);\n\n\t\t\t\tif (ret)\n\t\t\t\t\treturn ret;\n\t\t\t}\n\n\t\t\tbreak;\n\t\t}\n\n\t\tpos = &cur->list;\n\n\t\t/* Wait-Die: ensure younger waiters die. */\n\t\t__ww_mutex_die(lock, cur, ww_ctx);\n\t}\n\n\t__mutex_add_waiter(lock, waiter, pos);\n\n\t/*\n\t * Wound-Wait: if we're blocking on a mutex owned by a younger context,\n\t * wound that such that we might proceed.\n\t */\n\tif (!is_wait_die) {\n\t\tstruct ww_mutex *ww = container_of(lock, struct ww_mutex, base);\n\n\t\t/*\n\t\t * See ww_mutex_set_context_fastpath(). Orders setting\n\t\t * MUTEX_FLAG_WAITERS vs the ww->ctx load,\n\t\t * such that either we or the fastpath will wound @ww->ctx.\n\t\t */\n\t\tsmp_mb();\n\t\t__ww_mutex_wound(lock, ww_ctx, ww->ctx);\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "__ww_mutex_check_kill",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "777-811",
    "snippet": "static inline int __sched\n__ww_mutex_check_kill(struct mutex *lock, struct mutex_waiter *waiter,\n\t\t      struct ww_acquire_ctx *ctx)\n{\n\tstruct ww_mutex *ww = container_of(lock, struct ww_mutex, base);\n\tstruct ww_acquire_ctx *hold_ctx = READ_ONCE(ww->ctx);\n\tstruct mutex_waiter *cur;\n\n\tif (ctx->acquired == 0)\n\t\treturn 0;\n\n\tif (!ctx->is_wait_die) {\n\t\tif (ctx->wounded)\n\t\t\treturn __ww_mutex_kill(lock, ctx);\n\n\t\treturn 0;\n\t}\n\n\tif (hold_ctx && __ww_ctx_stamp_after(ctx, hold_ctx))\n\t\treturn __ww_mutex_kill(lock, ctx);\n\n\t/*\n\t * If there is a waiter in front of us that has a context, then its\n\t * stamp is earlier than ours and we must kill ourself.\n\t */\n\tcur = waiter;\n\tlist_for_each_entry_continue_reverse(cur, &lock->wait_list, list) {\n\t\tif (!cur->ww_ctx)\n\t\t\tcontinue;\n\n\t\treturn __ww_mutex_kill(lock, ctx);\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__ww_mutex_kill",
          "args": [
            "lock",
            "ctx"
          ],
          "line": 807
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_kill",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "748-763",
          "snippet": "__sched\n__ww_mutex_kill(struct mutex *lock, struct ww_acquire_ctx *ww_ctx)\n{\n\tif (ww_ctx->acquired > 0) {\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\tstruct ww_mutex *ww;\n\n\t\tww = container_of(lock, struct ww_mutex, base);\n\t\tDEBUG_LOCKS_WARN_ON(ww_ctx->contending_lock);\n\t\tww_ctx->contending_lock = ww;\n#endif\n\t\treturn -EDEADLK;\n\t}\n\n\treturn 0;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__ww_mutex_kill(struct mutex *lock, struct ww_acquire_ctx *ww_ctx)\n{\n\tif (ww_ctx->acquired > 0) {\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\tstruct ww_mutex *ww;\n\n\t\tww = container_of(lock, struct ww_mutex, base);\n\t\tDEBUG_LOCKS_WARN_ON(ww_ctx->contending_lock);\n\t\tww_ctx->contending_lock = ww;\n#endif\n\t\treturn -EDEADLK;\n\t}\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_for_each_entry_continue_reverse",
          "args": [
            "cur",
            "&lock->wait_list",
            "list"
          ],
          "line": 803
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__ww_ctx_stamp_after",
          "args": [
            "ctx",
            "hold_ctx"
          ],
          "line": 795
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_ctx_stamp_after",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "324-329",
          "snippet": "static inline bool __sched\n__ww_ctx_stamp_after(struct ww_acquire_ctx *a, struct ww_acquire_ctx *b)\n{\n\n\treturn (signed long)(a->stamp - b->stamp) > 0;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline bool __sched\n__ww_ctx_stamp_after(struct ww_acquire_ctx *a, struct ww_acquire_ctx *b)\n{\n\n\treturn (signed long)(a->stamp - b->stamp) > 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "ww->ctx"
          ],
          "line": 782
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "lock",
            "structww_mutex",
            "base"
          ],
          "line": 781
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline int __sched\n__ww_mutex_check_kill(struct mutex *lock, struct mutex_waiter *waiter,\n\t\t      struct ww_acquire_ctx *ctx)\n{\n\tstruct ww_mutex *ww = container_of(lock, struct ww_mutex, base);\n\tstruct ww_acquire_ctx *hold_ctx = READ_ONCE(ww->ctx);\n\tstruct mutex_waiter *cur;\n\n\tif (ctx->acquired == 0)\n\t\treturn 0;\n\n\tif (!ctx->is_wait_die) {\n\t\tif (ctx->wounded)\n\t\t\treturn __ww_mutex_kill(lock, ctx);\n\n\t\treturn 0;\n\t}\n\n\tif (hold_ctx && __ww_ctx_stamp_after(ctx, hold_ctx))\n\t\treturn __ww_mutex_kill(lock, ctx);\n\n\t/*\n\t * If there is a waiter in front of us that has a context, then its\n\t * stamp is earlier than ours and we must kill ourself.\n\t */\n\tcur = waiter;\n\tlist_for_each_entry_continue_reverse(cur, &lock->wait_list, list) {\n\t\tif (!cur->ww_ctx)\n\t\t\tcontinue;\n\n\t\treturn __ww_mutex_kill(lock, ctx);\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "__ww_mutex_kill",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "748-763",
    "snippet": "__sched\n__ww_mutex_kill(struct mutex *lock, struct ww_acquire_ctx *ww_ctx)\n{\n\tif (ww_ctx->acquired > 0) {\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\tstruct ww_mutex *ww;\n\n\t\tww = container_of(lock, struct ww_mutex, base);\n\t\tDEBUG_LOCKS_WARN_ON(ww_ctx->contending_lock);\n\t\tww_ctx->contending_lock = ww;\n#endif\n\t\treturn -EDEADLK;\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "DEBUG_LOCKS_WARN_ON",
          "args": [
            "ww_ctx->contending_lock"
          ],
          "line": 756
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "lock",
            "structww_mutex",
            "base"
          ],
          "line": 755
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__ww_mutex_kill(struct mutex *lock, struct ww_acquire_ctx *ww_ctx)\n{\n\tif (ww_ctx->acquired > 0) {\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\tstruct ww_mutex *ww;\n\n\t\tww = container_of(lock, struct ww_mutex, base);\n\t\tDEBUG_LOCKS_WARN_ON(ww_ctx->contending_lock);\n\t\tww_ctx->contending_lock = ww;\n#endif\n\t\treturn -EDEADLK;\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "ww_mutex_unlock",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "728-744",
    "snippet": "void __sched ww_mutex_unlock(struct ww_mutex *lock)\n{\n\t/*\n\t * The unlocking fastpath is the 0->1 transition from 'locked'\n\t * into 'unlocked' state:\n\t */\n\tif (lock->ctx) {\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\tDEBUG_LOCKS_WARN_ON(!lock->ctx->acquired);\n#endif\n\t\tif (lock->ctx->acquired > 0)\n\t\t\tlock->ctx->acquired--;\n\t\tlock->ctx = NULL;\n\t}\n\n\tmutex_unlock(&lock->base);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&lock->base"
          ],
          "line": 743
        },
        "resolved": true,
        "details": {
          "function_name": "ww_mutex_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "728-744",
          "snippet": "void __sched ww_mutex_unlock(struct ww_mutex *lock)\n{\n\t/*\n\t * The unlocking fastpath is the 0->1 transition from 'locked'\n\t * into 'unlocked' state:\n\t */\n\tif (lock->ctx) {\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\tDEBUG_LOCKS_WARN_ON(!lock->ctx->acquired);\n#endif\n\t\tif (lock->ctx->acquired > 0)\n\t\t\tlock->ctx->acquired--;\n\t\tlock->ctx = NULL;\n\t}\n\n\tmutex_unlock(&lock->base);\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "DEBUG_LOCKS_WARN_ON",
          "args": [
            "!lock->ctx->acquired"
          ],
          "line": 736
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nvoid __sched ww_mutex_unlock(struct ww_mutex *lock)\n{\n\t/*\n\t * The unlocking fastpath is the 0->1 transition from 'locked'\n\t * into 'unlocked' state:\n\t */\n\tif (lock->ctx) {\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\tDEBUG_LOCKS_WARN_ON(!lock->ctx->acquired);\n#endif\n\t\tif (lock->ctx->acquired > 0)\n\t\t\tlock->ctx->acquired--;\n\t\tlock->ctx = NULL;\n\t}\n\n\tmutex_unlock(&lock->base);\n}"
  },
  {
    "function_name": "mutex_unlock",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "707-714",
    "snippet": "void __sched mutex_unlock(struct mutex *lock)\n{\n#ifndef CONFIG_DEBUG_LOCK_ALLOC\n\tif (__mutex_unlock_fast(lock))\n\t\treturn;\n#endif\n\t__mutex_unlock_slowpath(lock, _RET_IP_);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_unlock_slowpath",
          "args": [
            "lock",
            "_RET_IP_"
          ],
          "line": 713
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_unlock_slowpath",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "1191-1250",
          "snippet": "__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip)\n{\n\tstruct task_struct *next = NULL;\n\tDEFINE_WAKE_Q(wake_q);\n\tunsigned long owner;\n\n\tmutex_release(&lock->dep_map, 1, ip);\n\n\t/*\n\t * Release the lock before (potentially) taking the spinlock such that\n\t * other contenders can get on with things ASAP.\n\t *\n\t * Except when HANDOFF, in that case we must not clear the owner field,\n\t * but instead set it to the top waiter.\n\t */\n\towner = atomic_long_read(&lock->owner);\n\tfor (;;) {\n\t\tunsigned long old;\n\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\tDEBUG_LOCKS_WARN_ON(__owner_task(owner) != current);\n\t\tDEBUG_LOCKS_WARN_ON(owner & MUTEX_FLAG_PICKUP);\n#endif\n\n\t\tif (owner & MUTEX_FLAG_HANDOFF)\n\t\t\tbreak;\n\n\t\told = atomic_long_cmpxchg_release(&lock->owner, owner,\n\t\t\t\t\t\t  __owner_flags(owner));\n\t\tif (old == owner) {\n\t\t\tif (owner & MUTEX_FLAG_WAITERS)\n\t\t\t\tbreak;\n\n\t\t\treturn;\n\t\t}\n\n\t\towner = old;\n\t}\n\n\tspin_lock(&lock->wait_lock);\n\tdebug_mutex_unlock(lock);\n\tif (!list_empty(&lock->wait_list)) {\n\t\t/* get the first entry from the wait-list: */\n\t\tstruct mutex_waiter *waiter =\n\t\t\tlist_first_entry(&lock->wait_list,\n\t\t\t\t\t struct mutex_waiter, list);\n\n\t\tnext = waiter->task;\n\n\t\tdebug_mutex_wake_waiter(lock, waiter);\n\t\twake_q_add(&wake_q, next);\n\t}\n\n\tif (owner & MUTEX_FLAG_HANDOFF)\n\t\t__mutex_handoff(lock, next);\n\n\tspin_unlock(&lock->wait_lock);\n\n\twake_up_q(&wake_q);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAG_PICKUP\t0x04",
            "#define MUTEX_FLAG_HANDOFF\t0x02",
            "#define MUTEX_FLAG_WAITERS\t0x01"
          ],
          "globals_used": [
            "__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAG_PICKUP\t0x04\n#define MUTEX_FLAG_HANDOFF\t0x02\n#define MUTEX_FLAG_WAITERS\t0x01\n\n__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip);\n\n__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip)\n{\n\tstruct task_struct *next = NULL;\n\tDEFINE_WAKE_Q(wake_q);\n\tunsigned long owner;\n\n\tmutex_release(&lock->dep_map, 1, ip);\n\n\t/*\n\t * Release the lock before (potentially) taking the spinlock such that\n\t * other contenders can get on with things ASAP.\n\t *\n\t * Except when HANDOFF, in that case we must not clear the owner field,\n\t * but instead set it to the top waiter.\n\t */\n\towner = atomic_long_read(&lock->owner);\n\tfor (;;) {\n\t\tunsigned long old;\n\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\tDEBUG_LOCKS_WARN_ON(__owner_task(owner) != current);\n\t\tDEBUG_LOCKS_WARN_ON(owner & MUTEX_FLAG_PICKUP);\n#endif\n\n\t\tif (owner & MUTEX_FLAG_HANDOFF)\n\t\t\tbreak;\n\n\t\told = atomic_long_cmpxchg_release(&lock->owner, owner,\n\t\t\t\t\t\t  __owner_flags(owner));\n\t\tif (old == owner) {\n\t\t\tif (owner & MUTEX_FLAG_WAITERS)\n\t\t\t\tbreak;\n\n\t\t\treturn;\n\t\t}\n\n\t\towner = old;\n\t}\n\n\tspin_lock(&lock->wait_lock);\n\tdebug_mutex_unlock(lock);\n\tif (!list_empty(&lock->wait_list)) {\n\t\t/* get the first entry from the wait-list: */\n\t\tstruct mutex_waiter *waiter =\n\t\t\tlist_first_entry(&lock->wait_list,\n\t\t\t\t\t struct mutex_waiter, list);\n\n\t\tnext = waiter->task;\n\n\t\tdebug_mutex_wake_waiter(lock, waiter);\n\t\twake_q_add(&wake_q, next);\n\t}\n\n\tif (owner & MUTEX_FLAG_HANDOFF)\n\t\t__mutex_handoff(lock, next);\n\n\tspin_unlock(&lock->wait_lock);\n\n\twake_up_q(&wake_q);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_unlock_fast",
          "args": [
            "lock"
          ],
          "line": 710
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_unlock_fast",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "150-158",
          "snippet": "static __always_inline bool __mutex_unlock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\n\tif (atomic_long_cmpxchg_release(&lock->owner, curr, 0UL) == curr)\n\t\treturn true;\n\n\treturn false;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline int",
            "static __always_inline int"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline int;\nstatic __always_inline int;\n\nstatic __always_inline bool __mutex_unlock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\n\tif (atomic_long_cmpxchg_release(&lock->owner, curr, 0UL) == curr)\n\t\treturn true;\n\n\treturn false;\n}"
        }
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nvoid __sched mutex_unlock(struct mutex *lock)\n{\n#ifndef CONFIG_DEBUG_LOCK_ALLOC\n\tif (__mutex_unlock_fast(lock))\n\t\treturn;\n#endif\n\t__mutex_unlock_slowpath(lock, _RET_IP_);\n}"
  },
  {
    "function_name": "mutex_optimistic_spin",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "686-691",
    "snippet": "static __always_inline bool\nmutex_optimistic_spin(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,\n\t\t      const bool use_ww_ctx, struct mutex_waiter *waiter)\n{\n\treturn false;\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline int",
      "static __always_inline int"
    ],
    "called_functions": [],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline int;\nstatic __always_inline int;\n\nstatic __always_inline bool\nmutex_optimistic_spin(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,\n\t\t      const bool use_ww_ctx, struct mutex_waiter *waiter)\n{\n\treturn false;\n}"
  },
  {
    "function_name": "mutex_optimistic_spin",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "610-684",
    "snippet": "static __always_inline bool\nmutex_optimistic_spin(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,\n\t\t      const bool use_ww_ctx, struct mutex_waiter *waiter)\n{\n\tif (!waiter) {\n\t\t/*\n\t\t * The purpose of the mutex_can_spin_on_owner() function is\n\t\t * to eliminate the overhead of osq_lock() and osq_unlock()\n\t\t * in case spinning isn't possible. As a waiter-spinner\n\t\t * is not going to take OSQ lock anyway, there is no need\n\t\t * to call mutex_can_spin_on_owner().\n\t\t */\n\t\tif (!mutex_can_spin_on_owner(lock))\n\t\t\tgoto fail;\n\n\t\t/*\n\t\t * In order to avoid a stampede of mutex spinners trying to\n\t\t * acquire the mutex all at once, the spinners need to take a\n\t\t * MCS (queued) lock first before spinning on the owner field.\n\t\t */\n\t\tif (!osq_lock(&lock->osq))\n\t\t\tgoto fail;\n\t}\n\n\tfor (;;) {\n\t\tstruct task_struct *owner;\n\n\t\t/* Try to acquire the mutex... */\n\t\towner = __mutex_trylock_or_owner(lock);\n\t\tif (!owner)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * There's an owner, wait for it to either\n\t\t * release the lock or go to sleep.\n\t\t */\n\t\tif (!mutex_spin_on_owner(lock, owner, ww_ctx, waiter))\n\t\t\tgoto fail_unlock;\n\n\t\t/*\n\t\t * The cpu_relax() call is a compiler barrier which forces\n\t\t * everything in this loop to be re-loaded. We don't need\n\t\t * memory barriers as we'll eventually observe the right\n\t\t * values at the cost of a few extra spins.\n\t\t */\n\t\tcpu_relax();\n\t}\n\n\tif (!waiter)\n\t\tosq_unlock(&lock->osq);\n\n\treturn true;\n\n\nfail_unlock:\n\tif (!waiter)\n\t\tosq_unlock(&lock->osq);\n\nfail:\n\t/*\n\t * If we fell out of the spin path because of need_resched(),\n\t * reschedule now, before we try-lock the mutex. This avoids getting\n\t * scheduled out right after we obtained the mutex.\n\t */\n\tif (need_resched()) {\n\t\t/*\n\t\t * We _should_ have TASK_RUNNING here, but just in case\n\t\t * we do not, make it so, otherwise we might get stuck.\n\t\t */\n\t\t__set_current_state(TASK_RUNNING);\n\t\tschedule_preempt_disabled();\n\t}\n\n\treturn false;\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline int",
      "static __always_inline int"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "schedule_preempt_disabled",
          "args": [],
          "line": 680
        },
        "resolved": true,
        "details": {
          "function_name": "schedule_preempt_disabled",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/core.c",
          "lines": "3571-3576",
          "snippet": "void __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}",
          "includes": [
            "#include \"features.h\"",
            "#include <trace/events/sched.h>",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/kcov.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include <trace/events/sched.h>\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/kcov.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n\nstatic void __sched;\nstatic void __sched;\n\nvoid __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "__set_current_state",
          "args": [
            "TASK_RUNNING"
          ],
          "line": 679
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "need_resched",
          "args": [],
          "line": 674
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "osq_unlock",
          "args": [
            "&lock->osq"
          ],
          "line": 666
        },
        "resolved": true,
        "details": {
          "function_name": "osq_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/osq_lock.c",
          "lines": "206-231",
          "snippet": "void osq_unlock(struct optimistic_spin_queue *lock)\n{\n\tstruct optimistic_spin_node *node, *next;\n\tint curr = encode_cpu(smp_processor_id());\n\n\t/*\n\t * Fast path for the uncontended case.\n\t */\n\tif (likely(atomic_cmpxchg_release(&lock->tail, curr,\n\t\t\t\t\t  OSQ_UNLOCKED_VAL) == curr))\n\t\treturn;\n\n\t/*\n\t * Second most likely case.\n\t */\n\tnode = this_cpu_ptr(&osq_node);\n\tnext = xchg(&node->next, NULL);\n\tif (next) {\n\t\tWRITE_ONCE(next->locked, 1);\n\t\treturn;\n\t}\n\n\tnext = osq_wait_next(lock, node, NULL);\n\tif (next)\n\t\tWRITE_ONCE(next->locked, 1);\n}",
          "includes": [
            "#include <linux/osq_lock.h>",
            "#include <linux/sched.h>",
            "#include <linux/percpu.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct optimistic_spin_node, osq_node);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/osq_lock.h>\n#include <linux/sched.h>\n#include <linux/percpu.h>\n\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct optimistic_spin_node, osq_node);\n\nvoid osq_unlock(struct optimistic_spin_queue *lock)\n{\n\tstruct optimistic_spin_node *node, *next;\n\tint curr = encode_cpu(smp_processor_id());\n\n\t/*\n\t * Fast path for the uncontended case.\n\t */\n\tif (likely(atomic_cmpxchg_release(&lock->tail, curr,\n\t\t\t\t\t  OSQ_UNLOCKED_VAL) == curr))\n\t\treturn;\n\n\t/*\n\t * Second most likely case.\n\t */\n\tnode = this_cpu_ptr(&osq_node);\n\tnext = xchg(&node->next, NULL);\n\tif (next) {\n\t\tWRITE_ONCE(next->locked, 1);\n\t\treturn;\n\t}\n\n\tnext = osq_wait_next(lock, node, NULL);\n\tif (next)\n\t\tWRITE_ONCE(next->locked, 1);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpu_relax",
          "args": [],
          "line": 655
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_spin_on_owner",
          "args": [
            "lock",
            "owner",
            "ww_ctx",
            "waiter"
          ],
          "line": 646
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_spin_on_owner",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "522-557",
          "snippet": "static noinline\nbool mutex_spin_on_owner(struct mutex *lock, struct task_struct *owner,\n\t\t\t struct ww_acquire_ctx *ww_ctx, struct mutex_waiter *waiter)\n{\n\tbool ret = true;\n\n\trcu_read_lock();\n\twhile (__mutex_owner(lock) == owner) {\n\t\t/*\n\t\t * Ensure we emit the owner->on_cpu, dereference _after_\n\t\t * checking lock->owner still matches owner. If that fails,\n\t\t * owner might point to freed memory. If it still matches,\n\t\t * the rcu_read_lock() ensures the memory stays valid.\n\t\t */\n\t\tbarrier();\n\n\t\t/*\n\t\t * Use vcpu_is_preempted to detect lock holder preemption issue.\n\t\t */\n\t\tif (!owner->on_cpu || need_resched() ||\n\t\t\t\tvcpu_is_preempted(task_cpu(owner))) {\n\t\t\tret = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (ww_ctx && !ww_mutex_spin_on_owner(lock, ww_ctx, waiter)) {\n\t\t\tret = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tcpu_relax();\n\t}\n\trcu_read_unlock();\n\n\treturn ret;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static noinline void",
            "static noinline void"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic noinline void;\nstatic noinline void;\n\nstatic noinline\nbool mutex_spin_on_owner(struct mutex *lock, struct task_struct *owner,\n\t\t\t struct ww_acquire_ctx *ww_ctx, struct mutex_waiter *waiter)\n{\n\tbool ret = true;\n\n\trcu_read_lock();\n\twhile (__mutex_owner(lock) == owner) {\n\t\t/*\n\t\t * Ensure we emit the owner->on_cpu, dereference _after_\n\t\t * checking lock->owner still matches owner. If that fails,\n\t\t * owner might point to freed memory. If it still matches,\n\t\t * the rcu_read_lock() ensures the memory stays valid.\n\t\t */\n\t\tbarrier();\n\n\t\t/*\n\t\t * Use vcpu_is_preempted to detect lock holder preemption issue.\n\t\t */\n\t\tif (!owner->on_cpu || need_resched() ||\n\t\t\t\tvcpu_is_preempted(task_cpu(owner))) {\n\t\t\tret = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (ww_ctx && !ww_mutex_spin_on_owner(lock, ww_ctx, waiter)) {\n\t\t\tret = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tcpu_relax();\n\t}\n\trcu_read_unlock();\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_trylock_or_owner",
          "args": [
            "lock"
          ],
          "line": 638
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_trylock_or_owner",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "80-118",
          "snippet": "static inline struct task_struct *__mutex_trylock_or_owner(struct mutex *lock)\n{\n\tunsigned long owner, curr = (unsigned long)current;\n\n\towner = atomic_long_read(&lock->owner);\n\tfor (;;) { /* must loop, can race against a flag */\n\t\tunsigned long old, flags = __owner_flags(owner);\n\t\tunsigned long task = owner & ~MUTEX_FLAGS;\n\n\t\tif (task) {\n\t\t\tif (likely(task != curr))\n\t\t\t\tbreak;\n\n\t\t\tif (likely(!(flags & MUTEX_FLAG_PICKUP)))\n\t\t\t\tbreak;\n\n\t\t\tflags &= ~MUTEX_FLAG_PICKUP;\n\t\t} else {\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\t\tDEBUG_LOCKS_WARN_ON(flags & MUTEX_FLAG_PICKUP);\n#endif\n\t\t}\n\n\t\t/*\n\t\t * We set the HANDOFF bit, we must make sure it doesn't live\n\t\t * past the point where we acquire it. This would be possible\n\t\t * if we (accidentally) set the bit on an unlocked mutex.\n\t\t */\n\t\tflags &= ~MUTEX_FLAG_HANDOFF;\n\n\t\told = atomic_long_cmpxchg_acquire(&lock->owner, owner, curr | flags);\n\t\tif (old == owner)\n\t\t\treturn NULL;\n\n\t\towner = old;\n\t}\n\n\treturn __owner_task(owner);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAGS\t\t0x07",
            "#define MUTEX_FLAG_PICKUP\t0x04",
            "#define MUTEX_FLAG_HANDOFF\t0x02"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n#define MUTEX_FLAG_PICKUP\t0x04\n#define MUTEX_FLAG_HANDOFF\t0x02\n\nstatic inline struct task_struct *__mutex_trylock_or_owner(struct mutex *lock)\n{\n\tunsigned long owner, curr = (unsigned long)current;\n\n\towner = atomic_long_read(&lock->owner);\n\tfor (;;) { /* must loop, can race against a flag */\n\t\tunsigned long old, flags = __owner_flags(owner);\n\t\tunsigned long task = owner & ~MUTEX_FLAGS;\n\n\t\tif (task) {\n\t\t\tif (likely(task != curr))\n\t\t\t\tbreak;\n\n\t\t\tif (likely(!(flags & MUTEX_FLAG_PICKUP)))\n\t\t\t\tbreak;\n\n\t\t\tflags &= ~MUTEX_FLAG_PICKUP;\n\t\t} else {\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\t\tDEBUG_LOCKS_WARN_ON(flags & MUTEX_FLAG_PICKUP);\n#endif\n\t\t}\n\n\t\t/*\n\t\t * We set the HANDOFF bit, we must make sure it doesn't live\n\t\t * past the point where we acquire it. This would be possible\n\t\t * if we (accidentally) set the bit on an unlocked mutex.\n\t\t */\n\t\tflags &= ~MUTEX_FLAG_HANDOFF;\n\n\t\told = atomic_long_cmpxchg_acquire(&lock->owner, owner, curr | flags);\n\t\tif (old == owner)\n\t\t\treturn NULL;\n\n\t\towner = old;\n\t}\n\n\treturn __owner_task(owner);\n}"
        }
      },
      {
        "call_info": {
          "callee": "osq_lock",
          "args": [
            "&lock->osq"
          ],
          "line": 630
        },
        "resolved": true,
        "details": {
          "function_name": "osq_lock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/osq_lock.c",
          "lines": "90-204",
          "snippet": "bool osq_lock(struct optimistic_spin_queue *lock)\n{\n\tstruct optimistic_spin_node *node = this_cpu_ptr(&osq_node);\n\tstruct optimistic_spin_node *prev, *next;\n\tint curr = encode_cpu(smp_processor_id());\n\tint old;\n\n\tnode->locked = 0;\n\tnode->next = NULL;\n\tnode->cpu = curr;\n\n\t/*\n\t * We need both ACQUIRE (pairs with corresponding RELEASE in\n\t * unlock() uncontended, or fastpath) and RELEASE (to publish\n\t * the node fields we just initialised) semantics when updating\n\t * the lock tail.\n\t */\n\told = atomic_xchg(&lock->tail, curr);\n\tif (old == OSQ_UNLOCKED_VAL)\n\t\treturn true;\n\n\tprev = decode_cpu(old);\n\tnode->prev = prev;\n\n\t/*\n\t * osq_lock()\t\t\tunqueue\n\t *\n\t * node->prev = prev\t\tosq_wait_next()\n\t * WMB\t\t\t\tMB\n\t * prev->next = node\t\tnext->prev = prev // unqueue-C\n\t *\n\t * Here 'node->prev' and 'next->prev' are the same variable and we need\n\t * to ensure these stores happen in-order to avoid corrupting the list.\n\t */\n\tsmp_wmb();\n\n\tWRITE_ONCE(prev->next, node);\n\n\t/*\n\t * Normally @prev is untouchable after the above store; because at that\n\t * moment unlock can proceed and wipe the node element from stack.\n\t *\n\t * However, since our nodes are static per-cpu storage, we're\n\t * guaranteed their existence -- this allows us to apply\n\t * cmpxchg in an attempt to undo our queueing.\n\t */\n\n\twhile (!READ_ONCE(node->locked)) {\n\t\t/*\n\t\t * If we need to reschedule bail... so we can block.\n\t\t * Use vcpu_is_preempted() to avoid waiting for a preempted\n\t\t * lock holder:\n\t\t */\n\t\tif (need_resched() || vcpu_is_preempted(node_cpu(node->prev)))\n\t\t\tgoto unqueue;\n\n\t\tcpu_relax();\n\t}\n\treturn true;\n\nunqueue:\n\t/*\n\t * Step - A  -- stabilize @prev\n\t *\n\t * Undo our @prev->next assignment; this will make @prev's\n\t * unlock()/unqueue() wait for a next pointer since @lock points to us\n\t * (or later).\n\t */\n\n\tfor (;;) {\n\t\tif (prev->next == node &&\n\t\t    cmpxchg(&prev->next, node, NULL) == node)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * We can only fail the cmpxchg() racing against an unlock(),\n\t\t * in which case we should observe @node->locked becomming\n\t\t * true.\n\t\t */\n\t\tif (smp_load_acquire(&node->locked))\n\t\t\treturn true;\n\n\t\tcpu_relax();\n\n\t\t/*\n\t\t * Or we race against a concurrent unqueue()'s step-B, in which\n\t\t * case its step-C will write us a new @node->prev pointer.\n\t\t */\n\t\tprev = READ_ONCE(node->prev);\n\t}\n\n\t/*\n\t * Step - B -- stabilize @next\n\t *\n\t * Similar to unlock(), wait for @node->next or move @lock from @node\n\t * back to @prev.\n\t */\n\n\tnext = osq_wait_next(lock, node, prev);\n\tif (!next)\n\t\treturn false;\n\n\t/*\n\t * Step - C -- unlink\n\t *\n\t * @prev is stable because its still waiting for a new @prev->next\n\t * pointer, @next is stable because our @node->next pointer is NULL and\n\t * it will wait in Step-A.\n\t */\n\n\tWRITE_ONCE(next->prev, prev);\n\tWRITE_ONCE(prev->next, next);\n\n\treturn false;\n}",
          "includes": [
            "#include <linux/osq_lock.h>",
            "#include <linux/sched.h>",
            "#include <linux/percpu.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct optimistic_spin_node, osq_node);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/osq_lock.h>\n#include <linux/sched.h>\n#include <linux/percpu.h>\n\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct optimistic_spin_node, osq_node);\n\nbool osq_lock(struct optimistic_spin_queue *lock)\n{\n\tstruct optimistic_spin_node *node = this_cpu_ptr(&osq_node);\n\tstruct optimistic_spin_node *prev, *next;\n\tint curr = encode_cpu(smp_processor_id());\n\tint old;\n\n\tnode->locked = 0;\n\tnode->next = NULL;\n\tnode->cpu = curr;\n\n\t/*\n\t * We need both ACQUIRE (pairs with corresponding RELEASE in\n\t * unlock() uncontended, or fastpath) and RELEASE (to publish\n\t * the node fields we just initialised) semantics when updating\n\t * the lock tail.\n\t */\n\told = atomic_xchg(&lock->tail, curr);\n\tif (old == OSQ_UNLOCKED_VAL)\n\t\treturn true;\n\n\tprev = decode_cpu(old);\n\tnode->prev = prev;\n\n\t/*\n\t * osq_lock()\t\t\tunqueue\n\t *\n\t * node->prev = prev\t\tosq_wait_next()\n\t * WMB\t\t\t\tMB\n\t * prev->next = node\t\tnext->prev = prev // unqueue-C\n\t *\n\t * Here 'node->prev' and 'next->prev' are the same variable and we need\n\t * to ensure these stores happen in-order to avoid corrupting the list.\n\t */\n\tsmp_wmb();\n\n\tWRITE_ONCE(prev->next, node);\n\n\t/*\n\t * Normally @prev is untouchable after the above store; because at that\n\t * moment unlock can proceed and wipe the node element from stack.\n\t *\n\t * However, since our nodes are static per-cpu storage, we're\n\t * guaranteed their existence -- this allows us to apply\n\t * cmpxchg in an attempt to undo our queueing.\n\t */\n\n\twhile (!READ_ONCE(node->locked)) {\n\t\t/*\n\t\t * If we need to reschedule bail... so we can block.\n\t\t * Use vcpu_is_preempted() to avoid waiting for a preempted\n\t\t * lock holder:\n\t\t */\n\t\tif (need_resched() || vcpu_is_preempted(node_cpu(node->prev)))\n\t\t\tgoto unqueue;\n\n\t\tcpu_relax();\n\t}\n\treturn true;\n\nunqueue:\n\t/*\n\t * Step - A  -- stabilize @prev\n\t *\n\t * Undo our @prev->next assignment; this will make @prev's\n\t * unlock()/unqueue() wait for a next pointer since @lock points to us\n\t * (or later).\n\t */\n\n\tfor (;;) {\n\t\tif (prev->next == node &&\n\t\t    cmpxchg(&prev->next, node, NULL) == node)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * We can only fail the cmpxchg() racing against an unlock(),\n\t\t * in which case we should observe @node->locked becomming\n\t\t * true.\n\t\t */\n\t\tif (smp_load_acquire(&node->locked))\n\t\t\treturn true;\n\n\t\tcpu_relax();\n\n\t\t/*\n\t\t * Or we race against a concurrent unqueue()'s step-B, in which\n\t\t * case its step-C will write us a new @node->prev pointer.\n\t\t */\n\t\tprev = READ_ONCE(node->prev);\n\t}\n\n\t/*\n\t * Step - B -- stabilize @next\n\t *\n\t * Similar to unlock(), wait for @node->next or move @lock from @node\n\t * back to @prev.\n\t */\n\n\tnext = osq_wait_next(lock, node, prev);\n\tif (!next)\n\t\treturn false;\n\n\t/*\n\t * Step - C -- unlink\n\t *\n\t * @prev is stable because its still waiting for a new @prev->next\n\t * pointer, @next is stable because our @node->next pointer is NULL and\n\t * it will wait in Step-A.\n\t */\n\n\tWRITE_ONCE(next->prev, prev);\n\tWRITE_ONCE(prev->next, next);\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_can_spin_on_owner",
          "args": [
            "lock"
          ],
          "line": 622
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_can_spin_on_owner",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "562-587",
          "snippet": "static inline int mutex_can_spin_on_owner(struct mutex *lock)\n{\n\tstruct task_struct *owner;\n\tint retval = 1;\n\n\tif (need_resched())\n\t\treturn 0;\n\n\trcu_read_lock();\n\towner = __mutex_owner(lock);\n\n\t/*\n\t * As lock holder preemption issue, we both skip spinning if task is not\n\t * on cpu or its cpu is preempted\n\t */\n\tif (owner)\n\t\tretval = owner->on_cpu && !vcpu_is_preempted(task_cpu(owner));\n\trcu_read_unlock();\n\n\t/*\n\t * If lock->owner is not set, the mutex has been released. Return true\n\t * such that we'll trylock in the spin path, which is a faster option\n\t * than the blocking slow path.\n\t */\n\treturn retval;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline int mutex_can_spin_on_owner(struct mutex *lock)\n{\n\tstruct task_struct *owner;\n\tint retval = 1;\n\n\tif (need_resched())\n\t\treturn 0;\n\n\trcu_read_lock();\n\towner = __mutex_owner(lock);\n\n\t/*\n\t * As lock holder preemption issue, we both skip spinning if task is not\n\t * on cpu or its cpu is preempted\n\t */\n\tif (owner)\n\t\tretval = owner->on_cpu && !vcpu_is_preempted(task_cpu(owner));\n\trcu_read_unlock();\n\n\t/*\n\t * If lock->owner is not set, the mutex has been released. Return true\n\t * such that we'll trylock in the spin path, which is a faster option\n\t * than the blocking slow path.\n\t */\n\treturn retval;\n}"
        }
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline int;\nstatic __always_inline int;\n\nstatic __always_inline bool\nmutex_optimistic_spin(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,\n\t\t      const bool use_ww_ctx, struct mutex_waiter *waiter)\n{\n\tif (!waiter) {\n\t\t/*\n\t\t * The purpose of the mutex_can_spin_on_owner() function is\n\t\t * to eliminate the overhead of osq_lock() and osq_unlock()\n\t\t * in case spinning isn't possible. As a waiter-spinner\n\t\t * is not going to take OSQ lock anyway, there is no need\n\t\t * to call mutex_can_spin_on_owner().\n\t\t */\n\t\tif (!mutex_can_spin_on_owner(lock))\n\t\t\tgoto fail;\n\n\t\t/*\n\t\t * In order to avoid a stampede of mutex spinners trying to\n\t\t * acquire the mutex all at once, the spinners need to take a\n\t\t * MCS (queued) lock first before spinning on the owner field.\n\t\t */\n\t\tif (!osq_lock(&lock->osq))\n\t\t\tgoto fail;\n\t}\n\n\tfor (;;) {\n\t\tstruct task_struct *owner;\n\n\t\t/* Try to acquire the mutex... */\n\t\towner = __mutex_trylock_or_owner(lock);\n\t\tif (!owner)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * There's an owner, wait for it to either\n\t\t * release the lock or go to sleep.\n\t\t */\n\t\tif (!mutex_spin_on_owner(lock, owner, ww_ctx, waiter))\n\t\t\tgoto fail_unlock;\n\n\t\t/*\n\t\t * The cpu_relax() call is a compiler barrier which forces\n\t\t * everything in this loop to be re-loaded. We don't need\n\t\t * memory barriers as we'll eventually observe the right\n\t\t * values at the cost of a few extra spins.\n\t\t */\n\t\tcpu_relax();\n\t}\n\n\tif (!waiter)\n\t\tosq_unlock(&lock->osq);\n\n\treturn true;\n\n\nfail_unlock:\n\tif (!waiter)\n\t\tosq_unlock(&lock->osq);\n\nfail:\n\t/*\n\t * If we fell out of the spin path because of need_resched(),\n\t * reschedule now, before we try-lock the mutex. This avoids getting\n\t * scheduled out right after we obtained the mutex.\n\t */\n\tif (need_resched()) {\n\t\t/*\n\t\t * We _should_ have TASK_RUNNING here, but just in case\n\t\t * we do not, make it so, otherwise we might get stuck.\n\t\t */\n\t\t__set_current_state(TASK_RUNNING);\n\t\tschedule_preempt_disabled();\n\t}\n\n\treturn false;\n}"
  },
  {
    "function_name": "mutex_can_spin_on_owner",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "562-587",
    "snippet": "static inline int mutex_can_spin_on_owner(struct mutex *lock)\n{\n\tstruct task_struct *owner;\n\tint retval = 1;\n\n\tif (need_resched())\n\t\treturn 0;\n\n\trcu_read_lock();\n\towner = __mutex_owner(lock);\n\n\t/*\n\t * As lock holder preemption issue, we both skip spinning if task is not\n\t * on cpu or its cpu is preempted\n\t */\n\tif (owner)\n\t\tretval = owner->on_cpu && !vcpu_is_preempted(task_cpu(owner));\n\trcu_read_unlock();\n\n\t/*\n\t * If lock->owner is not set, the mutex has been released. Return true\n\t * such that we'll trylock in the spin path, which is a faster option\n\t * than the blocking slow path.\n\t */\n\treturn retval;\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 579
        },
        "resolved": true,
        "details": {
          "function_name": "__rcu_read_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/tree_plugin.h",
          "lines": "419-441",
          "snippet": "void __rcu_read_unlock(void)\n{\n\tstruct task_struct *t = current;\n\n\tif (t->rcu_read_lock_nesting != 1) {\n\t\t--t->rcu_read_lock_nesting;\n\t} else {\n\t\tbarrier();  /* critical section before exit code. */\n\t\tt->rcu_read_lock_nesting = INT_MIN;\n\t\tbarrier();  /* assign before ->rcu_read_unlock_special load */\n\t\tif (unlikely(READ_ONCE(t->rcu_read_unlock_special.s)))\n\t\t\trcu_read_unlock_special(t);\n\t\tbarrier();  /* ->rcu_read_unlock_special load before assign */\n\t\tt->rcu_read_lock_nesting = 0;\n\t}\n#ifdef CONFIG_PROVE_LOCKING\n\t{\n\t\tint rrln = READ_ONCE(t->rcu_read_lock_nesting);\n\n\t\tWARN_ON_ONCE(rrln < 0 && rrln > INT_MIN / 2);\n\t}\n#endif /* #ifdef CONFIG_PROVE_LOCKING */\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"../time/tick-internal.h\"",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/oom.h>",
            "#include <linux/gfp.h>",
            "#include <linux/delay.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"../time/tick-internal.h\"\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/isolation.h>\n#include <linux/smpboot.h>\n#include <linux/sched/debug.h>\n#include <linux/oom.h>\n#include <linux/gfp.h>\n#include <linux/delay.h>\n\nvoid __rcu_read_unlock(void)\n{\n\tstruct task_struct *t = current;\n\n\tif (t->rcu_read_lock_nesting != 1) {\n\t\t--t->rcu_read_lock_nesting;\n\t} else {\n\t\tbarrier();  /* critical section before exit code. */\n\t\tt->rcu_read_lock_nesting = INT_MIN;\n\t\tbarrier();  /* assign before ->rcu_read_unlock_special load */\n\t\tif (unlikely(READ_ONCE(t->rcu_read_unlock_special.s)))\n\t\t\trcu_read_unlock_special(t);\n\t\tbarrier();  /* ->rcu_read_unlock_special load before assign */\n\t\tt->rcu_read_lock_nesting = 0;\n\t}\n#ifdef CONFIG_PROVE_LOCKING\n\t{\n\t\tint rrln = READ_ONCE(t->rcu_read_lock_nesting);\n\n\t\tWARN_ON_ONCE(rrln < 0 && rrln > INT_MIN / 2);\n\t}\n#endif /* #ifdef CONFIG_PROVE_LOCKING */\n}"
        }
      },
      {
        "call_info": {
          "callee": "vcpu_is_preempted",
          "args": [
            "task_cpu(owner)"
          ],
          "line": 578
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "task_cpu",
          "args": [
            "owner"
          ],
          "line": 578
        },
        "resolved": true,
        "details": {
          "function_name": "ignore_task_cpu",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ftrace.c",
          "lines": "6542-6556",
          "snippet": "static void ignore_task_cpu(void *data)\n{\n\tstruct trace_array *tr = data;\n\tstruct trace_pid_list *pid_list;\n\n\t/*\n\t * This function is called by on_each_cpu() while the\n\t * event_mutex is held.\n\t */\n\tpid_list = rcu_dereference_protected(tr->function_pids,\n\t\t\t\t\t     mutex_is_locked(&ftrace_lock));\n\n\tthis_cpu_write(tr->trace_buffer.data->ftrace_ignore_pid,\n\t\t       trace_ignore_this_task(pid_list, current));\n}",
          "includes": [
            "#include \"trace_stat.h\"",
            "#include \"trace_output.h\"",
            "#include <asm/setup.h>",
            "#include <asm/sections.h>",
            "#include <trace/events/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/hash.h>",
            "#include <linux/list.h>",
            "#include <linux/sort.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/module.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/kthread.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/tracefs.h>",
            "#include <linux/suspend.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/clocksource.h>",
            "#include <linux/stop_machine.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_MUTEX(ftrace_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"trace_stat.h\"\n#include \"trace_output.h\"\n#include <asm/setup.h>\n#include <asm/sections.h>\n#include <trace/events/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/hash.h>\n#include <linux/list.h>\n#include <linux/sort.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/sysctl.h>\n#include <linux/ftrace.h>\n#include <linux/module.h>\n#include <linux/bsearch.h>\n#include <linux/uaccess.h>\n#include <linux/kthread.h>\n#include <linux/hardirq.h>\n#include <linux/tracefs.h>\n#include <linux/suspend.h>\n#include <linux/seq_file.h>\n#include <linux/kallsyms.h>\n#include <linux/sched/task.h>\n#include <linux/clocksource.h>\n#include <linux/stop_machine.h>\n\nstatic DEFINE_MUTEX(ftrace_lock);\n\nstatic void ignore_task_cpu(void *data)\n{\n\tstruct trace_array *tr = data;\n\tstruct trace_pid_list *pid_list;\n\n\t/*\n\t * This function is called by on_each_cpu() while the\n\t * event_mutex is held.\n\t */\n\tpid_list = rcu_dereference_protected(tr->function_pids,\n\t\t\t\t\t     mutex_is_locked(&ftrace_lock));\n\n\tthis_cpu_write(tr->trace_buffer.data->ftrace_ignore_pid,\n\t\t       trace_ignore_this_task(pid_list, current));\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_owner",
          "args": [
            "lock"
          ],
          "line": 571
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 570
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_bh_held",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/update.c",
          "lines": "300-309",
          "snippet": "int rcu_read_lock_bh_held(void)\n{\n\tif (!debug_lockdep_rcu_enabled())\n\t\treturn 1;\n\tif (!rcu_is_watching())\n\t\treturn 0;\n\tif (!rcu_lockdep_current_cpu_online())\n\t\treturn 0;\n\treturn in_softirq() || irqs_disabled();\n}",
          "includes": [
            "#include \"rcu.h\"",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu.h\"\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_bh_held(void)\n{\n\tif (!debug_lockdep_rcu_enabled())\n\t\treturn 1;\n\tif (!rcu_is_watching())\n\t\treturn 0;\n\tif (!rcu_lockdep_current_cpu_online())\n\t\treturn 0;\n\treturn in_softirq() || irqs_disabled();\n}"
        }
      },
      {
        "call_info": {
          "callee": "need_resched",
          "args": [],
          "line": 567
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline int mutex_can_spin_on_owner(struct mutex *lock)\n{\n\tstruct task_struct *owner;\n\tint retval = 1;\n\n\tif (need_resched())\n\t\treturn 0;\n\n\trcu_read_lock();\n\towner = __mutex_owner(lock);\n\n\t/*\n\t * As lock holder preemption issue, we both skip spinning if task is not\n\t * on cpu or its cpu is preempted\n\t */\n\tif (owner)\n\t\tretval = owner->on_cpu && !vcpu_is_preempted(task_cpu(owner));\n\trcu_read_unlock();\n\n\t/*\n\t * If lock->owner is not set, the mutex has been released. Return true\n\t * such that we'll trylock in the spin path, which is a faster option\n\t * than the blocking slow path.\n\t */\n\treturn retval;\n}"
  },
  {
    "function_name": "mutex_spin_on_owner",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "522-557",
    "snippet": "static noinline\nbool mutex_spin_on_owner(struct mutex *lock, struct task_struct *owner,\n\t\t\t struct ww_acquire_ctx *ww_ctx, struct mutex_waiter *waiter)\n{\n\tbool ret = true;\n\n\trcu_read_lock();\n\twhile (__mutex_owner(lock) == owner) {\n\t\t/*\n\t\t * Ensure we emit the owner->on_cpu, dereference _after_\n\t\t * checking lock->owner still matches owner. If that fails,\n\t\t * owner might point to freed memory. If it still matches,\n\t\t * the rcu_read_lock() ensures the memory stays valid.\n\t\t */\n\t\tbarrier();\n\n\t\t/*\n\t\t * Use vcpu_is_preempted to detect lock holder preemption issue.\n\t\t */\n\t\tif (!owner->on_cpu || need_resched() ||\n\t\t\t\tvcpu_is_preempted(task_cpu(owner))) {\n\t\t\tret = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (ww_ctx && !ww_mutex_spin_on_owner(lock, ww_ctx, waiter)) {\n\t\t\tret = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tcpu_relax();\n\t}\n\trcu_read_unlock();\n\n\treturn ret;\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static noinline void",
      "static noinline void"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 554
        },
        "resolved": true,
        "details": {
          "function_name": "__rcu_read_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/tree_plugin.h",
          "lines": "419-441",
          "snippet": "void __rcu_read_unlock(void)\n{\n\tstruct task_struct *t = current;\n\n\tif (t->rcu_read_lock_nesting != 1) {\n\t\t--t->rcu_read_lock_nesting;\n\t} else {\n\t\tbarrier();  /* critical section before exit code. */\n\t\tt->rcu_read_lock_nesting = INT_MIN;\n\t\tbarrier();  /* assign before ->rcu_read_unlock_special load */\n\t\tif (unlikely(READ_ONCE(t->rcu_read_unlock_special.s)))\n\t\t\trcu_read_unlock_special(t);\n\t\tbarrier();  /* ->rcu_read_unlock_special load before assign */\n\t\tt->rcu_read_lock_nesting = 0;\n\t}\n#ifdef CONFIG_PROVE_LOCKING\n\t{\n\t\tint rrln = READ_ONCE(t->rcu_read_lock_nesting);\n\n\t\tWARN_ON_ONCE(rrln < 0 && rrln > INT_MIN / 2);\n\t}\n#endif /* #ifdef CONFIG_PROVE_LOCKING */\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"../time/tick-internal.h\"",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/oom.h>",
            "#include <linux/gfp.h>",
            "#include <linux/delay.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"../time/tick-internal.h\"\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/isolation.h>\n#include <linux/smpboot.h>\n#include <linux/sched/debug.h>\n#include <linux/oom.h>\n#include <linux/gfp.h>\n#include <linux/delay.h>\n\nvoid __rcu_read_unlock(void)\n{\n\tstruct task_struct *t = current;\n\n\tif (t->rcu_read_lock_nesting != 1) {\n\t\t--t->rcu_read_lock_nesting;\n\t} else {\n\t\tbarrier();  /* critical section before exit code. */\n\t\tt->rcu_read_lock_nesting = INT_MIN;\n\t\tbarrier();  /* assign before ->rcu_read_unlock_special load */\n\t\tif (unlikely(READ_ONCE(t->rcu_read_unlock_special.s)))\n\t\t\trcu_read_unlock_special(t);\n\t\tbarrier();  /* ->rcu_read_unlock_special load before assign */\n\t\tt->rcu_read_lock_nesting = 0;\n\t}\n#ifdef CONFIG_PROVE_LOCKING\n\t{\n\t\tint rrln = READ_ONCE(t->rcu_read_lock_nesting);\n\n\t\tWARN_ON_ONCE(rrln < 0 && rrln > INT_MIN / 2);\n\t}\n#endif /* #ifdef CONFIG_PROVE_LOCKING */\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpu_relax",
          "args": [],
          "line": 552
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ww_mutex_spin_on_owner",
          "args": [
            "lock",
            "ww_ctx",
            "waiter"
          ],
          "line": 547
        },
        "resolved": true,
        "details": {
          "function_name": "ww_mutex_spin_on_owner",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "474-514",
          "snippet": "static inline\nbool ww_mutex_spin_on_owner(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,\n\t\t\t    struct mutex_waiter *waiter)\n{\n\tstruct ww_mutex *ww;\n\n\tww = container_of(lock, struct ww_mutex, base);\n\n\t/*\n\t * If ww->ctx is set the contents are undefined, only\n\t * by acquiring wait_lock there is a guarantee that\n\t * they are not invalid when reading.\n\t *\n\t * As such, when deadlock detection needs to be\n\t * performed the optimistic spinning cannot be done.\n\t *\n\t * Check this in every inner iteration because we may\n\t * be racing against another thread's ww_mutex_lock.\n\t */\n\tif (ww_ctx->acquired > 0 && READ_ONCE(ww->ctx))\n\t\treturn false;\n\n\t/*\n\t * If we aren't on the wait list yet, cancel the spin\n\t * if there are waiters. We want  to avoid stealing the\n\t * lock from a waiter with an earlier stamp, since the\n\t * other thread may already own a lock that we also\n\t * need.\n\t */\n\tif (!waiter && (atomic_long_read(&lock->owner) & MUTEX_FLAG_WAITERS))\n\t\treturn false;\n\n\t/*\n\t * Similarly, stop spinning if we are no longer the\n\t * first waiter.\n\t */\n\tif (waiter && !__mutex_waiter_is_first(lock, waiter))\n\t\treturn false;\n\n\treturn true;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAG_WAITERS\t0x01"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAG_WAITERS\t0x01\n\nstatic inline\nbool ww_mutex_spin_on_owner(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,\n\t\t\t    struct mutex_waiter *waiter)\n{\n\tstruct ww_mutex *ww;\n\n\tww = container_of(lock, struct ww_mutex, base);\n\n\t/*\n\t * If ww->ctx is set the contents are undefined, only\n\t * by acquiring wait_lock there is a guarantee that\n\t * they are not invalid when reading.\n\t *\n\t * As such, when deadlock detection needs to be\n\t * performed the optimistic spinning cannot be done.\n\t *\n\t * Check this in every inner iteration because we may\n\t * be racing against another thread's ww_mutex_lock.\n\t */\n\tif (ww_ctx->acquired > 0 && READ_ONCE(ww->ctx))\n\t\treturn false;\n\n\t/*\n\t * If we aren't on the wait list yet, cancel the spin\n\t * if there are waiters. We want  to avoid stealing the\n\t * lock from a waiter with an earlier stamp, since the\n\t * other thread may already own a lock that we also\n\t * need.\n\t */\n\tif (!waiter && (atomic_long_read(&lock->owner) & MUTEX_FLAG_WAITERS))\n\t\treturn false;\n\n\t/*\n\t * Similarly, stop spinning if we are no longer the\n\t * first waiter.\n\t */\n\tif (waiter && !__mutex_waiter_is_first(lock, waiter))\n\t\treturn false;\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "vcpu_is_preempted",
          "args": [
            "task_cpu(owner)"
          ],
          "line": 542
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "task_cpu",
          "args": [
            "owner"
          ],
          "line": 542
        },
        "resolved": true,
        "details": {
          "function_name": "ignore_task_cpu",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/trace/ftrace.c",
          "lines": "6542-6556",
          "snippet": "static void ignore_task_cpu(void *data)\n{\n\tstruct trace_array *tr = data;\n\tstruct trace_pid_list *pid_list;\n\n\t/*\n\t * This function is called by on_each_cpu() while the\n\t * event_mutex is held.\n\t */\n\tpid_list = rcu_dereference_protected(tr->function_pids,\n\t\t\t\t\t     mutex_is_locked(&ftrace_lock));\n\n\tthis_cpu_write(tr->trace_buffer.data->ftrace_ignore_pid,\n\t\t       trace_ignore_this_task(pid_list, current));\n}",
          "includes": [
            "#include \"trace_stat.h\"",
            "#include \"trace_output.h\"",
            "#include <asm/setup.h>",
            "#include <asm/sections.h>",
            "#include <trace/events/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/hash.h>",
            "#include <linux/list.h>",
            "#include <linux/sort.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/module.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/kthread.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/tracefs.h>",
            "#include <linux/suspend.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/clocksource.h>",
            "#include <linux/stop_machine.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_MUTEX(ftrace_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"trace_stat.h\"\n#include \"trace_output.h\"\n#include <asm/setup.h>\n#include <asm/sections.h>\n#include <trace/events/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/hash.h>\n#include <linux/list.h>\n#include <linux/sort.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/sysctl.h>\n#include <linux/ftrace.h>\n#include <linux/module.h>\n#include <linux/bsearch.h>\n#include <linux/uaccess.h>\n#include <linux/kthread.h>\n#include <linux/hardirq.h>\n#include <linux/tracefs.h>\n#include <linux/suspend.h>\n#include <linux/seq_file.h>\n#include <linux/kallsyms.h>\n#include <linux/sched/task.h>\n#include <linux/clocksource.h>\n#include <linux/stop_machine.h>\n\nstatic DEFINE_MUTEX(ftrace_lock);\n\nstatic void ignore_task_cpu(void *data)\n{\n\tstruct trace_array *tr = data;\n\tstruct trace_pid_list *pid_list;\n\n\t/*\n\t * This function is called by on_each_cpu() while the\n\t * event_mutex is held.\n\t */\n\tpid_list = rcu_dereference_protected(tr->function_pids,\n\t\t\t\t\t     mutex_is_locked(&ftrace_lock));\n\n\tthis_cpu_write(tr->trace_buffer.data->ftrace_ignore_pid,\n\t\t       trace_ignore_this_task(pid_list, current));\n}"
        }
      },
      {
        "call_info": {
          "callee": "need_resched",
          "args": [],
          "line": 541
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "barrier",
          "args": [],
          "line": 536
        },
        "resolved": true,
        "details": {
          "function_name": "membarrier_register_global_expedited",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/membarrier.c",
          "lines": "189-219",
          "snippet": "static int membarrier_register_global_expedited(void)\n{\n\tstruct task_struct *p = current;\n\tstruct mm_struct *mm = p->mm;\n\n\tif (atomic_read(&mm->membarrier_state) &\n\t    MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY)\n\t\treturn 0;\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED, &mm->membarrier_state);\n\tif (atomic_read(&mm->mm_users) == 1 && get_nr_threads(p) == 1) {\n\t\t/*\n\t\t * For single mm user, single threaded process, we can\n\t\t * simply issue a memory barrier after setting\n\t\t * MEMBARRIER_STATE_GLOBAL_EXPEDITED to guarantee that\n\t\t * no memory access following registration is reordered\n\t\t * before registration.\n\t\t */\n\t\tsmp_mb();\n\t} else {\n\t\t/*\n\t\t * For multi-mm user threads, we need to ensure all\n\t\t * future scheduler executions will observe the new\n\t\t * thread flag state for this mm.\n\t\t */\n\t\tsynchronize_sched();\n\t}\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY,\n\t\t  &mm->membarrier_state);\n\n\treturn 0;\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nstatic int membarrier_register_global_expedited(void)\n{\n\tstruct task_struct *p = current;\n\tstruct mm_struct *mm = p->mm;\n\n\tif (atomic_read(&mm->membarrier_state) &\n\t    MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY)\n\t\treturn 0;\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED, &mm->membarrier_state);\n\tif (atomic_read(&mm->mm_users) == 1 && get_nr_threads(p) == 1) {\n\t\t/*\n\t\t * For single mm user, single threaded process, we can\n\t\t * simply issue a memory barrier after setting\n\t\t * MEMBARRIER_STATE_GLOBAL_EXPEDITED to guarantee that\n\t\t * no memory access following registration is reordered\n\t\t * before registration.\n\t\t */\n\t\tsmp_mb();\n\t} else {\n\t\t/*\n\t\t * For multi-mm user threads, we need to ensure all\n\t\t * future scheduler executions will observe the new\n\t\t * thread flag state for this mm.\n\t\t */\n\t\tsynchronize_sched();\n\t}\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY,\n\t\t  &mm->membarrier_state);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_owner",
          "args": [
            "lock"
          ],
          "line": 529
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 528
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_bh_held",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/update.c",
          "lines": "300-309",
          "snippet": "int rcu_read_lock_bh_held(void)\n{\n\tif (!debug_lockdep_rcu_enabled())\n\t\treturn 1;\n\tif (!rcu_is_watching())\n\t\treturn 0;\n\tif (!rcu_lockdep_current_cpu_online())\n\t\treturn 0;\n\treturn in_softirq() || irqs_disabled();\n}",
          "includes": [
            "#include \"rcu.h\"",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu.h\"\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_bh_held(void)\n{\n\tif (!debug_lockdep_rcu_enabled())\n\t\treturn 1;\n\tif (!rcu_is_watching())\n\t\treturn 0;\n\tif (!rcu_lockdep_current_cpu_online())\n\t\treturn 0;\n\treturn in_softirq() || irqs_disabled();\n}"
        }
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic noinline void;\nstatic noinline void;\n\nstatic noinline\nbool mutex_spin_on_owner(struct mutex *lock, struct task_struct *owner,\n\t\t\t struct ww_acquire_ctx *ww_ctx, struct mutex_waiter *waiter)\n{\n\tbool ret = true;\n\n\trcu_read_lock();\n\twhile (__mutex_owner(lock) == owner) {\n\t\t/*\n\t\t * Ensure we emit the owner->on_cpu, dereference _after_\n\t\t * checking lock->owner still matches owner. If that fails,\n\t\t * owner might point to freed memory. If it still matches,\n\t\t * the rcu_read_lock() ensures the memory stays valid.\n\t\t */\n\t\tbarrier();\n\n\t\t/*\n\t\t * Use vcpu_is_preempted to detect lock holder preemption issue.\n\t\t */\n\t\tif (!owner->on_cpu || need_resched() ||\n\t\t\t\tvcpu_is_preempted(task_cpu(owner))) {\n\t\t\tret = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (ww_ctx && !ww_mutex_spin_on_owner(lock, ww_ctx, waiter)) {\n\t\t\tret = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tcpu_relax();\n\t}\n\trcu_read_unlock();\n\n\treturn ret;\n}"
  },
  {
    "function_name": "ww_mutex_spin_on_owner",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "474-514",
    "snippet": "static inline\nbool ww_mutex_spin_on_owner(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,\n\t\t\t    struct mutex_waiter *waiter)\n{\n\tstruct ww_mutex *ww;\n\n\tww = container_of(lock, struct ww_mutex, base);\n\n\t/*\n\t * If ww->ctx is set the contents are undefined, only\n\t * by acquiring wait_lock there is a guarantee that\n\t * they are not invalid when reading.\n\t *\n\t * As such, when deadlock detection needs to be\n\t * performed the optimistic spinning cannot be done.\n\t *\n\t * Check this in every inner iteration because we may\n\t * be racing against another thread's ww_mutex_lock.\n\t */\n\tif (ww_ctx->acquired > 0 && READ_ONCE(ww->ctx))\n\t\treturn false;\n\n\t/*\n\t * If we aren't on the wait list yet, cancel the spin\n\t * if there are waiters. We want  to avoid stealing the\n\t * lock from a waiter with an earlier stamp, since the\n\t * other thread may already own a lock that we also\n\t * need.\n\t */\n\tif (!waiter && (atomic_long_read(&lock->owner) & MUTEX_FLAG_WAITERS))\n\t\treturn false;\n\n\t/*\n\t * Similarly, stop spinning if we are no longer the\n\t * first waiter.\n\t */\n\tif (waiter && !__mutex_waiter_is_first(lock, waiter))\n\t\treturn false;\n\n\treturn true;\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [
      "#define MUTEX_FLAG_WAITERS\t0x01"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_waiter_is_first",
          "args": [
            "lock",
            "waiter"
          ],
          "line": 510
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_waiter_is_first",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "171-174",
          "snippet": "static inline bool __mutex_waiter_is_first(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\treturn list_first_entry(&lock->wait_list, struct mutex_waiter, list) == waiter;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline bool __mutex_waiter_is_first(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\treturn list_first_entry(&lock->wait_list, struct mutex_waiter, list) == waiter;\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&lock->owner"
          ],
          "line": 503
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "ww->ctx"
          ],
          "line": 493
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "lock",
            "structww_mutex",
            "base"
          ],
          "line": 480
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAG_WAITERS\t0x01\n\nstatic inline\nbool ww_mutex_spin_on_owner(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,\n\t\t\t    struct mutex_waiter *waiter)\n{\n\tstruct ww_mutex *ww;\n\n\tww = container_of(lock, struct ww_mutex, base);\n\n\t/*\n\t * If ww->ctx is set the contents are undefined, only\n\t * by acquiring wait_lock there is a guarantee that\n\t * they are not invalid when reading.\n\t *\n\t * As such, when deadlock detection needs to be\n\t * performed the optimistic spinning cannot be done.\n\t *\n\t * Check this in every inner iteration because we may\n\t * be racing against another thread's ww_mutex_lock.\n\t */\n\tif (ww_ctx->acquired > 0 && READ_ONCE(ww->ctx))\n\t\treturn false;\n\n\t/*\n\t * If we aren't on the wait list yet, cancel the spin\n\t * if there are waiters. We want  to avoid stealing the\n\t * lock from a waiter with an earlier stamp, since the\n\t * other thread may already own a lock that we also\n\t * need.\n\t */\n\tif (!waiter && (atomic_long_read(&lock->owner) & MUTEX_FLAG_WAITERS))\n\t\treturn false;\n\n\t/*\n\t * Similarly, stop spinning if we are no longer the\n\t * first waiter.\n\t */\n\tif (waiter && !__mutex_waiter_is_first(lock, waiter))\n\t\treturn false;\n\n\treturn true;\n}"
  },
  {
    "function_name": "ww_mutex_set_context_fastpath",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "437-470",
    "snippet": "static __always_inline void\nww_mutex_set_context_fastpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tww_mutex_lock_acquired(lock, ctx);\n\n\t/*\n\t * The lock->ctx update should be visible on all cores before\n\t * the WAITERS check is done, otherwise contended waiters might be\n\t * missed. The contended waiters will either see ww_ctx == NULL\n\t * and keep spinning, or it will acquire wait_lock, add itself\n\t * to waiter list and sleep.\n\t */\n\tsmp_mb(); /* See comments above and below. */\n\n\t/*\n\t * [W] ww->ctx = ctx\t    [W] MUTEX_FLAG_WAITERS\n\t *     MB\t\t        MB\n\t * [R] MUTEX_FLAG_WAITERS   [R] ww->ctx\n\t *\n\t * The memory barrier above pairs with the memory barrier in\n\t * __ww_mutex_add_waiter() and makes sure we either observe ww->ctx\n\t * and/or !empty list.\n\t */\n\tif (likely(!(atomic_long_read(&lock->base.owner) & MUTEX_FLAG_WAITERS)))\n\t\treturn;\n\n\t/*\n\t * Uh oh, we raced in fastpath, check if any of the waiters need to\n\t * die or wound us.\n\t */\n\tspin_lock(&lock->base.wait_lock);\n\t__ww_mutex_check_waiters(&lock->base, ctx);\n\tspin_unlock(&lock->base.wait_lock);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [
      "#define MUTEX_FLAG_WAITERS\t0x01"
    ],
    "globals_used": [
      "static __always_inline int",
      "static __always_inline int"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "spin_unlock",
          "args": [
            "&lock->base.wait_lock"
          ],
          "line": 469
        },
        "resolved": true,
        "details": {
          "function_name": "__pv_queued_spin_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/qspinlock_paravirt.h",
          "lines": "546-560",
          "snippet": "__visible void __pv_queued_spin_unlock(struct qspinlock *lock)\n{\n\tu8 locked;\n\n\t/*\n\t * We must not unlock if SLOW, because in that case we must first\n\t * unhash. Otherwise it would be possible to have multiple @lock\n\t * entries, which would be BAD.\n\t */\n\tlocked = cmpxchg_release(&lock->locked, _Q_LOCKED_VAL, 0);\n\tif (likely(locked == _Q_LOCKED_VAL))\n\t\treturn;\n\n\t__pv_queued_spin_unlock_slowpath(lock, locked);\n}",
          "includes": [
            "#include <asm/qspinlock_paravirt.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/memblock.h>",
            "#include <linux/hash.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/qspinlock_paravirt.h>\n#include <linux/debug_locks.h>\n#include <linux/memblock.h>\n#include <linux/hash.h>\n\n__visible void __pv_queued_spin_unlock(struct qspinlock *lock)\n{\n\tu8 locked;\n\n\t/*\n\t * We must not unlock if SLOW, because in that case we must first\n\t * unhash. Otherwise it would be possible to have multiple @lock\n\t * entries, which would be BAD.\n\t */\n\tlocked = cmpxchg_release(&lock->locked, _Q_LOCKED_VAL, 0);\n\tif (likely(locked == _Q_LOCKED_VAL))\n\t\treturn;\n\n\t__pv_queued_spin_unlock_slowpath(lock, locked);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__ww_mutex_check_waiters",
          "args": [
            "&lock->base",
            "ctx"
          ],
          "line": 468
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_check_waiters",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "416-431",
          "snippet": "static void __sched\n__ww_mutex_check_waiters(struct mutex *lock, struct ww_acquire_ctx *ww_ctx)\n{\n\tstruct mutex_waiter *cur;\n\n\tlockdep_assert_held(&lock->wait_lock);\n\n\tlist_for_each_entry(cur, &lock->wait_list, list) {\n\t\tif (!cur->ww_ctx)\n\t\t\tcontinue;\n\n\t\tif (__ww_mutex_die(lock, cur, ww_ctx) ||\n\t\t    __ww_mutex_wound(lock, cur->ww_ctx, ww_ctx))\n\t\t\tbreak;\n\t}\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic void __sched\n__ww_mutex_check_waiters(struct mutex *lock, struct ww_acquire_ctx *ww_ctx)\n{\n\tstruct mutex_waiter *cur;\n\n\tlockdep_assert_held(&lock->wait_lock);\n\n\tlist_for_each_entry(cur, &lock->wait_list, list) {\n\t\tif (!cur->ww_ctx)\n\t\t\tcontinue;\n\n\t\tif (__ww_mutex_die(lock, cur, ww_ctx) ||\n\t\t    __ww_mutex_wound(lock, cur->ww_ctx, ww_ctx))\n\t\t\tbreak;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "spin_lock",
          "args": [
            "&lock->base.wait_lock"
          ],
          "line": 467
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "166-169",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "!(atomic_long_read(&lock->base.owner) & MUTEX_FLAG_WAITERS)"
          ],
          "line": 460
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&lock->base.owner"
          ],
          "line": 460
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_mb",
          "args": [],
          "line": 449
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ww_mutex_lock_acquired",
          "args": [
            "lock",
            "ctx"
          ],
          "line": 440
        },
        "resolved": true,
        "details": {
          "function_name": "ww_mutex_lock_acquired",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "278-317",
          "snippet": "static __always_inline void\nww_mutex_lock_acquired(struct ww_mutex *ww, struct ww_acquire_ctx *ww_ctx)\n{\n#ifdef CONFIG_DEBUG_MUTEXES\n\t/*\n\t * If this WARN_ON triggers, you used ww_mutex_lock to acquire,\n\t * but released with a normal mutex_unlock in this call.\n\t *\n\t * This should never happen, always use ww_mutex_unlock.\n\t */\n\tDEBUG_LOCKS_WARN_ON(ww->ctx);\n\n\t/*\n\t * Not quite done after calling ww_acquire_done() ?\n\t */\n\tDEBUG_LOCKS_WARN_ON(ww_ctx->done_acquire);\n\n\tif (ww_ctx->contending_lock) {\n\t\t/*\n\t\t * After -EDEADLK you tried to\n\t\t * acquire a different ww_mutex? Bad!\n\t\t */\n\t\tDEBUG_LOCKS_WARN_ON(ww_ctx->contending_lock != ww);\n\n\t\t/*\n\t\t * You called ww_mutex_lock after receiving -EDEADLK,\n\t\t * but 'forgot' to unlock everything else first?\n\t\t */\n\t\tDEBUG_LOCKS_WARN_ON(ww_ctx->acquired > 0);\n\t\tww_ctx->contending_lock = NULL;\n\t}\n\n\t/*\n\t * Naughty, using a different class will lead to undefined behavior!\n\t */\n\tDEBUG_LOCKS_WARN_ON(ww_ctx->ww_class != ww->ww_class);\n#endif\n\tww_ctx->acquired++;\n\tww->ctx = ww_ctx;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline int",
            "static __always_inline int"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline int;\nstatic __always_inline int;\n\nstatic __always_inline void\nww_mutex_lock_acquired(struct ww_mutex *ww, struct ww_acquire_ctx *ww_ctx)\n{\n#ifdef CONFIG_DEBUG_MUTEXES\n\t/*\n\t * If this WARN_ON triggers, you used ww_mutex_lock to acquire,\n\t * but released with a normal mutex_unlock in this call.\n\t *\n\t * This should never happen, always use ww_mutex_unlock.\n\t */\n\tDEBUG_LOCKS_WARN_ON(ww->ctx);\n\n\t/*\n\t * Not quite done after calling ww_acquire_done() ?\n\t */\n\tDEBUG_LOCKS_WARN_ON(ww_ctx->done_acquire);\n\n\tif (ww_ctx->contending_lock) {\n\t\t/*\n\t\t * After -EDEADLK you tried to\n\t\t * acquire a different ww_mutex? Bad!\n\t\t */\n\t\tDEBUG_LOCKS_WARN_ON(ww_ctx->contending_lock != ww);\n\n\t\t/*\n\t\t * You called ww_mutex_lock after receiving -EDEADLK,\n\t\t * but 'forgot' to unlock everything else first?\n\t\t */\n\t\tDEBUG_LOCKS_WARN_ON(ww_ctx->acquired > 0);\n\t\tww_ctx->contending_lock = NULL;\n\t}\n\n\t/*\n\t * Naughty, using a different class will lead to undefined behavior!\n\t */\n\tDEBUG_LOCKS_WARN_ON(ww_ctx->ww_class != ww->ww_class);\n#endif\n\tww_ctx->acquired++;\n\tww->ctx = ww_ctx;\n}"
        }
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAG_WAITERS\t0x01\n\nstatic __always_inline int;\nstatic __always_inline int;\n\nstatic __always_inline void\nww_mutex_set_context_fastpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tww_mutex_lock_acquired(lock, ctx);\n\n\t/*\n\t * The lock->ctx update should be visible on all cores before\n\t * the WAITERS check is done, otherwise contended waiters might be\n\t * missed. The contended waiters will either see ww_ctx == NULL\n\t * and keep spinning, or it will acquire wait_lock, add itself\n\t * to waiter list and sleep.\n\t */\n\tsmp_mb(); /* See comments above and below. */\n\n\t/*\n\t * [W] ww->ctx = ctx\t    [W] MUTEX_FLAG_WAITERS\n\t *     MB\t\t        MB\n\t * [R] MUTEX_FLAG_WAITERS   [R] ww->ctx\n\t *\n\t * The memory barrier above pairs with the memory barrier in\n\t * __ww_mutex_add_waiter() and makes sure we either observe ww->ctx\n\t * and/or !empty list.\n\t */\n\tif (likely(!(atomic_long_read(&lock->base.owner) & MUTEX_FLAG_WAITERS)))\n\t\treturn;\n\n\t/*\n\t * Uh oh, we raced in fastpath, check if any of the waiters need to\n\t * die or wound us.\n\t */\n\tspin_lock(&lock->base.wait_lock);\n\t__ww_mutex_check_waiters(&lock->base, ctx);\n\tspin_unlock(&lock->base.wait_lock);\n}"
  },
  {
    "function_name": "__ww_mutex_check_waiters",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "416-431",
    "snippet": "static void __sched\n__ww_mutex_check_waiters(struct mutex *lock, struct ww_acquire_ctx *ww_ctx)\n{\n\tstruct mutex_waiter *cur;\n\n\tlockdep_assert_held(&lock->wait_lock);\n\n\tlist_for_each_entry(cur, &lock->wait_list, list) {\n\t\tif (!cur->ww_ctx)\n\t\t\tcontinue;\n\n\t\tif (__ww_mutex_die(lock, cur, ww_ctx) ||\n\t\t    __ww_mutex_wound(lock, cur->ww_ctx, ww_ctx))\n\t\t\tbreak;\n\t}\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__ww_mutex_wound",
          "args": [
            "lock",
            "cur->ww_ctx",
            "ww_ctx"
          ],
          "line": 428
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_wound",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "362-402",
          "snippet": "static bool __ww_mutex_wound(struct mutex *lock,\n\t\t\t     struct ww_acquire_ctx *ww_ctx,\n\t\t\t     struct ww_acquire_ctx *hold_ctx)\n{\n\tstruct task_struct *owner = __mutex_owner(lock);\n\n\tlockdep_assert_held(&lock->wait_lock);\n\n\t/*\n\t * Possible through __ww_mutex_add_waiter() when we race with\n\t * ww_mutex_set_context_fastpath(). In that case we'll get here again\n\t * through __ww_mutex_check_waiters().\n\t */\n\tif (!hold_ctx)\n\t\treturn false;\n\n\t/*\n\t * Can have !owner because of __mutex_unlock_slowpath(), but if owner,\n\t * it cannot go away because we'll have FLAG_WAITERS set and hold\n\t * wait_lock.\n\t */\n\tif (!owner)\n\t\treturn false;\n\n\tif (ww_ctx->acquired > 0 && __ww_ctx_stamp_after(hold_ctx, ww_ctx)) {\n\t\thold_ctx->wounded = 1;\n\n\t\t/*\n\t\t * wake_up_process() paired with set_current_state()\n\t\t * inserts sufficient barriers to make sure @owner either sees\n\t\t * it's wounded in __ww_mutex_check_kill() or has a\n\t\t * wakeup pending to re-read the wounded state.\n\t\t */\n\t\tif (owner != current)\n\t\t\twake_up_process(owner);\n\n\t\treturn true;\n\t}\n\n\treturn false;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic bool __ww_mutex_wound(struct mutex *lock,\n\t\t\t     struct ww_acquire_ctx *ww_ctx,\n\t\t\t     struct ww_acquire_ctx *hold_ctx)\n{\n\tstruct task_struct *owner = __mutex_owner(lock);\n\n\tlockdep_assert_held(&lock->wait_lock);\n\n\t/*\n\t * Possible through __ww_mutex_add_waiter() when we race with\n\t * ww_mutex_set_context_fastpath(). In that case we'll get here again\n\t * through __ww_mutex_check_waiters().\n\t */\n\tif (!hold_ctx)\n\t\treturn false;\n\n\t/*\n\t * Can have !owner because of __mutex_unlock_slowpath(), but if owner,\n\t * it cannot go away because we'll have FLAG_WAITERS set and hold\n\t * wait_lock.\n\t */\n\tif (!owner)\n\t\treturn false;\n\n\tif (ww_ctx->acquired > 0 && __ww_ctx_stamp_after(hold_ctx, ww_ctx)) {\n\t\thold_ctx->wounded = 1;\n\n\t\t/*\n\t\t * wake_up_process() paired with set_current_state()\n\t\t * inserts sufficient barriers to make sure @owner either sees\n\t\t * it's wounded in __ww_mutex_check_kill() or has a\n\t\t * wakeup pending to re-read the wounded state.\n\t\t */\n\t\tif (owner != current)\n\t\t\twake_up_process(owner);\n\n\t\treturn true;\n\t}\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__ww_mutex_die",
          "args": [
            "lock",
            "cur",
            "ww_ctx"
          ],
          "line": 427
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_die",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "339-353",
          "snippet": "static bool __sched\n__ww_mutex_die(struct mutex *lock, struct mutex_waiter *waiter,\n\t       struct ww_acquire_ctx *ww_ctx)\n{\n\tif (!ww_ctx->is_wait_die)\n\t\treturn false;\n\n\tif (waiter->ww_ctx->acquired > 0 &&\n\t\t\t__ww_ctx_stamp_after(waiter->ww_ctx, ww_ctx)) {\n\t\tdebug_mutex_wake_waiter(lock, waiter);\n\t\twake_up_process(waiter->task);\n\t}\n\n\treturn true;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic bool __sched\n__ww_mutex_die(struct mutex *lock, struct mutex_waiter *waiter,\n\t       struct ww_acquire_ctx *ww_ctx)\n{\n\tif (!ww_ctx->is_wait_die)\n\t\treturn false;\n\n\tif (waiter->ww_ctx->acquired > 0 &&\n\t\t\t__ww_ctx_stamp_after(waiter->ww_ctx, ww_ctx)) {\n\t\tdebug_mutex_wake_waiter(lock, waiter);\n\t\twake_up_process(waiter->task);\n\t}\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_for_each_entry",
          "args": [
            "cur",
            "&lock->wait_list",
            "list"
          ],
          "line": 423
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lockdep_assert_held",
          "args": [
            "&lock->wait_lock"
          ],
          "line": 421
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic void __sched\n__ww_mutex_check_waiters(struct mutex *lock, struct ww_acquire_ctx *ww_ctx)\n{\n\tstruct mutex_waiter *cur;\n\n\tlockdep_assert_held(&lock->wait_lock);\n\n\tlist_for_each_entry(cur, &lock->wait_list, list) {\n\t\tif (!cur->ww_ctx)\n\t\t\tcontinue;\n\n\t\tif (__ww_mutex_die(lock, cur, ww_ctx) ||\n\t\t    __ww_mutex_wound(lock, cur->ww_ctx, ww_ctx))\n\t\t\tbreak;\n\t}\n}"
  },
  {
    "function_name": "__ww_mutex_wound",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "362-402",
    "snippet": "static bool __ww_mutex_wound(struct mutex *lock,\n\t\t\t     struct ww_acquire_ctx *ww_ctx,\n\t\t\t     struct ww_acquire_ctx *hold_ctx)\n{\n\tstruct task_struct *owner = __mutex_owner(lock);\n\n\tlockdep_assert_held(&lock->wait_lock);\n\n\t/*\n\t * Possible through __ww_mutex_add_waiter() when we race with\n\t * ww_mutex_set_context_fastpath(). In that case we'll get here again\n\t * through __ww_mutex_check_waiters().\n\t */\n\tif (!hold_ctx)\n\t\treturn false;\n\n\t/*\n\t * Can have !owner because of __mutex_unlock_slowpath(), but if owner,\n\t * it cannot go away because we'll have FLAG_WAITERS set and hold\n\t * wait_lock.\n\t */\n\tif (!owner)\n\t\treturn false;\n\n\tif (ww_ctx->acquired > 0 && __ww_ctx_stamp_after(hold_ctx, ww_ctx)) {\n\t\thold_ctx->wounded = 1;\n\n\t\t/*\n\t\t * wake_up_process() paired with set_current_state()\n\t\t * inserts sufficient barriers to make sure @owner either sees\n\t\t * it's wounded in __ww_mutex_check_kill() or has a\n\t\t * wakeup pending to re-read the wounded state.\n\t\t */\n\t\tif (owner != current)\n\t\t\twake_up_process(owner);\n\n\t\treturn true;\n\t}\n\n\treturn false;\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "wake_up_process",
          "args": [
            "owner"
          ],
          "line": 396
        },
        "resolved": true,
        "details": {
          "function_name": "wake_up_process",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/core.c",
          "lines": "2127-2130",
          "snippet": "int wake_up_process(struct task_struct *p)\n{\n\treturn try_to_wake_up(p, TASK_NORMAL, 0);\n}",
          "includes": [
            "#include \"features.h\"",
            "#include <trace/events/sched.h>",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/kcov.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include <trace/events/sched.h>\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/kcov.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n\nstatic __always_inline struct;\n\nint wake_up_process(struct task_struct *p)\n{\n\treturn try_to_wake_up(p, TASK_NORMAL, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__ww_ctx_stamp_after",
          "args": [
            "hold_ctx",
            "ww_ctx"
          ],
          "line": 386
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_ctx_stamp_after",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "324-329",
          "snippet": "static inline bool __sched\n__ww_ctx_stamp_after(struct ww_acquire_ctx *a, struct ww_acquire_ctx *b)\n{\n\n\treturn (signed long)(a->stamp - b->stamp) > 0;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline bool __sched\n__ww_ctx_stamp_after(struct ww_acquire_ctx *a, struct ww_acquire_ctx *b)\n{\n\n\treturn (signed long)(a->stamp - b->stamp) > 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "lockdep_assert_held",
          "args": [
            "&lock->wait_lock"
          ],
          "line": 368
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__mutex_owner",
          "args": [
            "lock"
          ],
          "line": 366
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic bool __ww_mutex_wound(struct mutex *lock,\n\t\t\t     struct ww_acquire_ctx *ww_ctx,\n\t\t\t     struct ww_acquire_ctx *hold_ctx)\n{\n\tstruct task_struct *owner = __mutex_owner(lock);\n\n\tlockdep_assert_held(&lock->wait_lock);\n\n\t/*\n\t * Possible through __ww_mutex_add_waiter() when we race with\n\t * ww_mutex_set_context_fastpath(). In that case we'll get here again\n\t * through __ww_mutex_check_waiters().\n\t */\n\tif (!hold_ctx)\n\t\treturn false;\n\n\t/*\n\t * Can have !owner because of __mutex_unlock_slowpath(), but if owner,\n\t * it cannot go away because we'll have FLAG_WAITERS set and hold\n\t * wait_lock.\n\t */\n\tif (!owner)\n\t\treturn false;\n\n\tif (ww_ctx->acquired > 0 && __ww_ctx_stamp_after(hold_ctx, ww_ctx)) {\n\t\thold_ctx->wounded = 1;\n\n\t\t/*\n\t\t * wake_up_process() paired with set_current_state()\n\t\t * inserts sufficient barriers to make sure @owner either sees\n\t\t * it's wounded in __ww_mutex_check_kill() or has a\n\t\t * wakeup pending to re-read the wounded state.\n\t\t */\n\t\tif (owner != current)\n\t\t\twake_up_process(owner);\n\n\t\treturn true;\n\t}\n\n\treturn false;\n}"
  },
  {
    "function_name": "__ww_mutex_die",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "339-353",
    "snippet": "static bool __sched\n__ww_mutex_die(struct mutex *lock, struct mutex_waiter *waiter,\n\t       struct ww_acquire_ctx *ww_ctx)\n{\n\tif (!ww_ctx->is_wait_die)\n\t\treturn false;\n\n\tif (waiter->ww_ctx->acquired > 0 &&\n\t\t\t__ww_ctx_stamp_after(waiter->ww_ctx, ww_ctx)) {\n\t\tdebug_mutex_wake_waiter(lock, waiter);\n\t\twake_up_process(waiter->task);\n\t}\n\n\treturn true;\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "wake_up_process",
          "args": [
            "waiter->task"
          ],
          "line": 349
        },
        "resolved": true,
        "details": {
          "function_name": "wake_up_process",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/sched/core.c",
          "lines": "2127-2130",
          "snippet": "int wake_up_process(struct task_struct *p)\n{\n\treturn try_to_wake_up(p, TASK_NORMAL, 0);\n}",
          "includes": [
            "#include \"features.h\"",
            "#include <trace/events/sched.h>",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/kcov.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include <trace/events/sched.h>\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/kcov.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n\nstatic __always_inline struct;\n\nint wake_up_process(struct task_struct *p)\n{\n\treturn try_to_wake_up(p, TASK_NORMAL, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "debug_mutex_wake_waiter",
          "args": [
            "lock",
            "waiter"
          ],
          "line": 348
        },
        "resolved": true,
        "details": {
          "function_name": "debug_mutex_wake_waiter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex-debug.c",
          "lines": "37-43",
          "snippet": "void debug_mutex_wake_waiter(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\tSMP_DEBUG_LOCKS_WARN_ON(!spin_is_locked(&lock->wait_lock));\n\tDEBUG_LOCKS_WARN_ON(list_empty(&lock->wait_list));\n\tDEBUG_LOCKS_WARN_ON(waiter->magic != waiter);\n\tDEBUG_LOCKS_WARN_ON(list_empty(&waiter->list));\n}",
          "includes": [
            "#include \"mutex-debug.h\"",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/poison.h>",
            "#include <linux/export.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"mutex-debug.h\"\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/sched.h>\n#include <linux/poison.h>\n#include <linux/export.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n\nvoid debug_mutex_wake_waiter(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\tSMP_DEBUG_LOCKS_WARN_ON(!spin_is_locked(&lock->wait_lock));\n\tDEBUG_LOCKS_WARN_ON(list_empty(&lock->wait_list));\n\tDEBUG_LOCKS_WARN_ON(waiter->magic != waiter);\n\tDEBUG_LOCKS_WARN_ON(list_empty(&waiter->list));\n}"
        }
      },
      {
        "call_info": {
          "callee": "__ww_ctx_stamp_after",
          "args": [
            "waiter->ww_ctx",
            "ww_ctx"
          ],
          "line": 347
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_ctx_stamp_after",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "324-329",
          "snippet": "static inline bool __sched\n__ww_ctx_stamp_after(struct ww_acquire_ctx *a, struct ww_acquire_ctx *b)\n{\n\n\treturn (signed long)(a->stamp - b->stamp) > 0;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline bool __sched\n__ww_ctx_stamp_after(struct ww_acquire_ctx *a, struct ww_acquire_ctx *b)\n{\n\n\treturn (signed long)(a->stamp - b->stamp) > 0;\n}"
        }
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic bool __sched\n__ww_mutex_die(struct mutex *lock, struct mutex_waiter *waiter,\n\t       struct ww_acquire_ctx *ww_ctx)\n{\n\tif (!ww_ctx->is_wait_die)\n\t\treturn false;\n\n\tif (waiter->ww_ctx->acquired > 0 &&\n\t\t\t__ww_ctx_stamp_after(waiter->ww_ctx, ww_ctx)) {\n\t\tdebug_mutex_wake_waiter(lock, waiter);\n\t\twake_up_process(waiter->task);\n\t}\n\n\treturn true;\n}"
  },
  {
    "function_name": "__ww_ctx_stamp_after",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "324-329",
    "snippet": "static inline bool __sched\n__ww_ctx_stamp_after(struct ww_acquire_ctx *a, struct ww_acquire_ctx *b)\n{\n\n\treturn (signed long)(a->stamp - b->stamp) > 0;\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline bool __sched\n__ww_ctx_stamp_after(struct ww_acquire_ctx *a, struct ww_acquire_ctx *b)\n{\n\n\treturn (signed long)(a->stamp - b->stamp) > 0;\n}"
  },
  {
    "function_name": "ww_mutex_lock_acquired",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "278-317",
    "snippet": "static __always_inline void\nww_mutex_lock_acquired(struct ww_mutex *ww, struct ww_acquire_ctx *ww_ctx)\n{\n#ifdef CONFIG_DEBUG_MUTEXES\n\t/*\n\t * If this WARN_ON triggers, you used ww_mutex_lock to acquire,\n\t * but released with a normal mutex_unlock in this call.\n\t *\n\t * This should never happen, always use ww_mutex_unlock.\n\t */\n\tDEBUG_LOCKS_WARN_ON(ww->ctx);\n\n\t/*\n\t * Not quite done after calling ww_acquire_done() ?\n\t */\n\tDEBUG_LOCKS_WARN_ON(ww_ctx->done_acquire);\n\n\tif (ww_ctx->contending_lock) {\n\t\t/*\n\t\t * After -EDEADLK you tried to\n\t\t * acquire a different ww_mutex? Bad!\n\t\t */\n\t\tDEBUG_LOCKS_WARN_ON(ww_ctx->contending_lock != ww);\n\n\t\t/*\n\t\t * You called ww_mutex_lock after receiving -EDEADLK,\n\t\t * but 'forgot' to unlock everything else first?\n\t\t */\n\t\tDEBUG_LOCKS_WARN_ON(ww_ctx->acquired > 0);\n\t\tww_ctx->contending_lock = NULL;\n\t}\n\n\t/*\n\t * Naughty, using a different class will lead to undefined behavior!\n\t */\n\tDEBUG_LOCKS_WARN_ON(ww_ctx->ww_class != ww->ww_class);\n#endif\n\tww_ctx->acquired++;\n\tww->ctx = ww_ctx;\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline int",
      "static __always_inline int"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "DEBUG_LOCKS_WARN_ON",
          "args": [
            "ww_ctx->ww_class != ww->ww_class"
          ],
          "line": 313
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DEBUG_LOCKS_WARN_ON",
          "args": [
            "ww_ctx->acquired > 0"
          ],
          "line": 306
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DEBUG_LOCKS_WARN_ON",
          "args": [
            "ww_ctx->contending_lock != ww"
          ],
          "line": 300
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DEBUG_LOCKS_WARN_ON",
          "args": [
            "ww_ctx->done_acquire"
          ],
          "line": 293
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DEBUG_LOCKS_WARN_ON",
          "args": [
            "ww->ctx"
          ],
          "line": 288
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline int;\nstatic __always_inline int;\n\nstatic __always_inline void\nww_mutex_lock_acquired(struct ww_mutex *ww, struct ww_acquire_ctx *ww_ctx)\n{\n#ifdef CONFIG_DEBUG_MUTEXES\n\t/*\n\t * If this WARN_ON triggers, you used ww_mutex_lock to acquire,\n\t * but released with a normal mutex_unlock in this call.\n\t *\n\t * This should never happen, always use ww_mutex_unlock.\n\t */\n\tDEBUG_LOCKS_WARN_ON(ww->ctx);\n\n\t/*\n\t * Not quite done after calling ww_acquire_done() ?\n\t */\n\tDEBUG_LOCKS_WARN_ON(ww_ctx->done_acquire);\n\n\tif (ww_ctx->contending_lock) {\n\t\t/*\n\t\t * After -EDEADLK you tried to\n\t\t * acquire a different ww_mutex? Bad!\n\t\t */\n\t\tDEBUG_LOCKS_WARN_ON(ww_ctx->contending_lock != ww);\n\n\t\t/*\n\t\t * You called ww_mutex_lock after receiving -EDEADLK,\n\t\t * but 'forgot' to unlock everything else first?\n\t\t */\n\t\tDEBUG_LOCKS_WARN_ON(ww_ctx->acquired > 0);\n\t\tww_ctx->contending_lock = NULL;\n\t}\n\n\t/*\n\t * Naughty, using a different class will lead to undefined behavior!\n\t */\n\tDEBUG_LOCKS_WARN_ON(ww_ctx->ww_class != ww->ww_class);\n#endif\n\tww_ctx->acquired++;\n\tww->ctx = ww_ctx;\n}"
  },
  {
    "function_name": "mutex_lock",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "252-258",
    "snippet": "void __sched mutex_lock(struct mutex *lock)\n{\n\tmight_sleep();\n\n\tif (!__mutex_trylock_fast(lock))\n\t\t__mutex_lock_slowpath(lock);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_lock_slowpath",
          "args": [
            "lock"
          ],
          "line": 257
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock_slowpath",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "1330-1334",
          "snippet": "__sched\n__mutex_lock_slowpath(struct mutex *lock)\n{\n\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__mutex_lock_slowpath(struct mutex *lock)\n{\n\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_trylock_fast",
          "args": [
            "lock"
          ],
          "line": 256
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_trylock_fast",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "139-148",
          "snippet": "static __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline int",
            "static __always_inline int"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline int;\nstatic __always_inline int;\n\nstatic __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 254
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nvoid __sched mutex_lock(struct mutex *lock)\n{\n\tmight_sleep();\n\n\tif (!__mutex_trylock_fast(lock))\n\t\t__mutex_lock_slowpath(lock);\n}"
  },
  {
    "function_name": "__mutex_handoff",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "197-220",
    "snippet": "static void __mutex_handoff(struct mutex *lock, struct task_struct *task)\n{\n\tunsigned long owner = atomic_long_read(&lock->owner);\n\n\tfor (;;) {\n\t\tunsigned long old, new;\n\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\tDEBUG_LOCKS_WARN_ON(__owner_task(owner) != current);\n\t\tDEBUG_LOCKS_WARN_ON(owner & MUTEX_FLAG_PICKUP);\n#endif\n\n\t\tnew = (owner & MUTEX_FLAG_WAITERS);\n\t\tnew |= (unsigned long)task;\n\t\tif (task)\n\t\t\tnew |= MUTEX_FLAG_PICKUP;\n\n\t\told = atomic_long_cmpxchg_release(&lock->owner, owner, new);\n\t\tif (old == owner)\n\t\t\tbreak;\n\n\t\towner = old;\n\t}\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [
      "#define MUTEX_FLAG_PICKUP\t0x04",
      "#define MUTEX_FLAG_WAITERS\t0x01"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_cmpxchg_release",
          "args": [
            "&lock->owner",
            "owner",
            "new"
          ],
          "line": 214
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DEBUG_LOCKS_WARN_ON",
          "args": [
            "owner & MUTEX_FLAG_PICKUP"
          ],
          "line": 206
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DEBUG_LOCKS_WARN_ON",
          "args": [
            "__owner_task(owner) != current"
          ],
          "line": 205
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__owner_task",
          "args": [
            "owner"
          ],
          "line": 205
        },
        "resolved": true,
        "details": {
          "function_name": "__owner_task",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "67-70",
          "snippet": "static inline struct task_struct *__owner_task(unsigned long owner)\n{\n\treturn (struct task_struct *)(owner & ~MUTEX_FLAGS);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAGS\t\t0x07"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n\nstatic inline struct task_struct *__owner_task(unsigned long owner)\n{\n\treturn (struct task_struct *)(owner & ~MUTEX_FLAGS);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&lock->owner"
          ],
          "line": 199
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAG_PICKUP\t0x04\n#define MUTEX_FLAG_WAITERS\t0x01\n\nstatic void __mutex_handoff(struct mutex *lock, struct task_struct *task)\n{\n\tunsigned long owner = atomic_long_read(&lock->owner);\n\n\tfor (;;) {\n\t\tunsigned long old, new;\n\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\tDEBUG_LOCKS_WARN_ON(__owner_task(owner) != current);\n\t\tDEBUG_LOCKS_WARN_ON(owner & MUTEX_FLAG_PICKUP);\n#endif\n\n\t\tnew = (owner & MUTEX_FLAG_WAITERS);\n\t\tnew |= (unsigned long)task;\n\t\tif (task)\n\t\t\tnew |= MUTEX_FLAG_PICKUP;\n\n\t\told = atomic_long_cmpxchg_release(&lock->owner, owner, new);\n\t\tif (old == owner)\n\t\t\tbreak;\n\n\t\towner = old;\n\t}\n}"
  },
  {
    "function_name": "__mutex_add_waiter",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "180-189",
    "snippet": "static void __sched\n__mutex_add_waiter(struct mutex *lock, struct mutex_waiter *waiter,\n\t\t   struct list_head *list)\n{\n\tdebug_mutex_add_waiter(lock, waiter, current);\n\n\tlist_add_tail(&waiter->list, list);\n\tif (__mutex_waiter_is_first(lock, waiter))\n\t\t__mutex_set_flag(lock, MUTEX_FLAG_WAITERS);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [
      "#define MUTEX_FLAG_WAITERS\t0x01"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_set_flag",
          "args": [
            "lock",
            "MUTEX_FLAG_WAITERS"
          ],
          "line": 188
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_set_flag",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "161-164",
          "snippet": "static inline void __mutex_set_flag(struct mutex *lock, unsigned long flag)\n{\n\tatomic_long_or(flag, &lock->owner);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline void __mutex_set_flag(struct mutex *lock, unsigned long flag)\n{\n\tatomic_long_or(flag, &lock->owner);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_waiter_is_first",
          "args": [
            "lock",
            "waiter"
          ],
          "line": 187
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_waiter_is_first",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "171-174",
          "snippet": "static inline bool __mutex_waiter_is_first(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\treturn list_first_entry(&lock->wait_list, struct mutex_waiter, list) == waiter;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline bool __mutex_waiter_is_first(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\treturn list_first_entry(&lock->wait_list, struct mutex_waiter, list) == waiter;\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_add_tail",
          "args": [
            "&waiter->list",
            "list"
          ],
          "line": 186
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "debug_mutex_add_waiter",
          "args": [
            "lock",
            "waiter",
            "current"
          ],
          "line": 184
        },
        "resolved": true,
        "details": {
          "function_name": "debug_mutex_add_waiter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex-debug.c",
          "lines": "51-58",
          "snippet": "void debug_mutex_add_waiter(struct mutex *lock, struct mutex_waiter *waiter,\n\t\t\t    struct task_struct *task)\n{\n\tSMP_DEBUG_LOCKS_WARN_ON(!spin_is_locked(&lock->wait_lock));\n\n\t/* Mark the current thread as blocked on the lock: */\n\ttask->blocked_on = waiter;\n}",
          "includes": [
            "#include \"mutex-debug.h\"",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/poison.h>",
            "#include <linux/export.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"mutex-debug.h\"\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/sched.h>\n#include <linux/poison.h>\n#include <linux/export.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n\nvoid debug_mutex_add_waiter(struct mutex *lock, struct mutex_waiter *waiter,\n\t\t\t    struct task_struct *task)\n{\n\tSMP_DEBUG_LOCKS_WARN_ON(!spin_is_locked(&lock->wait_lock));\n\n\t/* Mark the current thread as blocked on the lock: */\n\ttask->blocked_on = waiter;\n}"
        }
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAG_WAITERS\t0x01\n\nstatic void __sched\n__mutex_add_waiter(struct mutex *lock, struct mutex_waiter *waiter,\n\t\t   struct list_head *list)\n{\n\tdebug_mutex_add_waiter(lock, waiter, current);\n\n\tlist_add_tail(&waiter->list, list);\n\tif (__mutex_waiter_is_first(lock, waiter))\n\t\t__mutex_set_flag(lock, MUTEX_FLAG_WAITERS);\n}"
  },
  {
    "function_name": "__mutex_waiter_is_first",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "171-174",
    "snippet": "static inline bool __mutex_waiter_is_first(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\treturn list_first_entry(&lock->wait_list, struct mutex_waiter, list) == waiter;\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "list_first_entry",
          "args": [
            "&lock->wait_list",
            "structmutex_waiter",
            "list"
          ],
          "line": 173
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline bool __mutex_waiter_is_first(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\treturn list_first_entry(&lock->wait_list, struct mutex_waiter, list) == waiter;\n}"
  },
  {
    "function_name": "__mutex_clear_flag",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "166-169",
    "snippet": "static inline void __mutex_clear_flag(struct mutex *lock, unsigned long flag)\n{\n\tatomic_long_andnot(flag, &lock->owner);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_andnot",
          "args": [
            "flag",
            "&lock->owner"
          ],
          "line": 168
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline void __mutex_clear_flag(struct mutex *lock, unsigned long flag)\n{\n\tatomic_long_andnot(flag, &lock->owner);\n}"
  },
  {
    "function_name": "__mutex_set_flag",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "161-164",
    "snippet": "static inline void __mutex_set_flag(struct mutex *lock, unsigned long flag)\n{\n\tatomic_long_or(flag, &lock->owner);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_or",
          "args": [
            "flag",
            "&lock->owner"
          ],
          "line": 163
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline void __mutex_set_flag(struct mutex *lock, unsigned long flag)\n{\n\tatomic_long_or(flag, &lock->owner);\n}"
  },
  {
    "function_name": "__mutex_unlock_fast",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "150-158",
    "snippet": "static __always_inline bool __mutex_unlock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\n\tif (atomic_long_cmpxchg_release(&lock->owner, curr, 0UL) == curr)\n\t\treturn true;\n\n\treturn false;\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline int",
      "static __always_inline int"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_cmpxchg_release",
          "args": [
            "&lock->owner",
            "curr",
            "0UL"
          ],
          "line": 154
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline int;\nstatic __always_inline int;\n\nstatic __always_inline bool __mutex_unlock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\n\tif (atomic_long_cmpxchg_release(&lock->owner, curr, 0UL) == curr)\n\t\treturn true;\n\n\treturn false;\n}"
  },
  {
    "function_name": "__mutex_trylock_fast",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "139-148",
    "snippet": "static __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static __always_inline int",
      "static __always_inline int"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_try_cmpxchg_acquire",
          "args": [
            "&lock->owner",
            "&zero",
            "curr"
          ],
          "line": 144
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline int;\nstatic __always_inline int;\n\nstatic __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}"
  },
  {
    "function_name": "__mutex_trylock",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "123-126",
    "snippet": "static inline bool __mutex_trylock(struct mutex *lock)\n{\n\treturn !__mutex_trylock_or_owner(lock);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_trylock_or_owner",
          "args": [
            "lock"
          ],
          "line": 125
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_trylock_or_owner",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "80-118",
          "snippet": "static inline struct task_struct *__mutex_trylock_or_owner(struct mutex *lock)\n{\n\tunsigned long owner, curr = (unsigned long)current;\n\n\towner = atomic_long_read(&lock->owner);\n\tfor (;;) { /* must loop, can race against a flag */\n\t\tunsigned long old, flags = __owner_flags(owner);\n\t\tunsigned long task = owner & ~MUTEX_FLAGS;\n\n\t\tif (task) {\n\t\t\tif (likely(task != curr))\n\t\t\t\tbreak;\n\n\t\t\tif (likely(!(flags & MUTEX_FLAG_PICKUP)))\n\t\t\t\tbreak;\n\n\t\t\tflags &= ~MUTEX_FLAG_PICKUP;\n\t\t} else {\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\t\tDEBUG_LOCKS_WARN_ON(flags & MUTEX_FLAG_PICKUP);\n#endif\n\t\t}\n\n\t\t/*\n\t\t * We set the HANDOFF bit, we must make sure it doesn't live\n\t\t * past the point where we acquire it. This would be possible\n\t\t * if we (accidentally) set the bit on an unlocked mutex.\n\t\t */\n\t\tflags &= ~MUTEX_FLAG_HANDOFF;\n\n\t\told = atomic_long_cmpxchg_acquire(&lock->owner, owner, curr | flags);\n\t\tif (old == owner)\n\t\t\treturn NULL;\n\n\t\towner = old;\n\t}\n\n\treturn __owner_task(owner);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAGS\t\t0x07",
            "#define MUTEX_FLAG_PICKUP\t0x04",
            "#define MUTEX_FLAG_HANDOFF\t0x02"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n#define MUTEX_FLAG_PICKUP\t0x04\n#define MUTEX_FLAG_HANDOFF\t0x02\n\nstatic inline struct task_struct *__mutex_trylock_or_owner(struct mutex *lock)\n{\n\tunsigned long owner, curr = (unsigned long)current;\n\n\towner = atomic_long_read(&lock->owner);\n\tfor (;;) { /* must loop, can race against a flag */\n\t\tunsigned long old, flags = __owner_flags(owner);\n\t\tunsigned long task = owner & ~MUTEX_FLAGS;\n\n\t\tif (task) {\n\t\t\tif (likely(task != curr))\n\t\t\t\tbreak;\n\n\t\t\tif (likely(!(flags & MUTEX_FLAG_PICKUP)))\n\t\t\t\tbreak;\n\n\t\t\tflags &= ~MUTEX_FLAG_PICKUP;\n\t\t} else {\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\t\tDEBUG_LOCKS_WARN_ON(flags & MUTEX_FLAG_PICKUP);\n#endif\n\t\t}\n\n\t\t/*\n\t\t * We set the HANDOFF bit, we must make sure it doesn't live\n\t\t * past the point where we acquire it. This would be possible\n\t\t * if we (accidentally) set the bit on an unlocked mutex.\n\t\t */\n\t\tflags &= ~MUTEX_FLAG_HANDOFF;\n\n\t\told = atomic_long_cmpxchg_acquire(&lock->owner, owner, curr | flags);\n\t\tif (old == owner)\n\t\t\treturn NULL;\n\n\t\towner = old;\n\t}\n\n\treturn __owner_task(owner);\n}"
        }
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline bool __mutex_trylock(struct mutex *lock)\n{\n\treturn !__mutex_trylock_or_owner(lock);\n}"
  },
  {
    "function_name": "__mutex_trylock_or_owner",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "80-118",
    "snippet": "static inline struct task_struct *__mutex_trylock_or_owner(struct mutex *lock)\n{\n\tunsigned long owner, curr = (unsigned long)current;\n\n\towner = atomic_long_read(&lock->owner);\n\tfor (;;) { /* must loop, can race against a flag */\n\t\tunsigned long old, flags = __owner_flags(owner);\n\t\tunsigned long task = owner & ~MUTEX_FLAGS;\n\n\t\tif (task) {\n\t\t\tif (likely(task != curr))\n\t\t\t\tbreak;\n\n\t\t\tif (likely(!(flags & MUTEX_FLAG_PICKUP)))\n\t\t\t\tbreak;\n\n\t\t\tflags &= ~MUTEX_FLAG_PICKUP;\n\t\t} else {\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\t\tDEBUG_LOCKS_WARN_ON(flags & MUTEX_FLAG_PICKUP);\n#endif\n\t\t}\n\n\t\t/*\n\t\t * We set the HANDOFF bit, we must make sure it doesn't live\n\t\t * past the point where we acquire it. This would be possible\n\t\t * if we (accidentally) set the bit on an unlocked mutex.\n\t\t */\n\t\tflags &= ~MUTEX_FLAG_HANDOFF;\n\n\t\told = atomic_long_cmpxchg_acquire(&lock->owner, owner, curr | flags);\n\t\tif (old == owner)\n\t\t\treturn NULL;\n\n\t\towner = old;\n\t}\n\n\treturn __owner_task(owner);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [
      "#define MUTEX_FLAGS\t\t0x07",
      "#define MUTEX_FLAG_PICKUP\t0x04",
      "#define MUTEX_FLAG_HANDOFF\t0x02"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__owner_task",
          "args": [
            "owner"
          ],
          "line": 117
        },
        "resolved": true,
        "details": {
          "function_name": "__owner_task",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "67-70",
          "snippet": "static inline struct task_struct *__owner_task(unsigned long owner)\n{\n\treturn (struct task_struct *)(owner & ~MUTEX_FLAGS);\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAGS\t\t0x07"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n\nstatic inline struct task_struct *__owner_task(unsigned long owner)\n{\n\treturn (struct task_struct *)(owner & ~MUTEX_FLAGS);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_cmpxchg_acquire",
          "args": [
            "&lock->owner",
            "owner",
            "curr | flags"
          ],
          "line": 110
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DEBUG_LOCKS_WARN_ON",
          "args": [
            "flags & MUTEX_FLAG_PICKUP"
          ],
          "line": 99
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "!(flags & MUTEX_FLAG_PICKUP)"
          ],
          "line": 93
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "task != curr"
          ],
          "line": 90
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__owner_flags",
          "args": [
            "owner"
          ],
          "line": 86
        },
        "resolved": true,
        "details": {
          "function_name": "__owner_flags",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
          "lines": "72-75",
          "snippet": "static inline unsigned long __owner_flags(unsigned long owner)\n{\n\treturn owner & MUTEX_FLAGS;\n}",
          "includes": [
            "# include \"mutex.h\"",
            "# include \"mutex-debug.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAGS\t\t0x07"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n\nstatic inline unsigned long __owner_flags(unsigned long owner)\n{\n\treturn owner & MUTEX_FLAGS;\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&lock->owner"
          ],
          "line": 84
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n#define MUTEX_FLAG_PICKUP\t0x04\n#define MUTEX_FLAG_HANDOFF\t0x02\n\nstatic inline struct task_struct *__mutex_trylock_or_owner(struct mutex *lock)\n{\n\tunsigned long owner, curr = (unsigned long)current;\n\n\towner = atomic_long_read(&lock->owner);\n\tfor (;;) { /* must loop, can race against a flag */\n\t\tunsigned long old, flags = __owner_flags(owner);\n\t\tunsigned long task = owner & ~MUTEX_FLAGS;\n\n\t\tif (task) {\n\t\t\tif (likely(task != curr))\n\t\t\t\tbreak;\n\n\t\t\tif (likely(!(flags & MUTEX_FLAG_PICKUP)))\n\t\t\t\tbreak;\n\n\t\t\tflags &= ~MUTEX_FLAG_PICKUP;\n\t\t} else {\n#ifdef CONFIG_DEBUG_MUTEXES\n\t\t\tDEBUG_LOCKS_WARN_ON(flags & MUTEX_FLAG_PICKUP);\n#endif\n\t\t}\n\n\t\t/*\n\t\t * We set the HANDOFF bit, we must make sure it doesn't live\n\t\t * past the point where we acquire it. This would be possible\n\t\t * if we (accidentally) set the bit on an unlocked mutex.\n\t\t */\n\t\tflags &= ~MUTEX_FLAG_HANDOFF;\n\n\t\told = atomic_long_cmpxchg_acquire(&lock->owner, owner, curr | flags);\n\t\tif (old == owner)\n\t\t\treturn NULL;\n\n\t\towner = old;\n\t}\n\n\treturn __owner_task(owner);\n}"
  },
  {
    "function_name": "__owner_flags",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "72-75",
    "snippet": "static inline unsigned long __owner_flags(unsigned long owner)\n{\n\treturn owner & MUTEX_FLAGS;\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [
      "#define MUTEX_FLAGS\t\t0x07"
    ],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n\nstatic inline unsigned long __owner_flags(unsigned long owner)\n{\n\treturn owner & MUTEX_FLAGS;\n}"
  },
  {
    "function_name": "__owner_task",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "67-70",
    "snippet": "static inline struct task_struct *__owner_task(unsigned long owner)\n{\n\treturn (struct task_struct *)(owner & ~MUTEX_FLAGS);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [
      "#define MUTEX_FLAGS\t\t0x07"
    ],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n\nstatic inline struct task_struct *__owner_task(unsigned long owner)\n{\n\treturn (struct task_struct *)(owner & ~MUTEX_FLAGS);\n}"
  },
  {
    "function_name": "__mutex_init",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex.c",
    "lines": "38-49",
    "snippet": "void\n__mutex_init(struct mutex *lock, const char *name, struct lock_class_key *key)\n{\n\tatomic_long_set(&lock->owner, 0);\n\tspin_lock_init(&lock->wait_lock);\n\tINIT_LIST_HEAD(&lock->wait_list);\n#ifdef CONFIG_MUTEX_SPIN_ON_OWNER\n\tosq_lock_init(&lock->osq);\n#endif\n\n\tdebug_mutex_init(lock, name, key);\n}",
    "includes": [
      "# include \"mutex.h\"",
      "# include \"mutex-debug.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "debug_mutex_init",
          "args": [
            "lock",
            "name",
            "key"
          ],
          "line": 48
        },
        "resolved": true,
        "details": {
          "function_name": "debug_mutex_init",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/mutex-debug.c",
          "lines": "80-91",
          "snippet": "void debug_mutex_init(struct mutex *lock, const char *name,\n\t\t      struct lock_class_key *key)\n{\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\t/*\n\t * Make sure we are not reinitializing a held lock:\n\t */\n\tdebug_check_no_locks_freed((void *)lock, sizeof(*lock));\n\tlockdep_init_map(&lock->dep_map, name, key, 0);\n#endif\n\tlock->magic = lock;\n}",
          "includes": [
            "#include \"mutex-debug.h\"",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/poison.h>",
            "#include <linux/export.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"mutex-debug.h\"\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/sched.h>\n#include <linux/poison.h>\n#include <linux/export.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n\nvoid debug_mutex_init(struct mutex *lock, const char *name,\n\t\t      struct lock_class_key *key)\n{\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\t/*\n\t * Make sure we are not reinitializing a held lock:\n\t */\n\tdebug_check_no_locks_freed((void *)lock, sizeof(*lock));\n\tlockdep_init_map(&lock->dep_map, name, key, 0);\n#endif\n\tlock->magic = lock;\n}"
        }
      },
      {
        "call_info": {
          "callee": "osq_lock_init",
          "args": [
            "&lock->osq"
          ],
          "line": 45
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "INIT_LIST_HEAD",
          "args": [
            "&lock->wait_list"
          ],
          "line": 43
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_lock_init",
          "args": [
            "&lock->wait_lock"
          ],
          "line": 42
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_set",
          "args": [
            "&lock->owner",
            "0"
          ],
          "line": 41
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "# include \"mutex.h\"\n# include \"mutex-debug.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nvoid\n__mutex_init(struct mutex *lock, const char *name, struct lock_class_key *key)\n{\n\tatomic_long_set(&lock->owner, 0);\n\tspin_lock_init(&lock->wait_lock);\n\tINIT_LIST_HEAD(&lock->wait_list);\n#ifdef CONFIG_MUTEX_SPIN_ON_OWNER\n\tosq_lock_init(&lock->osq);\n#endif\n\n\tdebug_mutex_init(lock, name, key);\n}"
  }
]