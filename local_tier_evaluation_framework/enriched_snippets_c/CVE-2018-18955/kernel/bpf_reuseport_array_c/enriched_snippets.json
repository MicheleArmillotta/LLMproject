[
  {
    "function_name": "reuseport_array_get_next_key",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/reuseport_array.c",
    "lines": "337-354",
    "snippet": "static int reuseport_array_get_next_key(struct bpf_map *map, void *key,\n\t\t\t\t\tvoid *next_key)\n{\n\tstruct reuseport_array *array = reuseport_array(map);\n\tu32 index = key ? *(u32 *)key : U32_MAX;\n\tu32 *next = (u32 *)next_key;\n\n\tif (index >= array->map.max_entries) {\n\t\t*next = 0;\n\t\treturn 0;\n\t}\n\n\tif (index == array->map.max_entries - 1)\n\t\treturn -ENOENT;\n\n\t*next = index + 1;\n\treturn 0;\n}",
    "includes": [
      "#include <net/sock_reuseport.h>",
      "#include <linux/sock_diag.h>",
      "#include <linux/err.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "reuseport_array",
          "args": [
            "map"
          ],
          "line": 340
        },
        "resolved": true,
        "details": {
          "function_name": "reuseport_array_alloc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/reuseport_array.c",
          "lines": "150-182",
          "snippet": "static struct bpf_map *reuseport_array_alloc(union bpf_attr *attr)\n{\n\tint err, numa_node = bpf_map_attr_numa_node(attr);\n\tstruct reuseport_array *array;\n\tu64 cost, array_size;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn ERR_PTR(-EPERM);\n\n\tarray_size = sizeof(*array);\n\tarray_size += (u64)attr->max_entries * sizeof(struct sock *);\n\n\t/* make sure there is no u32 overflow later in round_up() */\n\tcost = array_size;\n\tif (cost >= U32_MAX - PAGE_SIZE)\n\t\treturn ERR_PTR(-ENOMEM);\n\tcost = round_up(cost, PAGE_SIZE) >> PAGE_SHIFT;\n\n\terr = bpf_map_precharge_memlock(cost);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\t/* allocate all map elements and zero-initialize them */\n\tarray = bpf_map_area_alloc(array_size, numa_node);\n\tif (!array)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t/* copy mandatory map attributes */\n\tbpf_map_init_from_attr(&array->map, attr);\n\tarray->map.pages = cost;\n\n\treturn &array->map;\n}",
          "includes": [
            "#include <net/sock_reuseport.h>",
            "#include <linux/sock_diag.h>",
            "#include <linux/err.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <net/sock_reuseport.h>\n#include <linux/sock_diag.h>\n#include <linux/err.h>\n#include <linux/bpf.h>\n\nstatic struct bpf_map *reuseport_array_alloc(union bpf_attr *attr)\n{\n\tint err, numa_node = bpf_map_attr_numa_node(attr);\n\tstruct reuseport_array *array;\n\tu64 cost, array_size;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn ERR_PTR(-EPERM);\n\n\tarray_size = sizeof(*array);\n\tarray_size += (u64)attr->max_entries * sizeof(struct sock *);\n\n\t/* make sure there is no u32 overflow later in round_up() */\n\tcost = array_size;\n\tif (cost >= U32_MAX - PAGE_SIZE)\n\t\treturn ERR_PTR(-ENOMEM);\n\tcost = round_up(cost, PAGE_SIZE) >> PAGE_SHIFT;\n\n\terr = bpf_map_precharge_memlock(cost);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\t/* allocate all map elements and zero-initialize them */\n\tarray = bpf_map_area_alloc(array_size, numa_node);\n\tif (!array)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t/* copy mandatory map attributes */\n\tbpf_map_init_from_attr(&array->map, attr);\n\tarray->map.pages = cost;\n\n\treturn &array->map;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <net/sock_reuseport.h>\n#include <linux/sock_diag.h>\n#include <linux/err.h>\n#include <linux/bpf.h>\n\nstatic int reuseport_array_get_next_key(struct bpf_map *map, void *key,\n\t\t\t\t\tvoid *next_key)\n{\n\tstruct reuseport_array *array = reuseport_array(map);\n\tu32 index = key ? *(u32 *)key : U32_MAX;\n\tu32 *next = (u32 *)next_key;\n\n\tif (index >= array->map.max_entries) {\n\t\t*next = 0;\n\t\treturn 0;\n\t}\n\n\tif (index == array->map.max_entries - 1)\n\t\treturn -ENOENT;\n\n\t*next = index + 1;\n\treturn 0;\n}"
  },
  {
    "function_name": "bpf_fd_reuseport_array_update_elem",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/reuseport_array.c",
    "lines": "251-334",
    "snippet": "int bpf_fd_reuseport_array_update_elem(struct bpf_map *map, void *key,\n\t\t\t\t       void *value, u64 map_flags)\n{\n\tstruct reuseport_array *array = reuseport_array(map);\n\tstruct sock *free_osk = NULL, *osk, *nsk;\n\tstruct sock_reuseport *reuse;\n\tu32 index = *(u32 *)key;\n\tstruct socket *socket;\n\tint err, fd;\n\n\tif (map_flags > BPF_EXIST)\n\t\treturn -EINVAL;\n\n\tif (index >= map->max_entries)\n\t\treturn -E2BIG;\n\n\tif (map->value_size == sizeof(u64)) {\n\t\tu64 fd64 = *(u64 *)value;\n\n\t\tif (fd64 > S32_MAX)\n\t\t\treturn -EINVAL;\n\t\tfd = fd64;\n\t} else {\n\t\tfd = *(int *)value;\n\t}\n\n\tsocket = sockfd_lookup(fd, &err);\n\tif (!socket)\n\t\treturn err;\n\n\tnsk = socket->sk;\n\tif (!nsk) {\n\t\terr = -EINVAL;\n\t\tgoto put_file;\n\t}\n\n\t/* Quick checks before taking reuseport_lock */\n\terr = reuseport_array_update_check(array, nsk,\n\t\t\t\t\t   rcu_access_pointer(array->ptrs[index]),\n\t\t\t\t\t   rcu_access_pointer(nsk->sk_reuseport_cb),\n\t\t\t\t\t   map_flags);\n\tif (err)\n\t\tgoto put_file;\n\n\tspin_lock_bh(&reuseport_lock);\n\t/*\n\t * Some of the checks only need reuseport_lock\n\t * but it is done under sk_callback_lock also\n\t * for simplicity reason.\n\t */\n\twrite_lock_bh(&nsk->sk_callback_lock);\n\n\tosk = rcu_dereference_protected(array->ptrs[index],\n\t\t\t\t\tlockdep_is_held(&reuseport_lock));\n\treuse = rcu_dereference_protected(nsk->sk_reuseport_cb,\n\t\t\t\t\t  lockdep_is_held(&reuseport_lock));\n\terr = reuseport_array_update_check(array, nsk, osk, reuse, map_flags);\n\tif (err)\n\t\tgoto put_file_unlock;\n\n\t/* Ensure reuse->reuseport_id is set */\n\terr = reuseport_get_id(reuse);\n\tif (err < 0)\n\t\tgoto put_file_unlock;\n\n\tWRITE_ONCE(nsk->sk_user_data, &array->ptrs[index]);\n\trcu_assign_pointer(array->ptrs[index], nsk);\n\tfree_osk = osk;\n\terr = 0;\n\nput_file_unlock:\n\twrite_unlock_bh(&nsk->sk_callback_lock);\n\n\tif (free_osk) {\n\t\twrite_lock_bh(&free_osk->sk_callback_lock);\n\t\tWRITE_ONCE(free_osk->sk_user_data, NULL);\n\t\twrite_unlock_bh(&free_osk->sk_callback_lock);\n\t}\n\n\tspin_unlock_bh(&reuseport_lock);\nput_file:\n\tfput(socket->file);\n\treturn err;\n}",
    "includes": [
      "#include <net/sock_reuseport.h>",
      "#include <linux/sock_diag.h>",
      "#include <linux/err.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "fput",
          "args": [
            "socket->file"
          ],
          "line": 332
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_unlock_bh",
          "args": [
            "&reuseport_lock"
          ],
          "line": 330
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "198-201",
          "snippet": "void __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "write_unlock_bh",
          "args": [
            "&free_osk->sk_callback_lock"
          ],
          "line": 327
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_write_unlock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "342-345",
          "snippet": "void __lockfunc _raw_write_unlock_bh(rwlock_t *lock)\n{\n\t__raw_write_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_write_unlock_bh(rwlock_t *lock)\n{\n\t__raw_write_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "free_osk->sk_user_data",
            "NULL"
          ],
          "line": 326
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "write_lock_bh",
          "args": [
            "&free_osk->sk_callback_lock"
          ],
          "line": 325
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_write_lock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "310-313",
          "snippet": "void __lockfunc _raw_write_lock_bh(rwlock_t *lock)\n{\n\t__raw_write_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_write_lock_bh(rwlock_t *lock)\n{\n\t__raw_write_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_assign_pointer",
          "args": [
            "array->ptrs[index]",
            "nsk"
          ],
          "line": 317
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "nsk->sk_user_data",
            "&array->ptrs[index]"
          ],
          "line": 316
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "reuseport_get_id",
          "args": [
            "reuse"
          ],
          "line": 312
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "reuseport_array_update_check",
          "args": [
            "array",
            "nsk",
            "osk",
            "reuse",
            "map_flags"
          ],
          "line": 307
        },
        "resolved": true,
        "details": {
          "function_name": "reuseport_array_update_check",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/reuseport_array.c",
          "lines": "206-244",
          "snippet": "static int\nreuseport_array_update_check(const struct reuseport_array *array,\n\t\t\t     const struct sock *nsk,\n\t\t\t     const struct sock *osk,\n\t\t\t     const struct sock_reuseport *nsk_reuse,\n\t\t\t     u32 map_flags)\n{\n\tif (osk && map_flags == BPF_NOEXIST)\n\t\treturn -EEXIST;\n\n\tif (!osk && map_flags == BPF_EXIST)\n\t\treturn -ENOENT;\n\n\tif (nsk->sk_protocol != IPPROTO_UDP && nsk->sk_protocol != IPPROTO_TCP)\n\t\treturn -ENOTSUPP;\n\n\tif (nsk->sk_family != AF_INET && nsk->sk_family != AF_INET6)\n\t\treturn -ENOTSUPP;\n\n\tif (nsk->sk_type != SOCK_STREAM && nsk->sk_type != SOCK_DGRAM)\n\t\treturn -ENOTSUPP;\n\n\t/*\n\t * sk must be hashed (i.e. listening in the TCP case or binded\n\t * in the UDP case) and\n\t * it must also be a SO_REUSEPORT sk (i.e. reuse cannot be NULL).\n\t *\n\t * Also, sk will be used in bpf helper that is protected by\n\t * rcu_read_lock().\n\t */\n\tif (!sock_flag(nsk, SOCK_RCU_FREE) || !sk_hashed(nsk) || !nsk_reuse)\n\t\treturn -EINVAL;\n\n\t/* READ_ONCE because the sk->sk_callback_lock may not be held here */\n\tif (READ_ONCE(nsk->sk_user_data))\n\t\treturn -EBUSY;\n\n\treturn 0;\n}",
          "includes": [
            "#include <net/sock_reuseport.h>",
            "#include <linux/sock_diag.h>",
            "#include <linux/err.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <net/sock_reuseport.h>\n#include <linux/sock_diag.h>\n#include <linux/err.h>\n#include <linux/bpf.h>\n\nstatic int\nreuseport_array_update_check(const struct reuseport_array *array,\n\t\t\t     const struct sock *nsk,\n\t\t\t     const struct sock *osk,\n\t\t\t     const struct sock_reuseport *nsk_reuse,\n\t\t\t     u32 map_flags)\n{\n\tif (osk && map_flags == BPF_NOEXIST)\n\t\treturn -EEXIST;\n\n\tif (!osk && map_flags == BPF_EXIST)\n\t\treturn -ENOENT;\n\n\tif (nsk->sk_protocol != IPPROTO_UDP && nsk->sk_protocol != IPPROTO_TCP)\n\t\treturn -ENOTSUPP;\n\n\tif (nsk->sk_family != AF_INET && nsk->sk_family != AF_INET6)\n\t\treturn -ENOTSUPP;\n\n\tif (nsk->sk_type != SOCK_STREAM && nsk->sk_type != SOCK_DGRAM)\n\t\treturn -ENOTSUPP;\n\n\t/*\n\t * sk must be hashed (i.e. listening in the TCP case or binded\n\t * in the UDP case) and\n\t * it must also be a SO_REUSEPORT sk (i.e. reuse cannot be NULL).\n\t *\n\t * Also, sk will be used in bpf helper that is protected by\n\t * rcu_read_lock().\n\t */\n\tif (!sock_flag(nsk, SOCK_RCU_FREE) || !sk_hashed(nsk) || !nsk_reuse)\n\t\treturn -EINVAL;\n\n\t/* READ_ONCE because the sk->sk_callback_lock may not be held here */\n\tif (READ_ONCE(nsk->sk_user_data))\n\t\treturn -EBUSY;\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_dereference_protected",
          "args": [
            "nsk->sk_reuseport_cb",
            "lockdep_is_held(&reuseport_lock)"
          ],
          "line": 305
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lockdep_is_held",
          "args": [
            "&reuseport_lock"
          ],
          "line": 306
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_dereference_protected",
          "args": [
            "array->ptrs[index]",
            "lockdep_is_held(&reuseport_lock)"
          ],
          "line": 303
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lockdep_is_held",
          "args": [
            "&reuseport_lock"
          ],
          "line": 304
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_lock_bh",
          "args": [
            "&reuseport_lock"
          ],
          "line": 295
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "166-169",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_access_pointer",
          "args": [
            "nsk->sk_reuseport_cb"
          ],
          "line": 290
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_access_pointer",
          "args": [
            "array->ptrs[index]"
          ],
          "line": 289
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sockfd_lookup",
          "args": [
            "fd",
            "&err"
          ],
          "line": 277
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "reuseport_array",
          "args": [
            "map"
          ],
          "line": 254
        },
        "resolved": true,
        "details": {
          "function_name": "reuseport_array_alloc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/reuseport_array.c",
          "lines": "150-182",
          "snippet": "static struct bpf_map *reuseport_array_alloc(union bpf_attr *attr)\n{\n\tint err, numa_node = bpf_map_attr_numa_node(attr);\n\tstruct reuseport_array *array;\n\tu64 cost, array_size;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn ERR_PTR(-EPERM);\n\n\tarray_size = sizeof(*array);\n\tarray_size += (u64)attr->max_entries * sizeof(struct sock *);\n\n\t/* make sure there is no u32 overflow later in round_up() */\n\tcost = array_size;\n\tif (cost >= U32_MAX - PAGE_SIZE)\n\t\treturn ERR_PTR(-ENOMEM);\n\tcost = round_up(cost, PAGE_SIZE) >> PAGE_SHIFT;\n\n\terr = bpf_map_precharge_memlock(cost);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\t/* allocate all map elements and zero-initialize them */\n\tarray = bpf_map_area_alloc(array_size, numa_node);\n\tif (!array)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t/* copy mandatory map attributes */\n\tbpf_map_init_from_attr(&array->map, attr);\n\tarray->map.pages = cost;\n\n\treturn &array->map;\n}",
          "includes": [
            "#include <net/sock_reuseport.h>",
            "#include <linux/sock_diag.h>",
            "#include <linux/err.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <net/sock_reuseport.h>\n#include <linux/sock_diag.h>\n#include <linux/err.h>\n#include <linux/bpf.h>\n\nstatic struct bpf_map *reuseport_array_alloc(union bpf_attr *attr)\n{\n\tint err, numa_node = bpf_map_attr_numa_node(attr);\n\tstruct reuseport_array *array;\n\tu64 cost, array_size;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn ERR_PTR(-EPERM);\n\n\tarray_size = sizeof(*array);\n\tarray_size += (u64)attr->max_entries * sizeof(struct sock *);\n\n\t/* make sure there is no u32 overflow later in round_up() */\n\tcost = array_size;\n\tif (cost >= U32_MAX - PAGE_SIZE)\n\t\treturn ERR_PTR(-ENOMEM);\n\tcost = round_up(cost, PAGE_SIZE) >> PAGE_SHIFT;\n\n\terr = bpf_map_precharge_memlock(cost);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\t/* allocate all map elements and zero-initialize them */\n\tarray = bpf_map_area_alloc(array_size, numa_node);\n\tif (!array)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t/* copy mandatory map attributes */\n\tbpf_map_init_from_attr(&array->map, attr);\n\tarray->map.pages = cost;\n\n\treturn &array->map;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <net/sock_reuseport.h>\n#include <linux/sock_diag.h>\n#include <linux/err.h>\n#include <linux/bpf.h>\n\nint bpf_fd_reuseport_array_update_elem(struct bpf_map *map, void *key,\n\t\t\t\t       void *value, u64 map_flags)\n{\n\tstruct reuseport_array *array = reuseport_array(map);\n\tstruct sock *free_osk = NULL, *osk, *nsk;\n\tstruct sock_reuseport *reuse;\n\tu32 index = *(u32 *)key;\n\tstruct socket *socket;\n\tint err, fd;\n\n\tif (map_flags > BPF_EXIST)\n\t\treturn -EINVAL;\n\n\tif (index >= map->max_entries)\n\t\treturn -E2BIG;\n\n\tif (map->value_size == sizeof(u64)) {\n\t\tu64 fd64 = *(u64 *)value;\n\n\t\tif (fd64 > S32_MAX)\n\t\t\treturn -EINVAL;\n\t\tfd = fd64;\n\t} else {\n\t\tfd = *(int *)value;\n\t}\n\n\tsocket = sockfd_lookup(fd, &err);\n\tif (!socket)\n\t\treturn err;\n\n\tnsk = socket->sk;\n\tif (!nsk) {\n\t\terr = -EINVAL;\n\t\tgoto put_file;\n\t}\n\n\t/* Quick checks before taking reuseport_lock */\n\terr = reuseport_array_update_check(array, nsk,\n\t\t\t\t\t   rcu_access_pointer(array->ptrs[index]),\n\t\t\t\t\t   rcu_access_pointer(nsk->sk_reuseport_cb),\n\t\t\t\t\t   map_flags);\n\tif (err)\n\t\tgoto put_file;\n\n\tspin_lock_bh(&reuseport_lock);\n\t/*\n\t * Some of the checks only need reuseport_lock\n\t * but it is done under sk_callback_lock also\n\t * for simplicity reason.\n\t */\n\twrite_lock_bh(&nsk->sk_callback_lock);\n\n\tosk = rcu_dereference_protected(array->ptrs[index],\n\t\t\t\t\tlockdep_is_held(&reuseport_lock));\n\treuse = rcu_dereference_protected(nsk->sk_reuseport_cb,\n\t\t\t\t\t  lockdep_is_held(&reuseport_lock));\n\terr = reuseport_array_update_check(array, nsk, osk, reuse, map_flags);\n\tif (err)\n\t\tgoto put_file_unlock;\n\n\t/* Ensure reuse->reuseport_id is set */\n\terr = reuseport_get_id(reuse);\n\tif (err < 0)\n\t\tgoto put_file_unlock;\n\n\tWRITE_ONCE(nsk->sk_user_data, &array->ptrs[index]);\n\trcu_assign_pointer(array->ptrs[index], nsk);\n\tfree_osk = osk;\n\terr = 0;\n\nput_file_unlock:\n\twrite_unlock_bh(&nsk->sk_callback_lock);\n\n\tif (free_osk) {\n\t\twrite_lock_bh(&free_osk->sk_callback_lock);\n\t\tWRITE_ONCE(free_osk->sk_user_data, NULL);\n\t\twrite_unlock_bh(&free_osk->sk_callback_lock);\n\t}\n\n\tspin_unlock_bh(&reuseport_lock);\nput_file:\n\tfput(socket->file);\n\treturn err;\n}"
  },
  {
    "function_name": "reuseport_array_update_check",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/reuseport_array.c",
    "lines": "206-244",
    "snippet": "static int\nreuseport_array_update_check(const struct reuseport_array *array,\n\t\t\t     const struct sock *nsk,\n\t\t\t     const struct sock *osk,\n\t\t\t     const struct sock_reuseport *nsk_reuse,\n\t\t\t     u32 map_flags)\n{\n\tif (osk && map_flags == BPF_NOEXIST)\n\t\treturn -EEXIST;\n\n\tif (!osk && map_flags == BPF_EXIST)\n\t\treturn -ENOENT;\n\n\tif (nsk->sk_protocol != IPPROTO_UDP && nsk->sk_protocol != IPPROTO_TCP)\n\t\treturn -ENOTSUPP;\n\n\tif (nsk->sk_family != AF_INET && nsk->sk_family != AF_INET6)\n\t\treturn -ENOTSUPP;\n\n\tif (nsk->sk_type != SOCK_STREAM && nsk->sk_type != SOCK_DGRAM)\n\t\treturn -ENOTSUPP;\n\n\t/*\n\t * sk must be hashed (i.e. listening in the TCP case or binded\n\t * in the UDP case) and\n\t * it must also be a SO_REUSEPORT sk (i.e. reuse cannot be NULL).\n\t *\n\t * Also, sk will be used in bpf helper that is protected by\n\t * rcu_read_lock().\n\t */\n\tif (!sock_flag(nsk, SOCK_RCU_FREE) || !sk_hashed(nsk) || !nsk_reuse)\n\t\treturn -EINVAL;\n\n\t/* READ_ONCE because the sk->sk_callback_lock may not be held here */\n\tif (READ_ONCE(nsk->sk_user_data))\n\t\treturn -EBUSY;\n\n\treturn 0;\n}",
    "includes": [
      "#include <net/sock_reuseport.h>",
      "#include <linux/sock_diag.h>",
      "#include <linux/err.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "nsk->sk_user_data"
          ],
          "line": 240
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sk_hashed",
          "args": [
            "nsk"
          ],
          "line": 236
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sock_flag",
          "args": [
            "nsk",
            "SOCK_RCU_FREE"
          ],
          "line": 236
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <net/sock_reuseport.h>\n#include <linux/sock_diag.h>\n#include <linux/err.h>\n#include <linux/bpf.h>\n\nstatic int\nreuseport_array_update_check(const struct reuseport_array *array,\n\t\t\t     const struct sock *nsk,\n\t\t\t     const struct sock *osk,\n\t\t\t     const struct sock_reuseport *nsk_reuse,\n\t\t\t     u32 map_flags)\n{\n\tif (osk && map_flags == BPF_NOEXIST)\n\t\treturn -EEXIST;\n\n\tif (!osk && map_flags == BPF_EXIST)\n\t\treturn -ENOENT;\n\n\tif (nsk->sk_protocol != IPPROTO_UDP && nsk->sk_protocol != IPPROTO_TCP)\n\t\treturn -ENOTSUPP;\n\n\tif (nsk->sk_family != AF_INET && nsk->sk_family != AF_INET6)\n\t\treturn -ENOTSUPP;\n\n\tif (nsk->sk_type != SOCK_STREAM && nsk->sk_type != SOCK_DGRAM)\n\t\treturn -ENOTSUPP;\n\n\t/*\n\t * sk must be hashed (i.e. listening in the TCP case or binded\n\t * in the UDP case) and\n\t * it must also be a SO_REUSEPORT sk (i.e. reuse cannot be NULL).\n\t *\n\t * Also, sk will be used in bpf helper that is protected by\n\t * rcu_read_lock().\n\t */\n\tif (!sock_flag(nsk, SOCK_RCU_FREE) || !sk_hashed(nsk) || !nsk_reuse)\n\t\treturn -EINVAL;\n\n\t/* READ_ONCE because the sk->sk_callback_lock may not be held here */\n\tif (READ_ONCE(nsk->sk_user_data))\n\t\treturn -EBUSY;\n\n\treturn 0;\n}"
  },
  {
    "function_name": "bpf_fd_reuseport_array_lookup_elem",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/reuseport_array.c",
    "lines": "184-204",
    "snippet": "int bpf_fd_reuseport_array_lookup_elem(struct bpf_map *map, void *key,\n\t\t\t\t       void *value)\n{\n\tstruct sock *sk;\n\tint err;\n\n\tif (map->value_size != sizeof(u64))\n\t\treturn -ENOSPC;\n\n\trcu_read_lock();\n\tsk = reuseport_array_lookup_elem(map, key);\n\tif (sk) {\n\t\t*(u64 *)value = sock_gen_cookie(sk);\n\t\terr = 0;\n\t} else {\n\t\terr = -ENOENT;\n\t}\n\trcu_read_unlock();\n\n\treturn err;\n}",
    "includes": [
      "#include <net/sock_reuseport.h>",
      "#include <linux/sock_diag.h>",
      "#include <linux/err.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 201
        },
        "resolved": true,
        "details": {
          "function_name": "__rcu_read_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/tree_plugin.h",
          "lines": "419-441",
          "snippet": "void __rcu_read_unlock(void)\n{\n\tstruct task_struct *t = current;\n\n\tif (t->rcu_read_lock_nesting != 1) {\n\t\t--t->rcu_read_lock_nesting;\n\t} else {\n\t\tbarrier();  /* critical section before exit code. */\n\t\tt->rcu_read_lock_nesting = INT_MIN;\n\t\tbarrier();  /* assign before ->rcu_read_unlock_special load */\n\t\tif (unlikely(READ_ONCE(t->rcu_read_unlock_special.s)))\n\t\t\trcu_read_unlock_special(t);\n\t\tbarrier();  /* ->rcu_read_unlock_special load before assign */\n\t\tt->rcu_read_lock_nesting = 0;\n\t}\n#ifdef CONFIG_PROVE_LOCKING\n\t{\n\t\tint rrln = READ_ONCE(t->rcu_read_lock_nesting);\n\n\t\tWARN_ON_ONCE(rrln < 0 && rrln > INT_MIN / 2);\n\t}\n#endif /* #ifdef CONFIG_PROVE_LOCKING */\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"../time/tick-internal.h\"",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/oom.h>",
            "#include <linux/gfp.h>",
            "#include <linux/delay.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"../time/tick-internal.h\"\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/isolation.h>\n#include <linux/smpboot.h>\n#include <linux/sched/debug.h>\n#include <linux/oom.h>\n#include <linux/gfp.h>\n#include <linux/delay.h>\n\nvoid __rcu_read_unlock(void)\n{\n\tstruct task_struct *t = current;\n\n\tif (t->rcu_read_lock_nesting != 1) {\n\t\t--t->rcu_read_lock_nesting;\n\t} else {\n\t\tbarrier();  /* critical section before exit code. */\n\t\tt->rcu_read_lock_nesting = INT_MIN;\n\t\tbarrier();  /* assign before ->rcu_read_unlock_special load */\n\t\tif (unlikely(READ_ONCE(t->rcu_read_unlock_special.s)))\n\t\t\trcu_read_unlock_special(t);\n\t\tbarrier();  /* ->rcu_read_unlock_special load before assign */\n\t\tt->rcu_read_lock_nesting = 0;\n\t}\n#ifdef CONFIG_PROVE_LOCKING\n\t{\n\t\tint rrln = READ_ONCE(t->rcu_read_lock_nesting);\n\n\t\tWARN_ON_ONCE(rrln < 0 && rrln > INT_MIN / 2);\n\t}\n#endif /* #ifdef CONFIG_PROVE_LOCKING */\n}"
        }
      },
      {
        "call_info": {
          "callee": "sock_gen_cookie",
          "args": [
            "sk"
          ],
          "line": 196
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "reuseport_array_lookup_elem",
          "args": [
            "map",
            "key"
          ],
          "line": 194
        },
        "resolved": true,
        "details": {
          "function_name": "reuseport_array_lookup_elem",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/reuseport_array.c",
          "lines": "49-58",
          "snippet": "static void *reuseport_array_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct reuseport_array *array = reuseport_array(map);\n\tu32 index = *(u32 *)key;\n\n\tif (unlikely(index >= array->map.max_entries))\n\t\treturn NULL;\n\n\treturn rcu_dereference(array->ptrs[index]);\n}",
          "includes": [
            "#include <net/sock_reuseport.h>",
            "#include <linux/sock_diag.h>",
            "#include <linux/err.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <net/sock_reuseport.h>\n#include <linux/sock_diag.h>\n#include <linux/err.h>\n#include <linux/bpf.h>\n\nstatic void *reuseport_array_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct reuseport_array *array = reuseport_array(map);\n\tu32 index = *(u32 *)key;\n\n\tif (unlikely(index >= array->map.max_entries))\n\t\treturn NULL;\n\n\treturn rcu_dereference(array->ptrs[index]);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 193
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_bh_held",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/update.c",
          "lines": "300-309",
          "snippet": "int rcu_read_lock_bh_held(void)\n{\n\tif (!debug_lockdep_rcu_enabled())\n\t\treturn 1;\n\tif (!rcu_is_watching())\n\t\treturn 0;\n\tif (!rcu_lockdep_current_cpu_online())\n\t\treturn 0;\n\treturn in_softirq() || irqs_disabled();\n}",
          "includes": [
            "#include \"rcu.h\"",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu.h\"\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_bh_held(void)\n{\n\tif (!debug_lockdep_rcu_enabled())\n\t\treturn 1;\n\tif (!rcu_is_watching())\n\t\treturn 0;\n\tif (!rcu_lockdep_current_cpu_online())\n\t\treturn 0;\n\treturn in_softirq() || irqs_disabled();\n}"
        }
      }
    ],
    "contextual_snippet": "#include <net/sock_reuseport.h>\n#include <linux/sock_diag.h>\n#include <linux/err.h>\n#include <linux/bpf.h>\n\nint bpf_fd_reuseport_array_lookup_elem(struct bpf_map *map, void *key,\n\t\t\t\t       void *value)\n{\n\tstruct sock *sk;\n\tint err;\n\n\tif (map->value_size != sizeof(u64))\n\t\treturn -ENOSPC;\n\n\trcu_read_lock();\n\tsk = reuseport_array_lookup_elem(map, key);\n\tif (sk) {\n\t\t*(u64 *)value = sock_gen_cookie(sk);\n\t\terr = 0;\n\t} else {\n\t\terr = -ENOENT;\n\t}\n\trcu_read_unlock();\n\n\treturn err;\n}"
  },
  {
    "function_name": "reuseport_array_alloc",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/reuseport_array.c",
    "lines": "150-182",
    "snippet": "static struct bpf_map *reuseport_array_alloc(union bpf_attr *attr)\n{\n\tint err, numa_node = bpf_map_attr_numa_node(attr);\n\tstruct reuseport_array *array;\n\tu64 cost, array_size;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn ERR_PTR(-EPERM);\n\n\tarray_size = sizeof(*array);\n\tarray_size += (u64)attr->max_entries * sizeof(struct sock *);\n\n\t/* make sure there is no u32 overflow later in round_up() */\n\tcost = array_size;\n\tif (cost >= U32_MAX - PAGE_SIZE)\n\t\treturn ERR_PTR(-ENOMEM);\n\tcost = round_up(cost, PAGE_SIZE) >> PAGE_SHIFT;\n\n\terr = bpf_map_precharge_memlock(cost);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\t/* allocate all map elements and zero-initialize them */\n\tarray = bpf_map_area_alloc(array_size, numa_node);\n\tif (!array)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t/* copy mandatory map attributes */\n\tbpf_map_init_from_attr(&array->map, attr);\n\tarray->map.pages = cost;\n\n\treturn &array->map;\n}",
    "includes": [
      "#include <net/sock_reuseport.h>",
      "#include <linux/sock_diag.h>",
      "#include <linux/err.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_map_init_from_attr",
          "args": [
            "&array->map",
            "attr"
          ],
          "line": 178
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_init_from_attr",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/syscall.c",
          "lines": "161-169",
          "snippet": "void bpf_map_init_from_attr(struct bpf_map *map, union bpf_attr *attr)\n{\n\tmap->map_type = attr->map_type;\n\tmap->key_size = attr->key_size;\n\tmap->value_size = attr->value_size;\n\tmap->max_entries = attr->max_entries;\n\tmap->map_flags = attr->map_flags;\n\tmap->numa_node = bpf_map_attr_numa_node(attr);\n}",
          "includes": [
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/version.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/version.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf.h>\n\nvoid bpf_map_init_from_attr(struct bpf_map *map, union bpf_attr *attr)\n{\n\tmap->map_type = attr->map_type;\n\tmap->key_size = attr->key_size;\n\tmap->value_size = attr->value_size;\n\tmap->max_entries = attr->max_entries;\n\tmap->map_flags = attr->map_flags;\n\tmap->numa_node = bpf_map_attr_numa_node(attr);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-ENOMEM"
          ],
          "line": 175
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_map_area_alloc",
          "args": [
            "array_size",
            "numa_node"
          ],
          "line": 173
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_area_alloc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/syscall.c",
          "lines": "137-154",
          "snippet": "void *bpf_map_area_alloc(size_t size, int numa_node)\n{\n\t/* We definitely need __GFP_NORETRY, so OOM killer doesn't\n\t * trigger under memory pressure as we really just want to\n\t * fail instead.\n\t */\n\tconst gfp_t flags = __GFP_NOWARN | __GFP_NORETRY | __GFP_ZERO;\n\tvoid *area;\n\n\tif (size <= (PAGE_SIZE << PAGE_ALLOC_COSTLY_ORDER)) {\n\t\tarea = kmalloc_node(size, GFP_USER | flags, numa_node);\n\t\tif (area != NULL)\n\t\t\treturn area;\n\t}\n\n\treturn __vmalloc_node_flags_caller(size, numa_node, GFP_KERNEL | flags,\n\t\t\t\t\t   __builtin_return_address(0));\n}",
          "includes": [
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/version.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/version.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf.h>\n\nvoid *bpf_map_area_alloc(size_t size, int numa_node)\n{\n\t/* We definitely need __GFP_NORETRY, so OOM killer doesn't\n\t * trigger under memory pressure as we really just want to\n\t * fail instead.\n\t */\n\tconst gfp_t flags = __GFP_NOWARN | __GFP_NORETRY | __GFP_ZERO;\n\tvoid *area;\n\n\tif (size <= (PAGE_SIZE << PAGE_ALLOC_COSTLY_ORDER)) {\n\t\tarea = kmalloc_node(size, GFP_USER | flags, numa_node);\n\t\tif (area != NULL)\n\t\t\treturn area;\n\t}\n\n\treturn __vmalloc_node_flags_caller(size, numa_node, GFP_KERNEL | flags,\n\t\t\t\t\t   __builtin_return_address(0));\n}"
        }
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "err"
          ],
          "line": 170
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_map_precharge_memlock",
          "args": [
            "cost"
          ],
          "line": 168
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_precharge_memlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/syscall.c",
          "lines": "171-182",
          "snippet": "int bpf_map_precharge_memlock(u32 pages)\n{\n\tstruct user_struct *user = get_current_user();\n\tunsigned long memlock_limit, cur;\n\n\tmemlock_limit = rlimit(RLIMIT_MEMLOCK) >> PAGE_SHIFT;\n\tcur = atomic_long_read(&user->locked_vm);\n\tfree_uid(user);\n\tif (cur + pages > memlock_limit)\n\t\treturn -EPERM;\n\treturn 0;\n}",
          "includes": [
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/version.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/version.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf.h>\n\nint bpf_map_precharge_memlock(u32 pages)\n{\n\tstruct user_struct *user = get_current_user();\n\tunsigned long memlock_limit, cur;\n\n\tmemlock_limit = rlimit(RLIMIT_MEMLOCK) >> PAGE_SHIFT;\n\tcur = atomic_long_read(&user->locked_vm);\n\tfree_uid(user);\n\tif (cur + pages > memlock_limit)\n\t\treturn -EPERM;\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "cost",
            "PAGE_SIZE"
          ],
          "line": 166
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-ENOMEM"
          ],
          "line": 165
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-EPERM"
          ],
          "line": 157
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "capable",
          "args": [
            "CAP_SYS_ADMIN"
          ],
          "line": 156
        },
        "resolved": true,
        "details": {
          "function_name": "capable",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/capability.c",
          "lines": "429-432",
          "snippet": "bool capable(int cap)\n{\n\treturn ns_capable(&init_user_ns, cap);\n}",
          "includes": [
            "#include <linux/uaccess.h>",
            "#include <linux/user_namespace.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/security.h>",
            "#include <linux/export.h>",
            "#include <linux/mm.h>",
            "#include <linux/capability.h>",
            "#include <linux/audit.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/uaccess.h>\n#include <linux/user_namespace.h>\n#include <linux/pid_namespace.h>\n#include <linux/syscalls.h>\n#include <linux/security.h>\n#include <linux/export.h>\n#include <linux/mm.h>\n#include <linux/capability.h>\n#include <linux/audit.h>\n\nbool capable(int cap)\n{\n\treturn ns_capable(&init_user_ns, cap);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_attr_numa_node",
          "args": [
            "attr"
          ],
          "line": 152
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <net/sock_reuseport.h>\n#include <linux/sock_diag.h>\n#include <linux/err.h>\n#include <linux/bpf.h>\n\nstatic struct bpf_map *reuseport_array_alloc(union bpf_attr *attr)\n{\n\tint err, numa_node = bpf_map_attr_numa_node(attr);\n\tstruct reuseport_array *array;\n\tu64 cost, array_size;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn ERR_PTR(-EPERM);\n\n\tarray_size = sizeof(*array);\n\tarray_size += (u64)attr->max_entries * sizeof(struct sock *);\n\n\t/* make sure there is no u32 overflow later in round_up() */\n\tcost = array_size;\n\tif (cost >= U32_MAX - PAGE_SIZE)\n\t\treturn ERR_PTR(-ENOMEM);\n\tcost = round_up(cost, PAGE_SIZE) >> PAGE_SHIFT;\n\n\terr = bpf_map_precharge_memlock(cost);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\t/* allocate all map elements and zero-initialize them */\n\tarray = bpf_map_area_alloc(array_size, numa_node);\n\tif (!array)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t/* copy mandatory map attributes */\n\tbpf_map_init_from_attr(&array->map, attr);\n\tarray->map.pages = cost;\n\n\treturn &array->map;\n}"
  },
  {
    "function_name": "reuseport_array_free",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/reuseport_array.c",
    "lines": "93-148",
    "snippet": "static void reuseport_array_free(struct bpf_map *map)\n{\n\tstruct reuseport_array *array = reuseport_array(map);\n\tstruct sock *sk;\n\tu32 i;\n\n\tsynchronize_rcu();\n\n\t/*\n\t * ops->map_*_elem() will not be able to access this\n\t * array now. Hence, this function only races with\n\t * bpf_sk_reuseport_detach() which was triggerred by\n\t * close() or disconnect().\n\t *\n\t * This function and bpf_sk_reuseport_detach() are\n\t * both removing sk from \"array\".  Who removes it\n\t * first does not matter.\n\t *\n\t * The only concern here is bpf_sk_reuseport_detach()\n\t * may access \"array\" which is being freed here.\n\t * bpf_sk_reuseport_detach() access this \"array\"\n\t * through sk->sk_user_data _and_ with sk->sk_callback_lock\n\t * held which is enough because this \"array\" is not freed\n\t * until all sk->sk_user_data has stopped referencing this \"array\".\n\t *\n\t * Hence, due to the above, taking \"reuseport_lock\" is not\n\t * needed here.\n\t */\n\n\t/*\n\t * Since reuseport_lock is not taken, sk is accessed under\n\t * rcu_read_lock()\n\t */\n\trcu_read_lock();\n\tfor (i = 0; i < map->max_entries; i++) {\n\t\tsk = rcu_dereference(array->ptrs[i]);\n\t\tif (sk) {\n\t\t\twrite_lock_bh(&sk->sk_callback_lock);\n\t\t\t/*\n\t\t\t * No need for WRITE_ONCE(). At this point,\n\t\t\t * no one is reading it without taking the\n\t\t\t * sk->sk_callback_lock.\n\t\t\t */\n\t\t\tsk->sk_user_data = NULL;\n\t\t\twrite_unlock_bh(&sk->sk_callback_lock);\n\t\t\tRCU_INIT_POINTER(array->ptrs[i], NULL);\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\t/*\n\t * Once reaching here, all sk->sk_user_data is not\n\t * referenceing this \"array\".  \"array\" can be freed now.\n\t */\n\tbpf_map_area_free(array);\n}",
    "includes": [
      "#include <net/sock_reuseport.h>",
      "#include <linux/sock_diag.h>",
      "#include <linux/err.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_map_area_free",
          "args": [
            "array"
          ],
          "line": 147
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_area_free",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/syscall.c",
          "lines": "156-159",
          "snippet": "void bpf_map_area_free(void *area)\n{\n\tkvfree(area);\n}",
          "includes": [
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/version.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/version.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf.h>\n\nvoid bpf_map_area_free(void *area)\n{\n\tkvfree(area);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 141
        },
        "resolved": true,
        "details": {
          "function_name": "__rcu_read_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/tree_plugin.h",
          "lines": "419-441",
          "snippet": "void __rcu_read_unlock(void)\n{\n\tstruct task_struct *t = current;\n\n\tif (t->rcu_read_lock_nesting != 1) {\n\t\t--t->rcu_read_lock_nesting;\n\t} else {\n\t\tbarrier();  /* critical section before exit code. */\n\t\tt->rcu_read_lock_nesting = INT_MIN;\n\t\tbarrier();  /* assign before ->rcu_read_unlock_special load */\n\t\tif (unlikely(READ_ONCE(t->rcu_read_unlock_special.s)))\n\t\t\trcu_read_unlock_special(t);\n\t\tbarrier();  /* ->rcu_read_unlock_special load before assign */\n\t\tt->rcu_read_lock_nesting = 0;\n\t}\n#ifdef CONFIG_PROVE_LOCKING\n\t{\n\t\tint rrln = READ_ONCE(t->rcu_read_lock_nesting);\n\n\t\tWARN_ON_ONCE(rrln < 0 && rrln > INT_MIN / 2);\n\t}\n#endif /* #ifdef CONFIG_PROVE_LOCKING */\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"../time/tick-internal.h\"",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/oom.h>",
            "#include <linux/gfp.h>",
            "#include <linux/delay.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"../time/tick-internal.h\"\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/isolation.h>\n#include <linux/smpboot.h>\n#include <linux/sched/debug.h>\n#include <linux/oom.h>\n#include <linux/gfp.h>\n#include <linux/delay.h>\n\nvoid __rcu_read_unlock(void)\n{\n\tstruct task_struct *t = current;\n\n\tif (t->rcu_read_lock_nesting != 1) {\n\t\t--t->rcu_read_lock_nesting;\n\t} else {\n\t\tbarrier();  /* critical section before exit code. */\n\t\tt->rcu_read_lock_nesting = INT_MIN;\n\t\tbarrier();  /* assign before ->rcu_read_unlock_special load */\n\t\tif (unlikely(READ_ONCE(t->rcu_read_unlock_special.s)))\n\t\t\trcu_read_unlock_special(t);\n\t\tbarrier();  /* ->rcu_read_unlock_special load before assign */\n\t\tt->rcu_read_lock_nesting = 0;\n\t}\n#ifdef CONFIG_PROVE_LOCKING\n\t{\n\t\tint rrln = READ_ONCE(t->rcu_read_lock_nesting);\n\n\t\tWARN_ON_ONCE(rrln < 0 && rrln > INT_MIN / 2);\n\t}\n#endif /* #ifdef CONFIG_PROVE_LOCKING */\n}"
        }
      },
      {
        "call_info": {
          "callee": "RCU_INIT_POINTER",
          "args": [
            "array->ptrs[i]",
            "NULL"
          ],
          "line": 138
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "write_unlock_bh",
          "args": [
            "&sk->sk_callback_lock"
          ],
          "line": 137
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_write_unlock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "342-345",
          "snippet": "void __lockfunc _raw_write_unlock_bh(rwlock_t *lock)\n{\n\t__raw_write_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_write_unlock_bh(rwlock_t *lock)\n{\n\t__raw_write_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "write_lock_bh",
          "args": [
            "&sk->sk_callback_lock"
          ],
          "line": 130
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_write_lock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "310-313",
          "snippet": "void __lockfunc _raw_write_lock_bh(rwlock_t *lock)\n{\n\t__raw_write_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_write_lock_bh(rwlock_t *lock)\n{\n\t__raw_write_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_dereference",
          "args": [
            "array->ptrs[i]"
          ],
          "line": 128
        },
        "resolved": true,
        "details": {
          "function_name": "task_rcu_dereference",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/exit.c",
          "lines": "234-291",
          "snippet": "struct task_struct *task_rcu_dereference(struct task_struct **ptask)\n{\n\tstruct sighand_struct *sighand;\n\tstruct task_struct *task;\n\n\t/*\n\t * We need to verify that release_task() was not called and thus\n\t * delayed_put_task_struct() can't run and drop the last reference\n\t * before rcu_read_unlock(). We check task->sighand != NULL,\n\t * but we can read the already freed and reused memory.\n\t */\nretry:\n\ttask = rcu_dereference(*ptask);\n\tif (!task)\n\t\treturn NULL;\n\n\tprobe_kernel_address(&task->sighand, sighand);\n\n\t/*\n\t * Pairs with atomic_dec_and_test() in put_task_struct(). If this task\n\t * was already freed we can not miss the preceding update of this\n\t * pointer.\n\t */\n\tsmp_rmb();\n\tif (unlikely(task != READ_ONCE(*ptask)))\n\t\tgoto retry;\n\n\t/*\n\t * We've re-checked that \"task == *ptask\", now we have two different\n\t * cases:\n\t *\n\t * 1. This is actually the same task/task_struct. In this case\n\t *    sighand != NULL tells us it is still alive.\n\t *\n\t * 2. This is another task which got the same memory for task_struct.\n\t *    We can't know this of course, and we can not trust\n\t *    sighand != NULL.\n\t *\n\t *    In this case we actually return a random value, but this is\n\t *    correct.\n\t *\n\t *    If we return NULL - we can pretend that we actually noticed that\n\t *    *ptask was updated when the previous task has exited. Or pretend\n\t *    that probe_slab_address(&sighand) reads NULL.\n\t *\n\t *    If we return the new task (because sighand is not NULL for any\n\t *    reason) - this is fine too. This (new) task can't go away before\n\t *    another gp pass.\n\t *\n\t *    And note: We could even eliminate the false positive if re-read\n\t *    task->sighand once again to avoid the falsely NULL. But this case\n\t *    is very unlikely so we don't care.\n\t */\n\tif (!sighand)\n\t\treturn NULL;\n\n\treturn task;\n}",
          "includes": [
            "#include <asm/mmu_context.h>",
            "#include <asm/pgtable.h>",
            "#include <asm/unistd.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/compat.h>",
            "#include <linux/rcuwait.h>",
            "#include <linux/random.h>",
            "#include <linux/kcov.h>",
            "#include <linux/shm.h>",
            "#include <linux/writeback.h>",
            "#include <linux/oom.h>",
            "#include <linux/hw_breakpoint.h>",
            "#include <trace/events/sched.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/init_task.h>",
            "#include <linux/fs_struct.h>",
            "#include <linux/tracehook.h>",
            "#include <linux/task_io_accounting_ops.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/resource.h>",
            "#include <linux/audit.h> /* for audit_free() */",
            "#include <linux/pipe_fs_i.h>",
            "#include <linux/futex.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cn_proc.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/signal.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/taskstats_kern.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/kthread.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/mount.h>",
            "#include <linux/profile.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/binfmts.h>",
            "#include <linux/freezer.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/file.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/acct.h>",
            "#include <linux/cpu.h>",
            "#include <linux/key.h>",
            "#include <linux/iocontext.h>",
            "#include <linux/tty.h>",
            "#include <linux/personality.h>",
            "#include <linux/completion.h>",
            "#include <linux/capability.h>",
            "#include <linux/module.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/slab.h>",
            "#include <linux/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/mmu_context.h>\n#include <asm/pgtable.h>\n#include <asm/unistd.h>\n#include <linux/uaccess.h>\n#include <linux/compat.h>\n#include <linux/rcuwait.h>\n#include <linux/random.h>\n#include <linux/kcov.h>\n#include <linux/shm.h>\n#include <linux/writeback.h>\n#include <linux/oom.h>\n#include <linux/hw_breakpoint.h>\n#include <trace/events/sched.h>\n#include <linux/perf_event.h>\n#include <linux/init_task.h>\n#include <linux/fs_struct.h>\n#include <linux/tracehook.h>\n#include <linux/task_io_accounting_ops.h>\n#include <linux/blkdev.h>\n#include <linux/resource.h>\n#include <linux/audit.h> /* for audit_free() */\n#include <linux/pipe_fs_i.h>\n#include <linux/futex.h>\n#include <linux/mutex.h>\n#include <linux/cn_proc.h>\n#include <linux/posix-timers.h>\n#include <linux/signal.h>\n#include <linux/syscalls.h>\n#include <linux/cgroup.h>\n#include <linux/delayacct.h>\n#include <linux/taskstats_kern.h>\n#include <linux/mempolicy.h>\n#include <linux/kthread.h>\n#include <linux/proc_fs.h>\n#include <linux/mount.h>\n#include <linux/profile.h>\n#include <linux/ptrace.h>\n#include <linux/pid_namespace.h>\n#include <linux/nsproxy.h>\n#include <linux/binfmts.h>\n#include <linux/freezer.h>\n#include <linux/fdtable.h>\n#include <linux/file.h>\n#include <linux/tsacct_kern.h>\n#include <linux/acct.h>\n#include <linux/cpu.h>\n#include <linux/key.h>\n#include <linux/iocontext.h>\n#include <linux/tty.h>\n#include <linux/personality.h>\n#include <linux/completion.h>\n#include <linux/capability.h>\n#include <linux/module.h>\n#include <linux/interrupt.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/autogroup.h>\n#include <linux/slab.h>\n#include <linux/mm.h>\n\nstruct task_struct *task_rcu_dereference(struct task_struct **ptask)\n{\n\tstruct sighand_struct *sighand;\n\tstruct task_struct *task;\n\n\t/*\n\t * We need to verify that release_task() was not called and thus\n\t * delayed_put_task_struct() can't run and drop the last reference\n\t * before rcu_read_unlock(). We check task->sighand != NULL,\n\t * but we can read the already freed and reused memory.\n\t */\nretry:\n\ttask = rcu_dereference(*ptask);\n\tif (!task)\n\t\treturn NULL;\n\n\tprobe_kernel_address(&task->sighand, sighand);\n\n\t/*\n\t * Pairs with atomic_dec_and_test() in put_task_struct(). If this task\n\t * was already freed we can not miss the preceding update of this\n\t * pointer.\n\t */\n\tsmp_rmb();\n\tif (unlikely(task != READ_ONCE(*ptask)))\n\t\tgoto retry;\n\n\t/*\n\t * We've re-checked that \"task == *ptask\", now we have two different\n\t * cases:\n\t *\n\t * 1. This is actually the same task/task_struct. In this case\n\t *    sighand != NULL tells us it is still alive.\n\t *\n\t * 2. This is another task which got the same memory for task_struct.\n\t *    We can't know this of course, and we can not trust\n\t *    sighand != NULL.\n\t *\n\t *    In this case we actually return a random value, but this is\n\t *    correct.\n\t *\n\t *    If we return NULL - we can pretend that we actually noticed that\n\t *    *ptask was updated when the previous task has exited. Or pretend\n\t *    that probe_slab_address(&sighand) reads NULL.\n\t *\n\t *    If we return the new task (because sighand is not NULL for any\n\t *    reason) - this is fine too. This (new) task can't go away before\n\t *    another gp pass.\n\t *\n\t *    And note: We could even eliminate the false positive if re-read\n\t *    task->sighand once again to avoid the falsely NULL. But this case\n\t *    is very unlikely so we don't care.\n\t */\n\tif (!sighand)\n\t\treturn NULL;\n\n\treturn task;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 126
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_bh_held",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/update.c",
          "lines": "300-309",
          "snippet": "int rcu_read_lock_bh_held(void)\n{\n\tif (!debug_lockdep_rcu_enabled())\n\t\treturn 1;\n\tif (!rcu_is_watching())\n\t\treturn 0;\n\tif (!rcu_lockdep_current_cpu_online())\n\t\treturn 0;\n\treturn in_softirq() || irqs_disabled();\n}",
          "includes": [
            "#include \"rcu.h\"",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu.h\"\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_bh_held(void)\n{\n\tif (!debug_lockdep_rcu_enabled())\n\t\treturn 1;\n\tif (!rcu_is_watching())\n\t\treturn 0;\n\tif (!rcu_lockdep_current_cpu_online())\n\t\treturn 0;\n\treturn in_softirq() || irqs_disabled();\n}"
        }
      },
      {
        "call_info": {
          "callee": "synchronize_rcu",
          "args": [],
          "line": 99
        },
        "resolved": true,
        "details": {
          "function_name": "synchronize_rcu_tasks",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/rcu/update.c",
          "lines": "603-611",
          "snippet": "void synchronize_rcu_tasks(void)\n{\n\t/* Complain if the scheduler has not started.  */\n\tRCU_LOCKDEP_WARN(rcu_scheduler_active == RCU_SCHEDULER_INACTIVE,\n\t\t\t \"synchronize_rcu_tasks called too soon\");\n\n\t/* Wait for the grace period. */\n\twait_rcu_gp(call_rcu_tasks);\n}",
          "includes": [
            "#include \"rcu.h\"",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu.h\"\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nvoid synchronize_rcu_tasks(void)\n{\n\t/* Complain if the scheduler has not started.  */\n\tRCU_LOCKDEP_WARN(rcu_scheduler_active == RCU_SCHEDULER_INACTIVE,\n\t\t\t \"synchronize_rcu_tasks called too soon\");\n\n\t/* Wait for the grace period. */\n\twait_rcu_gp(call_rcu_tasks);\n}"
        }
      },
      {
        "call_info": {
          "callee": "reuseport_array",
          "args": [
            "map"
          ],
          "line": 95
        },
        "resolved": true,
        "details": {
          "function_name": "reuseport_array_alloc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/reuseport_array.c",
          "lines": "150-182",
          "snippet": "static struct bpf_map *reuseport_array_alloc(union bpf_attr *attr)\n{\n\tint err, numa_node = bpf_map_attr_numa_node(attr);\n\tstruct reuseport_array *array;\n\tu64 cost, array_size;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn ERR_PTR(-EPERM);\n\n\tarray_size = sizeof(*array);\n\tarray_size += (u64)attr->max_entries * sizeof(struct sock *);\n\n\t/* make sure there is no u32 overflow later in round_up() */\n\tcost = array_size;\n\tif (cost >= U32_MAX - PAGE_SIZE)\n\t\treturn ERR_PTR(-ENOMEM);\n\tcost = round_up(cost, PAGE_SIZE) >> PAGE_SHIFT;\n\n\terr = bpf_map_precharge_memlock(cost);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\t/* allocate all map elements and zero-initialize them */\n\tarray = bpf_map_area_alloc(array_size, numa_node);\n\tif (!array)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t/* copy mandatory map attributes */\n\tbpf_map_init_from_attr(&array->map, attr);\n\tarray->map.pages = cost;\n\n\treturn &array->map;\n}",
          "includes": [
            "#include <net/sock_reuseport.h>",
            "#include <linux/sock_diag.h>",
            "#include <linux/err.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <net/sock_reuseport.h>\n#include <linux/sock_diag.h>\n#include <linux/err.h>\n#include <linux/bpf.h>\n\nstatic struct bpf_map *reuseport_array_alloc(union bpf_attr *attr)\n{\n\tint err, numa_node = bpf_map_attr_numa_node(attr);\n\tstruct reuseport_array *array;\n\tu64 cost, array_size;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn ERR_PTR(-EPERM);\n\n\tarray_size = sizeof(*array);\n\tarray_size += (u64)attr->max_entries * sizeof(struct sock *);\n\n\t/* make sure there is no u32 overflow later in round_up() */\n\tcost = array_size;\n\tif (cost >= U32_MAX - PAGE_SIZE)\n\t\treturn ERR_PTR(-ENOMEM);\n\tcost = round_up(cost, PAGE_SIZE) >> PAGE_SHIFT;\n\n\terr = bpf_map_precharge_memlock(cost);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\t/* allocate all map elements and zero-initialize them */\n\tarray = bpf_map_area_alloc(array_size, numa_node);\n\tif (!array)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t/* copy mandatory map attributes */\n\tbpf_map_init_from_attr(&array->map, attr);\n\tarray->map.pages = cost;\n\n\treturn &array->map;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <net/sock_reuseport.h>\n#include <linux/sock_diag.h>\n#include <linux/err.h>\n#include <linux/bpf.h>\n\nstatic void reuseport_array_free(struct bpf_map *map)\n{\n\tstruct reuseport_array *array = reuseport_array(map);\n\tstruct sock *sk;\n\tu32 i;\n\n\tsynchronize_rcu();\n\n\t/*\n\t * ops->map_*_elem() will not be able to access this\n\t * array now. Hence, this function only races with\n\t * bpf_sk_reuseport_detach() which was triggerred by\n\t * close() or disconnect().\n\t *\n\t * This function and bpf_sk_reuseport_detach() are\n\t * both removing sk from \"array\".  Who removes it\n\t * first does not matter.\n\t *\n\t * The only concern here is bpf_sk_reuseport_detach()\n\t * may access \"array\" which is being freed here.\n\t * bpf_sk_reuseport_detach() access this \"array\"\n\t * through sk->sk_user_data _and_ with sk->sk_callback_lock\n\t * held which is enough because this \"array\" is not freed\n\t * until all sk->sk_user_data has stopped referencing this \"array\".\n\t *\n\t * Hence, due to the above, taking \"reuseport_lock\" is not\n\t * needed here.\n\t */\n\n\t/*\n\t * Since reuseport_lock is not taken, sk is accessed under\n\t * rcu_read_lock()\n\t */\n\trcu_read_lock();\n\tfor (i = 0; i < map->max_entries; i++) {\n\t\tsk = rcu_dereference(array->ptrs[i]);\n\t\tif (sk) {\n\t\t\twrite_lock_bh(&sk->sk_callback_lock);\n\t\t\t/*\n\t\t\t * No need for WRITE_ONCE(). At this point,\n\t\t\t * no one is reading it without taking the\n\t\t\t * sk->sk_callback_lock.\n\t\t\t */\n\t\t\tsk->sk_user_data = NULL;\n\t\t\twrite_unlock_bh(&sk->sk_callback_lock);\n\t\t\tRCU_INIT_POINTER(array->ptrs[i], NULL);\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\t/*\n\t * Once reaching here, all sk->sk_user_data is not\n\t * referenceing this \"array\".  \"array\" can be freed now.\n\t */\n\tbpf_map_area_free(array);\n}"
  },
  {
    "function_name": "reuseport_array_delete_elem",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/reuseport_array.c",
    "lines": "61-91",
    "snippet": "static int reuseport_array_delete_elem(struct bpf_map *map, void *key)\n{\n\tstruct reuseport_array *array = reuseport_array(map);\n\tu32 index = *(u32 *)key;\n\tstruct sock *sk;\n\tint err;\n\n\tif (index >= map->max_entries)\n\t\treturn -E2BIG;\n\n\tif (!rcu_access_pointer(array->ptrs[index]))\n\t\treturn -ENOENT;\n\n\tspin_lock_bh(&reuseport_lock);\n\n\tsk = rcu_dereference_protected(array->ptrs[index],\n\t\t\t\t       lockdep_is_held(&reuseport_lock));\n\tif (sk) {\n\t\twrite_lock_bh(&sk->sk_callback_lock);\n\t\tWRITE_ONCE(sk->sk_user_data, NULL);\n\t\tRCU_INIT_POINTER(array->ptrs[index], NULL);\n\t\twrite_unlock_bh(&sk->sk_callback_lock);\n\t\terr = 0;\n\t} else {\n\t\terr = -ENOENT;\n\t}\n\n\tspin_unlock_bh(&reuseport_lock);\n\n\treturn err;\n}",
    "includes": [
      "#include <net/sock_reuseport.h>",
      "#include <linux/sock_diag.h>",
      "#include <linux/err.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "spin_unlock_bh",
          "args": [
            "&reuseport_lock"
          ],
          "line": 88
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "198-201",
          "snippet": "void __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "write_unlock_bh",
          "args": [
            "&sk->sk_callback_lock"
          ],
          "line": 82
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_write_unlock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "342-345",
          "snippet": "void __lockfunc _raw_write_unlock_bh(rwlock_t *lock)\n{\n\t__raw_write_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_write_unlock_bh(rwlock_t *lock)\n{\n\t__raw_write_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RCU_INIT_POINTER",
          "args": [
            "array->ptrs[index]",
            "NULL"
          ],
          "line": 81
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "sk->sk_user_data",
            "NULL"
          ],
          "line": 80
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "write_lock_bh",
          "args": [
            "&sk->sk_callback_lock"
          ],
          "line": 79
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_write_lock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "310-313",
          "snippet": "void __lockfunc _raw_write_lock_bh(rwlock_t *lock)\n{\n\t__raw_write_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_write_lock_bh(rwlock_t *lock)\n{\n\t__raw_write_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_dereference_protected",
          "args": [
            "array->ptrs[index]",
            "lockdep_is_held(&reuseport_lock)"
          ],
          "line": 76
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lockdep_is_held",
          "args": [
            "&reuseport_lock"
          ],
          "line": 77
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_lock_bh",
          "args": [
            "&reuseport_lock"
          ],
          "line": 74
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "166-169",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_access_pointer",
          "args": [
            "array->ptrs[index]"
          ],
          "line": 71
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "reuseport_array",
          "args": [
            "map"
          ],
          "line": 63
        },
        "resolved": true,
        "details": {
          "function_name": "reuseport_array_alloc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/reuseport_array.c",
          "lines": "150-182",
          "snippet": "static struct bpf_map *reuseport_array_alloc(union bpf_attr *attr)\n{\n\tint err, numa_node = bpf_map_attr_numa_node(attr);\n\tstruct reuseport_array *array;\n\tu64 cost, array_size;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn ERR_PTR(-EPERM);\n\n\tarray_size = sizeof(*array);\n\tarray_size += (u64)attr->max_entries * sizeof(struct sock *);\n\n\t/* make sure there is no u32 overflow later in round_up() */\n\tcost = array_size;\n\tif (cost >= U32_MAX - PAGE_SIZE)\n\t\treturn ERR_PTR(-ENOMEM);\n\tcost = round_up(cost, PAGE_SIZE) >> PAGE_SHIFT;\n\n\terr = bpf_map_precharge_memlock(cost);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\t/* allocate all map elements and zero-initialize them */\n\tarray = bpf_map_area_alloc(array_size, numa_node);\n\tif (!array)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t/* copy mandatory map attributes */\n\tbpf_map_init_from_attr(&array->map, attr);\n\tarray->map.pages = cost;\n\n\treturn &array->map;\n}",
          "includes": [
            "#include <net/sock_reuseport.h>",
            "#include <linux/sock_diag.h>",
            "#include <linux/err.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <net/sock_reuseport.h>\n#include <linux/sock_diag.h>\n#include <linux/err.h>\n#include <linux/bpf.h>\n\nstatic struct bpf_map *reuseport_array_alloc(union bpf_attr *attr)\n{\n\tint err, numa_node = bpf_map_attr_numa_node(attr);\n\tstruct reuseport_array *array;\n\tu64 cost, array_size;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn ERR_PTR(-EPERM);\n\n\tarray_size = sizeof(*array);\n\tarray_size += (u64)attr->max_entries * sizeof(struct sock *);\n\n\t/* make sure there is no u32 overflow later in round_up() */\n\tcost = array_size;\n\tif (cost >= U32_MAX - PAGE_SIZE)\n\t\treturn ERR_PTR(-ENOMEM);\n\tcost = round_up(cost, PAGE_SIZE) >> PAGE_SHIFT;\n\n\terr = bpf_map_precharge_memlock(cost);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\t/* allocate all map elements and zero-initialize them */\n\tarray = bpf_map_area_alloc(array_size, numa_node);\n\tif (!array)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t/* copy mandatory map attributes */\n\tbpf_map_init_from_attr(&array->map, attr);\n\tarray->map.pages = cost;\n\n\treturn &array->map;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <net/sock_reuseport.h>\n#include <linux/sock_diag.h>\n#include <linux/err.h>\n#include <linux/bpf.h>\n\nstatic int reuseport_array_delete_elem(struct bpf_map *map, void *key)\n{\n\tstruct reuseport_array *array = reuseport_array(map);\n\tu32 index = *(u32 *)key;\n\tstruct sock *sk;\n\tint err;\n\n\tif (index >= map->max_entries)\n\t\treturn -E2BIG;\n\n\tif (!rcu_access_pointer(array->ptrs[index]))\n\t\treturn -ENOENT;\n\n\tspin_lock_bh(&reuseport_lock);\n\n\tsk = rcu_dereference_protected(array->ptrs[index],\n\t\t\t\t       lockdep_is_held(&reuseport_lock));\n\tif (sk) {\n\t\twrite_lock_bh(&sk->sk_callback_lock);\n\t\tWRITE_ONCE(sk->sk_user_data, NULL);\n\t\tRCU_INIT_POINTER(array->ptrs[index], NULL);\n\t\twrite_unlock_bh(&sk->sk_callback_lock);\n\t\terr = 0;\n\t} else {\n\t\terr = -ENOENT;\n\t}\n\n\tspin_unlock_bh(&reuseport_lock);\n\n\treturn err;\n}"
  },
  {
    "function_name": "reuseport_array_lookup_elem",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/reuseport_array.c",
    "lines": "49-58",
    "snippet": "static void *reuseport_array_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct reuseport_array *array = reuseport_array(map);\n\tu32 index = *(u32 *)key;\n\n\tif (unlikely(index >= array->map.max_entries))\n\t\treturn NULL;\n\n\treturn rcu_dereference(array->ptrs[index]);\n}",
    "includes": [
      "#include <net/sock_reuseport.h>",
      "#include <linux/sock_diag.h>",
      "#include <linux/err.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_dereference",
          "args": [
            "array->ptrs[index]"
          ],
          "line": 57
        },
        "resolved": true,
        "details": {
          "function_name": "task_rcu_dereference",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/exit.c",
          "lines": "234-291",
          "snippet": "struct task_struct *task_rcu_dereference(struct task_struct **ptask)\n{\n\tstruct sighand_struct *sighand;\n\tstruct task_struct *task;\n\n\t/*\n\t * We need to verify that release_task() was not called and thus\n\t * delayed_put_task_struct() can't run and drop the last reference\n\t * before rcu_read_unlock(). We check task->sighand != NULL,\n\t * but we can read the already freed and reused memory.\n\t */\nretry:\n\ttask = rcu_dereference(*ptask);\n\tif (!task)\n\t\treturn NULL;\n\n\tprobe_kernel_address(&task->sighand, sighand);\n\n\t/*\n\t * Pairs with atomic_dec_and_test() in put_task_struct(). If this task\n\t * was already freed we can not miss the preceding update of this\n\t * pointer.\n\t */\n\tsmp_rmb();\n\tif (unlikely(task != READ_ONCE(*ptask)))\n\t\tgoto retry;\n\n\t/*\n\t * We've re-checked that \"task == *ptask\", now we have two different\n\t * cases:\n\t *\n\t * 1. This is actually the same task/task_struct. In this case\n\t *    sighand != NULL tells us it is still alive.\n\t *\n\t * 2. This is another task which got the same memory for task_struct.\n\t *    We can't know this of course, and we can not trust\n\t *    sighand != NULL.\n\t *\n\t *    In this case we actually return a random value, but this is\n\t *    correct.\n\t *\n\t *    If we return NULL - we can pretend that we actually noticed that\n\t *    *ptask was updated when the previous task has exited. Or pretend\n\t *    that probe_slab_address(&sighand) reads NULL.\n\t *\n\t *    If we return the new task (because sighand is not NULL for any\n\t *    reason) - this is fine too. This (new) task can't go away before\n\t *    another gp pass.\n\t *\n\t *    And note: We could even eliminate the false positive if re-read\n\t *    task->sighand once again to avoid the falsely NULL. But this case\n\t *    is very unlikely so we don't care.\n\t */\n\tif (!sighand)\n\t\treturn NULL;\n\n\treturn task;\n}",
          "includes": [
            "#include <asm/mmu_context.h>",
            "#include <asm/pgtable.h>",
            "#include <asm/unistd.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/compat.h>",
            "#include <linux/rcuwait.h>",
            "#include <linux/random.h>",
            "#include <linux/kcov.h>",
            "#include <linux/shm.h>",
            "#include <linux/writeback.h>",
            "#include <linux/oom.h>",
            "#include <linux/hw_breakpoint.h>",
            "#include <trace/events/sched.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/init_task.h>",
            "#include <linux/fs_struct.h>",
            "#include <linux/tracehook.h>",
            "#include <linux/task_io_accounting_ops.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/resource.h>",
            "#include <linux/audit.h> /* for audit_free() */",
            "#include <linux/pipe_fs_i.h>",
            "#include <linux/futex.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cn_proc.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/signal.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/taskstats_kern.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/kthread.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/mount.h>",
            "#include <linux/profile.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/binfmts.h>",
            "#include <linux/freezer.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/file.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/acct.h>",
            "#include <linux/cpu.h>",
            "#include <linux/key.h>",
            "#include <linux/iocontext.h>",
            "#include <linux/tty.h>",
            "#include <linux/personality.h>",
            "#include <linux/completion.h>",
            "#include <linux/capability.h>",
            "#include <linux/module.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/slab.h>",
            "#include <linux/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/mmu_context.h>\n#include <asm/pgtable.h>\n#include <asm/unistd.h>\n#include <linux/uaccess.h>\n#include <linux/compat.h>\n#include <linux/rcuwait.h>\n#include <linux/random.h>\n#include <linux/kcov.h>\n#include <linux/shm.h>\n#include <linux/writeback.h>\n#include <linux/oom.h>\n#include <linux/hw_breakpoint.h>\n#include <trace/events/sched.h>\n#include <linux/perf_event.h>\n#include <linux/init_task.h>\n#include <linux/fs_struct.h>\n#include <linux/tracehook.h>\n#include <linux/task_io_accounting_ops.h>\n#include <linux/blkdev.h>\n#include <linux/resource.h>\n#include <linux/audit.h> /* for audit_free() */\n#include <linux/pipe_fs_i.h>\n#include <linux/futex.h>\n#include <linux/mutex.h>\n#include <linux/cn_proc.h>\n#include <linux/posix-timers.h>\n#include <linux/signal.h>\n#include <linux/syscalls.h>\n#include <linux/cgroup.h>\n#include <linux/delayacct.h>\n#include <linux/taskstats_kern.h>\n#include <linux/mempolicy.h>\n#include <linux/kthread.h>\n#include <linux/proc_fs.h>\n#include <linux/mount.h>\n#include <linux/profile.h>\n#include <linux/ptrace.h>\n#include <linux/pid_namespace.h>\n#include <linux/nsproxy.h>\n#include <linux/binfmts.h>\n#include <linux/freezer.h>\n#include <linux/fdtable.h>\n#include <linux/file.h>\n#include <linux/tsacct_kern.h>\n#include <linux/acct.h>\n#include <linux/cpu.h>\n#include <linux/key.h>\n#include <linux/iocontext.h>\n#include <linux/tty.h>\n#include <linux/personality.h>\n#include <linux/completion.h>\n#include <linux/capability.h>\n#include <linux/module.h>\n#include <linux/interrupt.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/autogroup.h>\n#include <linux/slab.h>\n#include <linux/mm.h>\n\nstruct task_struct *task_rcu_dereference(struct task_struct **ptask)\n{\n\tstruct sighand_struct *sighand;\n\tstruct task_struct *task;\n\n\t/*\n\t * We need to verify that release_task() was not called and thus\n\t * delayed_put_task_struct() can't run and drop the last reference\n\t * before rcu_read_unlock(). We check task->sighand != NULL,\n\t * but we can read the already freed and reused memory.\n\t */\nretry:\n\ttask = rcu_dereference(*ptask);\n\tif (!task)\n\t\treturn NULL;\n\n\tprobe_kernel_address(&task->sighand, sighand);\n\n\t/*\n\t * Pairs with atomic_dec_and_test() in put_task_struct(). If this task\n\t * was already freed we can not miss the preceding update of this\n\t * pointer.\n\t */\n\tsmp_rmb();\n\tif (unlikely(task != READ_ONCE(*ptask)))\n\t\tgoto retry;\n\n\t/*\n\t * We've re-checked that \"task == *ptask\", now we have two different\n\t * cases:\n\t *\n\t * 1. This is actually the same task/task_struct. In this case\n\t *    sighand != NULL tells us it is still alive.\n\t *\n\t * 2. This is another task which got the same memory for task_struct.\n\t *    We can't know this of course, and we can not trust\n\t *    sighand != NULL.\n\t *\n\t *    In this case we actually return a random value, but this is\n\t *    correct.\n\t *\n\t *    If we return NULL - we can pretend that we actually noticed that\n\t *    *ptask was updated when the previous task has exited. Or pretend\n\t *    that probe_slab_address(&sighand) reads NULL.\n\t *\n\t *    If we return the new task (because sighand is not NULL for any\n\t *    reason) - this is fine too. This (new) task can't go away before\n\t *    another gp pass.\n\t *\n\t *    And note: We could even eliminate the false positive if re-read\n\t *    task->sighand once again to avoid the falsely NULL. But this case\n\t *    is very unlikely so we don't care.\n\t */\n\tif (!sighand)\n\t\treturn NULL;\n\n\treturn task;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "index >= array->map.max_entries"
          ],
          "line": 54
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "reuseport_array",
          "args": [
            "map"
          ],
          "line": 51
        },
        "resolved": true,
        "details": {
          "function_name": "reuseport_array_alloc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/reuseport_array.c",
          "lines": "150-182",
          "snippet": "static struct bpf_map *reuseport_array_alloc(union bpf_attr *attr)\n{\n\tint err, numa_node = bpf_map_attr_numa_node(attr);\n\tstruct reuseport_array *array;\n\tu64 cost, array_size;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn ERR_PTR(-EPERM);\n\n\tarray_size = sizeof(*array);\n\tarray_size += (u64)attr->max_entries * sizeof(struct sock *);\n\n\t/* make sure there is no u32 overflow later in round_up() */\n\tcost = array_size;\n\tif (cost >= U32_MAX - PAGE_SIZE)\n\t\treturn ERR_PTR(-ENOMEM);\n\tcost = round_up(cost, PAGE_SIZE) >> PAGE_SHIFT;\n\n\terr = bpf_map_precharge_memlock(cost);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\t/* allocate all map elements and zero-initialize them */\n\tarray = bpf_map_area_alloc(array_size, numa_node);\n\tif (!array)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t/* copy mandatory map attributes */\n\tbpf_map_init_from_attr(&array->map, attr);\n\tarray->map.pages = cost;\n\n\treturn &array->map;\n}",
          "includes": [
            "#include <net/sock_reuseport.h>",
            "#include <linux/sock_diag.h>",
            "#include <linux/err.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <net/sock_reuseport.h>\n#include <linux/sock_diag.h>\n#include <linux/err.h>\n#include <linux/bpf.h>\n\nstatic struct bpf_map *reuseport_array_alloc(union bpf_attr *attr)\n{\n\tint err, numa_node = bpf_map_attr_numa_node(attr);\n\tstruct reuseport_array *array;\n\tu64 cost, array_size;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn ERR_PTR(-EPERM);\n\n\tarray_size = sizeof(*array);\n\tarray_size += (u64)attr->max_entries * sizeof(struct sock *);\n\n\t/* make sure there is no u32 overflow later in round_up() */\n\tcost = array_size;\n\tif (cost >= U32_MAX - PAGE_SIZE)\n\t\treturn ERR_PTR(-ENOMEM);\n\tcost = round_up(cost, PAGE_SIZE) >> PAGE_SHIFT;\n\n\terr = bpf_map_precharge_memlock(cost);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\t/* allocate all map elements and zero-initialize them */\n\tarray = bpf_map_area_alloc(array_size, numa_node);\n\tif (!array)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t/* copy mandatory map attributes */\n\tbpf_map_init_from_attr(&array->map, attr);\n\tarray->map.pages = cost;\n\n\treturn &array->map;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <net/sock_reuseport.h>\n#include <linux/sock_diag.h>\n#include <linux/err.h>\n#include <linux/bpf.h>\n\nstatic void *reuseport_array_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct reuseport_array *array = reuseport_array(map);\n\tu32 index = *(u32 *)key;\n\n\tif (unlikely(index >= array->map.max_entries))\n\t\treturn NULL;\n\n\treturn rcu_dereference(array->ptrs[index]);\n}"
  },
  {
    "function_name": "reuseport_array_alloc_check",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/reuseport_array.c",
    "lines": "40-47",
    "snippet": "static int reuseport_array_alloc_check(union bpf_attr *attr)\n{\n\tif (attr->value_size != sizeof(u32) &&\n\t    attr->value_size != sizeof(u64))\n\t\treturn -EINVAL;\n\n\treturn array_map_alloc_check(attr);\n}",
    "includes": [
      "#include <net/sock_reuseport.h>",
      "#include <linux/sock_diag.h>",
      "#include <linux/err.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "array_map_alloc_check",
          "args": [
            "attr"
          ],
          "line": 46
        },
        "resolved": true,
        "details": {
          "function_name": "fd_array_map_alloc_check",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/arraymap.c",
          "lines": "428-434",
          "snippet": "static int fd_array_map_alloc_check(union bpf_attr *attr)\n{\n\t/* only file descriptors can be stored in this type of map */\n\tif (attr->value_size != sizeof(u32))\n\t\treturn -EINVAL;\n\treturn array_map_alloc_check(attr);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include <uapi/linux/btf.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/filter.h>",
            "#include <linux/mm.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include <uapi/linux/btf.h>\n#include <linux/perf_event.h>\n#include <linux/filter.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int fd_array_map_alloc_check(union bpf_attr *attr)\n{\n\t/* only file descriptors can be stored in this type of map */\n\tif (attr->value_size != sizeof(u32))\n\t\treturn -EINVAL;\n\treturn array_map_alloc_check(attr);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <net/sock_reuseport.h>\n#include <linux/sock_diag.h>\n#include <linux/err.h>\n#include <linux/bpf.h>\n\nstatic int reuseport_array_alloc_check(union bpf_attr *attr)\n{\n\tif (attr->value_size != sizeof(u32) &&\n\t    attr->value_size != sizeof(u64))\n\t\treturn -EINVAL;\n\n\treturn array_map_alloc_check(attr);\n}"
  },
  {
    "function_name": "bpf_sk_reuseport_detach",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/reuseport_array.c",
    "lines": "21-38",
    "snippet": "void bpf_sk_reuseport_detach(struct sock *sk)\n{\n\tstruct sock __rcu **socks;\n\n\twrite_lock_bh(&sk->sk_callback_lock);\n\tsocks = sk->sk_user_data;\n\tif (socks) {\n\t\tWRITE_ONCE(sk->sk_user_data, NULL);\n\t\t/*\n\t\t * Do not move this NULL assignment outside of\n\t\t * sk->sk_callback_lock because there is\n\t\t * a race with reuseport_array_free()\n\t\t * which does not hold the reuseport_lock.\n\t\t */\n\t\tRCU_INIT_POINTER(*socks, NULL);\n\t}\n\twrite_unlock_bh(&sk->sk_callback_lock);\n}",
    "includes": [
      "#include <net/sock_reuseport.h>",
      "#include <linux/sock_diag.h>",
      "#include <linux/err.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "write_unlock_bh",
          "args": [
            "&sk->sk_callback_lock"
          ],
          "line": 37
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_write_unlock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "342-345",
          "snippet": "void __lockfunc _raw_write_unlock_bh(rwlock_t *lock)\n{\n\t__raw_write_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_write_unlock_bh(rwlock_t *lock)\n{\n\t__raw_write_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RCU_INIT_POINTER",
          "args": [
            "*socks",
            "NULL"
          ],
          "line": 35
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "sk->sk_user_data",
            "NULL"
          ],
          "line": 28
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "write_lock_bh",
          "args": [
            "&sk->sk_callback_lock"
          ],
          "line": 25
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_write_lock_bh",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/spinlock.c",
          "lines": "310-313",
          "snippet": "void __lockfunc _raw_write_lock_bh(rwlock_t *lock)\n{\n\t__raw_write_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_write_lock_bh(rwlock_t *lock)\n{\n\t__raw_write_lock_bh(lock);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <net/sock_reuseport.h>\n#include <linux/sock_diag.h>\n#include <linux/err.h>\n#include <linux/bpf.h>\n\nvoid bpf_sk_reuseport_detach(struct sock *sk)\n{\n\tstruct sock __rcu **socks;\n\n\twrite_lock_bh(&sk->sk_callback_lock);\n\tsocks = sk->sk_user_data;\n\tif (socks) {\n\t\tWRITE_ONCE(sk->sk_user_data, NULL);\n\t\t/*\n\t\t * Do not move this NULL assignment outside of\n\t\t * sk->sk_callback_lock because there is\n\t\t * a race with reuseport_array_free()\n\t\t * which does not hold the reuseport_lock.\n\t\t */\n\t\tRCU_INIT_POINTER(*socks, NULL);\n\t}\n\twrite_unlock_bh(&sk->sk_callback_lock);\n}"
  },
  {
    "function_name": "reuseport_array",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/reuseport_array.c",
    "lines": "15-18",
    "snippet": "static struct reuseport_array *reuseport_array(struct bpf_map *map)\n{\n\treturn (struct reuseport_array *)map;\n}",
    "includes": [
      "#include <net/sock_reuseport.h>",
      "#include <linux/sock_diag.h>",
      "#include <linux/err.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include <net/sock_reuseport.h>\n#include <linux/sock_diag.h>\n#include <linux/err.h>\n#include <linux/bpf.h>\n\nstatic struct reuseport_array *reuseport_array(struct bpf_map *map)\n{\n\treturn (struct reuseport_array *)map;\n}"
  }
]