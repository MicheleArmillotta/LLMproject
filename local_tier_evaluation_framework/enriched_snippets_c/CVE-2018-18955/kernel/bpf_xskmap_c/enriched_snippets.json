[
  {
    "function_name": "xsk_map_delete_elem",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/xskmap.c",
    "lines": "202-216",
    "snippet": "static int xsk_map_delete_elem(struct bpf_map *map, void *key)\n{\n\tstruct xsk_map *m = container_of(map, struct xsk_map, map);\n\tstruct xdp_sock *old_xs;\n\tint k = *(u32 *)key;\n\n\tif (k >= map->max_entries)\n\t\treturn -EINVAL;\n\n\told_xs = xchg(&m->xsk_map[k], NULL);\n\tif (old_xs)\n\t\tsock_put((struct sock *)old_xs);\n\n\treturn 0;\n}",
    "includes": [
      "#include <linux/sched.h>",
      "#include <linux/slab.h>",
      "#include <net/xdp_sock.h>",
      "#include <linux/capability.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "sock_put",
          "args": [
            "(struct sock *)old_xs"
          ],
          "line": 213
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "xchg",
          "args": [
            "&m->xsk_map[k]",
            "NULL"
          ],
          "line": 211
        },
        "resolved": true,
        "details": {
          "function_name": "xchg_tail",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/qspinlock.c",
          "lines": "231-249",
          "snippet": "static __always_inline u32 xchg_tail(struct qspinlock *lock, u32 tail)\n{\n\tu32 old, new, val = atomic_read(&lock->val);\n\n\tfor (;;) {\n\t\tnew = (val & _Q_LOCKED_PENDING_MASK) | tail;\n\t\t/*\n\t\t * We can use relaxed semantics since the caller ensures that\n\t\t * the MCS node is properly initialized before updating the\n\t\t * tail.\n\t\t */\n\t\told = atomic_cmpxchg_relaxed(&lock->val, val, new);\n\t\tif (old == val)\n\t\t\tbreak;\n\n\t\tval = old;\n\t}\n\treturn old;\n}",
          "includes": [
            "#include \"qspinlock.c\"",
            "#include \"qspinlock_paravirt.h\"",
            "#include \"mcs_spinlock.h\"",
            "#include \"qspinlock_stat.h\"",
            "#include <asm/qspinlock.h>",
            "#include <asm/byteorder.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/mutex.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/cpumask.h>",
            "#include <linux/bug.h>",
            "#include <linux/smp.h>"
          ],
          "macros_used": [
            "#define _Q_LOCKED_PENDING_MASK (_Q_LOCKED_MASK | _Q_PENDING_MASK)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"qspinlock.c\"\n#include \"qspinlock_paravirt.h\"\n#include \"mcs_spinlock.h\"\n#include \"qspinlock_stat.h\"\n#include <asm/qspinlock.h>\n#include <asm/byteorder.h>\n#include <linux/prefetch.h>\n#include <linux/mutex.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/cpumask.h>\n#include <linux/bug.h>\n#include <linux/smp.h>\n\n#define _Q_LOCKED_PENDING_MASK (_Q_LOCKED_MASK | _Q_PENDING_MASK)\n\nstatic __always_inline u32 xchg_tail(struct qspinlock *lock, u32 tail)\n{\n\tu32 old, new, val = atomic_read(&lock->val);\n\n\tfor (;;) {\n\t\tnew = (val & _Q_LOCKED_PENDING_MASK) | tail;\n\t\t/*\n\t\t * We can use relaxed semantics since the caller ensures that\n\t\t * the MCS node is properly initialized before updating the\n\t\t * tail.\n\t\t */\n\t\told = atomic_cmpxchg_relaxed(&lock->val, val, new);\n\t\tif (old == val)\n\t\t\tbreak;\n\n\t\tval = old;\n\t}\n\treturn old;\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structxsk_map",
            "map"
          ],
          "line": 204
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/sched.h>\n#include <linux/slab.h>\n#include <net/xdp_sock.h>\n#include <linux/capability.h>\n#include <linux/bpf.h>\n\nstatic int xsk_map_delete_elem(struct bpf_map *map, void *key)\n{\n\tstruct xsk_map *m = container_of(map, struct xsk_map, map);\n\tstruct xdp_sock *old_xs;\n\tint k = *(u32 *)key;\n\n\tif (k >= map->max_entries)\n\t\treturn -EINVAL;\n\n\told_xs = xchg(&m->xsk_map[k], NULL);\n\tif (old_xs)\n\t\tsock_put((struct sock *)old_xs);\n\n\treturn 0;\n}"
  },
  {
    "function_name": "xsk_map_update_elem",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/xskmap.c",
    "lines": "160-200",
    "snippet": "static int xsk_map_update_elem(struct bpf_map *map, void *key, void *value,\n\t\t\t       u64 map_flags)\n{\n\tstruct xsk_map *m = container_of(map, struct xsk_map, map);\n\tu32 i = *(u32 *)key, fd = *(u32 *)value;\n\tstruct xdp_sock *xs, *old_xs;\n\tstruct socket *sock;\n\tint err;\n\n\tif (unlikely(map_flags > BPF_EXIST))\n\t\treturn -EINVAL;\n\tif (unlikely(i >= m->map.max_entries))\n\t\treturn -E2BIG;\n\tif (unlikely(map_flags == BPF_NOEXIST))\n\t\treturn -EEXIST;\n\n\tsock = sockfd_lookup(fd, &err);\n\tif (!sock)\n\t\treturn err;\n\n\tif (sock->sk->sk_family != PF_XDP) {\n\t\tsockfd_put(sock);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\txs = (struct xdp_sock *)sock->sk;\n\n\tif (!xsk_is_setup_for_bpf_map(xs)) {\n\t\tsockfd_put(sock);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tsock_hold(sock->sk);\n\n\told_xs = xchg(&m->xsk_map[i], xs);\n\tif (old_xs)\n\t\tsock_put((struct sock *)old_xs);\n\n\tsockfd_put(sock);\n\treturn 0;\n}",
    "includes": [
      "#include <linux/sched.h>",
      "#include <linux/slab.h>",
      "#include <net/xdp_sock.h>",
      "#include <linux/capability.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "sockfd_put",
          "args": [
            "sock"
          ],
          "line": 198
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sock_put",
          "args": [
            "(struct sock *)old_xs"
          ],
          "line": 196
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "xchg",
          "args": [
            "&m->xsk_map[i]",
            "xs"
          ],
          "line": 194
        },
        "resolved": true,
        "details": {
          "function_name": "xchg_tail",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/qspinlock.c",
          "lines": "231-249",
          "snippet": "static __always_inline u32 xchg_tail(struct qspinlock *lock, u32 tail)\n{\n\tu32 old, new, val = atomic_read(&lock->val);\n\n\tfor (;;) {\n\t\tnew = (val & _Q_LOCKED_PENDING_MASK) | tail;\n\t\t/*\n\t\t * We can use relaxed semantics since the caller ensures that\n\t\t * the MCS node is properly initialized before updating the\n\t\t * tail.\n\t\t */\n\t\told = atomic_cmpxchg_relaxed(&lock->val, val, new);\n\t\tif (old == val)\n\t\t\tbreak;\n\n\t\tval = old;\n\t}\n\treturn old;\n}",
          "includes": [
            "#include \"qspinlock.c\"",
            "#include \"qspinlock_paravirt.h\"",
            "#include \"mcs_spinlock.h\"",
            "#include \"qspinlock_stat.h\"",
            "#include <asm/qspinlock.h>",
            "#include <asm/byteorder.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/mutex.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/cpumask.h>",
            "#include <linux/bug.h>",
            "#include <linux/smp.h>"
          ],
          "macros_used": [
            "#define _Q_LOCKED_PENDING_MASK (_Q_LOCKED_MASK | _Q_PENDING_MASK)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"qspinlock.c\"\n#include \"qspinlock_paravirt.h\"\n#include \"mcs_spinlock.h\"\n#include \"qspinlock_stat.h\"\n#include <asm/qspinlock.h>\n#include <asm/byteorder.h>\n#include <linux/prefetch.h>\n#include <linux/mutex.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/cpumask.h>\n#include <linux/bug.h>\n#include <linux/smp.h>\n\n#define _Q_LOCKED_PENDING_MASK (_Q_LOCKED_MASK | _Q_PENDING_MASK)\n\nstatic __always_inline u32 xchg_tail(struct qspinlock *lock, u32 tail)\n{\n\tu32 old, new, val = atomic_read(&lock->val);\n\n\tfor (;;) {\n\t\tnew = (val & _Q_LOCKED_PENDING_MASK) | tail;\n\t\t/*\n\t\t * We can use relaxed semantics since the caller ensures that\n\t\t * the MCS node is properly initialized before updating the\n\t\t * tail.\n\t\t */\n\t\told = atomic_cmpxchg_relaxed(&lock->val, val, new);\n\t\tif (old == val)\n\t\t\tbreak;\n\n\t\tval = old;\n\t}\n\treturn old;\n}"
        }
      },
      {
        "call_info": {
          "callee": "sock_hold",
          "args": [
            "sock->sk"
          ],
          "line": 192
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sockfd_put",
          "args": [
            "sock"
          ],
          "line": 188
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "xsk_is_setup_for_bpf_map",
          "args": [
            "xs"
          ],
          "line": 187
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sockfd_put",
          "args": [
            "sock"
          ],
          "line": 181
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sockfd_lookup",
          "args": [
            "fd",
            "&err"
          ],
          "line": 176
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "map_flags == BPF_NOEXIST"
          ],
          "line": 173
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "i >= m->map.max_entries"
          ],
          "line": 171
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "map_flags > BPF_EXIST"
          ],
          "line": 169
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structxsk_map",
            "map"
          ],
          "line": 163
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/sched.h>\n#include <linux/slab.h>\n#include <net/xdp_sock.h>\n#include <linux/capability.h>\n#include <linux/bpf.h>\n\nstatic int xsk_map_update_elem(struct bpf_map *map, void *key, void *value,\n\t\t\t       u64 map_flags)\n{\n\tstruct xsk_map *m = container_of(map, struct xsk_map, map);\n\tu32 i = *(u32 *)key, fd = *(u32 *)value;\n\tstruct xdp_sock *xs, *old_xs;\n\tstruct socket *sock;\n\tint err;\n\n\tif (unlikely(map_flags > BPF_EXIST))\n\t\treturn -EINVAL;\n\tif (unlikely(i >= m->map.max_entries))\n\t\treturn -E2BIG;\n\tif (unlikely(map_flags == BPF_NOEXIST))\n\t\treturn -EEXIST;\n\n\tsock = sockfd_lookup(fd, &err);\n\tif (!sock)\n\t\treturn err;\n\n\tif (sock->sk->sk_family != PF_XDP) {\n\t\tsockfd_put(sock);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\txs = (struct xdp_sock *)sock->sk;\n\n\tif (!xsk_is_setup_for_bpf_map(xs)) {\n\t\tsockfd_put(sock);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tsock_hold(sock->sk);\n\n\told_xs = xchg(&m->xsk_map[i], xs);\n\tif (old_xs)\n\t\tsock_put((struct sock *)old_xs);\n\n\tsockfd_put(sock);\n\treturn 0;\n}"
  },
  {
    "function_name": "xsk_map_lookup_elem",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/xskmap.c",
    "lines": "155-158",
    "snippet": "static void *xsk_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\treturn ERR_PTR(-EOPNOTSUPP);\n}",
    "includes": [
      "#include <linux/sched.h>",
      "#include <linux/slab.h>",
      "#include <net/xdp_sock.h>",
      "#include <linux/capability.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-EOPNOTSUPP"
          ],
          "line": 157
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/sched.h>\n#include <linux/slab.h>\n#include <net/xdp_sock.h>\n#include <linux/capability.h>\n#include <linux/bpf.h>\n\nstatic void *xsk_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\treturn ERR_PTR(-EOPNOTSUPP);\n}"
  },
  {
    "function_name": "__xsk_map_flush",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/xskmap.c",
    "lines": "142-153",
    "snippet": "void __xsk_map_flush(struct bpf_map *map)\n{\n\tstruct xsk_map *m = container_of(map, struct xsk_map, map);\n\tstruct list_head *flush_list = this_cpu_ptr(m->flush_list);\n\tstruct xdp_sock *xs, *tmp;\n\n\tlist_for_each_entry_safe(xs, tmp, flush_list, flush_node) {\n\t\txsk_flush(xs);\n\t\t__list_del(xs->flush_node.prev, xs->flush_node.next);\n\t\txs->flush_node.prev = NULL;\n\t}\n}",
    "includes": [
      "#include <linux/sched.h>",
      "#include <linux/slab.h>",
      "#include <net/xdp_sock.h>",
      "#include <linux/capability.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__list_del",
          "args": [
            "xs->flush_node.prev",
            "xs->flush_node.next"
          ],
          "line": 150
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "xsk_flush",
          "args": [
            "xs"
          ],
          "line": 149
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_for_each_entry_safe",
          "args": [
            "xs",
            "tmp",
            "flush_list",
            "flush_node"
          ],
          "line": 148
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "m->flush_list"
          ],
          "line": 145
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structxsk_map",
            "map"
          ],
          "line": 144
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/sched.h>\n#include <linux/slab.h>\n#include <net/xdp_sock.h>\n#include <linux/capability.h>\n#include <linux/bpf.h>\n\nvoid __xsk_map_flush(struct bpf_map *map)\n{\n\tstruct xsk_map *m = container_of(map, struct xsk_map, map);\n\tstruct list_head *flush_list = this_cpu_ptr(m->flush_list);\n\tstruct xdp_sock *xs, *tmp;\n\n\tlist_for_each_entry_safe(xs, tmp, flush_list, flush_node) {\n\t\txsk_flush(xs);\n\t\t__list_del(xs->flush_node.prev, xs->flush_node.next);\n\t\txs->flush_node.prev = NULL;\n\t}\n}"
  },
  {
    "function_name": "__xsk_map_redirect",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/xskmap.c",
    "lines": "125-140",
    "snippet": "int __xsk_map_redirect(struct bpf_map *map, struct xdp_buff *xdp,\n\t\t       struct xdp_sock *xs)\n{\n\tstruct xsk_map *m = container_of(map, struct xsk_map, map);\n\tstruct list_head *flush_list = this_cpu_ptr(m->flush_list);\n\tint err;\n\n\terr = xsk_rcv(xs, xdp);\n\tif (err)\n\t\treturn err;\n\n\tif (!xs->flush_node.prev)\n\t\tlist_add(&xs->flush_node, flush_list);\n\n\treturn 0;\n}",
    "includes": [
      "#include <linux/sched.h>",
      "#include <linux/slab.h>",
      "#include <net/xdp_sock.h>",
      "#include <linux/capability.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "list_add",
          "args": [
            "&xs->flush_node",
            "flush_list"
          ],
          "line": 137
        },
        "resolved": true,
        "details": {
          "function_name": "list_add_event",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/events/core.c",
          "lines": "1662-1690",
          "snippet": "static void\nlist_add_event(struct perf_event *event, struct perf_event_context *ctx)\n{\n\tlockdep_assert_held(&ctx->lock);\n\n\tWARN_ON_ONCE(event->attach_state & PERF_ATTACH_CONTEXT);\n\tevent->attach_state |= PERF_ATTACH_CONTEXT;\n\n\tevent->tstamp = perf_event_time(event);\n\n\t/*\n\t * If we're a stand alone event or group leader, we go to the context\n\t * list, group events are kept attached to the group so that\n\t * perf_group_detach can, at all times, locate all siblings.\n\t */\n\tif (event->group_leader == event) {\n\t\tevent->group_caps = event->event_caps;\n\t\tadd_event_to_groups(event, ctx);\n\t}\n\n\tlist_update_cgroup_event(event, ctx, true);\n\n\tlist_add_rcu(&event->event_entry, &ctx->event_list);\n\tctx->nr_events++;\n\tif (event->attr.inherit_stat)\n\t\tctx->nr_stat++;\n\n\tctx->generation++;\n}",
          "includes": [
            "#include <asm/irq_regs.h>",
            "#include \"internal.h\"",
            "#include <linux/mount.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/parser.h>",
            "#include <linux/namei.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/compat.h>",
            "#include <linux/mman.h>",
            "#include <linux/module.h>",
            "#include <linux/mm_types.h>",
            "#include <linux/hw_breakpoint.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/rculist.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/device.h>",
            "#include <linux/vmstat.h>",
            "#include <linux/reboot.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/percpu.h>",
            "#include <linux/dcache.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/tick.h>",
            "#include <linux/hash.h>",
            "#include <linux/slab.h>",
            "#include <linux/poll.h>",
            "#include <linux/file.h>",
            "#include <linux/idr.h>",
            "#include <linux/smp.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/fs.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void update_context_time(struct perf_event_context *ctx);",
            "static u64 perf_event_time(struct perf_event *event);",
            "static __must_check struct",
            "static void perf_log_itrace_start(struct perf_event *event);",
            "static void perf_event_free_filter(struct perf_event *event);",
            "static void perf_event_free_bpf_prog(struct perf_event *event);",
            "static int perf_copy_attr(struct perf_event_attr __user *uattr,\n\t\t\t  struct perf_event_attr *attr);",
            "static void perf_pmu_output_stop(struct perf_event *event);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/irq_regs.h>\n#include \"internal.h\"\n#include <linux/mount.h>\n#include <linux/proc_ns.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/clock.h>\n#include <linux/parser.h>\n#include <linux/namei.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/compat.h>\n#include <linux/mman.h>\n#include <linux/module.h>\n#include <linux/mm_types.h>\n#include <linux/hw_breakpoint.h>\n#include <linux/trace_events.h>\n#include <linux/perf_event.h>\n#include <linux/cgroup.h>\n#include <linux/kernel_stat.h>\n#include <linux/anon_inodes.h>\n#include <linux/syscalls.h>\n#include <linux/uaccess.h>\n#include <linux/rculist.h>\n#include <linux/hardirq.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/device.h>\n#include <linux/vmstat.h>\n#include <linux/reboot.h>\n#include <linux/ptrace.h>\n#include <linux/percpu.h>\n#include <linux/dcache.h>\n#include <linux/sysfs.h>\n#include <linux/tick.h>\n#include <linux/hash.h>\n#include <linux/slab.h>\n#include <linux/poll.h>\n#include <linux/file.h>\n#include <linux/idr.h>\n#include <linux/smp.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/fs.h>\n\nstatic void update_context_time(struct perf_event_context *ctx);\nstatic u64 perf_event_time(struct perf_event *event);\nstatic __must_check struct;\nstatic void perf_log_itrace_start(struct perf_event *event);\nstatic void perf_event_free_filter(struct perf_event *event);\nstatic void perf_event_free_bpf_prog(struct perf_event *event);\nstatic int perf_copy_attr(struct perf_event_attr __user *uattr,\n\t\t\t  struct perf_event_attr *attr);\nstatic void perf_pmu_output_stop(struct perf_event *event);\n\nstatic void\nlist_add_event(struct perf_event *event, struct perf_event_context *ctx)\n{\n\tlockdep_assert_held(&ctx->lock);\n\n\tWARN_ON_ONCE(event->attach_state & PERF_ATTACH_CONTEXT);\n\tevent->attach_state |= PERF_ATTACH_CONTEXT;\n\n\tevent->tstamp = perf_event_time(event);\n\n\t/*\n\t * If we're a stand alone event or group leader, we go to the context\n\t * list, group events are kept attached to the group so that\n\t * perf_group_detach can, at all times, locate all siblings.\n\t */\n\tif (event->group_leader == event) {\n\t\tevent->group_caps = event->event_caps;\n\t\tadd_event_to_groups(event, ctx);\n\t}\n\n\tlist_update_cgroup_event(event, ctx, true);\n\n\tlist_add_rcu(&event->event_entry, &ctx->event_list);\n\tctx->nr_events++;\n\tif (event->attr.inherit_stat)\n\t\tctx->nr_stat++;\n\n\tctx->generation++;\n}"
        }
      },
      {
        "call_info": {
          "callee": "xsk_rcv",
          "args": [
            "xs",
            "xdp"
          ],
          "line": 132
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "m->flush_list"
          ],
          "line": 129
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structxsk_map",
            "map"
          ],
          "line": 128
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/sched.h>\n#include <linux/slab.h>\n#include <net/xdp_sock.h>\n#include <linux/capability.h>\n#include <linux/bpf.h>\n\nint __xsk_map_redirect(struct bpf_map *map, struct xdp_buff *xdp,\n\t\t       struct xdp_sock *xs)\n{\n\tstruct xsk_map *m = container_of(map, struct xsk_map, map);\n\tstruct list_head *flush_list = this_cpu_ptr(m->flush_list);\n\tint err;\n\n\terr = xsk_rcv(xs, xdp);\n\tif (err)\n\t\treturn err;\n\n\tif (!xs->flush_node.prev)\n\t\tlist_add(&xs->flush_node, flush_list);\n\n\treturn 0;\n}"
  },
  {
    "function_name": "__xsk_map_lookup_elem",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/xskmap.c",
    "lines": "113-123",
    "snippet": "struct xdp_sock *__xsk_map_lookup_elem(struct bpf_map *map, u32 key)\n{\n\tstruct xsk_map *m = container_of(map, struct xsk_map, map);\n\tstruct xdp_sock *xs;\n\n\tif (key >= map->max_entries)\n\t\treturn NULL;\n\n\txs = READ_ONCE(m->xsk_map[key]);\n\treturn xs;\n}",
    "includes": [
      "#include <linux/sched.h>",
      "#include <linux/slab.h>",
      "#include <net/xdp_sock.h>",
      "#include <linux/capability.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "m->xsk_map[key]"
          ],
          "line": 121
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structxsk_map",
            "map"
          ],
          "line": 115
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/sched.h>\n#include <linux/slab.h>\n#include <net/xdp_sock.h>\n#include <linux/capability.h>\n#include <linux/bpf.h>\n\nstruct xdp_sock *__xsk_map_lookup_elem(struct bpf_map *map, u32 key)\n{\n\tstruct xsk_map *m = container_of(map, struct xsk_map, map);\n\tstruct xdp_sock *xs;\n\n\tif (key >= map->max_entries)\n\t\treturn NULL;\n\n\txs = READ_ONCE(m->xsk_map[key]);\n\treturn xs;\n}"
  },
  {
    "function_name": "xsk_map_get_next_key",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/xskmap.c",
    "lines": "96-111",
    "snippet": "static int xsk_map_get_next_key(struct bpf_map *map, void *key, void *next_key)\n{\n\tstruct xsk_map *m = container_of(map, struct xsk_map, map);\n\tu32 index = key ? *(u32 *)key : U32_MAX;\n\tu32 *next = next_key;\n\n\tif (index >= m->map.max_entries) {\n\t\t*next = 0;\n\t\treturn 0;\n\t}\n\n\tif (index == m->map.max_entries - 1)\n\t\treturn -ENOENT;\n\t*next = index + 1;\n\treturn 0;\n}",
    "includes": [
      "#include <linux/sched.h>",
      "#include <linux/slab.h>",
      "#include <net/xdp_sock.h>",
      "#include <linux/capability.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structxsk_map",
            "map"
          ],
          "line": 98
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/sched.h>\n#include <linux/slab.h>\n#include <net/xdp_sock.h>\n#include <linux/capability.h>\n#include <linux/bpf.h>\n\nstatic int xsk_map_get_next_key(struct bpf_map *map, void *key, void *next_key)\n{\n\tstruct xsk_map *m = container_of(map, struct xsk_map, map);\n\tu32 index = key ? *(u32 *)key : U32_MAX;\n\tu32 *next = next_key;\n\n\tif (index >= m->map.max_entries) {\n\t\t*next = 0;\n\t\treturn 0;\n\t}\n\n\tif (index == m->map.max_entries - 1)\n\t\treturn -ENOENT;\n\t*next = index + 1;\n\treturn 0;\n}"
  },
  {
    "function_name": "xsk_map_free",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/xskmap.c",
    "lines": "73-94",
    "snippet": "static void xsk_map_free(struct bpf_map *map)\n{\n\tstruct xsk_map *m = container_of(map, struct xsk_map, map);\n\tint i;\n\n\tbpf_clear_redirect_map(map);\n\tsynchronize_net();\n\n\tfor (i = 0; i < map->max_entries; i++) {\n\t\tstruct xdp_sock *xs;\n\n\t\txs = m->xsk_map[i];\n\t\tif (!xs)\n\t\t\tcontinue;\n\n\t\tsock_put((struct sock *)xs);\n\t}\n\n\tfree_percpu(m->flush_list);\n\tbpf_map_area_free(m->xsk_map);\n\tkfree(m);\n}",
    "includes": [
      "#include <linux/sched.h>",
      "#include <linux/slab.h>",
      "#include <net/xdp_sock.h>",
      "#include <linux/capability.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "m"
          ],
          "line": 93
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/params.c",
          "lines": "73-86",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_area_free",
          "args": [
            "m->xsk_map"
          ],
          "line": 92
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_area_free",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/syscall.c",
          "lines": "156-159",
          "snippet": "void bpf_map_area_free(void *area)\n{\n\tkvfree(area);\n}",
          "includes": [
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/version.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/version.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf.h>\n\nvoid bpf_map_area_free(void *area)\n{\n\tkvfree(area);\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_percpu",
          "args": [
            "m->flush_list"
          ],
          "line": 91
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_array_free_percpu",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/arraymap.c",
          "lines": "27-35",
          "snippet": "static void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include <uapi/linux/btf.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/filter.h>",
            "#include <linux/mm.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include <uapi/linux/btf.h>\n#include <linux/perf_event.h>\n#include <linux/filter.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "sock_put",
          "args": [
            "(struct sock *)xs"
          ],
          "line": 88
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "synchronize_net",
          "args": [],
          "line": 79
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_clear_redirect_map",
          "args": [
            "map"
          ],
          "line": 78
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structxsk_map",
            "map"
          ],
          "line": 75
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/sched.h>\n#include <linux/slab.h>\n#include <net/xdp_sock.h>\n#include <linux/capability.h>\n#include <linux/bpf.h>\n\nstatic void xsk_map_free(struct bpf_map *map)\n{\n\tstruct xsk_map *m = container_of(map, struct xsk_map, map);\n\tint i;\n\n\tbpf_clear_redirect_map(map);\n\tsynchronize_net();\n\n\tfor (i = 0; i < map->max_entries; i++) {\n\t\tstruct xdp_sock *xs;\n\n\t\txs = m->xsk_map[i];\n\t\tif (!xs)\n\t\t\tcontinue;\n\n\t\tsock_put((struct sock *)xs);\n\t}\n\n\tfree_percpu(m->flush_list);\n\tbpf_map_area_free(m->xsk_map);\n\tkfree(m);\n}"
  },
  {
    "function_name": "xsk_map_alloc",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/xskmap.c",
    "lines": "18-71",
    "snippet": "static struct bpf_map *xsk_map_alloc(union bpf_attr *attr)\n{\n\tint cpu, err = -EINVAL;\n\tstruct xsk_map *m;\n\tu64 cost;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn ERR_PTR(-EPERM);\n\n\tif (attr->max_entries == 0 || attr->key_size != 4 ||\n\t    attr->value_size != 4 ||\n\t    attr->map_flags & ~(BPF_F_NUMA_NODE | BPF_F_RDONLY | BPF_F_WRONLY))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tm = kzalloc(sizeof(*m), GFP_USER);\n\tif (!m)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tbpf_map_init_from_attr(&m->map, attr);\n\n\tcost = (u64)m->map.max_entries * sizeof(struct xdp_sock *);\n\tcost += sizeof(struct list_head) * num_possible_cpus();\n\tif (cost >= U32_MAX - PAGE_SIZE)\n\t\tgoto free_m;\n\n\tm->map.pages = round_up(cost, PAGE_SIZE) >> PAGE_SHIFT;\n\n\t/* Notice returns -EPERM on if map size is larger than memlock limit */\n\terr = bpf_map_precharge_memlock(m->map.pages);\n\tif (err)\n\t\tgoto free_m;\n\n\terr = -ENOMEM;\n\n\tm->flush_list = alloc_percpu(struct list_head);\n\tif (!m->flush_list)\n\t\tgoto free_m;\n\n\tfor_each_possible_cpu(cpu)\n\t\tINIT_LIST_HEAD(per_cpu_ptr(m->flush_list, cpu));\n\n\tm->xsk_map = bpf_map_area_alloc(m->map.max_entries *\n\t\t\t\t\tsizeof(struct xdp_sock *),\n\t\t\t\t\tm->map.numa_node);\n\tif (!m->xsk_map)\n\t\tgoto free_percpu;\n\treturn &m->map;\n\nfree_percpu:\n\tfree_percpu(m->flush_list);\nfree_m:\n\tkfree(m);\n\treturn ERR_PTR(err);\n}",
    "includes": [
      "#include <linux/sched.h>",
      "#include <linux/slab.h>",
      "#include <net/xdp_sock.h>",
      "#include <linux/capability.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "err"
          ],
          "line": 70
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "m"
          ],
          "line": 69
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/params.c",
          "lines": "73-86",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_percpu",
          "args": [
            "m->flush_list"
          ],
          "line": 67
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_array_free_percpu",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/arraymap.c",
          "lines": "27-35",
          "snippet": "static void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include <uapi/linux/btf.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/filter.h>",
            "#include <linux/mm.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include <uapi/linux/btf.h>\n#include <linux/perf_event.h>\n#include <linux/filter.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_area_alloc",
          "args": [
            "m->map.max_entries *\n\t\t\t\t\tsizeof(struct xdp_sock *)",
            "m->map.numa_node"
          ],
          "line": 59
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_area_alloc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/syscall.c",
          "lines": "137-154",
          "snippet": "void *bpf_map_area_alloc(size_t size, int numa_node)\n{\n\t/* We definitely need __GFP_NORETRY, so OOM killer doesn't\n\t * trigger under memory pressure as we really just want to\n\t * fail instead.\n\t */\n\tconst gfp_t flags = __GFP_NOWARN | __GFP_NORETRY | __GFP_ZERO;\n\tvoid *area;\n\n\tif (size <= (PAGE_SIZE << PAGE_ALLOC_COSTLY_ORDER)) {\n\t\tarea = kmalloc_node(size, GFP_USER | flags, numa_node);\n\t\tif (area != NULL)\n\t\t\treturn area;\n\t}\n\n\treturn __vmalloc_node_flags_caller(size, numa_node, GFP_KERNEL | flags,\n\t\t\t\t\t   __builtin_return_address(0));\n}",
          "includes": [
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/version.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/version.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf.h>\n\nvoid *bpf_map_area_alloc(size_t size, int numa_node)\n{\n\t/* We definitely need __GFP_NORETRY, so OOM killer doesn't\n\t * trigger under memory pressure as we really just want to\n\t * fail instead.\n\t */\n\tconst gfp_t flags = __GFP_NOWARN | __GFP_NORETRY | __GFP_ZERO;\n\tvoid *area;\n\n\tif (size <= (PAGE_SIZE << PAGE_ALLOC_COSTLY_ORDER)) {\n\t\tarea = kmalloc_node(size, GFP_USER | flags, numa_node);\n\t\tif (area != NULL)\n\t\t\treturn area;\n\t}\n\n\treturn __vmalloc_node_flags_caller(size, numa_node, GFP_KERNEL | flags,\n\t\t\t\t\t   __builtin_return_address(0));\n}"
        }
      },
      {
        "call_info": {
          "callee": "alloc_percpu",
          "args": [
            "structlist_head"
          ],
          "line": 52
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_array_alloc_percpu",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/arraymap.c",
          "lines": "37-54",
          "snippet": "static int bpf_array_alloc_percpu(struct bpf_array *array)\n{\n\tvoid __percpu *ptr;\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tptr = __alloc_percpu_gfp(array->elem_size, 8,\n\t\t\t\t\t GFP_USER | __GFP_NOWARN);\n\t\tif (!ptr) {\n\t\t\tbpf_array_free_percpu(array);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tarray->pptrs[i] = ptr;\n\t\tcond_resched();\n\t}\n\n\treturn 0;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include <uapi/linux/btf.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/filter.h>",
            "#include <linux/mm.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include <uapi/linux/btf.h>\n#include <linux/perf_event.h>\n#include <linux/filter.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int bpf_array_alloc_percpu(struct bpf_array *array)\n{\n\tvoid __percpu *ptr;\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tptr = __alloc_percpu_gfp(array->elem_size, 8,\n\t\t\t\t\t GFP_USER | __GFP_NOWARN);\n\t\tif (!ptr) {\n\t\t\tbpf_array_free_percpu(array);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tarray->pptrs[i] = ptr;\n\t\tcond_resched();\n\t}\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_precharge_memlock",
          "args": [
            "m->map.pages"
          ],
          "line": 46
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_precharge_memlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/syscall.c",
          "lines": "171-182",
          "snippet": "int bpf_map_precharge_memlock(u32 pages)\n{\n\tstruct user_struct *user = get_current_user();\n\tunsigned long memlock_limit, cur;\n\n\tmemlock_limit = rlimit(RLIMIT_MEMLOCK) >> PAGE_SHIFT;\n\tcur = atomic_long_read(&user->locked_vm);\n\tfree_uid(user);\n\tif (cur + pages > memlock_limit)\n\t\treturn -EPERM;\n\treturn 0;\n}",
          "includes": [
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/version.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/version.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf.h>\n\nint bpf_map_precharge_memlock(u32 pages)\n{\n\tstruct user_struct *user = get_current_user();\n\tunsigned long memlock_limit, cur;\n\n\tmemlock_limit = rlimit(RLIMIT_MEMLOCK) >> PAGE_SHIFT;\n\tcur = atomic_long_read(&user->locked_vm);\n\tfree_uid(user);\n\tif (cur + pages > memlock_limit)\n\t\treturn -EPERM;\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "cost",
            "PAGE_SIZE"
          ],
          "line": 43
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "num_possible_cpus",
          "args": [],
          "line": 39
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_map_init_from_attr",
          "args": [
            "&m->map",
            "attr"
          ],
          "line": 36
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_init_from_attr",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/bpf/syscall.c",
          "lines": "161-169",
          "snippet": "void bpf_map_init_from_attr(struct bpf_map *map, union bpf_attr *attr)\n{\n\tmap->map_type = attr->map_type;\n\tmap->key_size = attr->key_size;\n\tmap->value_size = attr->value_size;\n\tmap->max_entries = attr->max_entries;\n\tmap->map_flags = attr->map_flags;\n\tmap->numa_node = bpf_map_attr_numa_node(attr);\n}",
          "includes": [
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/version.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/version.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf.h>\n\nvoid bpf_map_init_from_attr(struct bpf_map *map, union bpf_attr *attr)\n{\n\tmap->map_type = attr->map_type;\n\tmap->key_size = attr->key_size;\n\tmap->value_size = attr->value_size;\n\tmap->max_entries = attr->max_entries;\n\tmap->map_flags = attr->map_flags;\n\tmap->numa_node = bpf_map_attr_numa_node(attr);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-ENOMEM"
          ],
          "line": 34
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kzalloc",
          "args": [
            "sizeof(*m)",
            "GFP_USER"
          ],
          "line": 32
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-EINVAL"
          ],
          "line": 30
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-EPERM"
          ],
          "line": 25
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "capable",
          "args": [
            "CAP_NET_ADMIN"
          ],
          "line": 24
        },
        "resolved": true,
        "details": {
          "function_name": "capable",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/capability.c",
          "lines": "429-432",
          "snippet": "bool capable(int cap)\n{\n\treturn ns_capable(&init_user_ns, cap);\n}",
          "includes": [
            "#include <linux/uaccess.h>",
            "#include <linux/user_namespace.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/security.h>",
            "#include <linux/export.h>",
            "#include <linux/mm.h>",
            "#include <linux/capability.h>",
            "#include <linux/audit.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/uaccess.h>\n#include <linux/user_namespace.h>\n#include <linux/pid_namespace.h>\n#include <linux/syscalls.h>\n#include <linux/security.h>\n#include <linux/export.h>\n#include <linux/mm.h>\n#include <linux/capability.h>\n#include <linux/audit.h>\n\nbool capable(int cap)\n{\n\treturn ns_capable(&init_user_ns, cap);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/sched.h>\n#include <linux/slab.h>\n#include <net/xdp_sock.h>\n#include <linux/capability.h>\n#include <linux/bpf.h>\n\nstatic struct bpf_map *xsk_map_alloc(union bpf_attr *attr)\n{\n\tint cpu, err = -EINVAL;\n\tstruct xsk_map *m;\n\tu64 cost;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn ERR_PTR(-EPERM);\n\n\tif (attr->max_entries == 0 || attr->key_size != 4 ||\n\t    attr->value_size != 4 ||\n\t    attr->map_flags & ~(BPF_F_NUMA_NODE | BPF_F_RDONLY | BPF_F_WRONLY))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tm = kzalloc(sizeof(*m), GFP_USER);\n\tif (!m)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tbpf_map_init_from_attr(&m->map, attr);\n\n\tcost = (u64)m->map.max_entries * sizeof(struct xdp_sock *);\n\tcost += sizeof(struct list_head) * num_possible_cpus();\n\tif (cost >= U32_MAX - PAGE_SIZE)\n\t\tgoto free_m;\n\n\tm->map.pages = round_up(cost, PAGE_SIZE) >> PAGE_SHIFT;\n\n\t/* Notice returns -EPERM on if map size is larger than memlock limit */\n\terr = bpf_map_precharge_memlock(m->map.pages);\n\tif (err)\n\t\tgoto free_m;\n\n\terr = -ENOMEM;\n\n\tm->flush_list = alloc_percpu(struct list_head);\n\tif (!m->flush_list)\n\t\tgoto free_m;\n\n\tfor_each_possible_cpu(cpu)\n\t\tINIT_LIST_HEAD(per_cpu_ptr(m->flush_list, cpu));\n\n\tm->xsk_map = bpf_map_area_alloc(m->map.max_entries *\n\t\t\t\t\tsizeof(struct xdp_sock *),\n\t\t\t\t\tm->map.numa_node);\n\tif (!m->xsk_map)\n\t\tgoto free_percpu;\n\treturn &m->map;\n\nfree_percpu:\n\tfree_percpu(m->flush_list);\nfree_m:\n\tkfree(m);\n\treturn ERR_PTR(err);\n}"
  }
]