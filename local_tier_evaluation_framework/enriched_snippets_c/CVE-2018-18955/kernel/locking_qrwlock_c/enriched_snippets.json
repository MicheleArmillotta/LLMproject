[
  {
    "function_name": "queued_write_lock_slowpath",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/qrwlock.c",
    "lines": "71-91",
    "snippet": "void queued_write_lock_slowpath(struct qrwlock *lock)\n{\n\t/* Put the writer into the wait queue */\n\tarch_spin_lock(&lock->wait_lock);\n\n\t/* Try to acquire the lock directly if no reader is present */\n\tif (!atomic_read(&lock->cnts) &&\n\t    (atomic_cmpxchg_acquire(&lock->cnts, 0, _QW_LOCKED) == 0))\n\t\tgoto unlock;\n\n\t/* Set the waiting flag to notify readers that a writer is pending */\n\tatomic_add(_QW_WAITING, &lock->cnts);\n\n\t/* When no more readers or writers, set the locked flag */\n\tdo {\n\t\tatomic_cond_read_acquire(&lock->cnts, VAL == _QW_WAITING);\n\t} while (atomic_cmpxchg_relaxed(&lock->cnts, _QW_WAITING,\n\t\t\t\t\t_QW_LOCKED) != _QW_WAITING);\nunlock:\n\tarch_spin_unlock(&lock->wait_lock);\n}",
    "includes": [
      "#include <asm/qrwlock.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/hardirq.h>",
      "#include <linux/percpu.h>",
      "#include <linux/cpumask.h>",
      "#include <linux/bug.h>",
      "#include <linux/smp.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "arch_spin_unlock",
          "args": [
            "&lock->wait_lock"
          ],
          "line": 90
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_cmpxchg_relaxed",
          "args": [
            "&lock->cnts",
            "_QW_WAITING",
            "_QW_LOCKED"
          ],
          "line": 87
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_cond_read_acquire",
          "args": [
            "&lock->cnts",
            "VAL == _QW_WAITING"
          ],
          "line": 86
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_add",
          "args": [
            "_QW_WAITING",
            "&lock->cnts"
          ],
          "line": 82
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_cmpxchg_acquire",
          "args": [
            "&lock->cnts",
            "0",
            "_QW_LOCKED"
          ],
          "line": 78
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&lock->cnts"
          ],
          "line": 77
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "arch_spin_lock",
          "args": [
            "&lock->wait_lock"
          ],
          "line": 74
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/qrwlock.h>\n#include <linux/spinlock.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/cpumask.h>\n#include <linux/bug.h>\n#include <linux/smp.h>\n\nvoid queued_write_lock_slowpath(struct qrwlock *lock)\n{\n\t/* Put the writer into the wait queue */\n\tarch_spin_lock(&lock->wait_lock);\n\n\t/* Try to acquire the lock directly if no reader is present */\n\tif (!atomic_read(&lock->cnts) &&\n\t    (atomic_cmpxchg_acquire(&lock->cnts, 0, _QW_LOCKED) == 0))\n\t\tgoto unlock;\n\n\t/* Set the waiting flag to notify readers that a writer is pending */\n\tatomic_add(_QW_WAITING, &lock->cnts);\n\n\t/* When no more readers or writers, set the locked flag */\n\tdo {\n\t\tatomic_cond_read_acquire(&lock->cnts, VAL == _QW_WAITING);\n\t} while (atomic_cmpxchg_relaxed(&lock->cnts, _QW_WAITING,\n\t\t\t\t\t_QW_LOCKED) != _QW_WAITING);\nunlock:\n\tarch_spin_unlock(&lock->wait_lock);\n}"
  },
  {
    "function_name": "queued_read_lock_slowpath",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18955/repo/kernel/locking/qrwlock.c",
    "lines": "30-64",
    "snippet": "void queued_read_lock_slowpath(struct qrwlock *lock)\n{\n\t/*\n\t * Readers come here when they cannot get the lock without waiting\n\t */\n\tif (unlikely(in_interrupt())) {\n\t\t/*\n\t\t * Readers in interrupt context will get the lock immediately\n\t\t * if the writer is just waiting (not holding the lock yet),\n\t\t * so spin with ACQUIRE semantics until the lock is available\n\t\t * without waiting in the queue.\n\t\t */\n\t\tatomic_cond_read_acquire(&lock->cnts, !(VAL & _QW_LOCKED));\n\t\treturn;\n\t}\n\tatomic_sub(_QR_BIAS, &lock->cnts);\n\n\t/*\n\t * Put the reader into the wait queue\n\t */\n\tarch_spin_lock(&lock->wait_lock);\n\tatomic_add(_QR_BIAS, &lock->cnts);\n\n\t/*\n\t * The ACQUIRE semantics of the following spinning code ensure\n\t * that accesses can't leak upwards out of our subsequent critical\n\t * section in the case that the lock is currently held for write.\n\t */\n\tatomic_cond_read_acquire(&lock->cnts, !(VAL & _QW_LOCKED));\n\n\t/*\n\t * Signal the next one in queue to become queue head\n\t */\n\tarch_spin_unlock(&lock->wait_lock);\n}",
    "includes": [
      "#include <asm/qrwlock.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/hardirq.h>",
      "#include <linux/percpu.h>",
      "#include <linux/cpumask.h>",
      "#include <linux/bug.h>",
      "#include <linux/smp.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "arch_spin_unlock",
          "args": [
            "&lock->wait_lock"
          ],
          "line": 63
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_cond_read_acquire",
          "args": [
            "&lock->cnts",
            "!(VAL & _QW_LOCKED)"
          ],
          "line": 58
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_add",
          "args": [
            "_QR_BIAS",
            "&lock->cnts"
          ],
          "line": 51
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "arch_spin_lock",
          "args": [
            "&lock->wait_lock"
          ],
          "line": 50
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_sub",
          "args": [
            "_QR_BIAS",
            "&lock->cnts"
          ],
          "line": 45
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_cond_read_acquire",
          "args": [
            "&lock->cnts",
            "!(VAL & _QW_LOCKED)"
          ],
          "line": 42
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "in_interrupt()"
          ],
          "line": 35
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "in_interrupt",
          "args": [],
          "line": 35
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <asm/qrwlock.h>\n#include <linux/spinlock.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/cpumask.h>\n#include <linux/bug.h>\n#include <linux/smp.h>\n\nvoid queued_read_lock_slowpath(struct qrwlock *lock)\n{\n\t/*\n\t * Readers come here when they cannot get the lock without waiting\n\t */\n\tif (unlikely(in_interrupt())) {\n\t\t/*\n\t\t * Readers in interrupt context will get the lock immediately\n\t\t * if the writer is just waiting (not holding the lock yet),\n\t\t * so spin with ACQUIRE semantics until the lock is available\n\t\t * without waiting in the queue.\n\t\t */\n\t\tatomic_cond_read_acquire(&lock->cnts, !(VAL & _QW_LOCKED));\n\t\treturn;\n\t}\n\tatomic_sub(_QR_BIAS, &lock->cnts);\n\n\t/*\n\t * Put the reader into the wait queue\n\t */\n\tarch_spin_lock(&lock->wait_lock);\n\tatomic_add(_QR_BIAS, &lock->cnts);\n\n\t/*\n\t * The ACQUIRE semantics of the following spinning code ensure\n\t * that accesses can't leak upwards out of our subsequent critical\n\t * section in the case that the lock is currently held for write.\n\t */\n\tatomic_cond_read_acquire(&lock->cnts, !(VAL & _QW_LOCKED));\n\n\t/*\n\t * Signal the next one in queue to become queue head\n\t */\n\tarch_spin_unlock(&lock->wait_lock);\n}"
  }
]